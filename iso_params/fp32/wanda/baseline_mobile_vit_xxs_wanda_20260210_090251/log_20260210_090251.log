2026-02-10 09:02:51,763 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/log_20260210_090251.log'에 저장됩니다.
2026-02-10 09:02:51,768 - INFO - ==================================================
2026-02-10 09:02:51,769 - INFO - config.yaml:
2026-02-10 09:02:51,769 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: mobile_vit_xxs
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.047585

2026-02-10 09:02:51,769 - INFO - ==================================================
2026-02-10 09:02:51,816 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 09:02:51,817 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 09:02:51,817 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 09:02:51,824 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 09:02:51,824 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 09:02:51,825 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 09:02:51,825 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:02:52,062 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 09:02:52,089 - INFO - ==================================================
2026-02-10 09:02:52,089 - INFO - 모델 파라미터 수:
2026-02-10 09:02:52,089 - INFO -   - 총 파라미터: 951,666 개
2026-02-10 09:02:52,089 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-02-10 09:02:52,089 - INFO - ================================================================================
2026-02-10 09:02:52,089 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 09:02:52,089 - INFO - ================================================================================
2026-02-10 09:02:52,089 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 09:02:52,090 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 09:02:52,090 - INFO - ==================================================
2026-02-10 09:02:52,090 - INFO - train 모드를 시작합니다.
2026-02-10 09:02:52,090 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 09:02:52,090 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 09:02:52,090 - INFO - --------------------------------------------------
2026-02-10 09:02:52,091 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 09:03:00,294 - INFO - [Train] [1/10] | Loss: 0.5205 | Train Acc: 78.35%
2026-02-10 09:03:02,257 - INFO - [Valid] [1/10] | Loss: 0.5401 | Val Acc: 81.42%
2026-02-10 09:03:02,265 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 09:03:02,265 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 09:03:02,292 - INFO - [Best Model Saved] (val loss: 0.5401) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:03:02,293 - INFO - --------------------------------------------------
2026-02-10 09:03:02,294 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 09:03:10,011 - INFO - [Train] [2/10] | Loss: 0.4618 | Train Acc: 83.26%
2026-02-10 09:03:11,357 - INFO - [Valid] [2/10] | Loss: 0.5161 | Val Acc: 82.60%
2026-02-10 09:03:11,364 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-02-10 09:03:11,364 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-02-10 09:03:11,406 - INFO - [Best Model Saved] (val loss: 0.5161) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:03:11,407 - INFO - --------------------------------------------------
2026-02-10 09:03:11,408 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 09:03:18,431 - INFO - [Train] [3/10] | Loss: 0.4263 | Train Acc: 85.42%
2026-02-10 09:03:19,307 - INFO - [Valid] [3/10] | Loss: 0.5167 | Val Acc: 81.12%
2026-02-10 09:03:19,312 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-02-10 09:03:19,312 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-02-10 09:03:19,314 - INFO - --------------------------------------------------
2026-02-10 09:03:19,325 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 09:03:26,633 - INFO - [Train] [4/10] | Loss: 0.3900 | Train Acc: 88.10%
2026-02-10 09:03:27,780 - INFO - [Valid] [4/10] | Loss: 0.4966 | Val Acc: 83.48%
2026-02-10 09:03:27,785 - INFO - [Metrics for 'abnormal'] | Precision: 0.8344 | Recall: 0.8025 | F1: 0.8182
2026-02-10 09:03:27,785 - INFO - [Metrics for 'normal'] | Precision: 0.8351 | Recall: 0.8626 | F1: 0.8486
2026-02-10 09:03:27,811 - INFO - [Best Model Saved] (val loss: 0.4966) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:03:27,812 - INFO - --------------------------------------------------
2026-02-10 09:03:27,814 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 09:03:35,047 - INFO - [Train] [5/10] | Loss: 0.3807 | Train Acc: 88.54%
2026-02-10 09:03:36,172 - INFO - [Valid] [5/10] | Loss: 0.5540 | Val Acc: 82.30%
2026-02-10 09:03:36,177 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-02-10 09:03:36,178 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-02-10 09:03:36,179 - INFO - --------------------------------------------------
2026-02-10 09:03:36,181 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 09:03:42,838 - INFO - [Train] [6/10] | Loss: 0.3539 | Train Acc: 90.77%
2026-02-10 09:03:43,987 - INFO - [Valid] [6/10] | Loss: 0.4984 | Val Acc: 80.83%
2026-02-10 09:03:43,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-02-10 09:03:43,993 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-02-10 09:03:43,994 - INFO - --------------------------------------------------
2026-02-10 09:03:43,996 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 09:03:50,716 - INFO - [Train] [7/10] | Loss: 0.3156 | Train Acc: 93.01%
2026-02-10 09:03:51,991 - INFO - [Valid] [7/10] | Loss: 0.5002 | Val Acc: 80.83%
2026-02-10 09:03:51,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-02-10 09:03:51,996 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-02-10 09:03:51,998 - INFO - --------------------------------------------------
2026-02-10 09:03:52,000 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 09:03:58,686 - INFO - [Train] [8/10] | Loss: 0.2832 | Train Acc: 95.91%
2026-02-10 09:04:00,040 - INFO - [Valid] [8/10] | Loss: 0.4895 | Val Acc: 82.01%
2026-02-10 09:04:00,045 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-02-10 09:04:00,045 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-02-10 09:04:00,088 - INFO - [Best Model Saved] (val loss: 0.4895) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:04:00,088 - INFO - --------------------------------------------------
2026-02-10 09:04:00,089 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 09:04:06,540 - INFO - [Train] [9/10] | Loss: 0.2660 | Train Acc: 97.10%
2026-02-10 09:04:08,040 - INFO - [Valid] [9/10] | Loss: 0.4895 | Val Acc: 83.48%
2026-02-10 09:04:08,045 - INFO - [Metrics for 'abnormal'] | Precision: 0.8137 | Recall: 0.8344 | F1: 0.8239
2026-02-10 09:04:08,045 - INFO - [Metrics for 'normal'] | Precision: 0.8539 | Recall: 0.8352 | F1: 0.8444
2026-02-10 09:04:08,074 - INFO - [Best Model Saved] (val loss: 0.4895) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:04:08,074 - INFO - --------------------------------------------------
2026-02-10 09:04:08,075 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 09:04:13,914 - INFO - [Train] [10/10] | Loss: 0.2549 | Train Acc: 97.69%
2026-02-10 09:04:15,453 - INFO - [Valid] [10/10] | Loss: 0.4951 | Val Acc: 82.60%
2026-02-10 09:04:15,458 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-02-10 09:04:15,458 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-02-10 09:04:15,461 - INFO - ================================================================================
2026-02-10 09:04:15,461 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 09:04:15,461 - INFO - ================================================================================
2026-02-10 09:04:15,552 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'을(를) 불러왔습니다.
2026-02-10 09:04:15,553 - INFO - ================================================================================
2026-02-10 09:04:15,553 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 09:04:15,554 - INFO - 원본 모델 파라미터: 0.9517M
2026-02-10 09:04:15,608 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:15,608 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:15,611 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:20,433 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:20,435 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:20,866 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 09:04:20,867 - INFO - ==================================================
2026-02-10 09:04:20,868 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.3049M (감소율: 67.96%)
2026-02-10 09:04:20,901 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:20,901 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:20,904 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:26,162 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:26,163 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:27,022 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 09:04:27,023 - INFO - ==================================================
2026-02-10 09:04:27,026 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1109M (감소율: 88.35%)
2026-02-10 09:04:27,057 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:27,058 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:27,062 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:33,154 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:33,155 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:33,501 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 09:04:33,502 - INFO - ==================================================
2026-02-10 09:04:33,504 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0459M (감소율: 95.18%)
2026-02-10 09:04:33,533 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:33,533 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:33,535 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:39,052 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:39,053 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:39,413 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.804375)에 맞춰 변경되었습니다.
2026-02-10 09:04:39,413 - INFO - ==================================================
2026-02-10 09:04:39,416 - INFO -   [탐색  4] 희소도: 0.8044 -> 파라미터: 0.0757M (감소율: 92.04%)
2026-02-10 09:04:39,448 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:39,448 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:39,452 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:44,824 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:44,825 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:45,201 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8353124999999999)에 맞춰 변경되었습니다.
2026-02-10 09:04:45,201 - INFO - ==================================================
2026-02-10 09:04:45,203 - INFO -   [탐색  5] 희소도: 0.8353 -> 파라미터: 0.0610M (감소율: 93.59%)
2026-02-10 09:04:45,233 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:45,233 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:45,235 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:50,953 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:50,954 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:51,336 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8507812499999999)에 맞춰 변경되었습니다.
2026-02-10 09:04:51,337 - INFO - ==================================================
2026-02-10 09:04:51,339 - INFO -   [탐색  6] 희소도: 0.8508 -> 파라미터: 0.0530M (감소율: 94.43%)
2026-02-10 09:04:51,370 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:51,371 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:51,373 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:04:56,931 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:04:56,932 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:04:57,875 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8585156249999999)에 맞춰 변경되었습니다.
2026-02-10 09:04:57,875 - INFO - ==================================================
2026-02-10 09:04:57,879 - INFO -   [탐색  7] 희소도: 0.8585 -> 파라미터: 0.0509M (감소율: 94.65%)
2026-02-10 09:04:57,912 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:04:57,912 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:04:57,914 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:03,159 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:03,159 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:03,548 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8623828124999999)에 맞춰 변경되었습니다.
2026-02-10 09:05:03,549 - INFO - ==================================================
2026-02-10 09:05:03,551 - INFO -   [탐색  8] 희소도: 0.8624 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:05:03,580 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:03,580 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:03,582 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:09,378 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:09,379 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:09,714 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 09:05:09,715 - INFO - ==================================================
2026-02-10 09:05:09,717 - INFO -   [탐색  9] 희소도: 0.8643 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:05:09,749 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:09,749 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:09,751 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:15,249 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:15,250 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:15,677 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8633496093749999)에 맞춰 변경되었습니다.
2026-02-10 09:05:15,677 - INFO - ==================================================
2026-02-10 09:05:15,679 - INFO -   [탐색 10] 희소도: 0.8633 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:05:15,707 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:15,707 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:15,710 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:21,876 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:21,877 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:22,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8628662109374999)에 맞춰 변경되었습니다.
2026-02-10 09:05:22,445 - INFO - ==================================================
2026-02-10 09:05:22,447 - INFO -   [탐색 11] 희소도: 0.8629 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:05:22,476 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:22,476 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:22,478 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:28,245 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:28,246 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:29,152 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8626245117187499)에 맞춰 변경되었습니다.
2026-02-10 09:05:29,152 - INFO - ==================================================
2026-02-10 09:05:29,156 - INFO -   [탐색 12] 희소도: 0.8626 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:05:29,188 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:29,188 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:29,191 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:34,368 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:34,370 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:34,734 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625036621093749)에 맞춰 변경되었습니다.
2026-02-10 09:05:34,734 - INFO - ==================================================
2026-02-10 09:05:34,736 - INFO -   [탐색 13] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:05:34,772 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:34,772 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:34,779 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:40,095 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:40,096 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:40,451 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624432373046874)에 맞춰 변경되었습니다.
2026-02-10 09:05:40,451 - INFO - ==================================================
2026-02-10 09:05:40,453 - INFO -   [탐색 14] 희소도: 0.8624 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:05:40,483 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:40,483 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:40,485 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:46,090 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:46,091 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:46,456 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624734497070312)에 맞춰 변경되었습니다.
2026-02-10 09:05:46,457 - INFO - ==================================================
2026-02-10 09:05:46,459 - INFO -   [탐색 15] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:05:46,490 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:46,491 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:46,493 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:52,171 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:52,172 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:52,516 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624885559082031)에 맞춰 변경되었습니다.
2026-02-10 09:05:52,516 - INFO - ==================================================
2026-02-10 09:05:52,518 - INFO -   [탐색 16] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:05:52,548 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:52,549 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:52,551 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:05:58,198 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:05:58,199 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:05:59,136 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862496109008789)에 맞춰 변경되었습니다.
2026-02-10 09:05:59,136 - INFO - ==================================================
2026-02-10 09:05:59,139 - INFO -   [탐색 17] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:05:59,168 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:05:59,168 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:05:59,171 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:04,601 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:04,603 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:04,944 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499885559082)에 맞춰 변경되었습니다.
2026-02-10 09:06:04,944 - INFO - ==================================================
2026-02-10 09:06:04,946 - INFO -   [탐색 18] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:06:04,976 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:04,976 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:04,978 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:10,246 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:10,247 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:10,656 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625017738342284)에 맞춰 변경되었습니다.
2026-02-10 09:06:10,656 - INFO - ==================================================
2026-02-10 09:06:10,659 - INFO -   [탐색 19] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:06:10,688 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:10,688 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:10,691 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:16,325 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:16,326 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:16,675 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625008296966552)에 맞춰 변경되었습니다.
2026-02-10 09:06:16,676 - INFO - ==================================================
2026-02-10 09:06:16,678 - INFO -   [탐색 20] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:06:16,710 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:16,710 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:16,713 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:22,728 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:22,729 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:23,061 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625003576278686)에 맞춰 변경되었습니다.
2026-02-10 09:06:23,061 - INFO - ==================================================
2026-02-10 09:06:23,063 - INFO -   [탐색 21] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:06:23,094 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:23,094 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:23,096 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:28,650 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:28,656 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:29,782 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625001215934753)에 맞춰 변경되었습니다.
2026-02-10 09:06:29,782 - INFO - ==================================================
2026-02-10 09:06:29,786 - INFO -   [탐색 22] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:06:29,815 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:29,815 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:29,818 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:35,283 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:35,284 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:35,679 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000035762787)에 맞춰 변경되었습니다.
2026-02-10 09:06:35,679 - INFO - ==================================================
2026-02-10 09:06:35,681 - INFO -   [탐색 23] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:06:35,712 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:35,712 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:35,715 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:40,967 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:40,968 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:41,322 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999445676803)에 맞춰 변경되었습니다.
2026-02-10 09:06:41,323 - INFO - ==================================================
2026-02-10 09:06:41,325 - INFO -   [탐색 24] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:06:41,356 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:41,356 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:41,359 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:46,886 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:46,887 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:47,320 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999740719794)에 맞춰 변경되었습니다.
2026-02-10 09:06:47,320 - INFO - ==================================================
2026-02-10 09:06:47,322 - INFO -   [탐색 25] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:06:47,354 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:47,355 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:47,357 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:52,653 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:52,654 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:53,016 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499988824129)에 맞춰 변경되었습니다.
2026-02-10 09:06:53,016 - INFO - ==================================================
2026-02-10 09:06:53,018 - INFO -   [탐색 26] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:06:53,051 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:53,051 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:53,053 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:06:58,305 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:58,311 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:59,069 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999962002038)에 맞춰 변경되었습니다.
2026-02-10 09:06:59,069 - INFO - ==================================================
2026-02-10 09:06:59,072 - INFO -   [탐색 27] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:06:59,104 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:06:59,104 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:06:59,107 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:03,984 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:03,985 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:04,327 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999998882412)에 맞춰 변경되었습니다.
2026-02-10 09:07:04,328 - INFO - ==================================================
2026-02-10 09:07:04,330 - INFO -   [탐색 28] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:07:04,366 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:04,367 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:04,369 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:09,949 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:09,950 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:10,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000017322599)에 맞춰 변경되었습니다.
2026-02-10 09:07:10,238 - INFO - ==================================================
2026-02-10 09:07:10,240 - INFO -   [탐색 29] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:10,262 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:10,262 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:10,264 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:14,298 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:14,299 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:14,629 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000008102506)에 맞춰 변경되었습니다.
2026-02-10 09:07:14,629 - INFO - ==================================================
2026-02-10 09:07:14,633 - INFO -   [탐색 30] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:14,669 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:14,669 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:14,671 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:18,484 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:18,485 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:18,716 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000003492459)에 맞춰 변경되었습니다.
2026-02-10 09:07:18,716 - INFO - ==================================================
2026-02-10 09:07:18,717 - INFO -   [탐색 31] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:18,734 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:18,734 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:18,735 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:23,217 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:23,218 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:23,539 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000001187435)에 맞춰 변경되었습니다.
2026-02-10 09:07:23,540 - INFO - ==================================================
2026-02-10 09:07:23,541 - INFO -   [탐색 32] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:23,934 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:23,934 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:23,936 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:28,604 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:28,609 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:28,929 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000034924)에 맞춰 변경되었습니다.
2026-02-10 09:07:28,929 - INFO - ==================================================
2026-02-10 09:07:28,931 - INFO -   [탐색 33] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:28,956 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:28,957 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:28,958 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:32,980 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:32,981 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:33,320 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999458668)에 맞춰 변경되었습니다.
2026-02-10 09:07:33,320 - INFO - ==================================================
2026-02-10 09:07:33,323 - INFO -   [탐색 34] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:07:33,357 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:33,357 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:33,360 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:36,303 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:36,307 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:36,596 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999746796)에 맞춰 변경되었습니다.
2026-02-10 09:07:36,597 - INFO - ==================================================
2026-02-10 09:07:36,599 - INFO -   [탐색 35] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:07:36,628 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:36,629 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:36,632 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:39,778 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:39,779 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:40,086 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499999989086)에 맞춰 변경되었습니다.
2026-02-10 09:07:40,087 - INFO - ==================================================
2026-02-10 09:07:40,089 - INFO -   [탐색 36] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:07:40,119 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:40,120 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:40,123 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:43,455 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:43,456 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:43,755 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999962892)에 맞춰 변경되었습니다.
2026-02-10 09:07:43,755 - INFO - ==================================================
2026-02-10 09:07:43,757 - INFO -   [탐색 37] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:07:44,218 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:44,218 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:44,220 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:47,395 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:47,395 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:47,696 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999998908)에 맞춰 변경되었습니다.
2026-02-10 09:07:47,696 - INFO - ==================================================
2026-02-10 09:07:47,699 - INFO -   [탐색 38] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:07:47,734 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:47,734 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:47,737 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:50,709 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:50,711 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:51,032 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000016916)에 맞춰 변경되었습니다.
2026-02-10 09:07:51,032 - INFO - ==================================================
2026-02-10 09:07:51,035 - INFO -   [탐색 39] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:51,065 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:51,065 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:51,067 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:54,325 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:54,326 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:54,586 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000007912)에 맞춰 변경되었습니다.
2026-02-10 09:07:54,587 - INFO - ==================================================
2026-02-10 09:07:54,589 - INFO -   [탐색 40] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:54,618 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:54,619 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:54,620 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:07:58,118 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:58,119 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:58,464 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862500000000341)에 맞춰 변경되었습니다.
2026-02-10 09:07:58,464 - INFO - ==================================================
2026-02-10 09:07:58,467 - INFO -   [탐색 41] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:07:58,492 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:07:58,492 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:07:58,494 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:01,409 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:01,410 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:02,251 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862500000000116)에 맞춰 변경되었습니다.
2026-02-10 09:08:02,251 - INFO - ==================================================
2026-02-10 09:08:02,256 - INFO -   [탐색 42] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:02,285 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:02,285 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:02,288 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:05,131 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:05,132 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:05,461 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000034)에 맞춰 변경되었습니다.
2026-02-10 09:08:05,461 - INFO - ==================================================
2026-02-10 09:08:05,464 - INFO -   [탐색 43] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:05,500 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:05,500 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:05,503 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:08,633 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:08,635 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:08,917 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999471)에 맞춰 변경되었습니다.
2026-02-10 09:08:08,918 - INFO - ==================================================
2026-02-10 09:08:08,920 - INFO -   [탐색 44] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:08:08,947 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:08,947 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:08,949 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:12,543 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:12,543 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:12,781 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999752)에 맞춰 변경되었습니다.
2026-02-10 09:08:12,782 - INFO - ==================================================
2026-02-10 09:08:12,783 - INFO -   [탐색 45] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:08:12,813 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:12,813 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:12,816 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:16,547 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:16,549 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:16,797 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999893)에 맞춰 변경되었습니다.
2026-02-10 09:08:16,797 - INFO - ==================================================
2026-02-10 09:08:16,799 - INFO -   [탐색 46] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:08:16,819 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:16,819 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:16,820 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:20,332 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:20,333 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:20,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999963)에 맞춰 변경되었습니다.
2026-02-10 09:08:20,682 - INFO - ==================================================
2026-02-10 09:08:20,684 - INFO -   [탐색 47] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:08:21,154 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:21,155 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:21,157 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:24,404 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:24,405 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:24,726 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999998)에 맞춰 변경되었습니다.
2026-02-10 09:08:24,726 - INFO - ==================================================
2026-02-10 09:08:24,728 - INFO -   [탐색 48] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:08:24,754 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:24,755 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:24,757 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:28,248 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:28,249 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:28,536 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000016)에 맞춰 변경되었습니다.
2026-02-10 09:08:28,536 - INFO - ==================================================
2026-02-10 09:08:28,538 - INFO -   [탐색 49] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:28,563 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:28,563 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:28,565 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:32,140 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:32,141 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:32,384 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000007)에 맞춰 변경되었습니다.
2026-02-10 09:08:32,385 - INFO - ==================================================
2026-02-10 09:08:32,386 - INFO -   [탐색 50] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:32,400 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:32,400 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:32,401 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:36,054 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:36,055 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:36,358 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000003)에 맞춰 변경되었습니다.
2026-02-10 09:08:36,358 - INFO - ==================================================
2026-02-10 09:08:36,360 - INFO -   [탐색 51] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:36,388 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:36,388 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:36,391 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:40,191 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:40,192 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:40,462 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:08:40,473 - INFO - ==================================================
2026-02-10 09:08:40,476 - INFO -   [탐색 52] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:40,779 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:40,779 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:40,781 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:44,407 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:44,408 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:44,713 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999999)에 맞춰 변경되었습니다.
2026-02-10 09:08:44,713 - INFO - ==================================================
2026-02-10 09:08:44,718 - INFO -   [탐색 53] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 09:08:44,747 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:44,747 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:44,750 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:47,939 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:47,940 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:48,274 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:08:48,274 - INFO - ==================================================
2026-02-10 09:08:48,277 - INFO -   [탐색 54] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:48,309 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:48,309 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:48,312 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:51,319 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:51,320 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:51,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:08:51,629 - INFO - ==================================================
2026-02-10 09:08:51,631 - INFO -   [탐색 55] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:51,661 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:51,661 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:51,664 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:54,788 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:54,789 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:55,081 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:08:55,081 - INFO - ==================================================
2026-02-10 09:08:55,084 - INFO -   [탐색 56] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:55,114 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:55,114 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:55,117 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:08:58,514 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:08:58,515 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:08:59,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:08:59,354 - INFO - ==================================================
2026-02-10 09:08:59,357 - INFO -   [탐색 57] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:08:59,384 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:08:59,385 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:08:59,387 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:02,312 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:02,312 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:02,601 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:02,601 - INFO - ==================================================
2026-02-10 09:09:02,602 - INFO -   [탐색 58] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:02,618 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:02,618 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:02,619 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:05,080 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:05,081 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:05,329 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:05,329 - INFO - ==================================================
2026-02-10 09:09:05,332 - INFO -   [탐색 59] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:05,358 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:05,358 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:05,360 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:08,114 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:08,114 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:08,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:08,403 - INFO - ==================================================
2026-02-10 09:09:08,405 - INFO -   [탐색 60] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:08,430 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:08,431 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:08,433 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:10,757 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:10,758 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:10,978 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:10,978 - INFO - ==================================================
2026-02-10 09:09:10,979 - INFO -   [탐색 61] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:10,994 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:10,994 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:10,995 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:13,322 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:13,322 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:13,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:13,584 - INFO - ==================================================
2026-02-10 09:09:13,585 - INFO -   [탐색 62] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:13,864 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:13,864 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:13,866 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:16,105 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:16,106 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:16,341 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:16,341 - INFO - ==================================================
2026-02-10 09:09:16,343 - INFO -   [탐색 63] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:16,360 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:16,360 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:16,361 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:18,429 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:18,430 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:18,719 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:18,720 - INFO - ==================================================
2026-02-10 09:09:18,721 - INFO -   [탐색 64] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:18,746 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:18,746 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:18,748 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:20,673 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:20,674 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:20,890 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:20,890 - INFO - ==================================================
2026-02-10 09:09:20,891 - INFO -   [탐색 65] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:20,916 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:20,916 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:20,918 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:23,129 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:23,129 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:23,320 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:23,320 - INFO - ==================================================
2026-02-10 09:09:23,321 - INFO -   [탐색 66] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:23,339 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:23,339 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:23,340 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:25,716 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:25,716 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:26,198 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:26,199 - INFO - ==================================================
2026-02-10 09:09:26,201 - INFO -   [탐색 67] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:26,217 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:26,217 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:26,219 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:28,501 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:28,501 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:28,744 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:28,744 - INFO - ==================================================
2026-02-10 09:09:28,745 - INFO -   [탐색 68] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:28,762 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:28,762 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:28,763 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:30,662 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:30,663 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:30,895 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:30,895 - INFO - ==================================================
2026-02-10 09:09:30,897 - INFO -   [탐색 69] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:30,914 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:30,914 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:30,916 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:33,016 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:33,016 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:33,166 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:33,166 - INFO - ==================================================
2026-02-10 09:09:33,168 - INFO -   [탐색 70] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:33,191 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:33,191 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:33,193 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:35,510 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:35,510 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:35,734 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:35,734 - INFO - ==================================================
2026-02-10 09:09:35,736 - INFO -   [탐색 71] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:35,761 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:35,761 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:35,763 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:38,017 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:38,018 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:38,602 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:38,602 - INFO - ==================================================
2026-02-10 09:09:38,614 - INFO -   [탐색 72] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:38,631 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:38,631 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:38,633 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:41,035 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:41,035 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:41,245 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:41,245 - INFO - ==================================================
2026-02-10 09:09:41,246 - INFO -   [탐색 73] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:41,261 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:41,262 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:41,263 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:43,180 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:43,181 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:43,447 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:43,448 - INFO - ==================================================
2026-02-10 09:09:43,450 - INFO -   [탐색 74] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:43,474 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:43,474 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:43,476 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:45,512 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:45,512 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:45,697 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:45,697 - INFO - ==================================================
2026-02-10 09:09:45,699 - INFO -   [탐색 75] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:45,723 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:45,723 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:45,725 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:47,972 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:47,973 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:48,188 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:48,188 - INFO - ==================================================
2026-02-10 09:09:48,190 - INFO -   [탐색 76] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:48,214 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:48,215 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:48,216 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:50,538 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:50,539 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:51,057 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:51,058 - INFO - ==================================================
2026-02-10 09:09:51,059 - INFO -   [탐색 77] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:51,076 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:51,077 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:51,078 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:53,349 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:53,350 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:53,557 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:53,558 - INFO - ==================================================
2026-02-10 09:09:53,559 - INFO -   [탐색 78] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:53,576 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:53,577 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:53,578 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:55,443 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:55,444 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:55,645 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:55,645 - INFO - ==================================================
2026-02-10 09:09:55,647 - INFO -   [탐색 79] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:55,684 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:55,684 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:55,688 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:09:57,791 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:09:57,792 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:09:57,994 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:09:57,994 - INFO - ==================================================
2026-02-10 09:09:57,995 - INFO -   [탐색 80] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:09:58,009 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:09:58,010 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:09:58,011 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:00,262 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:00,263 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:00,490 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:00,490 - INFO - ==================================================
2026-02-10 09:10:00,491 - INFO -   [탐색 81] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:00,504 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:00,504 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:00,505 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:02,804 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:02,805 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:03,025 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:03,025 - INFO - ==================================================
2026-02-10 09:10:03,027 - INFO -   [탐색 82] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:03,311 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:03,311 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:03,312 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:05,471 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:05,472 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:05,754 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:05,754 - INFO - ==================================================
2026-02-10 09:10:05,757 - INFO -   [탐색 83] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:05,783 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:05,783 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:05,785 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:07,751 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:07,752 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:08,036 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:08,036 - INFO - ==================================================
2026-02-10 09:10:08,038 - INFO -   [탐색 84] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:08,061 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:08,062 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:08,063 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:10,123 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:10,123 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:10,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:10,348 - INFO - ==================================================
2026-02-10 09:10:10,349 - INFO -   [탐색 85] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:10,363 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:10,363 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:10,364 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:12,654 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:12,654 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:12,881 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:12,881 - INFO - ==================================================
2026-02-10 09:10:12,882 - INFO -   [탐색 86] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:12,894 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:12,894 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:12,895 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:15,209 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:15,210 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:15,430 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:15,430 - INFO - ==================================================
2026-02-10 09:10:15,432 - INFO -   [탐색 87] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:15,701 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:15,701 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:15,702 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:17,873 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:17,874 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:18,125 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:18,125 - INFO - ==================================================
2026-02-10 09:10:18,127 - INFO -   [탐색 88] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:18,144 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:18,144 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:18,145 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:20,036 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:20,037 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:20,332 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:20,332 - INFO - ==================================================
2026-02-10 09:10:20,333 - INFO -   [탐색 89] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:20,358 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:20,358 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:20,360 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:22,492 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:22,492 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:22,693 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:22,693 - INFO - ==================================================
2026-02-10 09:10:22,695 - INFO -   [탐색 90] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:22,724 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:22,725 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:22,727 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:25,009 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:25,010 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:25,228 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:25,228 - INFO - ==================================================
2026-02-10 09:10:25,229 - INFO -   [탐색 91] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:25,243 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:25,243 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:25,245 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:27,300 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:27,301 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:27,533 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:27,533 - INFO - ==================================================
2026-02-10 09:10:27,536 - INFO -   [탐색 92] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:27,932 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:27,932 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:27,933 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:30,014 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:30,015 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:30,314 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:30,314 - INFO - ==================================================
2026-02-10 09:10:30,316 - INFO -   [탐색 93] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:30,342 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:30,342 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:30,344 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:32,334 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:32,335 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:32,570 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:32,570 - INFO - ==================================================
2026-02-10 09:10:32,573 - INFO -   [탐색 94] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:32,597 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:32,598 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:32,600 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:34,968 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:34,968 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:35,101 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:35,101 - INFO - ==================================================
2026-02-10 09:10:35,102 - INFO -   [탐색 95] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:35,115 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:35,115 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:35,116 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:36,820 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:36,821 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:36,954 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:36,955 - INFO - ==================================================
2026-02-10 09:10:36,955 - INFO -   [탐색 96] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:36,967 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:36,967 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:36,968 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:39,118 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:39,118 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:39,576 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:39,576 - INFO - ==================================================
2026-02-10 09:10:39,577 - INFO -   [탐색 97] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:39,595 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:39,595 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:39,597 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:41,956 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:41,957 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:42,092 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:42,092 - INFO - ==================================================
2026-02-10 09:10:42,093 - INFO -   [탐색 98] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:42,105 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:42,105 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:42,106 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:43,652 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:43,652 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:43,800 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:43,800 - INFO - ==================================================
2026-02-10 09:10:43,801 - INFO -   [탐색 99] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:43,816 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:43,816 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:43,817 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:45,345 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:45,346 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:45,479 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 09:10:45,479 - INFO - ==================================================
2026-02-10 09:10:45,480 - INFO -   [탐색 100] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 09:10:45,480 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.8643 입니다.
2026-02-10 09:10:45,480 - INFO - ================================================================================
2026-02-10 09:10:45,481 - INFO - 계산된 Pruning 정보(희소도: 0.8643)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/pruning_info.yaml'에 저장했습니다.
2026-02-10 09:10:45,499 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 09:10:45,533 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:10:45,533 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:10:45,534 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:10:47,067 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:10:47,067 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:10:47,203 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 09:10:47,203 - INFO - ==================================================
2026-02-10 09:10:47,204 - INFO - ==================================================
2026-02-10 09:10:47,204 - INFO - 모델 파라미터 수:
2026-02-10 09:10:47,204 - INFO -   - 총 파라미터: 47,330 개
2026-02-10 09:10:47,204 - INFO -   - 학습 가능한 파라미터: 47,330 개
2026-02-10 09:10:47,231 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 09:10:47,265 - INFO - FLOPs가 0.5384 GFLOPs에서 0.0262 GFLOPs로 감소했습니다 (감소율: 95.12%).
2026-02-10 09:10:47,265 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 09:10:47,265 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 09:10:47,265 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 09:10:47,265 - INFO - ==================================================
2026-02-10 09:10:47,265 - INFO - train 모드를 시작합니다.
2026-02-10 09:10:47,265 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 09:10:47,265 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 09:10:47,265 - INFO - --------------------------------------------------
2026-02-10 09:10:47,266 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 09:10:48,917 - INFO - [Train] [11/90] | Loss: 0.5711 | Train Acc: 74.40%
2026-02-10 09:10:49,328 - INFO - [Valid] [11/90] | Loss: 0.6095 | Val Acc: 66.96%
2026-02-10 09:10:49,331 - INFO - [Metrics for 'abnormal'] | Precision: 0.5966 | Recall: 0.8854 | F1: 0.7128
2026-02-10 09:10:49,331 - INFO - [Metrics for 'normal'] | Precision: 0.8302 | Recall: 0.4835 | F1: 0.6111
2026-02-10 09:10:49,340 - INFO - [Best Model Saved] (val loss: 0.6095) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:10:49,340 - INFO - --------------------------------------------------
2026-02-10 09:10:49,341 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 09:10:50,976 - INFO - [Train] [12/90] | Loss: 0.5086 | Train Acc: 78.79%
2026-02-10 09:10:51,381 - INFO - [Valid] [12/90] | Loss: 0.6803 | Val Acc: 65.49%
2026-02-10 09:10:51,384 - INFO - [Metrics for 'abnormal'] | Precision: 0.5806 | Recall: 0.9172 | F1: 0.7111
2026-02-10 09:10:51,384 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.4286 | F1: 0.5714
2026-02-10 09:10:51,384 - INFO - --------------------------------------------------
2026-02-10 09:10:51,385 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 09:10:53,075 - INFO - [Train] [13/90] | Loss: 0.5036 | Train Acc: 79.39%
2026-02-10 09:10:53,474 - INFO - [Valid] [13/90] | Loss: 0.5283 | Val Acc: 80.24%
2026-02-10 09:10:53,477 - INFO - [Metrics for 'abnormal'] | Precision: 0.7812 | Recall: 0.7962 | F1: 0.7886
2026-02-10 09:10:53,477 - INFO - [Metrics for 'normal'] | Precision: 0.8212 | Recall: 0.8077 | F1: 0.8144
2026-02-10 09:10:53,486 - INFO - [Best Model Saved] (val loss: 0.5283) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:10:53,486 - INFO - --------------------------------------------------
2026-02-10 09:10:53,487 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 09:10:55,124 - INFO - [Train] [14/90] | Loss: 0.4754 | Train Acc: 81.99%
2026-02-10 09:10:55,535 - INFO - [Valid] [14/90] | Loss: 0.5313 | Val Acc: 77.29%
2026-02-10 09:10:55,538 - INFO - [Metrics for 'abnormal'] | Precision: 0.7222 | Recall: 0.8280 | F1: 0.7715
2026-02-10 09:10:55,538 - INFO - [Metrics for 'normal'] | Precision: 0.8302 | Recall: 0.7253 | F1: 0.7742
2026-02-10 09:10:55,538 - INFO - --------------------------------------------------
2026-02-10 09:10:55,539 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 09:10:57,192 - INFO - [Train] [15/90] | Loss: 0.4889 | Train Acc: 81.40%
2026-02-10 09:10:57,586 - INFO - [Valid] [15/90] | Loss: 0.5213 | Val Acc: 79.94%
2026-02-10 09:10:57,589 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-02-10 09:10:57,589 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-02-10 09:10:57,598 - INFO - [Best Model Saved] (val loss: 0.5213) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:10:57,598 - INFO - --------------------------------------------------
2026-02-10 09:10:57,599 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 09:10:59,254 - INFO - [Train] [16/90] | Loss: 0.4640 | Train Acc: 82.74%
2026-02-10 09:10:59,659 - INFO - [Valid] [16/90] | Loss: 0.5789 | Val Acc: 75.52%
2026-02-10 09:10:59,662 - INFO - [Metrics for 'abnormal'] | Precision: 0.6927 | Recall: 0.8471 | F1: 0.7622
2026-02-10 09:10:59,662 - INFO - [Metrics for 'normal'] | Precision: 0.8367 | Recall: 0.6758 | F1: 0.7477
2026-02-10 09:10:59,662 - INFO - --------------------------------------------------
2026-02-10 09:10:59,663 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 09:11:01,337 - INFO - [Train] [17/90] | Loss: 0.4556 | Train Acc: 83.11%
2026-02-10 09:11:01,742 - INFO - [Valid] [17/90] | Loss: 0.5774 | Val Acc: 76.99%
2026-02-10 09:11:01,745 - INFO - [Metrics for 'abnormal'] | Precision: 0.6985 | Recall: 0.8854 | F1: 0.7809
2026-02-10 09:11:01,745 - INFO - [Metrics for 'normal'] | Precision: 0.8714 | Recall: 0.6703 | F1: 0.7578
2026-02-10 09:11:01,746 - INFO - --------------------------------------------------
2026-02-10 09:11:01,747 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 09:11:03,405 - INFO - [Train] [18/90] | Loss: 0.4512 | Train Acc: 83.48%
2026-02-10 09:11:03,812 - INFO - [Valid] [18/90] | Loss: 0.5386 | Val Acc: 77.29%
2026-02-10 09:11:03,815 - INFO - [Metrics for 'abnormal'] | Precision: 0.7469 | Recall: 0.7707 | F1: 0.7586
2026-02-10 09:11:03,815 - INFO - [Metrics for 'normal'] | Precision: 0.7966 | Recall: 0.7747 | F1: 0.7855
2026-02-10 09:11:03,816 - INFO - --------------------------------------------------
2026-02-10 09:11:03,816 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 09:11:05,482 - INFO - [Train] [19/90] | Loss: 0.4443 | Train Acc: 84.30%
2026-02-10 09:11:05,890 - INFO - [Valid] [19/90] | Loss: 0.5696 | Val Acc: 74.04%
2026-02-10 09:11:05,893 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.6115 | F1: 0.6857
2026-02-10 09:11:05,893 - INFO - [Metrics for 'normal'] | Precision: 0.7176 | Recall: 0.8516 | F1: 0.7789
2026-02-10 09:11:05,894 - INFO - --------------------------------------------------
2026-02-10 09:11:05,894 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 09:11:07,565 - INFO - [Train] [20/90] | Loss: 0.4330 | Train Acc: 85.04%
2026-02-10 09:11:07,976 - INFO - [Valid] [20/90] | Loss: 0.5426 | Val Acc: 77.29%
2026-02-10 09:11:07,978 - INFO - [Metrics for 'abnormal'] | Precision: 0.7899 | Recall: 0.6943 | F1: 0.7390
2026-02-10 09:11:07,978 - INFO - [Metrics for 'normal'] | Precision: 0.7612 | Recall: 0.8407 | F1: 0.7990
2026-02-10 09:11:07,979 - INFO - --------------------------------------------------
2026-02-10 09:11:07,980 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 09:11:09,625 - INFO - [Train] [21/90] | Loss: 0.4343 | Train Acc: 84.15%
2026-02-10 09:11:10,040 - INFO - [Valid] [21/90] | Loss: 0.5185 | Val Acc: 79.65%
2026-02-10 09:11:10,043 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-02-10 09:11:10,043 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-02-10 09:11:10,053 - INFO - [Best Model Saved] (val loss: 0.5185) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:11:10,053 - INFO - --------------------------------------------------
2026-02-10 09:11:10,053 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 09:11:11,695 - INFO - [Train] [22/90] | Loss: 0.4207 | Train Acc: 85.49%
2026-02-10 09:11:12,104 - INFO - [Valid] [22/90] | Loss: 0.5560 | Val Acc: 78.76%
2026-02-10 09:11:12,107 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-02-10 09:11:12,107 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-02-10 09:11:12,108 - INFO - --------------------------------------------------
2026-02-10 09:11:12,109 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 09:11:13,761 - INFO - [Train] [23/90] | Loss: 0.4107 | Train Acc: 86.98%
2026-02-10 09:11:14,165 - INFO - [Valid] [23/90] | Loss: 0.5358 | Val Acc: 79.35%
2026-02-10 09:11:14,168 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-02-10 09:11:14,168 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-02-10 09:11:14,169 - INFO - --------------------------------------------------
2026-02-10 09:11:14,169 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 09:11:15,836 - INFO - [Train] [24/90] | Loss: 0.4134 | Train Acc: 86.68%
2026-02-10 09:11:16,243 - INFO - [Valid] [24/90] | Loss: 0.5667 | Val Acc: 78.76%
2026-02-10 09:11:16,246 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-02-10 09:11:16,246 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-02-10 09:11:16,247 - INFO - --------------------------------------------------
2026-02-10 09:11:16,247 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 09:11:17,903 - INFO - [Train] [25/90] | Loss: 0.4056 | Train Acc: 86.24%
2026-02-10 09:11:18,312 - INFO - [Valid] [25/90] | Loss: 0.5141 | Val Acc: 79.06%
2026-02-10 09:11:18,314 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-02-10 09:11:18,314 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-02-10 09:11:18,324 - INFO - [Best Model Saved] (val loss: 0.5141) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:11:18,324 - INFO - --------------------------------------------------
2026-02-10 09:11:18,324 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 09:11:19,947 - INFO - [Train] [26/90] | Loss: 0.4001 | Train Acc: 87.35%
2026-02-10 09:11:20,340 - INFO - [Valid] [26/90] | Loss: 0.5415 | Val Acc: 77.88%
2026-02-10 09:11:20,342 - INFO - [Metrics for 'abnormal'] | Precision: 0.7595 | Recall: 0.7643 | F1: 0.7619
2026-02-10 09:11:20,343 - INFO - [Metrics for 'normal'] | Precision: 0.7956 | Recall: 0.7912 | F1: 0.7934
2026-02-10 09:11:20,343 - INFO - --------------------------------------------------
2026-02-10 09:11:20,344 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 09:11:22,011 - INFO - [Train] [27/90] | Loss: 0.3967 | Train Acc: 87.65%
2026-02-10 09:11:22,422 - INFO - [Valid] [27/90] | Loss: 0.5756 | Val Acc: 75.81%
2026-02-10 09:11:22,425 - INFO - [Metrics for 'abnormal'] | Precision: 0.6904 | Recall: 0.8662 | F1: 0.7684
2026-02-10 09:11:22,425 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.6648 | F1: 0.7469
2026-02-10 09:11:22,425 - INFO - --------------------------------------------------
2026-02-10 09:11:22,426 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 09:11:24,076 - INFO - [Train] [28/90] | Loss: 0.3946 | Train Acc: 89.06%
2026-02-10 09:11:24,481 - INFO - [Valid] [28/90] | Loss: 0.5521 | Val Acc: 77.88%
2026-02-10 09:11:24,483 - INFO - [Metrics for 'abnormal'] | Precision: 0.7412 | Recall: 0.8025 | F1: 0.7706
2026-02-10 09:11:24,483 - INFO - [Metrics for 'normal'] | Precision: 0.8166 | Recall: 0.7582 | F1: 0.7863
2026-02-10 09:11:24,484 - INFO - --------------------------------------------------
2026-02-10 09:11:24,485 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 09:11:26,134 - INFO - [Train] [29/90] | Loss: 0.3821 | Train Acc: 88.69%
2026-02-10 09:11:26,544 - INFO - [Valid] [29/90] | Loss: 0.5929 | Val Acc: 76.11%
2026-02-10 09:11:26,546 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.6624 | F1: 0.7197
2026-02-10 09:11:26,546 - INFO - [Metrics for 'normal'] | Precision: 0.7440 | Recall: 0.8462 | F1: 0.7918
2026-02-10 09:11:26,547 - INFO - --------------------------------------------------
2026-02-10 09:11:26,547 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 09:11:28,179 - INFO - [Train] [30/90] | Loss: 0.3734 | Train Acc: 88.99%
2026-02-10 09:11:28,590 - INFO - [Valid] [30/90] | Loss: 0.5632 | Val Acc: 76.99%
2026-02-10 09:11:28,592 - INFO - [Metrics for 'abnormal'] | Precision: 0.7310 | Recall: 0.7962 | F1: 0.7622
2026-02-10 09:11:28,592 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.7473 | F1: 0.7771
2026-02-10 09:11:28,593 - INFO - --------------------------------------------------
2026-02-10 09:11:28,594 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 09:11:30,242 - INFO - [Train] [31/90] | Loss: 0.3890 | Train Acc: 88.17%
2026-02-10 09:11:30,649 - INFO - [Valid] [31/90] | Loss: 0.5532 | Val Acc: 78.47%
2026-02-10 09:11:30,651 - INFO - [Metrics for 'abnormal'] | Precision: 0.7442 | Recall: 0.8153 | F1: 0.7781
2026-02-10 09:11:30,660 - INFO - [Metrics for 'normal'] | Precision: 0.8263 | Recall: 0.7582 | F1: 0.7908
2026-02-10 09:11:30,661 - INFO - --------------------------------------------------
2026-02-10 09:11:30,662 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 09:11:32,309 - INFO - [Train] [32/90] | Loss: 0.3609 | Train Acc: 90.48%
2026-02-10 09:11:32,720 - INFO - [Valid] [32/90] | Loss: 0.5549 | Val Acc: 80.24%
2026-02-10 09:11:32,722 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-02-10 09:11:32,722 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-02-10 09:11:32,723 - INFO - --------------------------------------------------
2026-02-10 09:11:32,724 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 09:11:34,386 - INFO - [Train] [33/90] | Loss: 0.3651 | Train Acc: 90.40%
2026-02-10 09:11:34,788 - INFO - [Valid] [33/90] | Loss: 0.5721 | Val Acc: 79.65%
2026-02-10 09:11:34,791 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 09:11:34,791 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 09:11:34,791 - INFO - --------------------------------------------------
2026-02-10 09:11:34,792 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 09:11:36,437 - INFO - [Train] [34/90] | Loss: 0.3558 | Train Acc: 90.10%
2026-02-10 09:11:36,845 - INFO - [Valid] [34/90] | Loss: 0.5545 | Val Acc: 79.06%
2026-02-10 09:11:36,847 - INFO - [Metrics for 'abnormal'] | Precision: 0.7986 | Recall: 0.7325 | F1: 0.7641
2026-02-10 09:11:36,847 - INFO - [Metrics for 'normal'] | Precision: 0.7846 | Recall: 0.8407 | F1: 0.8117
2026-02-10 09:11:36,848 - INFO - --------------------------------------------------
2026-02-10 09:11:36,849 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 09:11:38,484 - INFO - [Train] [35/90] | Loss: 0.3431 | Train Acc: 91.22%
2026-02-10 09:11:38,891 - INFO - [Valid] [35/90] | Loss: 0.5761 | Val Acc: 78.76%
2026-02-10 09:11:38,894 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.7580 | F1: 0.7677
2026-02-10 09:11:38,894 - INFO - [Metrics for 'normal'] | Precision: 0.7957 | Recall: 0.8132 | F1: 0.8043
2026-02-10 09:11:38,895 - INFO - --------------------------------------------------
2026-02-10 09:11:38,896 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 09:11:40,527 - INFO - [Train] [36/90] | Loss: 0.3417 | Train Acc: 91.29%
2026-02-10 09:11:40,928 - INFO - [Valid] [36/90] | Loss: 0.5822 | Val Acc: 77.58%
2026-02-10 09:11:40,931 - INFO - [Metrics for 'abnormal'] | Precision: 0.7314 | Recall: 0.8153 | F1: 0.7711
2026-02-10 09:11:40,931 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.7418 | F1: 0.7803
2026-02-10 09:11:40,932 - INFO - --------------------------------------------------
2026-02-10 09:11:40,932 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 09:11:42,564 - INFO - [Train] [37/90] | Loss: 0.3384 | Train Acc: 92.04%
2026-02-10 09:11:42,968 - INFO - [Valid] [37/90] | Loss: 0.5769 | Val Acc: 79.65%
2026-02-10 09:11:42,971 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-02-10 09:11:42,971 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-02-10 09:11:42,972 - INFO - --------------------------------------------------
2026-02-10 09:11:42,972 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 09:11:44,638 - INFO - [Train] [38/90] | Loss: 0.3483 | Train Acc: 90.18%
2026-02-10 09:11:45,041 - INFO - [Valid] [38/90] | Loss: 0.6003 | Val Acc: 77.29%
2026-02-10 09:11:45,043 - INFO - [Metrics for 'abnormal'] | Precision: 0.7198 | Recall: 0.8344 | F1: 0.7729
2026-02-10 09:11:45,043 - INFO - [Metrics for 'normal'] | Precision: 0.8344 | Recall: 0.7198 | F1: 0.7729
2026-02-10 09:11:45,044 - INFO - --------------------------------------------------
2026-02-10 09:11:45,045 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 09:11:46,703 - INFO - [Train] [39/90] | Loss: 0.3327 | Train Acc: 92.04%
2026-02-10 09:11:47,109 - INFO - [Valid] [39/90] | Loss: 0.5833 | Val Acc: 80.24%
2026-02-10 09:11:47,112 - INFO - [Metrics for 'abnormal'] | Precision: 0.7812 | Recall: 0.7962 | F1: 0.7886
2026-02-10 09:11:47,112 - INFO - [Metrics for 'normal'] | Precision: 0.8212 | Recall: 0.8077 | F1: 0.8144
2026-02-10 09:11:47,113 - INFO - --------------------------------------------------
2026-02-10 09:11:47,113 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 09:11:48,780 - INFO - [Train] [40/90] | Loss: 0.3426 | Train Acc: 90.70%
2026-02-10 09:11:49,193 - INFO - [Valid] [40/90] | Loss: 0.5242 | Val Acc: 80.24%
2026-02-10 09:11:49,195 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-02-10 09:11:49,195 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-02-10 09:11:49,196 - INFO - --------------------------------------------------
2026-02-10 09:11:49,197 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 09:11:50,843 - INFO - [Train] [41/90] | Loss: 0.3291 | Train Acc: 92.93%
2026-02-10 09:11:51,246 - INFO - [Valid] [41/90] | Loss: 0.5464 | Val Acc: 79.94%
2026-02-10 09:11:51,249 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-02-10 09:11:51,249 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-02-10 09:11:51,250 - INFO - --------------------------------------------------
2026-02-10 09:11:51,250 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 09:11:52,891 - INFO - [Train] [42/90] | Loss: 0.3272 | Train Acc: 92.19%
2026-02-10 09:11:53,290 - INFO - [Valid] [42/90] | Loss: 0.5494 | Val Acc: 81.12%
2026-02-10 09:11:53,293 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-02-10 09:11:53,293 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-02-10 09:11:53,294 - INFO - --------------------------------------------------
2026-02-10 09:11:53,294 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 09:11:54,951 - INFO - [Train] [43/90] | Loss: 0.3325 | Train Acc: 92.19%
2026-02-10 09:11:55,360 - INFO - [Valid] [43/90] | Loss: 0.5912 | Val Acc: 79.06%
2026-02-10 09:11:55,363 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.7834 | F1: 0.7760
2026-02-10 09:11:55,363 - INFO - [Metrics for 'normal'] | Precision: 0.8101 | Recall: 0.7967 | F1: 0.8033
2026-02-10 09:11:55,364 - INFO - --------------------------------------------------
2026-02-10 09:11:55,364 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 09:11:56,991 - INFO - [Train] [44/90] | Loss: 0.3127 | Train Acc: 93.45%
2026-02-10 09:11:57,398 - INFO - [Valid] [44/90] | Loss: 0.6096 | Val Acc: 76.99%
2026-02-10 09:11:57,401 - INFO - [Metrics for 'abnormal'] | Precision: 0.7582 | Recall: 0.7389 | F1: 0.7484
2026-02-10 09:11:57,401 - INFO - [Metrics for 'normal'] | Precision: 0.7796 | Recall: 0.7967 | F1: 0.7880
2026-02-10 09:11:57,402 - INFO - --------------------------------------------------
2026-02-10 09:11:57,402 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 09:11:59,059 - INFO - [Train] [45/90] | Loss: 0.3375 | Train Acc: 91.82%
2026-02-10 09:11:59,468 - INFO - [Valid] [45/90] | Loss: 0.5700 | Val Acc: 80.53%
2026-02-10 09:11:59,471 - INFO - [Metrics for 'abnormal'] | Precision: 0.8421 | Recall: 0.7134 | F1: 0.7724
2026-02-10 09:11:59,471 - INFO - [Metrics for 'normal'] | Precision: 0.7816 | Recall: 0.8846 | F1: 0.8299
2026-02-10 09:11:59,472 - INFO - --------------------------------------------------
2026-02-10 09:11:59,472 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 09:12:01,134 - INFO - [Train] [46/90] | Loss: 0.3147 | Train Acc: 93.45%
2026-02-10 09:12:01,544 - INFO - [Valid] [46/90] | Loss: 0.5721 | Val Acc: 80.53%
2026-02-10 09:12:01,547 - INFO - [Metrics for 'abnormal'] | Precision: 0.7630 | Recall: 0.8408 | F1: 0.8000
2026-02-10 09:12:01,547 - INFO - [Metrics for 'normal'] | Precision: 0.8494 | Recall: 0.7747 | F1: 0.8103
2026-02-10 09:12:01,548 - INFO - --------------------------------------------------
2026-02-10 09:12:01,548 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 09:12:03,205 - INFO - [Train] [47/90] | Loss: 0.3182 | Train Acc: 93.01%
2026-02-10 09:12:03,609 - INFO - [Valid] [47/90] | Loss: 0.5593 | Val Acc: 78.76%
2026-02-10 09:12:03,612 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-02-10 09:12:03,612 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-02-10 09:12:03,613 - INFO - --------------------------------------------------
2026-02-10 09:12:03,613 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 09:12:05,255 - INFO - [Train] [48/90] | Loss: 0.3049 | Train Acc: 94.57%
2026-02-10 09:12:05,663 - INFO - [Valid] [48/90] | Loss: 0.5931 | Val Acc: 78.76%
2026-02-10 09:12:05,666 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-02-10 09:12:05,666 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-02-10 09:12:05,667 - INFO - --------------------------------------------------
2026-02-10 09:12:05,667 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 09:12:07,317 - INFO - [Train] [49/90] | Loss: 0.3165 | Train Acc: 93.60%
2026-02-10 09:12:07,725 - INFO - [Valid] [49/90] | Loss: 0.5890 | Val Acc: 77.88%
2026-02-10 09:12:07,727 - INFO - [Metrics for 'abnormal'] | Precision: 0.7595 | Recall: 0.7643 | F1: 0.7619
2026-02-10 09:12:07,727 - INFO - [Metrics for 'normal'] | Precision: 0.7956 | Recall: 0.7912 | F1: 0.7934
2026-02-10 09:12:07,728 - INFO - --------------------------------------------------
2026-02-10 09:12:07,729 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 09:12:09,363 - INFO - [Train] [50/90] | Loss: 0.3092 | Train Acc: 93.90%
2026-02-10 09:12:09,770 - INFO - [Valid] [50/90] | Loss: 0.5898 | Val Acc: 79.06%
2026-02-10 09:12:09,773 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-02-10 09:12:09,773 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-02-10 09:12:09,774 - INFO - --------------------------------------------------
2026-02-10 09:12:09,775 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 09:12:11,408 - INFO - [Train] [51/90] | Loss: 0.3019 | Train Acc: 94.49%
2026-02-10 09:12:11,806 - INFO - [Valid] [51/90] | Loss: 0.5728 | Val Acc: 80.53%
2026-02-10 09:12:11,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-02-10 09:12:11,809 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-02-10 09:12:11,810 - INFO - --------------------------------------------------
2026-02-10 09:12:11,810 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 09:12:13,444 - INFO - [Train] [52/90] | Loss: 0.2970 | Train Acc: 94.79%
2026-02-10 09:12:13,854 - INFO - [Valid] [52/90] | Loss: 0.5764 | Val Acc: 78.76%
2026-02-10 09:12:13,857 - INFO - [Metrics for 'abnormal'] | Precision: 0.7815 | Recall: 0.7516 | F1: 0.7662
2026-02-10 09:12:13,857 - INFO - [Metrics for 'normal'] | Precision: 0.7926 | Recall: 0.8187 | F1: 0.8054
2026-02-10 09:12:13,857 - INFO - --------------------------------------------------
2026-02-10 09:12:13,858 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 09:12:15,456 - INFO - [Train] [53/90] | Loss: 0.2848 | Train Acc: 95.09%
2026-02-10 09:12:15,862 - INFO - [Valid] [53/90] | Loss: 0.5506 | Val Acc: 80.83%
2026-02-10 09:12:15,864 - INFO - [Metrics for 'abnormal'] | Precision: 0.8108 | Recall: 0.7643 | F1: 0.7869
2026-02-10 09:12:15,864 - INFO - [Metrics for 'normal'] | Precision: 0.8063 | Recall: 0.8462 | F1: 0.8257
2026-02-10 09:12:15,865 - INFO - --------------------------------------------------
2026-02-10 09:12:15,866 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 09:12:17,517 - INFO - [Train] [54/90] | Loss: 0.3002 | Train Acc: 94.42%
2026-02-10 09:12:17,926 - INFO - [Valid] [54/90] | Loss: 0.5621 | Val Acc: 79.94%
2026-02-10 09:12:17,929 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-02-10 09:12:17,929 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-02-10 09:12:17,929 - INFO - --------------------------------------------------
2026-02-10 09:12:17,930 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 09:12:19,548 - INFO - [Train] [55/90] | Loss: 0.2893 | Train Acc: 95.46%
2026-02-10 09:12:19,956 - INFO - [Valid] [55/90] | Loss: 0.5810 | Val Acc: 79.35%
2026-02-10 09:12:19,958 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7389 | F1: 0.7682
2026-02-10 09:12:19,958 - INFO - [Metrics for 'normal'] | Precision: 0.7887 | Recall: 0.8407 | F1: 0.8138
2026-02-10 09:12:19,959 - INFO - --------------------------------------------------
2026-02-10 09:12:19,960 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 09:12:21,607 - INFO - [Train] [56/90] | Loss: 0.3020 | Train Acc: 94.79%
2026-02-10 09:12:22,013 - INFO - [Valid] [56/90] | Loss: 0.5489 | Val Acc: 79.65%
2026-02-10 09:12:22,015 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-02-10 09:12:22,015 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-02-10 09:12:22,016 - INFO - --------------------------------------------------
2026-02-10 09:12:22,017 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 09:12:23,676 - INFO - [Train] [57/90] | Loss: 0.2718 | Train Acc: 96.06%
2026-02-10 09:12:24,084 - INFO - [Valid] [57/90] | Loss: 0.5588 | Val Acc: 81.12%
2026-02-10 09:12:24,086 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 09:12:24,086 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 09:12:24,087 - INFO - --------------------------------------------------
2026-02-10 09:12:24,088 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 09:12:25,739 - INFO - [Train] [58/90] | Loss: 0.2920 | Train Acc: 94.42%
2026-02-10 09:12:26,143 - INFO - [Valid] [58/90] | Loss: 0.5737 | Val Acc: 80.83%
2026-02-10 09:12:26,145 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-02-10 09:12:26,145 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-02-10 09:12:26,146 - INFO - --------------------------------------------------
2026-02-10 09:12:26,147 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 09:12:27,795 - INFO - [Train] [59/90] | Loss: 0.2782 | Train Acc: 95.91%
2026-02-10 09:12:28,198 - INFO - [Valid] [59/90] | Loss: 0.5501 | Val Acc: 82.01%
2026-02-10 09:12:28,201 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-02-10 09:12:28,201 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-02-10 09:12:28,202 - INFO - --------------------------------------------------
2026-02-10 09:12:28,202 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 09:12:29,869 - INFO - [Train] [60/90] | Loss: 0.2686 | Train Acc: 96.95%
2026-02-10 09:12:30,263 - INFO - [Valid] [60/90] | Loss: 0.6057 | Val Acc: 81.71%
2026-02-10 09:12:30,265 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-02-10 09:12:30,265 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-02-10 09:12:30,266 - INFO - --------------------------------------------------
2026-02-10 09:12:30,267 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 09:12:31,940 - INFO - [Train] [61/90] | Loss: 0.2887 | Train Acc: 95.31%
2026-02-10 09:12:32,347 - INFO - [Valid] [61/90] | Loss: 0.5455 | Val Acc: 80.53%
2026-02-10 09:12:32,349 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.7452 | F1: 0.7800
2026-02-10 09:12:32,349 - INFO - [Metrics for 'normal'] | Precision: 0.7959 | Recall: 0.8571 | F1: 0.8254
2026-02-10 09:12:32,350 - INFO - --------------------------------------------------
2026-02-10 09:12:32,351 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 09:12:34,010 - INFO - [Train] [62/90] | Loss: 0.2742 | Train Acc: 96.06%
2026-02-10 09:12:34,415 - INFO - [Valid] [62/90] | Loss: 0.5744 | Val Acc: 80.53%
2026-02-10 09:12:34,417 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-02-10 09:12:34,417 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-02-10 09:12:34,418 - INFO - --------------------------------------------------
2026-02-10 09:12:34,419 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 09:12:36,066 - INFO - [Train] [63/90] | Loss: 0.2788 | Train Acc: 96.35%
2026-02-10 09:12:36,474 - INFO - [Valid] [63/90] | Loss: 0.5783 | Val Acc: 79.65%
2026-02-10 09:12:36,476 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-02-10 09:12:36,476 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-02-10 09:12:36,477 - INFO - --------------------------------------------------
2026-02-10 09:12:36,478 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 09:12:38,121 - INFO - [Train] [64/90] | Loss: 0.2659 | Train Acc: 96.95%
2026-02-10 09:12:38,533 - INFO - [Valid] [64/90] | Loss: 0.5648 | Val Acc: 80.83%
2026-02-10 09:12:38,535 - INFO - [Metrics for 'abnormal'] | Precision: 0.8194 | Recall: 0.7516 | F1: 0.7841
2026-02-10 09:12:38,535 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8571 | F1: 0.8276
2026-02-10 09:12:38,536 - INFO - --------------------------------------------------
2026-02-10 09:12:38,537 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 09:12:40,176 - INFO - [Train] [65/90] | Loss: 0.2664 | Train Acc: 97.02%
2026-02-10 09:12:40,584 - INFO - [Valid] [65/90] | Loss: 0.5632 | Val Acc: 80.83%
2026-02-10 09:12:40,586 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-02-10 09:12:40,587 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-02-10 09:12:40,587 - INFO - --------------------------------------------------
2026-02-10 09:12:40,588 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 09:12:42,207 - INFO - [Train] [66/90] | Loss: 0.2571 | Train Acc: 97.10%
2026-02-10 09:12:42,615 - INFO - [Valid] [66/90] | Loss: 0.5920 | Val Acc: 79.65%
2026-02-10 09:12:42,617 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-02-10 09:12:42,617 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-02-10 09:12:42,618 - INFO - --------------------------------------------------
2026-02-10 09:12:42,619 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 09:12:44,275 - INFO - [Train] [67/90] | Loss: 0.2866 | Train Acc: 95.09%
2026-02-10 09:12:44,683 - INFO - [Valid] [67/90] | Loss: 0.5647 | Val Acc: 79.65%
2026-02-10 09:12:44,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7857 | Recall: 0.7707 | F1: 0.7781
2026-02-10 09:12:44,686 - INFO - [Metrics for 'normal'] | Precision: 0.8054 | Recall: 0.8187 | F1: 0.8120
2026-02-10 09:12:44,687 - INFO - --------------------------------------------------
2026-02-10 09:12:44,688 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 09:12:46,341 - INFO - [Train] [68/90] | Loss: 0.2690 | Train Acc: 96.95%
2026-02-10 09:12:46,749 - INFO - [Valid] [68/90] | Loss: 0.5786 | Val Acc: 81.12%
2026-02-10 09:12:46,752 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-02-10 09:12:46,752 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-02-10 09:12:46,753 - INFO - --------------------------------------------------
2026-02-10 09:12:46,753 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 09:12:48,406 - INFO - [Train] [69/90] | Loss: 0.2564 | Train Acc: 96.88%
2026-02-10 09:12:48,814 - INFO - [Valid] [69/90] | Loss: 0.5717 | Val Acc: 79.94%
2026-02-10 09:12:48,817 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-02-10 09:12:48,817 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-02-10 09:12:48,818 - INFO - --------------------------------------------------
2026-02-10 09:12:48,818 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 09:12:50,465 - INFO - [Train] [70/90] | Loss: 0.2731 | Train Acc: 96.28%
2026-02-10 09:12:50,869 - INFO - [Valid] [70/90] | Loss: 0.5685 | Val Acc: 79.94%
2026-02-10 09:12:50,872 - INFO - [Metrics for 'abnormal'] | Precision: 0.7908 | Recall: 0.7707 | F1: 0.7806
2026-02-10 09:12:50,872 - INFO - [Metrics for 'normal'] | Precision: 0.8065 | Recall: 0.8242 | F1: 0.8152
2026-02-10 09:12:50,873 - INFO - --------------------------------------------------
2026-02-10 09:12:50,873 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 09:12:52,516 - INFO - [Train] [71/90] | Loss: 0.2597 | Train Acc: 97.17%
2026-02-10 09:12:52,916 - INFO - [Valid] [71/90] | Loss: 0.5990 | Val Acc: 79.35%
2026-02-10 09:12:52,918 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.7580 | F1: 0.7727
2026-02-10 09:12:52,918 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8242 | F1: 0.8108
2026-02-10 09:12:52,919 - INFO - --------------------------------------------------
2026-02-10 09:12:52,920 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 09:12:54,559 - INFO - [Train] [72/90] | Loss: 0.2770 | Train Acc: 95.98%
2026-02-10 09:12:54,961 - INFO - [Valid] [72/90] | Loss: 0.5680 | Val Acc: 79.35%
2026-02-10 09:12:54,964 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.7580 | F1: 0.7727
2026-02-10 09:12:54,964 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8242 | F1: 0.8108
2026-02-10 09:12:54,965 - INFO - --------------------------------------------------
2026-02-10 09:12:54,965 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 09:12:56,616 - INFO - [Train] [73/90] | Loss: 0.2455 | Train Acc: 97.77%
2026-02-10 09:12:57,022 - INFO - [Valid] [73/90] | Loss: 0.5809 | Val Acc: 79.06%
2026-02-10 09:12:57,024 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-02-10 09:12:57,024 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-02-10 09:12:57,025 - INFO - --------------------------------------------------
2026-02-10 09:12:57,026 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 09:12:58,658 - INFO - [Train] [74/90] | Loss: 0.2733 | Train Acc: 96.58%
2026-02-10 09:12:59,067 - INFO - [Valid] [74/90] | Loss: 0.5663 | Val Acc: 80.24%
2026-02-10 09:12:59,069 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-02-10 09:12:59,069 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-02-10 09:12:59,070 - INFO - --------------------------------------------------
2026-02-10 09:12:59,071 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 09:13:00,702 - INFO - [Train] [75/90] | Loss: 0.2661 | Train Acc: 96.88%
2026-02-10 09:13:01,112 - INFO - [Valid] [75/90] | Loss: 0.5908 | Val Acc: 79.94%
2026-02-10 09:13:01,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-02-10 09:13:01,115 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-02-10 09:13:01,116 - INFO - --------------------------------------------------
2026-02-10 09:13:01,116 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 09:13:02,791 - INFO - [Train] [76/90] | Loss: 0.2490 | Train Acc: 98.21%
2026-02-10 09:13:03,199 - INFO - [Valid] [76/90] | Loss: 0.5820 | Val Acc: 80.24%
2026-02-10 09:13:03,201 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-02-10 09:13:03,201 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-02-10 09:13:03,202 - INFO - --------------------------------------------------
2026-02-10 09:13:03,203 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 09:13:04,874 - INFO - [Train] [77/90] | Loss: 0.2562 | Train Acc: 97.25%
2026-02-10 09:13:05,275 - INFO - [Valid] [77/90] | Loss: 0.5959 | Val Acc: 79.94%
2026-02-10 09:13:05,278 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-02-10 09:13:05,278 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-02-10 09:13:05,278 - INFO - --------------------------------------------------
2026-02-10 09:13:05,279 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 09:13:06,937 - INFO - [Train] [78/90] | Loss: 0.2509 | Train Acc: 97.92%
2026-02-10 09:13:07,344 - INFO - [Valid] [78/90] | Loss: 0.5859 | Val Acc: 79.65%
2026-02-10 09:13:07,346 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-02-10 09:13:07,347 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-02-10 09:13:07,347 - INFO - --------------------------------------------------
2026-02-10 09:13:07,348 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 09:13:09,013 - INFO - [Train] [79/90] | Loss: 0.2634 | Train Acc: 97.17%
2026-02-10 09:13:09,422 - INFO - [Valid] [79/90] | Loss: 0.5866 | Val Acc: 80.24%
2026-02-10 09:13:09,425 - INFO - [Metrics for 'abnormal'] | Precision: 0.7922 | Recall: 0.7771 | F1: 0.7846
2026-02-10 09:13:09,425 - INFO - [Metrics for 'normal'] | Precision: 0.8108 | Recall: 0.8242 | F1: 0.8174
2026-02-10 09:13:09,426 - INFO - --------------------------------------------------
2026-02-10 09:13:09,426 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 09:13:11,084 - INFO - [Train] [80/90] | Loss: 0.2548 | Train Acc: 97.54%
2026-02-10 09:13:11,495 - INFO - [Valid] [80/90] | Loss: 0.5929 | Val Acc: 80.83%
2026-02-10 09:13:11,498 - INFO - [Metrics for 'abnormal'] | Precision: 0.8108 | Recall: 0.7643 | F1: 0.7869
2026-02-10 09:13:11,498 - INFO - [Metrics for 'normal'] | Precision: 0.8063 | Recall: 0.8462 | F1: 0.8257
2026-02-10 09:13:11,499 - INFO - --------------------------------------------------
2026-02-10 09:13:11,499 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 09:13:13,160 - INFO - [Train] [81/90] | Loss: 0.2627 | Train Acc: 97.02%
2026-02-10 09:13:13,566 - INFO - [Valid] [81/90] | Loss: 0.5768 | Val Acc: 80.53%
2026-02-10 09:13:13,568 - INFO - [Metrics for 'abnormal'] | Precision: 0.8054 | Recall: 0.7643 | F1: 0.7843
2026-02-10 09:13:13,568 - INFO - [Metrics for 'normal'] | Precision: 0.8053 | Recall: 0.8407 | F1: 0.8226
2026-02-10 09:13:13,569 - INFO - --------------------------------------------------
2026-02-10 09:13:13,570 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 09:13:15,232 - INFO - [Train] [82/90] | Loss: 0.2557 | Train Acc: 97.40%
2026-02-10 09:13:15,640 - INFO - [Valid] [82/90] | Loss: 0.5878 | Val Acc: 80.24%
2026-02-10 09:13:15,642 - INFO - [Metrics for 'abnormal'] | Precision: 0.8214 | Recall: 0.7325 | F1: 0.7744
2026-02-10 09:13:15,642 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.8626 | F1: 0.8241
2026-02-10 09:13:15,643 - INFO - --------------------------------------------------
2026-02-10 09:13:15,644 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 09:13:17,305 - INFO - [Train] [83/90] | Loss: 0.2690 | Train Acc: 96.13%
2026-02-10 09:13:17,710 - INFO - [Valid] [83/90] | Loss: 0.5936 | Val Acc: 80.24%
2026-02-10 09:13:17,712 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-02-10 09:13:17,712 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-02-10 09:13:17,713 - INFO - --------------------------------------------------
2026-02-10 09:13:17,714 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 09:13:19,388 - INFO - [Train] [84/90] | Loss: 0.2579 | Train Acc: 97.62%
2026-02-10 09:13:19,795 - INFO - [Valid] [84/90] | Loss: 0.5816 | Val Acc: 80.53%
2026-02-10 09:13:19,798 - INFO - [Metrics for 'abnormal'] | Precision: 0.8054 | Recall: 0.7643 | F1: 0.7843
2026-02-10 09:13:19,798 - INFO - [Metrics for 'normal'] | Precision: 0.8053 | Recall: 0.8407 | F1: 0.8226
2026-02-10 09:13:19,799 - INFO - --------------------------------------------------
2026-02-10 09:13:19,799 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 09:13:21,460 - INFO - [Train] [85/90] | Loss: 0.2552 | Train Acc: 97.47%
2026-02-10 09:13:21,872 - INFO - [Valid] [85/90] | Loss: 0.5859 | Val Acc: 80.53%
2026-02-10 09:13:21,874 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.7452 | F1: 0.7800
2026-02-10 09:13:21,874 - INFO - [Metrics for 'normal'] | Precision: 0.7959 | Recall: 0.8571 | F1: 0.8254
2026-02-10 09:13:21,875 - INFO - --------------------------------------------------
2026-02-10 09:13:21,876 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 09:13:23,523 - INFO - [Train] [86/90] | Loss: 0.2472 | Train Acc: 97.77%
2026-02-10 09:13:23,934 - INFO - [Valid] [86/90] | Loss: 0.5984 | Val Acc: 79.65%
2026-02-10 09:13:23,937 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-02-10 09:13:23,937 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-02-10 09:13:23,937 - INFO - --------------------------------------------------
2026-02-10 09:13:23,938 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 09:13:25,601 - INFO - [Train] [87/90] | Loss: 0.2518 | Train Acc: 97.84%
2026-02-10 09:13:26,020 - INFO - [Valid] [87/90] | Loss: 0.5914 | Val Acc: 80.83%
2026-02-10 09:13:26,022 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-02-10 09:13:26,022 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-02-10 09:13:26,023 - INFO - --------------------------------------------------
2026-02-10 09:13:26,024 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 09:13:27,680 - INFO - [Train] [88/90] | Loss: 0.2469 | Train Acc: 97.99%
2026-02-10 09:13:28,085 - INFO - [Valid] [88/90] | Loss: 0.6059 | Val Acc: 80.53%
2026-02-10 09:13:28,088 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-02-10 09:13:28,088 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-02-10 09:13:28,089 - INFO - --------------------------------------------------
2026-02-10 09:13:28,089 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 09:13:29,729 - INFO - [Train] [89/90] | Loss: 0.2495 | Train Acc: 97.92%
2026-02-10 09:13:30,138 - INFO - [Valid] [89/90] | Loss: 0.5795 | Val Acc: 80.83%
2026-02-10 09:13:30,140 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-02-10 09:13:30,140 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-02-10 09:13:30,141 - INFO - --------------------------------------------------
2026-02-10 09:13:30,142 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 09:13:31,789 - INFO - [Train] [90/90] | Loss: 0.2439 | Train Acc: 98.29%
2026-02-10 09:13:32,197 - INFO - [Valid] [90/90] | Loss: 0.6028 | Val Acc: 79.65%
2026-02-10 09:13:32,199 - INFO - [Metrics for 'abnormal'] | Precision: 0.7821 | Recall: 0.7771 | F1: 0.7796
2026-02-10 09:13:32,200 - INFO - [Metrics for 'normal'] | Precision: 0.8087 | Recall: 0.8132 | F1: 0.8110
2026-02-10 09:13:32,201 - INFO - ==================================================
2026-02-10 09:13:32,201 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 09:13:32,201 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 09:13:32,201 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:13:32,362 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 09:13:32,366 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 09:13:32,367 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 09:13:32,367 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 09:13:32,368 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 09:13:33,889 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:13:33,889 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:13:34,022 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 09:13:34,023 - INFO - ==================================================
2026-02-10 09:13:34,041 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/best_model.pth'
2026-02-10 09:13:34,041 - INFO - ==================================================
2026-02-10 09:13:34,041 - INFO - Test 모드를 시작합니다.
2026-02-10 09:13:34,073 - INFO - 연산량 (MACs): 0.0131 GMACs per sample
2026-02-10 09:13:34,073 - INFO - 연산량 (FLOPs): 0.0262 GFLOPs per sample
2026-02-10 09:13:34,073 - INFO - ==================================================
2026-02-10 09:13:34,073 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 09:13:34,570 - INFO - 샘플 당 평균 Forward Pass 시간: 2.29ms (std: 0.09ms), FPS: 436.92 (std: 12.99) (1개 샘플 x 100회 반복)
2026-02-10 09:13:34,570 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 38.54 MB
2026-02-10 09:13:34,570 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 09:13:35,236 - INFO - [Test] Loss: 0.4593 | Test Acc: 79.06%
2026-02-10 09:13:35,239 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-02-10 09:13:35,239 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-02-10 09:13:35,365 - INFO - ==================================================
2026-02-10 09:13:35,365 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/confusion_matrix_20260210_090251.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/confusion_matrix_20260210_090251.pdf'
2026-02-10 09:13:35,365 - INFO - ==================================================
2026-02-10 09:13:35,365 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 09:13:35,550 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/model_fp32_20260210_090251.onnx'에 저장되었습니다. (크기: 0.36 MB)
2026-02-10 09:13:35,724 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 9.19 MB
2026-02-10 09:13:35,724 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 09:13:36,124 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 2.39ms (std: 0.05ms)
2026-02-10 09:13:36,124 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 419.11 FPS (std: 8.92) (1개 샘플 x 100회 반복)
2026-02-10 09:13:36,124 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 12.75 MB
2026-02-10 09:13:36,125 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 21.86 MB
2026-02-10 09:13:37,155 - INFO - [Test (ONNX)] | Test Acc (ONNX): 79.06%
2026-02-10 09:13:37,158 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-02-10 09:13:37,159 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-02-10 09:13:37,264 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/val_acc.pdf'
2026-02-10 09:13:37,372 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/train_val_acc.pdf'
2026-02-10 09:13:37,461 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/F1_normal.pdf'
2026-02-10 09:13:37,563 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/val_loss.pdf'
2026-02-10 09:13:37,653 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/learning_rate.pdf'
2026-02-10 09:13:38,610 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260210_090251/graph_20260210_090251/compile.pdf'
