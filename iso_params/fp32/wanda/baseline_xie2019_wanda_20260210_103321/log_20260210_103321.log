2026-02-10 10:33:21,899 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/log_20260210_103321.log'에 저장됩니다.
2026-02-10 10:33:21,901 - INFO - ==================================================
2026-02-10 10:33:21,901 - INFO - config.yaml:
2026-02-10 10:33:21,901 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: xie2019
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.047585

2026-02-10 10:33:21,901 - INFO - ==================================================
2026-02-10 10:33:22,063 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 10:33:22,063 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 10:33:22,063 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 10:33:22,066 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 10:33:22,066 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 10:33:22,066 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 10:33:22,066 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 10:33:22,168 - INFO - ==================================================
2026-02-10 10:33:22,168 - INFO - 모델 파라미터 수:
2026-02-10 10:33:22,168 - INFO -   - 총 파라미터: 9,160,194 개
2026-02-10 10:33:22,168 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-02-10 10:33:22,168 - INFO - ================================================================================
2026-02-10 10:33:22,168 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 10:33:22,168 - INFO - ================================================================================
2026-02-10 10:33:22,168 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 10:33:22,169 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 10:33:22,169 - INFO - ==================================================
2026-02-10 10:33:22,169 - INFO - train 모드를 시작합니다.
2026-02-10 10:33:22,169 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 10:33:22,169 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 10:33:22,169 - INFO - --------------------------------------------------
2026-02-10 10:33:22,169 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 10:33:23,828 - INFO - [Train] [1/10] | Loss: 0.5912 | Train Acc: 73.96%
2026-02-10 10:33:24,465 - INFO - [Valid] [1/10] | Loss: 0.5843 | Val Acc: 74.63%
2026-02-10 10:33:24,469 - INFO - [Metrics for 'abnormal'] | Precision: 0.8515 | Recall: 0.5478 | F1: 0.6667
2026-02-10 10:33:24,469 - INFO - [Metrics for 'normal'] | Precision: 0.7017 | Recall: 0.9176 | F1: 0.7952
2026-02-10 10:33:24,494 - INFO - [Best Model Saved] (val loss: 0.5843) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:33:24,494 - INFO - --------------------------------------------------
2026-02-10 10:33:24,494 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 10:33:25,978 - INFO - [Train] [2/10] | Loss: 0.5865 | Train Acc: 77.31%
2026-02-10 10:33:26,407 - INFO - [Valid] [2/10] | Loss: 0.9930 | Val Acc: 46.31%
2026-02-10 10:33:26,412 - INFO - [Metrics for 'abnormal'] | Precision: 0.4631 | Recall: 1.0000 | F1: 0.6331
2026-02-10 10:33:26,412 - INFO - [Metrics for 'normal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-02-10 10:33:26,413 - INFO - --------------------------------------------------
2026-02-10 10:33:26,413 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 10:33:28,676 - INFO - [Train] [3/10] | Loss: 0.5436 | Train Acc: 78.50%
2026-02-10 10:33:29,131 - INFO - [Valid] [3/10] | Loss: 0.5610 | Val Acc: 75.52%
2026-02-10 10:33:29,134 - INFO - [Metrics for 'abnormal'] | Precision: 0.7126 | Recall: 0.7898 | F1: 0.7492
2026-02-10 10:33:29,134 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7253 | F1: 0.7608
2026-02-10 10:33:29,179 - INFO - [Best Model Saved] (val loss: 0.5610) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:33:29,179 - INFO - --------------------------------------------------
2026-02-10 10:33:29,179 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 10:33:31,296 - INFO - [Train] [4/10] | Loss: 0.5122 | Train Acc: 80.88%
2026-02-10 10:33:32,028 - INFO - [Valid] [4/10] | Loss: 0.5679 | Val Acc: 75.81%
2026-02-10 10:33:32,031 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.6369 | F1: 0.7092
2026-02-10 10:33:32,031 - INFO - [Metrics for 'normal'] | Precision: 0.7336 | Recall: 0.8626 | F1: 0.7929
2026-02-10 10:33:32,032 - INFO - --------------------------------------------------
2026-02-10 10:33:32,032 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 10:33:34,121 - INFO - [Train] [5/10] | Loss: 0.5030 | Train Acc: 80.58%
2026-02-10 10:33:34,840 - INFO - [Valid] [5/10] | Loss: 0.5255 | Val Acc: 78.47%
2026-02-10 10:33:34,844 - INFO - [Metrics for 'abnormal'] | Precision: 0.7530 | Recall: 0.7962 | F1: 0.7740
2026-02-10 10:33:34,844 - INFO - [Metrics for 'normal'] | Precision: 0.8150 | Recall: 0.7747 | F1: 0.7944
2026-02-10 10:33:34,895 - INFO - [Best Model Saved] (val loss: 0.5255) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:33:34,895 - INFO - --------------------------------------------------
2026-02-10 10:33:34,895 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 10:33:37,070 - INFO - [Train] [6/10] | Loss: 0.4857 | Train Acc: 82.37%
2026-02-10 10:33:37,814 - INFO - [Valid] [6/10] | Loss: 0.5193 | Val Acc: 78.47%
2026-02-10 10:33:37,817 - INFO - [Metrics for 'abnormal'] | Precision: 0.7625 | Recall: 0.7771 | F1: 0.7697
2026-02-10 10:33:37,817 - INFO - [Metrics for 'normal'] | Precision: 0.8045 | Recall: 0.7912 | F1: 0.7978
2026-02-10 10:33:37,864 - INFO - [Best Model Saved] (val loss: 0.5193) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:33:37,864 - INFO - --------------------------------------------------
2026-02-10 10:33:37,864 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 10:33:39,961 - INFO - [Train] [7/10] | Loss: 0.4727 | Train Acc: 82.81%
2026-02-10 10:33:40,730 - INFO - [Valid] [7/10] | Loss: 0.5089 | Val Acc: 78.76%
2026-02-10 10:33:40,733 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.7580 | F1: 0.7677
2026-02-10 10:33:40,733 - INFO - [Metrics for 'normal'] | Precision: 0.7957 | Recall: 0.8132 | F1: 0.8043
2026-02-10 10:33:40,789 - INFO - [Best Model Saved] (val loss: 0.5089) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:33:40,789 - INFO - --------------------------------------------------
2026-02-10 10:33:40,789 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 10:33:42,922 - INFO - [Train] [8/10] | Loss: 0.4571 | Train Acc: 83.63%
2026-02-10 10:33:43,646 - INFO - [Valid] [8/10] | Loss: 0.5129 | Val Acc: 77.88%
2026-02-10 10:33:43,650 - INFO - [Metrics for 'abnormal'] | Precision: 0.7303 | Recall: 0.8280 | F1: 0.7761
2026-02-10 10:33:43,650 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7363 | F1: 0.7813
2026-02-10 10:33:43,651 - INFO - --------------------------------------------------
2026-02-10 10:33:43,652 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 10:33:45,656 - INFO - [Train] [9/10] | Loss: 0.4452 | Train Acc: 83.56%
2026-02-10 10:33:46,400 - INFO - [Valid] [9/10] | Loss: 0.5010 | Val Acc: 80.83%
2026-02-10 10:33:46,404 - INFO - [Metrics for 'abnormal'] | Precision: 0.8026 | Recall: 0.7771 | F1: 0.7896
2026-02-10 10:33:46,405 - INFO - [Metrics for 'normal'] | Precision: 0.8128 | Recall: 0.8352 | F1: 0.8238
2026-02-10 10:33:46,461 - INFO - [Best Model Saved] (val loss: 0.5010) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:33:46,462 - INFO - --------------------------------------------------
2026-02-10 10:33:46,462 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 10:33:48,663 - INFO - [Train] [10/10] | Loss: 0.4431 | Train Acc: 85.27%
2026-02-10 10:33:49,426 - INFO - [Valid] [10/10] | Loss: 0.5045 | Val Acc: 82.01%
2026-02-10 10:33:49,430 - INFO - [Metrics for 'abnormal'] | Precision: 0.8077 | Recall: 0.8025 | F1: 0.8051
2026-02-10 10:33:49,430 - INFO - [Metrics for 'normal'] | Precision: 0.8306 | Recall: 0.8352 | F1: 0.8329
2026-02-10 10:33:49,435 - INFO - ================================================================================
2026-02-10 10:33:49,435 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 10:33:49,435 - INFO - ================================================================================
2026-02-10 10:33:49,457 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'을(를) 불러왔습니다.
2026-02-10 10:33:49,457 - INFO - ================================================================================
2026-02-10 10:33:49,457 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 10:33:49,458 - INFO - 원본 모델 파라미터: 9.1602M
2026-02-10 10:33:49,460 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:33:49,460 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:33:49,460 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:33:51,481 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:33:51,927 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 10:33:51,927 - INFO - ==================================================
2026-02-10 10:33:51,927 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 2.3194M (감소율: 74.68%)
2026-02-10 10:33:51,929 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:33:51,929 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:33:51,929 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:33:53,903 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:33:54,295 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 10:33:54,295 - INFO - ==================================================
2026-02-10 10:33:54,295 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.5934M (감소율: 93.52%)
2026-02-10 10:33:54,297 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:33:54,297 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:33:54,297 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:33:56,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:33:56,759 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 10:33:56,760 - INFO - ==================================================
2026-02-10 10:33:56,760 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.1643M (감소율: 98.21%)
2026-02-10 10:33:56,762 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:33:56,762 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:33:56,762 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:33:58,964 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:33:59,375 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 10:33:59,376 - INFO - ==================================================
2026-02-10 10:33:59,376 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:33:59,378 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:33:59,378 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:33:59,378 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:01,431 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:02,125 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-02-10 10:34:02,125 - INFO - ==================================================
2026-02-10 10:34:02,125 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0975M (감소율: 98.94%)
2026-02-10 10:34:02,128 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:02,128 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:02,129 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:04,167 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:04,583 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-02-10 10:34:04,584 - INFO - ==================================================
2026-02-10 10:34:04,584 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0702M (감소율: 99.23%)
2026-02-10 10:34:04,585 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:04,586 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:04,586 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:06,621 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:07,002 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.920390625)에 맞춰 변경되었습니다.
2026-02-10 10:34:07,003 - INFO - ==================================================
2026-02-10 10:34:07,003 - INFO -   [탐색  7] 희소도: 0.9204 -> 파라미터: 0.0585M (감소율: 99.36%)
2026-02-10 10:34:07,005 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:07,005 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:07,005 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:08,996 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:09,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9242578125)에 맞춰 변경되었습니다.
2026-02-10 10:34:09,347 - INFO - ==================================================
2026-02-10 10:34:09,347 - INFO -   [탐색  8] 희소도: 0.9243 -> 파라미터: 0.0500M (감소율: 99.45%)
2026-02-10 10:34:09,348 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:09,348 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:09,348 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:11,279 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:11,667 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9261914062500001)에 맞춰 변경되었습니다.
2026-02-10 10:34:11,667 - INFO - ==================================================
2026-02-10 10:34:11,667 - INFO -   [탐색  9] 희소도: 0.9262 -> 파라미터: 0.0487M (감소율: 99.47%)
2026-02-10 10:34:11,669 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:11,669 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:11,669 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:13,878 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:14,296 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9271582031250001)에 맞춰 변경되었습니다.
2026-02-10 10:34:14,296 - INFO - ==================================================
2026-02-10 10:34:14,296 - INFO -   [탐색 10] 희소도: 0.9272 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:14,298 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:14,298 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:14,299 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:16,458 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:17,193 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9276416015625)에 맞춰 변경되었습니다.
2026-02-10 10:34:17,193 - INFO - ==================================================
2026-02-10 10:34:17,194 - INFO -   [탐색 11] 희소도: 0.9276 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:17,195 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:17,195 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:17,195 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:19,213 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:19,543 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9278833007812499)에 맞춰 변경되었습니다.
2026-02-10 10:34:19,543 - INFO - ==================================================
2026-02-10 10:34:19,544 - INFO -   [탐색 12] 희소도: 0.9279 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:19,545 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:19,545 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:19,545 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:21,426 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:21,783 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927762451171875)에 맞춰 변경되었습니다.
2026-02-10 10:34:21,783 - INFO - ==================================================
2026-02-10 10:34:21,784 - INFO -   [탐색 13] 희소도: 0.9278 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:21,786 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:21,786 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:21,786 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:23,809 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:24,150 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277020263671875)에 맞춰 변경되었습니다.
2026-02-10 10:34:24,150 - INFO - ==================================================
2026-02-10 10:34:24,150 - INFO -   [탐색 14] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:24,152 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:24,152 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:24,152 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:25,988 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:26,424 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277322387695313)에 맞춰 변경되었습니다.
2026-02-10 10:34:26,424 - INFO - ==================================================
2026-02-10 10:34:26,425 - INFO -   [탐색 15] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:26,426 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:26,427 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:26,427 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:28,594 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:28,919 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277473449707031)에 맞춰 변경되었습니다.
2026-02-10 10:34:28,919 - INFO - ==================================================
2026-02-10 10:34:28,919 - INFO -   [탐색 16] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:28,921 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:28,921 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:28,921 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:30,997 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:31,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277397918701171)에 맞춰 변경되었습니다.
2026-02-10 10:34:31,681 - INFO - ==================================================
2026-02-10 10:34:31,681 - INFO -   [탐색 17] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:31,682 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:31,682 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:31,683 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:33,650 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:34,050 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277360153198242)에 맞춰 변경되었습니다.
2026-02-10 10:34:34,050 - INFO - ==================================================
2026-02-10 10:34:34,051 - INFO -   [탐색 18] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:34,052 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:34,052 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:34,052 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:36,096 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:36,509 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277341270446777)에 맞춰 변경되었습니다.
2026-02-10 10:34:36,509 - INFO - ==================================================
2026-02-10 10:34:36,509 - INFO -   [탐색 19] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:36,511 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:36,511 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:36,511 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:38,496 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:38,884 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927735071182251)에 맞춰 변경되었습니다.
2026-02-10 10:34:38,884 - INFO - ==================================================
2026-02-10 10:34:38,885 - INFO -   [탐색 20] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:38,886 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:38,886 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:38,886 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:40,747 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:41,160 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277345991134643)에 맞춰 변경되었습니다.
2026-02-10 10:34:41,160 - INFO - ==================================================
2026-02-10 10:34:41,161 - INFO -   [탐색 21] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:41,163 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:41,163 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:41,163 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:43,223 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:43,966 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343630790711)에 맞춰 변경되었습니다.
2026-02-10 10:34:43,966 - INFO - ==================================================
2026-02-10 10:34:43,966 - INFO -   [탐색 22] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:43,968 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:43,968 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:43,968 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:45,887 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:46,320 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277344810962678)에 맞춰 변경되었습니다.
2026-02-10 10:34:46,320 - INFO - ==================================================
2026-02-10 10:34:46,321 - INFO -   [탐색 23] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:46,322 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:46,322 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:46,322 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:48,591 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:48,954 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277344220876694)에 맞춰 변경되었습니다.
2026-02-10 10:34:48,954 - INFO - ==================================================
2026-02-10 10:34:48,954 - INFO -   [탐색 24] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:48,955 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:48,955 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:48,956 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:50,995 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:51,383 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343925833703)에 맞춰 변경되었습니다.
2026-02-10 10:34:51,383 - INFO - ==================================================
2026-02-10 10:34:51,383 - INFO -   [탐색 25] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:51,384 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:51,384 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:51,384 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:53,392 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:53,787 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343778312207)에 맞춰 변경되었습니다.
2026-02-10 10:34:53,788 - INFO - ==================================================
2026-02-10 10:34:53,788 - INFO -   [탐색 26] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:34:53,789 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:53,789 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:53,789 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:55,581 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:55,909 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734370455146)에 맞춰 변경되었습니다.
2026-02-10 10:34:55,909 - INFO - ==================================================
2026-02-10 10:34:55,909 - INFO -   [탐색 27] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:55,911 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:55,911 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:55,911 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:34:57,902 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:34:58,316 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343741431834)에 맞춰 변경되었습니다.
2026-02-10 10:34:58,316 - INFO - ==================================================
2026-02-10 10:34:58,316 - INFO -   [탐색 28] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:34:58,318 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:34:58,318 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:34:58,318 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:00,397 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:01,126 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343759872021)에 맞춰 변경되었습니다.
2026-02-10 10:35:01,126 - INFO - ==================================================
2026-02-10 10:35:01,126 - INFO -   [탐색 29] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:01,128 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:01,128 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:01,128 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:03,189 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:03,602 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750651927)에 맞춰 변경되었습니다.
2026-02-10 10:35:03,602 - INFO - ==================================================
2026-02-10 10:35:03,602 - INFO -   [탐색 30] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:03,604 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:03,604 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:03,604 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:05,681 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:06,045 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343746041881)에 맞춰 변경되었습니다.
2026-02-10 10:35:06,045 - INFO - ==================================================
2026-02-10 10:35:06,045 - INFO -   [탐색 31] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:06,046 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:06,046 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:06,046 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:08,073 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:08,466 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343748346905)에 맞춰 변경되었습니다.
2026-02-10 10:35:08,466 - INFO - ==================================================
2026-02-10 10:35:08,466 - INFO -   [탐색 32] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:08,467 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:08,467 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:08,467 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:10,471 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:10,860 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749499416)에 맞춰 변경되었습니다.
2026-02-10 10:35:10,860 - INFO - ==================================================
2026-02-10 10:35:10,872 - INFO -   [탐색 33] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:10,874 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:10,874 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:10,874 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:12,522 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:12,938 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750075672)에 맞춰 변경되었습니다.
2026-02-10 10:35:12,938 - INFO - ==================================================
2026-02-10 10:35:12,939 - INFO -   [탐색 34] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:12,941 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:12,941 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:12,941 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:14,873 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:15,485 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749787543)에 맞춰 변경되었습니다.
2026-02-10 10:35:15,485 - INFO - ==================================================
2026-02-10 10:35:15,485 - INFO -   [탐색 35] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:15,486 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:15,486 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:15,486 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:17,560 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:17,998 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749931608)에 맞춰 변경되었습니다.
2026-02-10 10:35:17,998 - INFO - ==================================================
2026-02-10 10:35:17,998 - INFO -   [탐색 36] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:18,000 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:18,000 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:18,000 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:19,967 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:20,290 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750003639)에 맞춰 변경되었습니다.
2026-02-10 10:35:20,290 - INFO - ==================================================
2026-02-10 10:35:20,290 - INFO -   [탐색 37] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:20,292 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:20,292 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:20,292 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:22,325 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:22,767 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749967624)에 맞춰 변경되었습니다.
2026-02-10 10:35:22,767 - INFO - ==================================================
2026-02-10 10:35:22,767 - INFO -   [탐색 38] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:22,769 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:22,769 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:22,769 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:24,721 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:25,131 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749985631)에 맞춰 변경되었습니다.
2026-02-10 10:35:25,132 - INFO - ==================================================
2026-02-10 10:35:25,132 - INFO -   [탐색 39] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:25,134 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:25,134 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:25,134 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:27,128 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:27,551 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749994635)에 맞춰 변경되었습니다.
2026-02-10 10:35:27,551 - INFO - ==================================================
2026-02-10 10:35:27,552 - INFO -   [탐색 40] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:27,554 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:27,554 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:27,554 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:29,606 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:30,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749999137)에 맞춰 변경되었습니다.
2026-02-10 10:35:30,309 - INFO - ==================================================
2026-02-10 10:35:30,309 - INFO -   [탐색 41] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:30,311 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:30,311 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:30,311 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:32,303 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:32,732 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750001388)에 맞춰 변경되었습니다.
2026-02-10 10:35:32,732 - INFO - ==================================================
2026-02-10 10:35:32,733 - INFO -   [탐색 42] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:32,735 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:32,735 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:32,735 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:34,785 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:35,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000262)에 맞춰 변경되었습니다.
2026-02-10 10:35:35,177 - INFO - ==================================================
2026-02-10 10:35:35,177 - INFO -   [탐색 43] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:35,179 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:35,179 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:35,179 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:37,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:37,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.92773437499997)에 맞춰 변경되었습니다.
2026-02-10 10:35:37,492 - INFO - ==================================================
2026-02-10 10:35:37,493 - INFO -   [탐색 44] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:37,495 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:37,495 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:37,495 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:39,472 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:39,895 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749999981)에 맞춰 변경되었습니다.
2026-02-10 10:35:39,895 - INFO - ==================================================
2026-02-10 10:35:39,895 - INFO -   [탐색 45] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:39,897 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:39,897 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:39,897 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:41,785 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:42,211 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000122)에 맞춰 변경되었습니다.
2026-02-10 10:35:42,211 - INFO - ==================================================
2026-02-10 10:35:42,211 - INFO -   [탐색 46] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:42,213 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:42,213 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:42,213 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:44,243 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:44,958 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000051)에 맞춰 변경되었습니다.
2026-02-10 10:35:44,958 - INFO - ==================================================
2026-02-10 10:35:44,958 - INFO -   [탐색 47] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:44,960 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:44,960 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:44,960 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:47,049 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:47,411 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000016)에 맞춰 변경되었습니다.
2026-02-10 10:35:47,411 - INFO - ==================================================
2026-02-10 10:35:47,412 - INFO -   [탐색 48] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:47,413 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:47,413 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:47,413 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:49,430 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:49,813 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749999998)에 맞춰 변경되었습니다.
2026-02-10 10:35:49,814 - INFO - ==================================================
2026-02-10 10:35:49,814 - INFO -   [탐색 49] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:49,815 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:49,815 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:49,815 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:51,924 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:52,295 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000007)에 맞춰 변경되었습니다.
2026-02-10 10:35:52,295 - INFO - ==================================================
2026-02-10 10:35:52,295 - INFO -   [탐색 50] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:52,296 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:52,296 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:52,296 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:54,324 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:54,649 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000002)에 맞춰 변경되었습니다.
2026-02-10 10:35:54,649 - INFO - ==================================================
2026-02-10 10:35:54,649 - INFO -   [탐색 51] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:54,651 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:54,651 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:54,651 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:56,380 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:56,770 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:35:56,770 - INFO - ==================================================
2026-02-10 10:35:56,771 - INFO -   [탐색 52] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:35:56,772 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:56,772 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:56,772 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:35:58,802 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:35:59,217 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000001)에 맞춰 변경되었습니다.
2026-02-10 10:35:59,218 - INFO - ==================================================
2026-02-10 10:35:59,218 - INFO -   [탐색 53] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 10:35:59,220 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:35:59,220 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:35:59,220 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:01,151 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:01,798 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:01,799 - INFO - ==================================================
2026-02-10 10:36:01,799 - INFO -   [탐색 54] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:01,801 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:01,801 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:01,801 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:03,815 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:04,236 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:04,236 - INFO - ==================================================
2026-02-10 10:36:04,237 - INFO -   [탐색 55] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:04,238 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:04,238 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:04,238 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:06,193 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:06,566 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:06,567 - INFO - ==================================================
2026-02-10 10:36:06,567 - INFO -   [탐색 56] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:06,568 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:06,568 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:06,568 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:08,618 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:09,039 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:09,040 - INFO - ==================================================
2026-02-10 10:36:09,040 - INFO -   [탐색 57] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:09,042 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:09,042 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:09,042 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:11,091 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:11,501 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:11,501 - INFO - ==================================================
2026-02-10 10:36:11,502 - INFO -   [탐색 58] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:11,504 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:11,504 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:11,504 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:13,348 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:13,706 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:13,706 - INFO - ==================================================
2026-02-10 10:36:13,706 - INFO -   [탐색 59] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:13,708 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:13,708 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:13,708 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:15,821 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:16,477 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:16,477 - INFO - ==================================================
2026-02-10 10:36:16,478 - INFO -   [탐색 60] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:16,479 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:16,479 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:16,479 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:18,586 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:19,000 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:19,000 - INFO - ==================================================
2026-02-10 10:36:19,000 - INFO -   [탐색 61] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:19,001 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:19,002 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:19,002 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:20,914 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:21,266 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:21,267 - INFO - ==================================================
2026-02-10 10:36:21,267 - INFO -   [탐색 62] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:21,268 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:21,268 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:21,269 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:23,274 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:23,715 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:23,716 - INFO - ==================================================
2026-02-10 10:36:23,716 - INFO -   [탐색 63] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:23,717 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:23,718 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:23,718 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:25,832 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:26,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:26,156 - INFO - ==================================================
2026-02-10 10:36:26,156 - INFO -   [탐색 64] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:26,158 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:26,158 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:26,158 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:28,116 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:28,543 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:28,543 - INFO - ==================================================
2026-02-10 10:36:28,543 - INFO -   [탐색 65] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:28,546 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:28,546 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:28,546 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:30,702 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:31,397 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:31,397 - INFO - ==================================================
2026-02-10 10:36:31,397 - INFO -   [탐색 66] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:31,399 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:31,399 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:31,399 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:33,530 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:33,958 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:33,958 - INFO - ==================================================
2026-02-10 10:36:33,958 - INFO -   [탐색 67] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:33,960 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:33,960 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:33,961 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:36,023 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:36,420 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:36,420 - INFO - ==================================================
2026-02-10 10:36:36,420 - INFO -   [탐색 68] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:36,422 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:36,422 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:36,422 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:39,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:39,852 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:39,853 - INFO - ==================================================
2026-02-10 10:36:39,853 - INFO -   [탐색 69] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:39,855 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:39,855 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:39,855 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:42,984 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:43,511 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:43,512 - INFO - ==================================================
2026-02-10 10:36:43,512 - INFO -   [탐색 70] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:43,514 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:43,514 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:43,514 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:47,721 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:48,572 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:48,573 - INFO - ==================================================
2026-02-10 10:36:48,573 - INFO -   [탐색 71] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:48,575 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:48,575 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:48,575 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:52,624 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:53,168 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:53,168 - INFO - ==================================================
2026-02-10 10:36:53,169 - INFO -   [탐색 72] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:53,170 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:53,170 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:53,171 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:36:56,884 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:36:57,447 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:36:57,447 - INFO - ==================================================
2026-02-10 10:36:57,447 - INFO -   [탐색 73] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:36:57,450 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:36:57,450 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:36:57,450 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:01,596 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:02,138 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:02,138 - INFO - ==================================================
2026-02-10 10:37:02,139 - INFO -   [탐색 74] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:02,141 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:02,141 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:02,141 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:06,618 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:07,160 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:07,161 - INFO - ==================================================
2026-02-10 10:37:07,161 - INFO -   [탐색 75] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:07,164 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:07,164 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:07,164 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:10,782 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:11,373 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:11,374 - INFO - ==================================================
2026-02-10 10:37:11,374 - INFO -   [탐색 76] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:11,376 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:11,376 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:11,376 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:15,015 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:15,611 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:15,612 - INFO - ==================================================
2026-02-10 10:37:15,612 - INFO -   [탐색 77] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:15,615 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:15,615 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:15,615 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:20,065 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:21,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:21,060 - INFO - ==================================================
2026-02-10 10:37:21,060 - INFO -   [탐색 78] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:21,062 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:21,062 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:21,063 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:25,362 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:25,937 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:25,937 - INFO - ==================================================
2026-02-10 10:37:25,938 - INFO -   [탐색 79] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:25,939 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:25,939 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:25,940 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:30,667 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:31,248 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:31,248 - INFO - ==================================================
2026-02-10 10:37:31,249 - INFO -   [탐색 80] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:31,252 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:31,253 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:31,253 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:35,089 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:35,640 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:35,640 - INFO - ==================================================
2026-02-10 10:37:35,640 - INFO -   [탐색 81] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:35,642 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:35,642 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:35,642 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:39,310 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:39,832 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:39,832 - INFO - ==================================================
2026-02-10 10:37:39,832 - INFO -   [탐색 82] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:39,835 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:39,835 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:39,836 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:43,976 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:44,559 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:44,559 - INFO - ==================================================
2026-02-10 10:37:44,559 - INFO -   [탐색 83] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:44,561 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:44,562 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:44,562 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:48,760 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:49,695 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:49,695 - INFO - ==================================================
2026-02-10 10:37:49,695 - INFO -   [탐색 84] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:49,697 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:49,698 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:49,698 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:53,884 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:54,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:54,445 - INFO - ==================================================
2026-02-10 10:37:54,445 - INFO -   [탐색 85] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:54,448 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:54,448 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:54,448 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:58,717 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:59,301 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:37:59,302 - INFO - ==================================================
2026-02-10 10:37:59,302 - INFO -   [탐색 86] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:37:59,304 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:59,305 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:59,305 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:03,453 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:04,028 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:04,029 - INFO - ==================================================
2026-02-10 10:38:04,029 - INFO -   [탐색 87] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:04,031 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:04,031 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:04,031 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:08,519 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:09,086 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:09,086 - INFO - ==================================================
2026-02-10 10:38:09,087 - INFO -   [탐색 88] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:09,089 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:09,089 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:09,089 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:13,295 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:13,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:13,863 - INFO - ==================================================
2026-02-10 10:38:13,863 - INFO -   [탐색 89] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:13,865 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:13,865 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:13,865 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:18,494 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:19,486 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:19,487 - INFO - ==================================================
2026-02-10 10:38:19,487 - INFO -   [탐색 90] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:19,490 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:19,490 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:19,490 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:23,985 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:24,544 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:24,544 - INFO - ==================================================
2026-02-10 10:38:24,545 - INFO -   [탐색 91] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:24,547 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:24,547 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:24,547 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:28,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:29,422 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:29,422 - INFO - ==================================================
2026-02-10 10:38:29,423 - INFO -   [탐색 92] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:29,424 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:29,425 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:29,425 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:33,533 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:34,105 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:34,106 - INFO - ==================================================
2026-02-10 10:38:34,106 - INFO -   [탐색 93] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:34,108 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:34,108 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:34,108 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:37,987 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:38,535 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:38,535 - INFO - ==================================================
2026-02-10 10:38:38,536 - INFO -   [탐색 94] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:38,538 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:38,538 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:38,538 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:42,299 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:42,867 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:42,867 - INFO - ==================================================
2026-02-10 10:38:42,867 - INFO -   [탐색 95] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:42,869 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:42,869 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:42,869 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:47,294 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:48,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:48,268 - INFO - ==================================================
2026-02-10 10:38:48,269 - INFO -   [탐색 96] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:48,271 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:48,271 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:48,271 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:52,654 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:53,239 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:53,239 - INFO - ==================================================
2026-02-10 10:38:53,239 - INFO -   [탐색 97] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:53,241 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:53,241 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:53,241 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:57,876 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:58,470 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:38:58,471 - INFO - ==================================================
2026-02-10 10:38:58,472 - INFO -   [탐색 98] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:38:58,474 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:58,474 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:58,474 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:02,827 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:03,369 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:39:03,370 - INFO - ==================================================
2026-02-10 10:39:03,370 - INFO -   [탐색 99] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:39:03,373 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:03,374 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:03,374 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:07,242 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:07,766 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 10:39:07,766 - INFO - ==================================================
2026-02-10 10:39:07,766 - INFO -   [탐색 100] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 10:39:07,766 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.9281 입니다.
2026-02-10 10:39:07,767 - INFO - ================================================================================
2026-02-10 10:39:07,768 - INFO - 계산된 Pruning 정보(희소도: 0.9281)를 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/pruning_info.yaml'에 저장했습니다.
2026-02-10 10:39:07,772 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 10:39:07,777 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:07,777 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:07,777 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:12,270 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:12,807 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 10:39:12,808 - INFO - ==================================================
2026-02-10 10:39:12,808 - INFO - ==================================================
2026-02-10 10:39:12,808 - INFO - 모델 파라미터 수:
2026-02-10 10:39:12,808 - INFO -   - 총 파라미터: 47,386 개
2026-02-10 10:39:12,808 - INFO -   - 학습 가능한 파라미터: 47,386 개
2026-02-10 10:39:12,815 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 10:39:12,820 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1481 GFLOPs로 감소했습니다 (감소율: 94.84%).
2026-02-10 10:39:12,820 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 10:39:12,820 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 10:39:12,820 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 10:39:12,821 - INFO - ==================================================
2026-02-10 10:39:12,821 - INFO - train 모드를 시작합니다.
2026-02-10 10:39:12,821 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 10:39:12,821 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 10:39:12,821 - INFO - --------------------------------------------------
2026-02-10 10:39:12,821 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 10:39:17,450 - INFO - [Train] [11/90] | Loss: 0.5573 | Train Acc: 77.16%
2026-02-10 10:39:18,581 - INFO - [Valid] [11/90] | Loss: 0.5392 | Val Acc: 76.40%
2026-02-10 10:39:18,588 - INFO - [Metrics for 'abnormal'] | Precision: 0.7584 | Recall: 0.7197 | F1: 0.7386
2026-02-10 10:39:18,588 - INFO - [Metrics for 'normal'] | Precision: 0.7684 | Recall: 0.8022 | F1: 0.7849
2026-02-10 10:39:18,599 - INFO - [Best Model Saved] (val loss: 0.5392) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:39:18,599 - INFO - --------------------------------------------------
2026-02-10 10:39:18,599 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 10:39:23,548 - INFO - [Train] [12/90] | Loss: 0.5358 | Train Acc: 80.36%
2026-02-10 10:39:24,356 - INFO - [Valid] [12/90] | Loss: 0.5437 | Val Acc: 75.81%
2026-02-10 10:39:24,362 - INFO - [Metrics for 'abnormal'] | Precision: 0.7301 | Recall: 0.7580 | F1: 0.7438
2026-02-10 10:39:24,363 - INFO - [Metrics for 'normal'] | Precision: 0.7841 | Recall: 0.7582 | F1: 0.7709
2026-02-10 10:39:24,365 - INFO - --------------------------------------------------
2026-02-10 10:39:24,365 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 10:39:28,875 - INFO - [Train] [13/90] | Loss: 0.5109 | Train Acc: 80.06%
2026-02-10 10:39:29,674 - INFO - [Valid] [13/90] | Loss: 0.5590 | Val Acc: 72.57%
2026-02-10 10:39:29,679 - INFO - [Metrics for 'abnormal'] | Precision: 0.6584 | Recall: 0.8471 | F1: 0.7409
2026-02-10 10:39:29,679 - INFO - [Metrics for 'normal'] | Precision: 0.8248 | Recall: 0.6209 | F1: 0.7085
2026-02-10 10:39:29,681 - INFO - --------------------------------------------------
2026-02-10 10:39:29,681 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 10:39:34,435 - INFO - [Train] [14/90] | Loss: 0.5089 | Train Acc: 80.80%
2026-02-10 10:39:35,801 - INFO - [Valid] [14/90] | Loss: 0.5586 | Val Acc: 77.58%
2026-02-10 10:39:35,810 - INFO - [Metrics for 'abnormal'] | Precision: 0.8240 | Recall: 0.6561 | F1: 0.7305
2026-02-10 10:39:35,814 - INFO - [Metrics for 'normal'] | Precision: 0.7477 | Recall: 0.8791 | F1: 0.8081
2026-02-10 10:39:35,816 - INFO - --------------------------------------------------
2026-02-10 10:39:35,817 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 10:39:40,581 - INFO - [Train] [15/90] | Loss: 0.5079 | Train Acc: 81.47%
2026-02-10 10:39:41,775 - INFO - [Valid] [15/90] | Loss: 0.5283 | Val Acc: 76.11%
2026-02-10 10:39:41,783 - INFO - [Metrics for 'abnormal'] | Precision: 0.7346 | Recall: 0.7580 | F1: 0.7461
2026-02-10 10:39:41,783 - INFO - [Metrics for 'normal'] | Precision: 0.7853 | Recall: 0.7637 | F1: 0.7744
2026-02-10 10:39:41,791 - INFO - [Best Model Saved] (val loss: 0.5283) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:39:41,792 - INFO - --------------------------------------------------
2026-02-10 10:39:41,793 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 10:39:46,664 - INFO - [Train] [16/90] | Loss: 0.5021 | Train Acc: 80.73%
2026-02-10 10:39:47,902 - INFO - [Valid] [16/90] | Loss: 0.5230 | Val Acc: 77.88%
2026-02-10 10:39:47,907 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.7452 | F1: 0.7573
2026-02-10 10:39:47,908 - INFO - [Metrics for 'normal'] | Precision: 0.7861 | Recall: 0.8077 | F1: 0.7967
2026-02-10 10:39:47,912 - INFO - [Best Model Saved] (val loss: 0.5230) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:39:47,912 - INFO - --------------------------------------------------
2026-02-10 10:39:47,912 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 10:39:52,094 - INFO - [Train] [17/90] | Loss: 0.4887 | Train Acc: 82.07%
2026-02-10 10:39:53,371 - INFO - [Valid] [17/90] | Loss: 0.5267 | Val Acc: 78.76%
2026-02-10 10:39:53,377 - INFO - [Metrics for 'abnormal'] | Precision: 0.7815 | Recall: 0.7516 | F1: 0.7662
2026-02-10 10:39:53,377 - INFO - [Metrics for 'normal'] | Precision: 0.7926 | Recall: 0.8187 | F1: 0.8054
2026-02-10 10:39:53,378 - INFO - --------------------------------------------------
2026-02-10 10:39:53,379 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 10:39:57,133 - INFO - [Train] [18/90] | Loss: 0.4936 | Train Acc: 82.44%
2026-02-10 10:39:58,525 - INFO - [Valid] [18/90] | Loss: 0.5233 | Val Acc: 78.17%
2026-02-10 10:39:58,531 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-02-10 10:39:58,531 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-02-10 10:39:58,533 - INFO - --------------------------------------------------
2026-02-10 10:39:58,533 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 10:40:02,981 - INFO - [Train] [19/90] | Loss: 0.4781 | Train Acc: 83.71%
2026-02-10 10:40:04,204 - INFO - [Valid] [19/90] | Loss: 0.5219 | Val Acc: 77.88%
2026-02-10 10:40:04,209 - INFO - [Metrics for 'abnormal'] | Precision: 0.8015 | Recall: 0.6943 | F1: 0.7440
2026-02-10 10:40:04,216 - INFO - [Metrics for 'normal'] | Precision: 0.7635 | Recall: 0.8516 | F1: 0.8052
2026-02-10 10:40:04,222 - INFO - [Best Model Saved] (val loss: 0.5219) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:40:04,222 - INFO - --------------------------------------------------
2026-02-10 10:40:04,222 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 10:40:08,358 - INFO - [Train] [20/90] | Loss: 0.4822 | Train Acc: 82.07%
2026-02-10 10:40:09,541 - INFO - [Valid] [20/90] | Loss: 0.5047 | Val Acc: 79.94%
2026-02-10 10:40:09,546 - INFO - [Metrics for 'abnormal'] | Precision: 0.8450 | Recall: 0.6943 | F1: 0.7622
2026-02-10 10:40:09,546 - INFO - [Metrics for 'normal'] | Precision: 0.7714 | Recall: 0.8901 | F1: 0.8265
2026-02-10 10:40:09,551 - INFO - [Best Model Saved] (val loss: 0.5047) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:40:09,551 - INFO - --------------------------------------------------
2026-02-10 10:40:09,551 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 10:40:14,483 - INFO - [Train] [21/90] | Loss: 0.4739 | Train Acc: 82.74%
2026-02-10 10:40:15,262 - INFO - [Valid] [21/90] | Loss: 0.5147 | Val Acc: 78.47%
2026-02-10 10:40:15,267 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-02-10 10:40:15,267 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-02-10 10:40:15,268 - INFO - --------------------------------------------------
2026-02-10 10:40:15,268 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 10:40:20,027 - INFO - [Train] [22/90] | Loss: 0.4720 | Train Acc: 83.93%
2026-02-10 10:40:20,887 - INFO - [Valid] [22/90] | Loss: 0.5063 | Val Acc: 78.76%
2026-02-10 10:40:20,893 - INFO - [Metrics for 'abnormal'] | Precision: 0.7374 | Recall: 0.8408 | F1: 0.7857
2026-02-10 10:40:20,897 - INFO - [Metrics for 'normal'] | Precision: 0.8438 | Recall: 0.7418 | F1: 0.7895
2026-02-10 10:40:20,899 - INFO - --------------------------------------------------
2026-02-10 10:40:20,900 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 10:40:25,706 - INFO - [Train] [23/90] | Loss: 0.4674 | Train Acc: 83.71%
2026-02-10 10:40:26,897 - INFO - [Valid] [23/90] | Loss: 0.5123 | Val Acc: 77.88%
2026-02-10 10:40:26,902 - INFO - [Metrics for 'abnormal'] | Precision: 0.7356 | Recall: 0.8153 | F1: 0.7734
2026-02-10 10:40:26,902 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.7473 | F1: 0.7839
2026-02-10 10:40:26,904 - INFO - --------------------------------------------------
2026-02-10 10:40:26,904 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 10:40:31,577 - INFO - [Train] [24/90] | Loss: 0.4646 | Train Acc: 84.45%
2026-02-10 10:40:32,788 - INFO - [Valid] [24/90] | Loss: 0.5047 | Val Acc: 80.53%
2026-02-10 10:40:32,794 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-02-10 10:40:32,795 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-02-10 10:40:32,797 - INFO - --------------------------------------------------
2026-02-10 10:40:32,797 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 10:40:37,194 - INFO - [Train] [25/90] | Loss: 0.4616 | Train Acc: 84.08%
2026-02-10 10:40:38,363 - INFO - [Valid] [25/90] | Loss: 0.5280 | Val Acc: 76.70%
2026-02-10 10:40:38,367 - INFO - [Metrics for 'abnormal'] | Precision: 0.7167 | Recall: 0.8217 | F1: 0.7656
2026-02-10 10:40:38,368 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7198 | F1: 0.7683
2026-02-10 10:40:38,369 - INFO - --------------------------------------------------
2026-02-10 10:40:38,369 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 10:40:42,952 - INFO - [Train] [26/90] | Loss: 0.4500 | Train Acc: 83.93%
2026-02-10 10:40:44,227 - INFO - [Valid] [26/90] | Loss: 0.5088 | Val Acc: 81.12%
2026-02-10 10:40:44,239 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-02-10 10:40:44,240 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-02-10 10:40:44,242 - INFO - --------------------------------------------------
2026-02-10 10:40:44,242 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 10:40:48,583 - INFO - [Train] [27/90] | Loss: 0.4503 | Train Acc: 84.82%
2026-02-10 10:40:49,934 - INFO - [Valid] [27/90] | Loss: 0.4901 | Val Acc: 80.53%
2026-02-10 10:40:49,937 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7962 | F1: 0.7911
2026-02-10 10:40:49,937 - INFO - [Metrics for 'normal'] | Precision: 0.8222 | Recall: 0.8132 | F1: 0.8177
2026-02-10 10:40:49,939 - INFO - [Best Model Saved] (val loss: 0.4901) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:40:49,939 - INFO - --------------------------------------------------
2026-02-10 10:40:49,939 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 10:40:54,443 - INFO - [Train] [28/90] | Loss: 0.4606 | Train Acc: 84.97%
2026-02-10 10:40:55,412 - INFO - [Valid] [28/90] | Loss: 0.4902 | Val Acc: 82.60%
2026-02-10 10:40:55,417 - INFO - [Metrics for 'abnormal'] | Precision: 0.7882 | Recall: 0.8535 | F1: 0.8196
2026-02-10 10:40:55,417 - INFO - [Metrics for 'normal'] | Precision: 0.8639 | Recall: 0.8022 | F1: 0.8319
2026-02-10 10:40:55,418 - INFO - --------------------------------------------------
2026-02-10 10:40:55,419 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 10:41:00,336 - INFO - [Train] [29/90] | Loss: 0.4487 | Train Acc: 85.57%
2026-02-10 10:41:01,401 - INFO - [Valid] [29/90] | Loss: 0.4892 | Val Acc: 82.01%
2026-02-10 10:41:01,408 - INFO - [Metrics for 'abnormal'] | Precision: 0.8380 | Recall: 0.7580 | F1: 0.7960
2026-02-10 10:41:01,408 - INFO - [Metrics for 'normal'] | Precision: 0.8071 | Recall: 0.8736 | F1: 0.8391
2026-02-10 10:41:01,416 - INFO - [Best Model Saved] (val loss: 0.4892) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:41:01,416 - INFO - --------------------------------------------------
2026-02-10 10:41:01,417 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 10:41:06,020 - INFO - [Train] [30/90] | Loss: 0.4441 | Train Acc: 84.97%
2026-02-10 10:41:07,134 - INFO - [Valid] [30/90] | Loss: 0.4840 | Val Acc: 81.12%
2026-02-10 10:41:07,140 - INFO - [Metrics for 'abnormal'] | Precision: 0.8163 | Recall: 0.7643 | F1: 0.7895
2026-02-10 10:41:07,140 - INFO - [Metrics for 'normal'] | Precision: 0.8073 | Recall: 0.8516 | F1: 0.8289
2026-02-10 10:41:07,148 - INFO - [Best Model Saved] (val loss: 0.4840) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:41:07,148 - INFO - --------------------------------------------------
2026-02-10 10:41:07,148 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 10:41:11,374 - INFO - [Train] [31/90] | Loss: 0.4406 | Train Acc: 85.34%
2026-02-10 10:41:12,700 - INFO - [Valid] [31/90] | Loss: 0.4858 | Val Acc: 82.01%
2026-02-10 10:41:12,708 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-02-10 10:41:12,709 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-02-10 10:41:12,710 - INFO - --------------------------------------------------
2026-02-10 10:41:12,711 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 10:41:17,552 - INFO - [Train] [32/90] | Loss: 0.4336 | Train Acc: 85.94%
2026-02-10 10:41:18,891 - INFO - [Valid] [32/90] | Loss: 0.4802 | Val Acc: 82.89%
2026-02-10 10:41:18,896 - INFO - [Metrics for 'abnormal'] | Precision: 0.8153 | Recall: 0.8153 | F1: 0.8153
2026-02-10 10:41:18,899 - INFO - [Metrics for 'normal'] | Precision: 0.8407 | Recall: 0.8407 | F1: 0.8407
2026-02-10 10:41:18,903 - INFO - [Best Model Saved] (val loss: 0.4802) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:41:18,904 - INFO - --------------------------------------------------
2026-02-10 10:41:18,904 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 10:41:23,456 - INFO - [Train] [33/90] | Loss: 0.4295 | Train Acc: 85.71%
2026-02-10 10:41:24,957 - INFO - [Valid] [33/90] | Loss: 0.4916 | Val Acc: 82.60%
2026-02-10 10:41:24,969 - INFO - [Metrics for 'abnormal'] | Precision: 0.8311 | Recall: 0.7834 | F1: 0.8066
2026-02-10 10:41:24,969 - INFO - [Metrics for 'normal'] | Precision: 0.8220 | Recall: 0.8626 | F1: 0.8418
2026-02-10 10:41:24,971 - INFO - --------------------------------------------------
2026-02-10 10:41:24,976 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 10:41:29,605 - INFO - [Train] [34/90] | Loss: 0.4320 | Train Acc: 86.16%
2026-02-10 10:41:30,805 - INFO - [Valid] [34/90] | Loss: 0.4753 | Val Acc: 82.89%
2026-02-10 10:41:30,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.8037 | Recall: 0.8344 | F1: 0.8187
2026-02-10 10:41:30,811 - INFO - [Metrics for 'normal'] | Precision: 0.8523 | Recall: 0.8242 | F1: 0.8380
2026-02-10 10:41:30,817 - INFO - [Best Model Saved] (val loss: 0.4753) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:41:30,817 - INFO - --------------------------------------------------
2026-02-10 10:41:30,818 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 10:41:35,467 - INFO - [Train] [35/90] | Loss: 0.4355 | Train Acc: 86.09%
2026-02-10 10:41:36,483 - INFO - [Valid] [35/90] | Loss: 0.4849 | Val Acc: 83.19%
2026-02-10 10:41:36,487 - INFO - [Metrics for 'abnormal'] | Precision: 0.8049 | Recall: 0.8408 | F1: 0.8224
2026-02-10 10:41:36,492 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.8242 | F1: 0.8403
2026-02-10 10:41:36,495 - INFO - --------------------------------------------------
2026-02-10 10:41:36,496 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 10:41:41,393 - INFO - [Train] [36/90] | Loss: 0.4191 | Train Acc: 87.95%
2026-02-10 10:41:42,696 - INFO - [Valid] [36/90] | Loss: 0.4799 | Val Acc: 82.60%
2026-02-10 10:41:42,704 - INFO - [Metrics for 'abnormal'] | Precision: 0.8267 | Recall: 0.7898 | F1: 0.8078
2026-02-10 10:41:42,704 - INFO - [Metrics for 'normal'] | Precision: 0.8254 | Recall: 0.8571 | F1: 0.8410
2026-02-10 10:41:42,707 - INFO - --------------------------------------------------
2026-02-10 10:41:42,707 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 10:41:47,185 - INFO - [Train] [37/90] | Loss: 0.4241 | Train Acc: 86.98%
2026-02-10 10:41:48,483 - INFO - [Valid] [37/90] | Loss: 0.4687 | Val Acc: 82.89%
2026-02-10 10:41:48,488 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8408 | F1: 0.8199
2026-02-10 10:41:48,489 - INFO - [Metrics for 'normal'] | Precision: 0.8563 | Recall: 0.8187 | F1: 0.8371
2026-02-10 10:41:48,494 - INFO - [Best Model Saved] (val loss: 0.4687) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:41:48,494 - INFO - --------------------------------------------------
2026-02-10 10:41:48,494 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 10:41:53,058 - INFO - [Train] [38/90] | Loss: 0.4226 | Train Acc: 86.53%
2026-02-10 10:41:54,465 - INFO - [Valid] [38/90] | Loss: 0.4778 | Val Acc: 82.01%
2026-02-10 10:41:54,471 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-02-10 10:41:54,475 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-02-10 10:41:54,478 - INFO - --------------------------------------------------
2026-02-10 10:41:54,478 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 10:41:58,608 - INFO - [Train] [39/90] | Loss: 0.4132 | Train Acc: 87.43%
2026-02-10 10:41:59,920 - INFO - [Valid] [39/90] | Loss: 0.4914 | Val Acc: 79.65%
2026-02-10 10:41:59,926 - INFO - [Metrics for 'abnormal'] | Precision: 0.7391 | Recall: 0.8662 | F1: 0.7977
2026-02-10 10:41:59,926 - INFO - [Metrics for 'normal'] | Precision: 0.8645 | Recall: 0.7363 | F1: 0.7953
2026-02-10 10:41:59,928 - INFO - --------------------------------------------------
2026-02-10 10:41:59,929 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 10:42:04,235 - INFO - [Train] [40/90] | Loss: 0.4181 | Train Acc: 87.50%
2026-02-10 10:42:05,496 - INFO - [Valid] [40/90] | Loss: 0.4687 | Val Acc: 82.89%
2026-02-10 10:42:05,502 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.8025 | F1: 0.8129
2026-02-10 10:42:05,502 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8516 | F1: 0.8424
2026-02-10 10:42:05,503 - INFO - --------------------------------------------------
2026-02-10 10:42:05,504 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 10:42:10,295 - INFO - [Train] [41/90] | Loss: 0.4141 | Train Acc: 87.50%
2026-02-10 10:42:11,576 - INFO - [Valid] [41/90] | Loss: 0.4704 | Val Acc: 83.48%
2026-02-10 10:42:11,580 - INFO - [Metrics for 'abnormal'] | Precision: 0.8217 | Recall: 0.8217 | F1: 0.8217
2026-02-10 10:42:11,583 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.8462 | F1: 0.8462
2026-02-10 10:42:11,585 - INFO - --------------------------------------------------
2026-02-10 10:42:11,585 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 10:42:16,118 - INFO - [Train] [42/90] | Loss: 0.4041 | Train Acc: 88.02%
2026-02-10 10:42:17,419 - INFO - [Valid] [42/90] | Loss: 0.4687 | Val Acc: 82.89%
2026-02-10 10:42:17,428 - INFO - [Metrics for 'abnormal'] | Precision: 0.8037 | Recall: 0.8344 | F1: 0.8187
2026-02-10 10:42:17,428 - INFO - [Metrics for 'normal'] | Precision: 0.8523 | Recall: 0.8242 | F1: 0.8380
2026-02-10 10:42:17,430 - INFO - --------------------------------------------------
2026-02-10 10:42:17,430 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 10:42:21,940 - INFO - [Train] [43/90] | Loss: 0.4039 | Train Acc: 87.95%
2026-02-10 10:42:23,056 - INFO - [Valid] [43/90] | Loss: 0.4694 | Val Acc: 82.60%
2026-02-10 10:42:23,061 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8280 | F1: 0.8150
2026-02-10 10:42:23,061 - INFO - [Metrics for 'normal'] | Precision: 0.8475 | Recall: 0.8242 | F1: 0.8357
2026-02-10 10:42:23,062 - INFO - --------------------------------------------------
2026-02-10 10:42:23,062 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 10:42:27,528 - INFO - [Train] [44/90] | Loss: 0.3946 | Train Acc: 88.10%
2026-02-10 10:42:28,666 - INFO - [Valid] [44/90] | Loss: 0.4807 | Val Acc: 81.71%
2026-02-10 10:42:28,676 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-02-10 10:42:28,680 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-02-10 10:42:28,683 - INFO - --------------------------------------------------
2026-02-10 10:42:28,683 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 10:42:32,887 - INFO - [Train] [45/90] | Loss: 0.3975 | Train Acc: 88.24%
2026-02-10 10:42:34,174 - INFO - [Valid] [45/90] | Loss: 0.4827 | Val Acc: 81.12%
2026-02-10 10:42:34,182 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.8471 | F1: 0.8061
2026-02-10 10:42:34,182 - INFO - [Metrics for 'normal'] | Precision: 0.8554 | Recall: 0.7802 | F1: 0.8161
2026-02-10 10:42:34,185 - INFO - --------------------------------------------------
2026-02-10 10:42:34,185 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 10:42:38,838 - INFO - [Train] [46/90] | Loss: 0.3974 | Train Acc: 88.84%
2026-02-10 10:42:39,950 - INFO - [Valid] [46/90] | Loss: 0.4743 | Val Acc: 83.19%
2026-02-10 10:42:39,960 - INFO - [Metrics for 'abnormal'] | Precision: 0.8205 | Recall: 0.8153 | F1: 0.8179
2026-02-10 10:42:39,960 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.8462 | F1: 0.8438
2026-02-10 10:42:39,962 - INFO - --------------------------------------------------
2026-02-10 10:42:39,963 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 10:42:44,534 - INFO - [Train] [47/90] | Loss: 0.3882 | Train Acc: 88.76%
2026-02-10 10:42:45,691 - INFO - [Valid] [47/90] | Loss: 0.4747 | Val Acc: 81.42%
2026-02-10 10:42:45,701 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-02-10 10:42:45,705 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-02-10 10:42:45,708 - INFO - --------------------------------------------------
2026-02-10 10:42:45,708 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 10:42:49,906 - INFO - [Train] [48/90] | Loss: 0.3987 | Train Acc: 88.39%
2026-02-10 10:42:51,116 - INFO - [Valid] [48/90] | Loss: 0.4833 | Val Acc: 82.89%
2026-02-10 10:42:51,125 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.8025 | F1: 0.8129
2026-02-10 10:42:51,126 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8516 | F1: 0.8424
2026-02-10 10:42:51,127 - INFO - --------------------------------------------------
2026-02-10 10:42:51,128 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 10:42:55,537 - INFO - [Train] [49/90] | Loss: 0.3938 | Train Acc: 87.72%
2026-02-10 10:42:56,803 - INFO - [Valid] [49/90] | Loss: 0.4756 | Val Acc: 81.42%
2026-02-10 10:42:56,808 - INFO - [Metrics for 'abnormal'] | Precision: 0.7798 | Recall: 0.8344 | F1: 0.8062
2026-02-10 10:42:56,809 - INFO - [Metrics for 'normal'] | Precision: 0.8480 | Recall: 0.7967 | F1: 0.8215
2026-02-10 10:42:56,810 - INFO - --------------------------------------------------
2026-02-10 10:42:56,811 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 10:43:00,990 - INFO - [Train] [50/90] | Loss: 0.3950 | Train Acc: 89.66%
2026-02-10 10:43:02,226 - INFO - [Valid] [50/90] | Loss: 0.4806 | Val Acc: 80.83%
2026-02-10 10:43:02,231 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-02-10 10:43:02,232 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-02-10 10:43:02,233 - INFO - --------------------------------------------------
2026-02-10 10:43:02,234 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 10:43:06,676 - INFO - [Train] [51/90] | Loss: 0.3889 | Train Acc: 90.40%
2026-02-10 10:43:07,670 - INFO - [Valid] [51/90] | Loss: 0.4728 | Val Acc: 82.01%
2026-02-10 10:43:07,676 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-02-10 10:43:07,676 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-02-10 10:43:07,678 - INFO - --------------------------------------------------
2026-02-10 10:43:07,678 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 10:43:12,540 - INFO - [Train] [52/90] | Loss: 0.3907 | Train Acc: 89.58%
2026-02-10 10:43:13,771 - INFO - [Valid] [52/90] | Loss: 0.4703 | Val Acc: 82.60%
2026-02-10 10:43:13,776 - INFO - [Metrics for 'abnormal'] | Precision: 0.7882 | Recall: 0.8535 | F1: 0.8196
2026-02-10 10:43:13,776 - INFO - [Metrics for 'normal'] | Precision: 0.8639 | Recall: 0.8022 | F1: 0.8319
2026-02-10 10:43:13,778 - INFO - --------------------------------------------------
2026-02-10 10:43:13,778 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 10:43:18,105 - INFO - [Train] [53/90] | Loss: 0.3782 | Train Acc: 89.73%
2026-02-10 10:43:19,143 - INFO - [Valid] [53/90] | Loss: 0.4820 | Val Acc: 82.89%
2026-02-10 10:43:19,149 - INFO - [Metrics for 'abnormal'] | Precision: 0.8075 | Recall: 0.8280 | F1: 0.8176
2026-02-10 10:43:19,153 - INFO - [Metrics for 'normal'] | Precision: 0.8483 | Recall: 0.8297 | F1: 0.8389
2026-02-10 10:43:19,155 - INFO - --------------------------------------------------
2026-02-10 10:43:19,156 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 10:43:23,753 - INFO - [Train] [54/90] | Loss: 0.3840 | Train Acc: 89.81%
2026-02-10 10:43:24,994 - INFO - [Valid] [54/90] | Loss: 0.4672 | Val Acc: 82.60%
2026-02-10 10:43:25,004 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-02-10 10:43:25,004 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-02-10 10:43:25,010 - INFO - [Best Model Saved] (val loss: 0.4672) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:43:25,010 - INFO - --------------------------------------------------
2026-02-10 10:43:25,010 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 10:43:29,432 - INFO - [Train] [55/90] | Loss: 0.3763 | Train Acc: 90.10%
2026-02-10 10:43:30,681 - INFO - [Valid] [55/90] | Loss: 0.4699 | Val Acc: 84.37%
2026-02-10 10:43:30,689 - INFO - [Metrics for 'abnormal'] | Precision: 0.8377 | Recall: 0.8217 | F1: 0.8296
2026-02-10 10:43:30,690 - INFO - [Metrics for 'normal'] | Precision: 0.8486 | Recall: 0.8626 | F1: 0.8556
2026-02-10 10:43:30,691 - INFO - --------------------------------------------------
2026-02-10 10:43:30,695 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 10:43:35,368 - INFO - [Train] [56/90] | Loss: 0.3724 | Train Acc: 90.33%
2026-02-10 10:43:36,591 - INFO - [Valid] [56/90] | Loss: 0.4849 | Val Acc: 81.42%
2026-02-10 10:43:36,599 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-02-10 10:43:36,601 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-02-10 10:43:36,603 - INFO - --------------------------------------------------
2026-02-10 10:43:36,603 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 10:43:40,206 - INFO - [Train] [57/90] | Loss: 0.3735 | Train Acc: 89.88%
2026-02-10 10:43:41,544 - INFO - [Valid] [57/90] | Loss: 0.4772 | Val Acc: 82.30%
2026-02-10 10:43:41,549 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8280 | F1: 0.8125
2026-02-10 10:43:41,550 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.8187 | F1: 0.8324
2026-02-10 10:43:41,551 - INFO - --------------------------------------------------
2026-02-10 10:43:41,551 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 10:43:45,960 - INFO - [Train] [58/90] | Loss: 0.3701 | Train Acc: 90.10%
2026-02-10 10:43:47,285 - INFO - [Valid] [58/90] | Loss: 0.4750 | Val Acc: 81.71%
2026-02-10 10:43:47,290 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-02-10 10:43:47,290 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-02-10 10:43:47,292 - INFO - --------------------------------------------------
2026-02-10 10:43:47,292 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 10:43:51,763 - INFO - [Train] [59/90] | Loss: 0.3634 | Train Acc: 91.00%
2026-02-10 10:43:53,078 - INFO - [Valid] [59/90] | Loss: 0.4842 | Val Acc: 82.01%
2026-02-10 10:43:53,087 - INFO - [Metrics for 'abnormal'] | Precision: 0.7857 | Recall: 0.8408 | F1: 0.8123
2026-02-10 10:43:53,087 - INFO - [Metrics for 'normal'] | Precision: 0.8538 | Recall: 0.8022 | F1: 0.8272
2026-02-10 10:43:53,089 - INFO - --------------------------------------------------
2026-02-10 10:43:53,089 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 10:43:57,891 - INFO - [Train] [60/90] | Loss: 0.3652 | Train Acc: 91.44%
2026-02-10 10:43:58,936 - INFO - [Valid] [60/90] | Loss: 0.4735 | Val Acc: 82.89%
2026-02-10 10:43:58,940 - INFO - [Metrics for 'abnormal'] | Precision: 0.8037 | Recall: 0.8344 | F1: 0.8187
2026-02-10 10:43:58,941 - INFO - [Metrics for 'normal'] | Precision: 0.8523 | Recall: 0.8242 | F1: 0.8380
2026-02-10 10:43:58,942 - INFO - --------------------------------------------------
2026-02-10 10:43:58,943 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 10:44:03,494 - INFO - [Train] [61/90] | Loss: 0.3667 | Train Acc: 91.37%
2026-02-10 10:44:04,268 - INFO - [Valid] [61/90] | Loss: 0.4747 | Val Acc: 80.83%
2026-02-10 10:44:04,271 - INFO - [Metrics for 'abnormal'] | Precision: 0.7706 | Recall: 0.8344 | F1: 0.8012
2026-02-10 10:44:04,271 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.7857 | F1: 0.8148
2026-02-10 10:44:04,272 - INFO - --------------------------------------------------
2026-02-10 10:44:04,273 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 10:44:08,887 - INFO - [Train] [62/90] | Loss: 0.3620 | Train Acc: 90.55%
2026-02-10 10:44:09,737 - INFO - [Valid] [62/90] | Loss: 0.4714 | Val Acc: 82.01%
2026-02-10 10:44:09,742 - INFO - [Metrics for 'abnormal'] | Precision: 0.7857 | Recall: 0.8408 | F1: 0.8123
2026-02-10 10:44:09,742 - INFO - [Metrics for 'normal'] | Precision: 0.8538 | Recall: 0.8022 | F1: 0.8272
2026-02-10 10:44:09,744 - INFO - --------------------------------------------------
2026-02-10 10:44:09,745 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 10:44:14,500 - INFO - [Train] [63/90] | Loss: 0.3565 | Train Acc: 91.00%
2026-02-10 10:44:15,632 - INFO - [Valid] [63/90] | Loss: 0.4924 | Val Acc: 81.12%
2026-02-10 10:44:15,637 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-02-10 10:44:15,637 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-02-10 10:44:15,639 - INFO - --------------------------------------------------
2026-02-10 10:44:15,639 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 10:44:20,248 - INFO - [Train] [64/90] | Loss: 0.3543 | Train Acc: 91.15%
2026-02-10 10:44:21,298 - INFO - [Valid] [64/90] | Loss: 0.4838 | Val Acc: 82.01%
2026-02-10 10:44:21,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-02-10 10:44:21,304 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-02-10 10:44:21,306 - INFO - --------------------------------------------------
2026-02-10 10:44:21,306 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 10:44:25,998 - INFO - [Train] [65/90] | Loss: 0.3497 | Train Acc: 92.41%
2026-02-10 10:44:27,290 - INFO - [Valid] [65/90] | Loss: 0.4907 | Val Acc: 81.42%
2026-02-10 10:44:27,296 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-02-10 10:44:27,296 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-02-10 10:44:27,297 - INFO - --------------------------------------------------
2026-02-10 10:44:27,298 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 10:44:31,784 - INFO - [Train] [66/90] | Loss: 0.3500 | Train Acc: 91.59%
2026-02-10 10:44:32,915 - INFO - [Valid] [66/90] | Loss: 0.4834 | Val Acc: 82.30%
2026-02-10 10:44:32,921 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8280 | F1: 0.8125
2026-02-10 10:44:32,921 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.8187 | F1: 0.8324
2026-02-10 10:44:32,922 - INFO - --------------------------------------------------
2026-02-10 10:44:32,923 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 10:44:37,716 - INFO - [Train] [67/90] | Loss: 0.3486 | Train Acc: 91.37%
2026-02-10 10:44:38,669 - INFO - [Valid] [67/90] | Loss: 0.4892 | Val Acc: 83.48%
2026-02-10 10:44:38,675 - INFO - [Metrics for 'abnormal'] | Precision: 0.8098 | Recall: 0.8408 | F1: 0.8250
2026-02-10 10:44:38,675 - INFO - [Metrics for 'normal'] | Precision: 0.8580 | Recall: 0.8297 | F1: 0.8436
2026-02-10 10:44:38,678 - INFO - --------------------------------------------------
2026-02-10 10:44:38,678 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 10:44:43,223 - INFO - [Train] [68/90] | Loss: 0.3460 | Train Acc: 92.49%
2026-02-10 10:44:44,434 - INFO - [Valid] [68/90] | Loss: 0.4920 | Val Acc: 82.30%
2026-02-10 10:44:44,438 - INFO - [Metrics for 'abnormal'] | Precision: 0.7836 | Recall: 0.8535 | F1: 0.8171
2026-02-10 10:44:44,439 - INFO - [Metrics for 'normal'] | Precision: 0.8631 | Recall: 0.7967 | F1: 0.8286
2026-02-10 10:44:44,440 - INFO - --------------------------------------------------
2026-02-10 10:44:44,441 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 10:44:49,018 - INFO - [Train] [69/90] | Loss: 0.3458 | Train Acc: 92.34%
2026-02-10 10:44:50,258 - INFO - [Valid] [69/90] | Loss: 0.4851 | Val Acc: 83.48%
2026-02-10 10:44:50,262 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.8280 | F1: 0.8228
2026-02-10 10:44:50,263 - INFO - [Metrics for 'normal'] | Precision: 0.8500 | Recall: 0.8407 | F1: 0.8453
2026-02-10 10:44:50,264 - INFO - --------------------------------------------------
2026-02-10 10:44:50,264 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 10:44:54,683 - INFO - [Train] [70/90] | Loss: 0.3473 | Train Acc: 91.96%
2026-02-10 10:44:55,647 - INFO - [Valid] [70/90] | Loss: 0.4737 | Val Acc: 83.19%
2026-02-10 10:44:55,654 - INFO - [Metrics for 'abnormal'] | Precision: 0.8165 | Recall: 0.8217 | F1: 0.8190
2026-02-10 10:44:55,655 - INFO - [Metrics for 'normal'] | Precision: 0.8453 | Recall: 0.8407 | F1: 0.8430
2026-02-10 10:44:55,657 - INFO - --------------------------------------------------
2026-02-10 10:44:55,661 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 10:45:00,500 - INFO - [Train] [71/90] | Loss: 0.3510 | Train Acc: 92.04%
2026-02-10 10:45:01,565 - INFO - [Valid] [71/90] | Loss: 0.4822 | Val Acc: 82.01%
2026-02-10 10:45:01,572 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-02-10 10:45:01,572 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-02-10 10:45:01,574 - INFO - --------------------------------------------------
2026-02-10 10:45:01,574 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 10:45:06,254 - INFO - [Train] [72/90] | Loss: 0.3501 | Train Acc: 92.19%
2026-02-10 10:45:07,401 - INFO - [Valid] [72/90] | Loss: 0.4717 | Val Acc: 82.89%
2026-02-10 10:45:07,407 - INFO - [Metrics for 'abnormal'] | Precision: 0.8075 | Recall: 0.8280 | F1: 0.8176
2026-02-10 10:45:07,407 - INFO - [Metrics for 'normal'] | Precision: 0.8483 | Recall: 0.8297 | F1: 0.8389
2026-02-10 10:45:07,410 - INFO - --------------------------------------------------
2026-02-10 10:45:07,410 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 10:45:12,172 - INFO - [Train] [73/90] | Loss: 0.3431 | Train Acc: 92.19%
2026-02-10 10:45:13,208 - INFO - [Valid] [73/90] | Loss: 0.4813 | Val Acc: 81.71%
2026-02-10 10:45:13,215 - INFO - [Metrics for 'abnormal'] | Precision: 0.7811 | Recall: 0.8408 | F1: 0.8098
2026-02-10 10:45:13,215 - INFO - [Metrics for 'normal'] | Precision: 0.8529 | Recall: 0.7967 | F1: 0.8239
2026-02-10 10:45:13,218 - INFO - --------------------------------------------------
2026-02-10 10:45:13,218 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 10:45:17,844 - INFO - [Train] [74/90] | Loss: 0.3395 | Train Acc: 92.93%
2026-02-10 10:45:18,961 - INFO - [Valid] [74/90] | Loss: 0.4882 | Val Acc: 82.60%
2026-02-10 10:45:18,971 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-02-10 10:45:18,972 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-02-10 10:45:18,977 - INFO - --------------------------------------------------
2026-02-10 10:45:18,978 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 10:45:23,407 - INFO - [Train] [75/90] | Loss: 0.3434 | Train Acc: 92.93%
2026-02-10 10:45:24,521 - INFO - [Valid] [75/90] | Loss: 0.4863 | Val Acc: 82.30%
2026-02-10 10:45:24,539 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-02-10 10:45:24,541 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-02-10 10:45:24,542 - INFO - --------------------------------------------------
2026-02-10 10:45:24,543 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 10:45:29,352 - INFO - [Train] [76/90] | Loss: 0.3469 | Train Acc: 92.04%
2026-02-10 10:45:30,227 - INFO - [Valid] [76/90] | Loss: 0.4831 | Val Acc: 82.60%
2026-02-10 10:45:30,234 - INFO - [Metrics for 'abnormal'] | Precision: 0.7882 | Recall: 0.8535 | F1: 0.8196
2026-02-10 10:45:30,238 - INFO - [Metrics for 'normal'] | Precision: 0.8639 | Recall: 0.8022 | F1: 0.8319
2026-02-10 10:45:30,241 - INFO - --------------------------------------------------
2026-02-10 10:45:30,241 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 10:45:35,371 - INFO - [Train] [77/90] | Loss: 0.3454 | Train Acc: 92.19%
2026-02-10 10:45:36,613 - INFO - [Valid] [77/90] | Loss: 0.4807 | Val Acc: 82.60%
2026-02-10 10:45:36,621 - INFO - [Metrics for 'abnormal'] | Precision: 0.7952 | Recall: 0.8408 | F1: 0.8173
2026-02-10 10:45:36,621 - INFO - [Metrics for 'normal'] | Precision: 0.8555 | Recall: 0.8132 | F1: 0.8338
2026-02-10 10:45:36,623 - INFO - --------------------------------------------------
2026-02-10 10:45:36,623 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 10:45:41,564 - INFO - [Train] [78/90] | Loss: 0.3394 | Train Acc: 92.04%
2026-02-10 10:45:42,521 - INFO - [Valid] [78/90] | Loss: 0.4903 | Val Acc: 82.60%
2026-02-10 10:45:42,527 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8280 | F1: 0.8150
2026-02-10 10:45:42,527 - INFO - [Metrics for 'normal'] | Precision: 0.8475 | Recall: 0.8242 | F1: 0.8357
2026-02-10 10:45:42,529 - INFO - --------------------------------------------------
2026-02-10 10:45:42,530 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 10:45:47,211 - INFO - [Train] [79/90] | Loss: 0.3407 | Train Acc: 92.63%
2026-02-10 10:45:48,396 - INFO - [Valid] [79/90] | Loss: 0.4905 | Val Acc: 82.30%
2026-02-10 10:45:48,405 - INFO - [Metrics for 'abnormal'] | Precision: 0.7939 | Recall: 0.8344 | F1: 0.8137
2026-02-10 10:45:48,405 - INFO - [Metrics for 'normal'] | Precision: 0.8506 | Recall: 0.8132 | F1: 0.8315
2026-02-10 10:45:48,407 - INFO - --------------------------------------------------
2026-02-10 10:45:48,407 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 10:45:52,800 - INFO - [Train] [80/90] | Loss: 0.3353 | Train Acc: 93.53%
2026-02-10 10:45:53,915 - INFO - [Valid] [80/90] | Loss: 0.4881 | Val Acc: 82.60%
2026-02-10 10:45:53,927 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-02-10 10:45:53,927 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-02-10 10:45:53,929 - INFO - --------------------------------------------------
2026-02-10 10:45:53,929 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 10:45:58,294 - INFO - [Train] [81/90] | Loss: 0.3373 | Train Acc: 93.30%
2026-02-10 10:45:59,579 - INFO - [Valid] [81/90] | Loss: 0.4864 | Val Acc: 81.71%
2026-02-10 10:45:59,585 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-02-10 10:45:59,588 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-02-10 10:45:59,590 - INFO - --------------------------------------------------
2026-02-10 10:45:59,591 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 10:46:04,127 - INFO - [Train] [82/90] | Loss: 0.3364 | Train Acc: 92.63%
2026-02-10 10:46:05,286 - INFO - [Valid] [82/90] | Loss: 0.4865 | Val Acc: 82.01%
2026-02-10 10:46:05,291 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-02-10 10:46:05,291 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-02-10 10:46:05,293 - INFO - --------------------------------------------------
2026-02-10 10:46:05,293 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 10:46:09,437 - INFO - [Train] [83/90] | Loss: 0.3358 | Train Acc: 92.71%
2026-02-10 10:46:10,601 - INFO - [Valid] [83/90] | Loss: 0.4892 | Val Acc: 81.42%
2026-02-10 10:46:10,606 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-02-10 10:46:10,606 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-02-10 10:46:10,607 - INFO - --------------------------------------------------
2026-02-10 10:46:10,607 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 10:46:15,045 - INFO - [Train] [84/90] | Loss: 0.3323 | Train Acc: 93.08%
2026-02-10 10:46:16,330 - INFO - [Valid] [84/90] | Loss: 0.4831 | Val Acc: 81.42%
2026-02-10 10:46:16,334 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-02-10 10:46:16,334 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-02-10 10:46:16,336 - INFO - --------------------------------------------------
2026-02-10 10:46:16,336 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 10:46:20,709 - INFO - [Train] [85/90] | Loss: 0.3379 | Train Acc: 92.26%
2026-02-10 10:46:21,764 - INFO - [Valid] [85/90] | Loss: 0.4898 | Val Acc: 81.71%
2026-02-10 10:46:21,771 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-02-10 10:46:21,771 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-02-10 10:46:21,773 - INFO - --------------------------------------------------
2026-02-10 10:46:21,774 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 10:46:26,021 - INFO - [Train] [86/90] | Loss: 0.3340 | Train Acc: 92.41%
2026-02-10 10:46:27,228 - INFO - [Valid] [86/90] | Loss: 0.4898 | Val Acc: 81.42%
2026-02-10 10:46:27,233 - INFO - [Metrics for 'abnormal'] | Precision: 0.7798 | Recall: 0.8344 | F1: 0.8062
2026-02-10 10:46:27,233 - INFO - [Metrics for 'normal'] | Precision: 0.8480 | Recall: 0.7967 | F1: 0.8215
2026-02-10 10:46:27,234 - INFO - --------------------------------------------------
2026-02-10 10:46:27,235 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 10:46:31,514 - INFO - [Train] [87/90] | Loss: 0.3369 | Train Acc: 93.08%
2026-02-10 10:46:32,607 - INFO - [Valid] [87/90] | Loss: 0.4889 | Val Acc: 81.42%
2026-02-10 10:46:32,611 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-02-10 10:46:32,612 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-02-10 10:46:32,613 - INFO - --------------------------------------------------
2026-02-10 10:46:32,613 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 10:46:37,126 - INFO - [Train] [88/90] | Loss: 0.3280 | Train Acc: 93.90%
2026-02-10 10:46:38,446 - INFO - [Valid] [88/90] | Loss: 0.4923 | Val Acc: 82.30%
2026-02-10 10:46:38,451 - INFO - [Metrics for 'abnormal'] | Precision: 0.8012 | Recall: 0.8217 | F1: 0.8113
2026-02-10 10:46:38,451 - INFO - [Metrics for 'normal'] | Precision: 0.8427 | Recall: 0.8242 | F1: 0.8333
2026-02-10 10:46:38,453 - INFO - --------------------------------------------------
2026-02-10 10:46:38,457 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 10:46:42,803 - INFO - [Train] [89/90] | Loss: 0.3309 | Train Acc: 93.15%
2026-02-10 10:46:43,987 - INFO - [Valid] [89/90] | Loss: 0.4935 | Val Acc: 81.71%
2026-02-10 10:46:43,993 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-02-10 10:46:43,993 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-02-10 10:46:43,995 - INFO - --------------------------------------------------
2026-02-10 10:46:43,995 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 10:46:48,241 - INFO - [Train] [90/90] | Loss: 0.3365 | Train Acc: 92.41%
2026-02-10 10:46:49,357 - INFO - [Valid] [90/90] | Loss: 0.4928 | Val Acc: 81.71%
2026-02-10 10:46:49,364 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-02-10 10:46:49,364 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-02-10 10:46:49,366 - INFO - ==================================================
2026-02-10 10:46:49,370 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 10:46:49,370 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 10:46:49,370 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 10:46:49,437 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 10:46:49,438 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:46:49,439 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:46:49,439 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:46:54,034 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:46:54,625 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 10:46:54,625 - INFO - ==================================================
2026-02-10 10:46:54,629 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/best_model.pth'
2026-02-10 10:46:54,629 - INFO - ==================================================
2026-02-10 10:46:54,629 - INFO - Test 모드를 시작합니다.
2026-02-10 10:46:54,727 - INFO - 연산량 (MACs): 0.0741 GMACs per sample
2026-02-10 10:46:54,730 - INFO - 연산량 (FLOPs): 0.1481 GFLOPs per sample
2026-02-10 10:46:54,730 - INFO - ==================================================
2026-02-10 10:46:54,730 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 10:46:55,515 - INFO - 샘플 당 평균 Forward Pass 시간: 0.19ms (std: 0.13ms), FPS: 6712.04 (std: 3561.41) (1개 샘플 x 100회 반복)
2026-02-10 10:46:55,516 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 159.82 MB
2026-02-10 10:46:55,516 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 10:46:57,644 - INFO - [Test] Loss: 0.3941 | Test Acc: 82.60%
2026-02-10 10:46:57,654 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-02-10 10:46:57,654 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-02-10 10:46:57,961 - INFO - ==================================================
2026-02-10 10:46:57,962 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/confusion_matrix_20260210_103321.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/confusion_matrix_20260210_103321.pdf'
2026-02-10 10:46:57,962 - INFO - ==================================================
2026-02-10 10:46:57,962 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 10:46:58,156 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/model_fp32_20260210_103321.onnx'에 저장되었습니다. (크기: 0.18 MB)
2026-02-10 10:46:58,616 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 3.19 MB
2026-02-10 10:46:58,616 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 10:46:59,721 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 8.53ms (std: 8.02ms)
2026-02-10 10:46:59,721 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 548.73 FPS (std: 634.54) (1개 샘플 x 100회 반복)
2026-02-10 10:46:59,721 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 5.06 MB
2026-02-10 10:46:59,721 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 14.76 MB
2026-02-10 10:47:01,879 - INFO - [Test (ONNX)] | Test Acc (ONNX): 82.60%
2026-02-10 10:47:01,892 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-02-10 10:47:01,897 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-02-10 10:47:02,127 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/val_acc.pdf'
2026-02-10 10:47:02,364 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/train_val_acc.pdf'
2026-02-10 10:47:02,559 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/F1_normal.pdf'
2026-02-10 10:47:02,751 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/val_loss.pdf'
2026-02-10 10:47:02,939 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/learning_rate.pdf'
2026-02-10 10:47:04,896 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260210_103321/graph_20260210_103321/compile.pdf'
