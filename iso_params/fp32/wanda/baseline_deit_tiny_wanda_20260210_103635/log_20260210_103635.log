2026-02-10 10:36:35,213 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/log_20260210_103635.log'에 저장됩니다.
2026-02-10 10:36:35,215 - INFO - ==================================================
2026-02-10 10:36:35,216 - INFO - config.yaml:
2026-02-10 10:36:35,216 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: deit_tiny
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.047585

2026-02-10 10:36:35,216 - INFO - ==================================================
2026-02-10 10:36:35,243 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 10:36:35,244 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 10:36:35,244 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 10:36:35,250 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 10:36:35,250 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 10:36:35,251 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 10:36:35,251 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 10:36:37,060 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 10:36:37,062 - INFO - ==================================================
2026-02-10 10:36:37,062 - INFO - 모델 파라미터 수:
2026-02-10 10:36:37,062 - INFO -   - 총 파라미터: 5,524,802 개
2026-02-10 10:36:37,062 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-02-10 10:36:37,062 - INFO - ================================================================================
2026-02-10 10:36:37,062 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 10:36:37,062 - INFO - ================================================================================
2026-02-10 10:36:37,062 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 10:36:37,063 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 10:36:37,063 - INFO - ==================================================
2026-02-10 10:36:37,063 - INFO - train 모드를 시작합니다.
2026-02-10 10:36:37,063 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 10:36:37,063 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 10:36:37,063 - INFO - --------------------------------------------------
2026-02-10 10:36:37,064 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 10:36:41,724 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-02-10 10:36:43,363 - INFO - [Valid] [1/10] | Loss: 0.6724 | Val Acc: 59.88%
2026-02-10 10:36:43,370 - INFO - [Metrics for 'abnormal'] | Precision: 0.5488 | Recall: 0.7516 | F1: 0.6344
2026-02-10 10:36:43,370 - INFO - [Metrics for 'normal'] | Precision: 0.6855 | Recall: 0.4670 | F1: 0.5556
2026-02-10 10:36:43,403 - INFO - [Best Model Saved] (val loss: 0.6724) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:36:43,403 - INFO - --------------------------------------------------
2026-02-10 10:36:43,404 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 10:36:48,384 - INFO - [Train] [2/10] | Loss: 0.6464 | Train Acc: 64.43%
2026-02-10 10:36:49,336 - INFO - [Valid] [2/10] | Loss: 0.6629 | Val Acc: 61.65%
2026-02-10 10:36:49,341 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.2548 | F1: 0.3810
2026-02-10 10:36:49,342 - INFO - [Metrics for 'normal'] | Precision: 0.5909 | Recall: 0.9286 | F1: 0.7222
2026-02-10 10:36:49,389 - INFO - [Best Model Saved] (val loss: 0.6629) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:36:49,389 - INFO - --------------------------------------------------
2026-02-10 10:36:49,390 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 10:36:54,347 - INFO - [Train] [3/10] | Loss: 0.5956 | Train Acc: 68.90%
2026-02-10 10:36:55,376 - INFO - [Valid] [3/10] | Loss: 0.5660 | Val Acc: 74.93%
2026-02-10 10:36:55,381 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.6497 | F1: 0.7059
2026-02-10 10:36:55,381 - INFO - [Metrics for 'normal'] | Precision: 0.7343 | Recall: 0.8352 | F1: 0.7815
2026-02-10 10:36:55,430 - INFO - [Best Model Saved] (val loss: 0.5660) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:36:55,430 - INFO - --------------------------------------------------
2026-02-10 10:36:55,431 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 10:37:00,364 - INFO - [Train] [4/10] | Loss: 0.5630 | Train Acc: 75.82%
2026-02-10 10:37:01,597 - INFO - [Valid] [4/10] | Loss: 0.5505 | Val Acc: 74.04%
2026-02-10 10:37:01,601 - INFO - [Metrics for 'abnormal'] | Precision: 0.7117 | Recall: 0.7389 | F1: 0.7250
2026-02-10 10:37:01,601 - INFO - [Metrics for 'normal'] | Precision: 0.7670 | Recall: 0.7418 | F1: 0.7542
2026-02-10 10:37:01,637 - INFO - [Best Model Saved] (val loss: 0.5505) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:37:01,637 - INFO - --------------------------------------------------
2026-02-10 10:37:01,638 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 10:37:06,591 - INFO - [Train] [5/10] | Loss: 0.5155 | Train Acc: 78.94%
2026-02-10 10:37:07,760 - INFO - [Valid] [5/10] | Loss: 0.5579 | Val Acc: 74.63%
2026-02-10 10:37:07,766 - INFO - [Metrics for 'abnormal'] | Precision: 0.7126 | Recall: 0.7580 | F1: 0.7346
2026-02-10 10:37:07,766 - INFO - [Metrics for 'normal'] | Precision: 0.7791 | Recall: 0.7363 | F1: 0.7571
2026-02-10 10:37:07,768 - INFO - --------------------------------------------------
2026-02-10 10:37:07,769 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 10:37:12,433 - INFO - [Train] [6/10] | Loss: 0.5177 | Train Acc: 78.50%
2026-02-10 10:37:13,715 - INFO - [Valid] [6/10] | Loss: 0.5393 | Val Acc: 74.63%
2026-02-10 10:37:13,719 - INFO - [Metrics for 'abnormal'] | Precision: 0.6940 | Recall: 0.8089 | F1: 0.7471
2026-02-10 10:37:13,720 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.6923 | F1: 0.7456
2026-02-10 10:37:13,763 - INFO - [Best Model Saved] (val loss: 0.5393) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:37:13,763 - INFO - --------------------------------------------------
2026-02-10 10:37:13,765 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 10:37:18,591 - INFO - [Train] [7/10] | Loss: 0.4901 | Train Acc: 81.32%
2026-02-10 10:37:19,810 - INFO - [Valid] [7/10] | Loss: 0.5521 | Val Acc: 76.99%
2026-02-10 10:37:19,816 - INFO - [Metrics for 'abnormal'] | Precision: 0.8264 | Recall: 0.6369 | F1: 0.7194
2026-02-10 10:37:19,816 - INFO - [Metrics for 'normal'] | Precision: 0.7385 | Recall: 0.8846 | F1: 0.8050
2026-02-10 10:37:19,817 - INFO - --------------------------------------------------
2026-02-10 10:37:19,818 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 10:37:24,878 - INFO - [Train] [8/10] | Loss: 0.4861 | Train Acc: 81.70%
2026-02-10 10:37:25,906 - INFO - [Valid] [8/10] | Loss: 0.5293 | Val Acc: 77.29%
2026-02-10 10:37:25,911 - INFO - [Metrics for 'abnormal'] | Precision: 0.8175 | Recall: 0.6561 | F1: 0.7279
2026-02-10 10:37:25,911 - INFO - [Metrics for 'normal'] | Precision: 0.7465 | Recall: 0.8736 | F1: 0.8051
2026-02-10 10:37:25,960 - INFO - [Best Model Saved] (val loss: 0.5293) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:37:25,962 - INFO - --------------------------------------------------
2026-02-10 10:37:25,963 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 10:37:31,472 - INFO - [Train] [9/10] | Loss: 0.4830 | Train Acc: 80.88%
2026-02-10 10:37:32,421 - INFO - [Valid] [9/10] | Loss: 0.5372 | Val Acc: 76.40%
2026-02-10 10:37:32,426 - INFO - [Metrics for 'abnormal'] | Precision: 0.7655 | Recall: 0.7070 | F1: 0.7351
2026-02-10 10:37:32,427 - INFO - [Metrics for 'normal'] | Precision: 0.7629 | Recall: 0.8132 | F1: 0.7872
2026-02-10 10:37:32,431 - INFO - --------------------------------------------------
2026-02-10 10:37:32,432 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 10:37:37,731 - INFO - [Train] [10/10] | Loss: 0.4752 | Train Acc: 82.29%
2026-02-10 10:37:39,030 - INFO - [Valid] [10/10] | Loss: 0.5302 | Val Acc: 76.70%
2026-02-10 10:37:39,035 - INFO - [Metrics for 'abnormal'] | Precision: 0.7378 | Recall: 0.7707 | F1: 0.7539
2026-02-10 10:37:39,035 - INFO - [Metrics for 'normal'] | Precision: 0.7943 | Recall: 0.7637 | F1: 0.7787
2026-02-10 10:37:39,037 - INFO - ================================================================================
2026-02-10 10:37:39,038 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 10:37:39,038 - INFO - ================================================================================
2026-02-10 10:37:39,146 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'을(를) 불러왔습니다.
2026-02-10 10:37:39,146 - INFO - ================================================================================
2026-02-10 10:37:39,146 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 10:37:39,147 - INFO - 원본 모델 파라미터: 5.5248M
2026-02-10 10:37:39,176 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:39,176 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:39,178 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:43,633 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:43,634 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:37:43,902 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 10:37:43,902 - INFO - ==================================================
2026-02-10 10:37:43,903 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.8881M (감소율: 65.83%)
2026-02-10 10:37:43,923 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:43,923 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:43,925 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:47,994 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:47,998 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:37:48,695 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 10:37:48,695 - INFO - ==================================================
2026-02-10 10:37:48,698 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.7436M (감소율: 86.54%)
2026-02-10 10:37:48,717 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:48,717 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:48,719 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:53,379 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:53,380 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:37:53,613 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 10:37:53,613 - INFO - ==================================================
2026-02-10 10:37:53,614 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.3258M (감소율: 94.10%)
2026-02-10 10:37:53,633 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:53,633 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:53,635 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:37:58,118 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:37:58,121 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:37:58,339 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 10:37:58,340 - INFO - ==================================================
2026-02-10 10:37:58,341 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.1581M (감소율: 97.14%)
2026-02-10 10:37:58,360 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:37:58,361 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:37:58,363 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:02,341 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:02,342 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:02,575 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-02-10 10:38:02,575 - INFO - ==================================================
2026-02-10 10:38:02,577 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0843M (감소율: 98.47%)
2026-02-10 10:38:02,596 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:02,596 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:02,598 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:06,769 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:06,770 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:06,986 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97453125)에 맞춰 변경되었습니다.
2026-02-10 10:38:06,986 - INFO - ==================================================
2026-02-10 10:38:06,988 - INFO -   [탐색  6] 희소도: 0.9745 -> 파라미터: 0.0500M (감소율: 99.09%)
2026-02-10 10:38:07,007 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:07,007 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:07,008 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:11,267 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:11,267 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:11,958 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9822656249999999)에 맞춰 변경되었습니다.
2026-02-10 10:38:11,958 - INFO - ==================================================
2026-02-10 10:38:11,961 - INFO -   [탐색  7] 희소도: 0.9823 -> 파라미터: 0.0388M (감소율: 99.30%)
2026-02-10 10:38:11,977 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:11,977 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:11,978 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:16,309 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:16,310 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:16,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 10:38:16,515 - INFO - ==================================================
2026-02-10 10:38:16,516 - INFO -   [탐색  8] 희소도: 0.9784 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:38:16,533 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:16,533 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:16,535 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:20,851 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:20,852 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:21,097 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9803320312499999)에 맞춰 변경되었습니다.
2026-02-10 10:38:21,097 - INFO - ==================================================
2026-02-10 10:38:21,099 - INFO -   [탐색  9] 희소도: 0.9803 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:38:21,117 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:21,118 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:21,119 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:25,843 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:25,845 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:26,096 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9793652343749999)에 맞춰 변경되었습니다.
2026-02-10 10:38:26,096 - INFO - ==================================================
2026-02-10 10:38:26,097 - INFO -   [탐색 10] 희소도: 0.9794 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:38:26,114 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:26,115 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:26,116 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:30,673 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:30,674 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:30,901 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9788818359374999)에 맞춰 변경되었습니다.
2026-02-10 10:38:30,901 - INFO - ==================================================
2026-02-10 10:38:30,902 - INFO -   [탐색 11] 희소도: 0.9789 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:38:30,920 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:30,920 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:30,922 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:35,733 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:35,734 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:36,488 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97912353515625)에 맞춰 변경되었습니다.
2026-02-10 10:38:36,489 - INFO - ==================================================
2026-02-10 10:38:36,490 - INFO -   [탐색 12] 희소도: 0.9791 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:38:36,510 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:36,511 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:36,512 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:41,315 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:41,315 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:41,513 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9792443847656249)에 맞춰 변경되었습니다.
2026-02-10 10:38:41,513 - INFO - ==================================================
2026-02-10 10:38:41,526 - INFO -   [탐색 13] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:38:41,541 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:41,542 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:41,543 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:45,499 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:45,499 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:45,723 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791839599609374)에 맞춰 변경되었습니다.
2026-02-10 10:38:45,723 - INFO - ==================================================
2026-02-10 10:38:45,725 - INFO -   [탐색 14] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:38:45,742 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:45,743 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:45,744 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:49,814 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:49,815 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:50,025 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791537475585936)에 맞춰 변경되었습니다.
2026-02-10 10:38:50,025 - INFO - ==================================================
2026-02-10 10:38:50,027 - INFO -   [탐색 15] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:38:50,043 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:50,043 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:50,045 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:54,259 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:54,260 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:54,484 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791688537597656)에 맞춰 변경되었습니다.
2026-02-10 10:38:54,485 - INFO - ==================================================
2026-02-10 10:38:54,486 - INFO -   [탐색 16] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:38:54,502 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:54,502 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:54,504 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:38:58,805 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:38:58,805 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:38:59,587 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791613006591796)에 맞춰 변경되었습니다.
2026-02-10 10:38:59,587 - INFO - ==================================================
2026-02-10 10:38:59,589 - INFO -   [탐색 17] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:38:59,607 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:38:59,607 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:38:59,609 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:04,100 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:04,102 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:04,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791650772094727)에 맞춰 변경되었습니다.
2026-02-10 10:39:04,349 - INFO - ==================================================
2026-02-10 10:39:04,351 - INFO -   [탐색 18] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:04,368 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:04,369 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:04,372 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:08,942 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:08,943 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:09,174 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791669654846191)에 맞춰 변경되었습니다.
2026-02-10 10:39:09,174 - INFO - ==================================================
2026-02-10 10:39:09,176 - INFO -   [탐색 19] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:39:09,194 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:09,194 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:09,195 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:13,417 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:13,418 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:13,639 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791660213470459)에 맞춰 변경되었습니다.
2026-02-10 10:39:13,639 - INFO - ==================================================
2026-02-10 10:39:13,641 - INFO -   [탐색 20] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:13,660 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:13,660 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:13,663 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:18,561 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:18,563 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:18,781 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791664934158325)에 맞춰 변경되었습니다.
2026-02-10 10:39:18,782 - INFO - ==================================================
2026-02-10 10:39:18,783 - INFO -   [탐색 21] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:18,801 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:18,801 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:18,802 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:23,479 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:23,480 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:24,216 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791667294502258)에 맞춰 변경되었습니다.
2026-02-10 10:39:24,217 - INFO - ==================================================
2026-02-10 10:39:24,219 - INFO -   [탐색 22] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:39:24,236 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:24,236 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:24,238 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:29,094 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:29,095 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:29,328 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666114330291)에 맞춰 변경되었습니다.
2026-02-10 10:39:29,328 - INFO - ==================================================
2026-02-10 10:39:29,329 - INFO -   [탐색 23] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:29,346 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:29,346 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:29,347 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:34,130 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:34,131 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:34,338 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666704416274)에 맞춰 변경되었습니다.
2026-02-10 10:39:34,338 - INFO - ==================================================
2026-02-10 10:39:34,340 - INFO -   [탐색 24] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:39:34,354 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:34,355 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:34,356 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:38,825 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:38,827 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:39,113 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666409373283)에 맞춰 변경되었습니다.
2026-02-10 10:39:39,114 - INFO - ==================================================
2026-02-10 10:39:39,115 - INFO -   [탐색 25] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:39,132 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:39,132 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:39,134 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:43,702 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:43,703 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:43,923 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666556894778)에 맞춰 변경되었습니다.
2026-02-10 10:39:43,923 - INFO - ==================================================
2026-02-10 10:39:43,926 - INFO -   [탐색 26] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:43,945 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:43,946 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:43,947 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:48,490 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:48,491 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:49,229 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666630655527)에 맞춰 변경되었습니다.
2026-02-10 10:39:49,229 - INFO - ==================================================
2026-02-10 10:39:49,232 - INFO -   [탐색 27] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:49,248 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:49,249 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:49,250 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:54,182 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:54,183 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:54,410 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666667535901)에 맞춰 변경되었습니다.
2026-02-10 10:39:54,410 - INFO - ==================================================
2026-02-10 10:39:54,412 - INFO -   [탐색 28] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:39:54,426 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:54,426 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:54,428 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:39:59,109 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:39:59,109 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:39:59,328 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666649095714)에 맞춰 변경되었습니다.
2026-02-10 10:39:59,329 - INFO - ==================================================
2026-02-10 10:39:59,331 - INFO -   [탐색 29] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:39:59,349 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:39:59,349 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:39:59,350 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:04,475 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:04,475 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:04,688 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666658315807)에 맞춰 변경되었습니다.
2026-02-10 10:40:04,688 - INFO - ==================================================
2026-02-10 10:40:04,690 - INFO -   [탐색 30] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:04,706 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:04,707 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:04,708 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:09,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:09,471 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:09,666 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666662925854)에 맞춰 변경되었습니다.
2026-02-10 10:40:09,667 - INFO - ==================================================
2026-02-10 10:40:09,668 - INFO -   [탐색 31] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:09,683 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:09,683 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:09,685 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:14,590 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:14,591 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:15,290 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666665230878)에 맞춰 변경되었습니다.
2026-02-10 10:40:15,291 - INFO - ==================================================
2026-02-10 10:40:15,293 - INFO -   [탐색 32] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:15,310 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:15,310 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:15,312 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:20,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:20,330 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:20,569 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.979166666638339)에 맞춰 변경되었습니다.
2026-02-10 10:40:20,570 - INFO - ==================================================
2026-02-10 10:40:20,571 - INFO -   [탐색 33] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:20,589 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:20,589 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:20,591 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:25,516 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:25,517 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:25,700 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666959645)에 맞춰 변경되었습니다.
2026-02-10 10:40:25,700 - INFO - ==================================================
2026-02-10 10:40:25,701 - INFO -   [탐색 34] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:40:25,713 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:25,713 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:25,714 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:30,471 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:30,472 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:30,678 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666671517)에 맞춰 변경되었습니다.
2026-02-10 10:40:30,678 - INFO - ==================================================
2026-02-10 10:40:30,680 - INFO -   [탐색 35] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:40:30,696 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:30,696 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:30,697 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:35,282 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:35,283 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:35,495 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666527453)에 맞춰 변경되었습니다.
2026-02-10 10:40:35,495 - INFO - ==================================================
2026-02-10 10:40:35,497 - INFO -   [탐색 36] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:35,514 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:35,514 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:35,516 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:40,128 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:40,129 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:40,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666599486)에 맞춰 변경되었습니다.
2026-02-10 10:40:40,905 - INFO - ==================================================
2026-02-10 10:40:40,907 - INFO -   [탐색 37] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:40,924 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:40,924 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:40,926 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:45,445 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:45,446 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:45,680 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666635501)에 맞춰 변경되었습니다.
2026-02-10 10:40:45,680 - INFO - ==================================================
2026-02-10 10:40:45,682 - INFO -   [탐색 38] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:45,701 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:45,701 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:45,703 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:50,159 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:50,160 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:50,375 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666653509)에 맞춰 변경되었습니다.
2026-02-10 10:40:50,376 - INFO - ==================================================
2026-02-10 10:40:50,377 - INFO -   [탐색 39] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:50,392 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:50,393 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:50,394 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:40:55,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:40:55,103 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:40:55,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666662513)에 맞춰 변경되었습니다.
2026-02-10 10:40:55,306 - INFO - ==================================================
2026-02-10 10:40:55,310 - INFO -   [탐색 40] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:40:55,323 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:40:55,323 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:40:55,325 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:00,175 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:00,176 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:00,382 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666667015)에 맞춰 변경되었습니다.
2026-02-10 10:41:00,383 - INFO - ==================================================
2026-02-10 10:41:00,384 - INFO -   [탐색 41] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:41:00,401 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:00,401 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:00,403 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:05,208 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:05,210 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:05,860 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666664764)에 맞춰 변경되었습니다.
2026-02-10 10:41:05,861 - INFO - ==================================================
2026-02-10 10:41:05,863 - INFO -   [탐색 42] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:41:05,881 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:05,881 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:05,882 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:11,028 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:11,035 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:11,247 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.979166666666589)에 맞춰 변경되었습니다.
2026-02-10 10:41:11,248 - INFO - ==================================================
2026-02-10 10:41:11,249 - INFO -   [탐색 43] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:41:11,263 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:11,264 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:11,265 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:16,163 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:16,164 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:16,397 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666452)에 맞춰 변경되었습니다.
2026-02-10 10:41:16,398 - INFO - ==================================================
2026-02-10 10:41:16,399 - INFO -   [탐색 44] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:41:16,417 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:16,418 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:16,419 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:21,045 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:21,047 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:21,271 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666734)에 맞춰 변경되었습니다.
2026-02-10 10:41:21,271 - INFO - ==================================================
2026-02-10 10:41:21,273 - INFO -   [탐색 45] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:41:21,293 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:21,293 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:21,296 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:26,031 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:26,031 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:26,253 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666593)에 맞춰 변경되었습니다.
2026-02-10 10:41:26,253 - INFO - ==================================================
2026-02-10 10:41:26,255 - INFO -   [탐색 46] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:41:26,277 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:26,277 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:26,278 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:31,129 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:31,130 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:31,911 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666663)에 맞춰 변경되었습니다.
2026-02-10 10:41:31,911 - INFO - ==================================================
2026-02-10 10:41:31,913 - INFO -   [탐색 47] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:41:31,931 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:31,931 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:31,932 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:36,460 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:36,461 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:36,683 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666698)에 맞춰 변경되었습니다.
2026-02-10 10:41:36,683 - INFO - ==================================================
2026-02-10 10:41:36,685 - INFO -   [탐색 48] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:41:36,702 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:36,702 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:36,704 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:41,492 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:41,493 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:41,718 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666681)에 맞춰 변경되었습니다.
2026-02-10 10:41:41,718 - INFO - ==================================================
2026-02-10 10:41:41,720 - INFO -   [탐색 49] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:41:41,739 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:41,739 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:41,740 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:46,731 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:46,732 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:46,955 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666672)에 맞춰 변경되었습니다.
2026-02-10 10:41:46,955 - INFO - ==================================================
2026-02-10 10:41:46,956 - INFO -   [탐색 50] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:41:46,974 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:46,975 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:46,976 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:51,834 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:51,835 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:52,068 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:41:52,068 - INFO - ==================================================
2026-02-10 10:41:52,070 - INFO -   [탐색 51] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:41:52,087 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:52,087 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:52,088 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:41:57,053 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:41:57,053 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:41:57,843 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666665)에 맞춰 변경되었습니다.
2026-02-10 10:41:57,844 - INFO - ==================================================
2026-02-10 10:41:57,846 - INFO -   [탐색 52] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:41:57,863 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:41:57,863 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:41:57,865 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:02,633 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:02,636 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:02,896 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666666)에 맞춰 변경되었습니다.
2026-02-10 10:42:02,896 - INFO - ==================================================
2026-02-10 10:42:02,898 - INFO -   [탐색 53] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:42:02,916 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:02,916 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:02,918 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:07,744 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:07,744 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:07,967 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:07,968 - INFO - ==================================================
2026-02-10 10:42:07,969 - INFO -   [탐색 54] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:07,987 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:07,988 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:07,989 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:12,852 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:12,852 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:13,087 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:13,087 - INFO - ==================================================
2026-02-10 10:42:13,089 - INFO -   [탐색 55] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:13,105 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:13,106 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:13,107 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:17,861 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:17,870 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:18,083 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:18,083 - INFO - ==================================================
2026-02-10 10:42:18,084 - INFO -   [탐색 56] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:18,102 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:18,102 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:18,103 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:22,781 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:22,781 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:23,526 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:23,526 - INFO - ==================================================
2026-02-10 10:42:23,528 - INFO -   [탐색 57] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:23,546 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:23,546 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:23,548 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:27,805 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:27,805 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:28,033 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:28,033 - INFO - ==================================================
2026-02-10 10:42:28,035 - INFO -   [탐색 58] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:28,054 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:28,055 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:28,057 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:32,814 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:32,815 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:33,044 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:33,044 - INFO - ==================================================
2026-02-10 10:42:33,045 - INFO -   [탐색 59] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:33,064 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:33,064 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:33,065 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:38,085 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:38,086 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:38,303 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:38,304 - INFO - ==================================================
2026-02-10 10:42:38,305 - INFO -   [탐색 60] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:38,323 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:38,323 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:38,325 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:43,003 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:43,003 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:43,225 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:43,225 - INFO - ==================================================
2026-02-10 10:42:43,228 - INFO -   [탐색 61] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:43,244 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:43,244 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:43,245 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:47,850 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:47,851 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:48,565 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:48,566 - INFO - ==================================================
2026-02-10 10:42:48,568 - INFO -   [탐색 62] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:48,587 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:48,587 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:48,588 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:53,367 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:53,368 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:53,598 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:53,598 - INFO - ==================================================
2026-02-10 10:42:53,600 - INFO -   [탐색 63] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:53,616 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:53,617 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:53,618 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:42:57,974 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:42:57,975 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:42:58,183 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:42:58,183 - INFO - ==================================================
2026-02-10 10:42:58,185 - INFO -   [탐색 64] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:42:58,201 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:42:58,201 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:42:58,203 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:02,762 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:02,763 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:03,006 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:03,006 - INFO - ==================================================
2026-02-10 10:43:03,008 - INFO -   [탐색 65] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:03,024 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:03,024 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:03,025 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:07,528 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:07,530 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:07,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:07,749 - INFO - ==================================================
2026-02-10 10:43:07,750 - INFO -   [탐색 66] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:07,765 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:07,765 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:07,767 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:12,686 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:12,687 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:13,483 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:13,483 - INFO - ==================================================
2026-02-10 10:43:13,486 - INFO -   [탐색 67] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:13,501 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:13,501 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:13,503 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:18,416 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:18,417 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:18,672 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:18,672 - INFO - ==================================================
2026-02-10 10:43:18,674 - INFO -   [탐색 68] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:18,692 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:18,692 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:18,694 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:23,428 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:23,429 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:23,655 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:23,656 - INFO - ==================================================
2026-02-10 10:43:23,657 - INFO -   [탐색 69] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:23,674 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:23,674 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:23,675 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:28,193 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:28,194 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:28,412 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:28,412 - INFO - ==================================================
2026-02-10 10:43:28,414 - INFO -   [탐색 70] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:28,432 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:28,433 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:28,434 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:33,436 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:33,440 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:33,651 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:33,651 - INFO - ==================================================
2026-02-10 10:43:33,653 - INFO -   [탐색 71] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:33,669 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:33,669 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:33,671 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:38,654 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:38,655 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:39,396 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:39,397 - INFO - ==================================================
2026-02-10 10:43:39,411 - INFO -   [탐색 72] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:39,428 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:39,429 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:39,430 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:43,965 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:43,965 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:44,191 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:44,191 - INFO - ==================================================
2026-02-10 10:43:44,192 - INFO -   [탐색 73] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:44,209 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:44,209 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:44,211 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:48,862 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:48,866 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:49,094 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:49,095 - INFO - ==================================================
2026-02-10 10:43:49,097 - INFO -   [탐색 74] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:49,116 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:49,116 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:49,118 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:53,537 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:53,538 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:53,752 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:53,753 - INFO - ==================================================
2026-02-10 10:43:53,755 - INFO -   [탐색 75] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:53,773 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:53,774 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:53,775 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:43:58,876 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:43:58,878 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:43:59,095 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:43:59,095 - INFO - ==================================================
2026-02-10 10:43:59,096 - INFO -   [탐색 76] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:43:59,112 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:43:59,112 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:43:59,114 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:03,770 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:03,771 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:04,540 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:04,541 - INFO - ==================================================
2026-02-10 10:44:04,543 - INFO -   [탐색 77] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:04,559 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:04,559 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:04,560 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:09,069 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:09,070 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:09,317 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:09,317 - INFO - ==================================================
2026-02-10 10:44:09,319 - INFO -   [탐색 78] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:09,335 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:09,336 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:09,337 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:14,176 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:14,178 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:14,351 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:14,351 - INFO - ==================================================
2026-02-10 10:44:14,352 - INFO -   [탐색 79] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:14,362 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:14,362 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:14,362 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:18,839 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:18,840 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:19,058 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:19,058 - INFO - ==================================================
2026-02-10 10:44:19,060 - INFO -   [탐색 80] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:19,076 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:19,076 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:19,077 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:23,424 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:23,425 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:23,631 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:23,631 - INFO - ==================================================
2026-02-10 10:44:23,633 - INFO -   [탐색 81] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:23,652 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:23,652 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:23,653 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:27,834 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:27,835 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:28,594 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:28,595 - INFO - ==================================================
2026-02-10 10:44:28,598 - INFO -   [탐색 82] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:28,615 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:28,616 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:28,617 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:32,842 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:32,842 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:33,061 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:33,061 - INFO - ==================================================
2026-02-10 10:44:33,063 - INFO -   [탐색 83] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:33,079 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:33,079 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:33,081 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:37,710 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:37,711 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:37,940 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:37,941 - INFO - ==================================================
2026-02-10 10:44:37,942 - INFO -   [탐색 84] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:37,961 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:37,961 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:37,963 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:42,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:42,933 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:43,164 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:43,165 - INFO - ==================================================
2026-02-10 10:44:43,166 - INFO -   [탐색 85] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:43,183 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:43,183 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:43,185 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:47,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:47,653 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:47,883 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:47,884 - INFO - ==================================================
2026-02-10 10:44:47,885 - INFO -   [탐색 86] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:47,904 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:47,904 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:47,905 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:53,040 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:53,041 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:53,809 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:53,810 - INFO - ==================================================
2026-02-10 10:44:53,812 - INFO -   [탐색 87] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:53,829 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:53,829 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:53,831 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:44:58,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:44:58,112 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:44:58,337 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:44:58,337 - INFO - ==================================================
2026-02-10 10:44:58,339 - INFO -   [탐색 88] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:44:58,359 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:44:58,359 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:44:58,361 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:02,560 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:02,561 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:02,799 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:02,800 - INFO - ==================================================
2026-02-10 10:45:02,801 - INFO -   [탐색 89] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:02,820 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:02,820 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:02,822 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:07,253 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:07,254 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:07,480 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:07,480 - INFO - ==================================================
2026-02-10 10:45:07,482 - INFO -   [탐색 90] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:07,499 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:07,499 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:07,500 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:12,188 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:12,188 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:12,395 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:12,396 - INFO - ==================================================
2026-02-10 10:45:12,397 - INFO -   [탐색 91] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:12,415 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:12,415 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:12,416 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:17,261 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:17,262 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:18,011 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:18,011 - INFO - ==================================================
2026-02-10 10:45:18,013 - INFO -   [탐색 92] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:18,032 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:18,032 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:18,035 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:22,786 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:22,787 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:23,023 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:23,023 - INFO - ==================================================
2026-02-10 10:45:23,026 - INFO -   [탐색 93] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:23,042 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:23,042 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:23,043 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:27,730 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:27,731 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:27,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:27,971 - INFO - ==================================================
2026-02-10 10:45:27,973 - INFO -   [탐색 94] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:27,990 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:27,990 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:27,992 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:32,567 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:32,568 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:32,784 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:32,785 - INFO - ==================================================
2026-02-10 10:45:32,787 - INFO -   [탐색 95] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:32,804 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:32,804 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:32,806 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:36,891 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:36,892 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:37,095 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:37,096 - INFO - ==================================================
2026-02-10 10:45:37,097 - INFO -   [탐색 96] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:37,113 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:37,113 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:37,114 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:41,670 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:41,671 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:42,476 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:42,476 - INFO - ==================================================
2026-02-10 10:45:42,478 - INFO -   [탐색 97] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:42,499 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:42,499 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:42,500 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:47,086 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:47,087 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:47,311 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:47,311 - INFO - ==================================================
2026-02-10 10:45:47,313 - INFO -   [탐색 98] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:47,330 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:47,331 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:47,332 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:52,180 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:52,182 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:52,424 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:52,424 - INFO - ==================================================
2026-02-10 10:45:52,425 - INFO -   [탐색 99] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:52,442 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:52,442 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:52,443 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:45:57,225 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:45:57,226 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:45:57,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:45:57,445 - INFO - ==================================================
2026-02-10 10:45:57,446 - INFO -   [탐색 100] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:45:57,447 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.9784 입니다.
2026-02-10 10:45:57,447 - INFO - ================================================================================
2026-02-10 10:45:57,449 - INFO - 계산된 Pruning 정보(희소도: 0.9784)를 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/pruning_info.yaml'에 저장했습니다.
2026-02-10 10:45:57,473 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 10:45:57,524 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:45:57,524 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:45:57,526 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:46:01,523 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:46:01,527 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:46:01,755 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 10:46:01,755 - INFO - ==================================================
2026-02-10 10:46:01,756 - INFO - ==================================================
2026-02-10 10:46:01,756 - INFO - 모델 파라미터 수:
2026-02-10 10:46:01,756 - INFO -   - 총 파라미터: 49,678 개
2026-02-10 10:46:01,756 - INFO -   - 학습 가능한 파라미터: 49,678 개
2026-02-10 10:46:01,782 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 10:46:01,834 - INFO - FLOPs가 2.1493 GFLOPs에서 0.0163 GFLOPs로 감소했습니다 (감소율: 99.24%).
2026-02-10 10:46:01,835 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 10:46:01,835 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 10:46:01,836 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 10:46:01,836 - INFO - ==================================================
2026-02-10 10:46:01,836 - INFO - train 모드를 시작합니다.
2026-02-10 10:46:01,836 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 10:46:01,836 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 10:46:01,836 - INFO - --------------------------------------------------
2026-02-10 10:46:01,837 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 10:46:06,795 - INFO - [Train] [11/90] | Loss: 0.6651 | Train Acc: 65.77%
2026-02-10 10:46:08,125 - INFO - [Valid] [11/90] | Loss: 0.6622 | Val Acc: 61.95%
2026-02-10 10:46:08,130 - INFO - [Metrics for 'abnormal'] | Precision: 0.5547 | Recall: 0.9045 | F1: 0.6877
2026-02-10 10:46:08,130 - INFO - [Metrics for 'normal'] | Precision: 0.8193 | Recall: 0.3736 | F1: 0.5132
2026-02-10 10:46:08,152 - INFO - [Best Model Saved] (val loss: 0.6622) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:08,152 - INFO - --------------------------------------------------
2026-02-10 10:46:08,157 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 10:46:13,259 - INFO - [Train] [12/90] | Loss: 0.6401 | Train Acc: 66.89%
2026-02-10 10:46:14,669 - INFO - [Valid] [12/90] | Loss: 0.6465 | Val Acc: 62.83%
2026-02-10 10:46:14,674 - INFO - [Metrics for 'abnormal'] | Precision: 0.6069 | Recall: 0.5605 | F1: 0.5828
2026-02-10 10:46:14,674 - INFO - [Metrics for 'normal'] | Precision: 0.6443 | Recall: 0.6868 | F1: 0.6649
2026-02-10 10:46:14,686 - INFO - [Best Model Saved] (val loss: 0.6465) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:14,686 - INFO - --------------------------------------------------
2026-02-10 10:46:14,687 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 10:46:19,656 - INFO - [Train] [13/90] | Loss: 0.6177 | Train Acc: 68.60%
2026-02-10 10:46:20,879 - INFO - [Valid] [13/90] | Loss: 0.6436 | Val Acc: 62.24%
2026-02-10 10:46:20,887 - INFO - [Metrics for 'abnormal'] | Precision: 0.5597 | Recall: 0.8662 | F1: 0.6800
2026-02-10 10:46:20,888 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.4121 | F1: 0.5396
2026-02-10 10:46:20,905 - INFO - [Best Model Saved] (val loss: 0.6436) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:20,906 - INFO - --------------------------------------------------
2026-02-10 10:46:20,907 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 10:46:26,126 - INFO - [Train] [14/90] | Loss: 0.6103 | Train Acc: 68.38%
2026-02-10 10:46:27,391 - INFO - [Valid] [14/90] | Loss: 0.6265 | Val Acc: 64.01%
2026-02-10 10:46:27,397 - INFO - [Metrics for 'abnormal'] | Precision: 0.5738 | Recall: 0.8662 | F1: 0.6904
2026-02-10 10:46:27,397 - INFO - [Metrics for 'normal'] | Precision: 0.7941 | Recall: 0.4451 | F1: 0.5704
2026-02-10 10:46:27,409 - INFO - [Best Model Saved] (val loss: 0.6265) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:27,410 - INFO - --------------------------------------------------
2026-02-10 10:46:27,411 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 10:46:33,048 - INFO - [Train] [15/90] | Loss: 0.5860 | Train Acc: 71.95%
2026-02-10 10:46:34,227 - INFO - [Valid] [15/90] | Loss: 0.6249 | Val Acc: 64.01%
2026-02-10 10:46:34,233 - INFO - [Metrics for 'abnormal'] | Precision: 0.5738 | Recall: 0.8662 | F1: 0.6904
2026-02-10 10:46:34,233 - INFO - [Metrics for 'normal'] | Precision: 0.7941 | Recall: 0.4451 | F1: 0.5704
2026-02-10 10:46:34,250 - INFO - [Best Model Saved] (val loss: 0.6249) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:34,250 - INFO - --------------------------------------------------
2026-02-10 10:46:34,251 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 10:46:39,467 - INFO - [Train] [16/90] | Loss: 0.5668 | Train Acc: 73.07%
2026-02-10 10:46:40,771 - INFO - [Valid] [16/90] | Loss: 0.5969 | Val Acc: 70.80%
2026-02-10 10:46:40,775 - INFO - [Metrics for 'abnormal'] | Precision: 0.7788 | Recall: 0.5159 | F1: 0.6207
2026-02-10 10:46:40,776 - INFO - [Metrics for 'normal'] | Precision: 0.6766 | Recall: 0.8736 | F1: 0.7626
2026-02-10 10:46:40,791 - INFO - [Best Model Saved] (val loss: 0.5969) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:40,791 - INFO - --------------------------------------------------
2026-02-10 10:46:40,792 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 10:46:46,307 - INFO - [Train] [17/90] | Loss: 0.5586 | Train Acc: 74.40%
2026-02-10 10:46:47,605 - INFO - [Valid] [17/90] | Loss: 0.5904 | Val Acc: 73.45%
2026-02-10 10:46:47,610 - INFO - [Metrics for 'abnormal'] | Precision: 0.7863 | Recall: 0.5860 | F1: 0.6715
2026-02-10 10:46:47,610 - INFO - [Metrics for 'normal'] | Precision: 0.7072 | Recall: 0.8626 | F1: 0.7772
2026-02-10 10:46:47,622 - INFO - [Best Model Saved] (val loss: 0.5904) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:47,623 - INFO - --------------------------------------------------
2026-02-10 10:46:47,624 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 10:46:52,621 - INFO - [Train] [18/90] | Loss: 0.5466 | Train Acc: 75.30%
2026-02-10 10:46:53,879 - INFO - [Valid] [18/90] | Loss: 0.5742 | Val Acc: 71.39%
2026-02-10 10:46:53,885 - INFO - [Metrics for 'abnormal'] | Precision: 0.6705 | Recall: 0.7516 | F1: 0.7087
2026-02-10 10:46:53,885 - INFO - [Metrics for 'normal'] | Precision: 0.7607 | Recall: 0.6813 | F1: 0.7188
2026-02-10 10:46:53,901 - INFO - [Best Model Saved] (val loss: 0.5742) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:46:53,901 - INFO - --------------------------------------------------
2026-02-10 10:46:53,903 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 10:46:58,248 - INFO - [Train] [19/90] | Loss: 0.5478 | Train Acc: 76.34%
2026-02-10 10:46:58,935 - INFO - [Valid] [19/90] | Loss: 0.5762 | Val Acc: 69.62%
2026-02-10 10:46:58,944 - INFO - [Metrics for 'abnormal'] | Precision: 0.6364 | Recall: 0.8025 | F1: 0.7099
2026-02-10 10:46:58,944 - INFO - [Metrics for 'normal'] | Precision: 0.7801 | Recall: 0.6044 | F1: 0.6811
2026-02-10 10:46:58,946 - INFO - --------------------------------------------------
2026-02-10 10:46:58,946 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 10:47:03,517 - INFO - [Train] [20/90] | Loss: 0.5213 | Train Acc: 77.68%
2026-02-10 10:47:04,215 - INFO - [Valid] [20/90] | Loss: 0.5547 | Val Acc: 75.81%
2026-02-10 10:47:04,217 - INFO - [Metrics for 'abnormal'] | Precision: 0.7419 | Recall: 0.7325 | F1: 0.7372
2026-02-10 10:47:04,217 - INFO - [Metrics for 'normal'] | Precision: 0.7717 | Recall: 0.7802 | F1: 0.7760
2026-02-10 10:47:04,224 - INFO - [Best Model Saved] (val loss: 0.5547) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:47:04,224 - INFO - --------------------------------------------------
2026-02-10 10:47:04,224 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 10:47:07,355 - INFO - [Train] [21/90] | Loss: 0.5069 | Train Acc: 78.65%
2026-02-10 10:47:07,927 - INFO - [Valid] [21/90] | Loss: 0.5392 | Val Acc: 76.99%
2026-02-10 10:47:07,931 - INFO - [Metrics for 'abnormal'] | Precision: 0.7394 | Recall: 0.7771 | F1: 0.7578
2026-02-10 10:47:07,932 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.7637 | F1: 0.7809
2026-02-10 10:47:07,942 - INFO - [Best Model Saved] (val loss: 0.5392) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:47:07,942 - INFO - --------------------------------------------------
2026-02-10 10:47:07,943 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 10:47:11,279 - INFO - [Train] [22/90] | Loss: 0.5024 | Train Acc: 78.87%
2026-02-10 10:47:11,800 - INFO - [Valid] [22/90] | Loss: 0.5370 | Val Acc: 76.40%
2026-02-10 10:47:11,804 - INFO - [Metrics for 'abnormal'] | Precision: 0.7655 | Recall: 0.7070 | F1: 0.7351
2026-02-10 10:47:11,805 - INFO - [Metrics for 'normal'] | Precision: 0.7629 | Recall: 0.8132 | F1: 0.7872
2026-02-10 10:47:11,818 - INFO - [Best Model Saved] (val loss: 0.5370) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:47:11,818 - INFO - --------------------------------------------------
2026-02-10 10:47:11,818 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 10:47:14,634 - INFO - [Train] [23/90] | Loss: 0.5114 | Train Acc: 78.57%
2026-02-10 10:47:15,099 - INFO - [Valid] [23/90] | Loss: 0.5314 | Val Acc: 76.70%
2026-02-10 10:47:15,104 - INFO - [Metrics for 'abnormal'] | Precision: 0.7468 | Recall: 0.7516 | F1: 0.7492
2026-02-10 10:47:15,105 - INFO - [Metrics for 'normal'] | Precision: 0.7845 | Recall: 0.7802 | F1: 0.7824
2026-02-10 10:47:15,115 - INFO - [Best Model Saved] (val loss: 0.5314) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:47:15,116 - INFO - --------------------------------------------------
2026-02-10 10:47:15,117 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 10:47:17,837 - INFO - [Train] [24/90] | Loss: 0.4984 | Train Acc: 78.94%
2026-02-10 10:47:18,359 - INFO - [Valid] [24/90] | Loss: 0.5710 | Val Acc: 75.22%
2026-02-10 10:47:18,362 - INFO - [Metrics for 'abnormal'] | Precision: 0.6952 | Recall: 0.8280 | F1: 0.7558
2026-02-10 10:47:18,362 - INFO - [Metrics for 'normal'] | Precision: 0.8224 | Recall: 0.6868 | F1: 0.7485
2026-02-10 10:47:18,363 - INFO - --------------------------------------------------
2026-02-10 10:47:18,363 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 10:47:20,942 - INFO - [Train] [25/90] | Loss: 0.5104 | Train Acc: 78.72%
2026-02-10 10:47:21,494 - INFO - [Valid] [25/90] | Loss: 0.5489 | Val Acc: 75.22%
2026-02-10 10:47:21,497 - INFO - [Metrics for 'abnormal'] | Precision: 0.7062 | Recall: 0.7962 | F1: 0.7485
2026-02-10 10:47:21,497 - INFO - [Metrics for 'normal'] | Precision: 0.8025 | Recall: 0.7143 | F1: 0.7558
2026-02-10 10:47:21,498 - INFO - --------------------------------------------------
2026-02-10 10:47:21,498 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 10:47:24,034 - INFO - [Train] [26/90] | Loss: 0.5001 | Train Acc: 79.09%
2026-02-10 10:47:24,559 - INFO - [Valid] [26/90] | Loss: 0.5578 | Val Acc: 75.22%
2026-02-10 10:47:24,562 - INFO - [Metrics for 'abnormal'] | Precision: 0.6931 | Recall: 0.8344 | F1: 0.7572
2026-02-10 10:47:24,562 - INFO - [Metrics for 'normal'] | Precision: 0.8267 | Recall: 0.6813 | F1: 0.7470
2026-02-10 10:47:24,563 - INFO - --------------------------------------------------
2026-02-10 10:47:24,564 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 10:47:27,156 - INFO - [Train] [27/90] | Loss: 0.4899 | Train Acc: 79.84%
2026-02-10 10:47:27,684 - INFO - [Valid] [27/90] | Loss: 0.5334 | Val Acc: 76.99%
2026-02-10 10:47:27,687 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.7325 | F1: 0.7468
2026-02-10 10:47:27,687 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8022 | F1: 0.7892
2026-02-10 10:47:27,688 - INFO - --------------------------------------------------
2026-02-10 10:47:27,688 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 10:47:30,263 - INFO - [Train] [28/90] | Loss: 0.5120 | Train Acc: 78.50%
2026-02-10 10:47:30,791 - INFO - [Valid] [28/90] | Loss: 0.5331 | Val Acc: 76.99%
2026-02-10 10:47:30,793 - INFO - [Metrics for 'abnormal'] | Precision: 0.7548 | Recall: 0.7452 | F1: 0.7500
2026-02-10 10:47:30,794 - INFO - [Metrics for 'normal'] | Precision: 0.7826 | Recall: 0.7912 | F1: 0.7869
2026-02-10 10:47:30,794 - INFO - --------------------------------------------------
2026-02-10 10:47:30,795 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 10:47:33,307 - INFO - [Train] [29/90] | Loss: 0.4988 | Train Acc: 79.54%
2026-02-10 10:47:33,809 - INFO - [Valid] [29/90] | Loss: 0.5313 | Val Acc: 77.58%
2026-02-10 10:47:33,812 - INFO - [Metrics for 'abnormal'] | Precision: 0.7580 | Recall: 0.7580 | F1: 0.7580
2026-02-10 10:47:33,812 - INFO - [Metrics for 'normal'] | Precision: 0.7912 | Recall: 0.7912 | F1: 0.7912
2026-02-10 10:47:33,819 - INFO - [Best Model Saved] (val loss: 0.5313) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:47:33,819 - INFO - --------------------------------------------------
2026-02-10 10:47:33,819 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 10:47:36,397 - INFO - [Train] [30/90] | Loss: 0.4871 | Train Acc: 80.80%
2026-02-10 10:47:36,925 - INFO - [Valid] [30/90] | Loss: 0.5393 | Val Acc: 78.17%
2026-02-10 10:47:36,927 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7261 | F1: 0.7550
2026-02-10 10:47:36,927 - INFO - [Metrics for 'normal'] | Precision: 0.7784 | Recall: 0.8297 | F1: 0.8032
2026-02-10 10:47:36,928 - INFO - --------------------------------------------------
2026-02-10 10:47:36,929 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 10:47:39,488 - INFO - [Train] [31/90] | Loss: 0.4990 | Train Acc: 79.91%
2026-02-10 10:47:40,020 - INFO - [Valid] [31/90] | Loss: 0.5403 | Val Acc: 75.81%
2026-02-10 10:47:40,023 - INFO - [Metrics for 'abnormal'] | Precision: 0.7193 | Recall: 0.7834 | F1: 0.7500
2026-02-10 10:47:40,023 - INFO - [Metrics for 'normal'] | Precision: 0.7976 | Recall: 0.7363 | F1: 0.7657
2026-02-10 10:47:40,024 - INFO - --------------------------------------------------
2026-02-10 10:47:40,024 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 10:47:42,560 - INFO - [Train] [32/90] | Loss: 0.4877 | Train Acc: 80.95%
2026-02-10 10:47:43,090 - INFO - [Valid] [32/90] | Loss: 0.5356 | Val Acc: 76.70%
2026-02-10 10:47:43,093 - INFO - [Metrics for 'abnormal'] | Precision: 0.7438 | Recall: 0.7580 | F1: 0.7508
2026-02-10 10:47:43,093 - INFO - [Metrics for 'normal'] | Precision: 0.7877 | Recall: 0.7747 | F1: 0.7812
2026-02-10 10:47:43,094 - INFO - --------------------------------------------------
2026-02-10 10:47:43,094 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 10:47:45,618 - INFO - [Train] [33/90] | Loss: 0.4908 | Train Acc: 80.65%
2026-02-10 10:47:46,133 - INFO - [Valid] [33/90] | Loss: 0.5401 | Val Acc: 75.52%
2026-02-10 10:47:46,135 - INFO - [Metrics for 'abnormal'] | Precision: 0.7229 | Recall: 0.7643 | F1: 0.7430
2026-02-10 10:47:46,135 - INFO - [Metrics for 'normal'] | Precision: 0.7861 | Recall: 0.7473 | F1: 0.7662
2026-02-10 10:47:46,136 - INFO - --------------------------------------------------
2026-02-10 10:47:46,137 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 10:47:48,736 - INFO - [Train] [34/90] | Loss: 0.4865 | Train Acc: 80.21%
2026-02-10 10:47:49,296 - INFO - [Valid] [34/90] | Loss: 0.5326 | Val Acc: 79.06%
2026-02-10 10:47:49,300 - INFO - [Metrics for 'abnormal'] | Precision: 0.8162 | Recall: 0.7070 | F1: 0.7577
2026-02-10 10:47:49,300 - INFO - [Metrics for 'normal'] | Precision: 0.7734 | Recall: 0.8626 | F1: 0.8156
2026-02-10 10:47:49,301 - INFO - --------------------------------------------------
2026-02-10 10:47:49,301 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 10:47:51,864 - INFO - [Train] [35/90] | Loss: 0.4851 | Train Acc: 80.95%
2026-02-10 10:47:52,417 - INFO - [Valid] [35/90] | Loss: 0.5535 | Val Acc: 74.93%
2026-02-10 10:47:52,420 - INFO - [Metrics for 'abnormal'] | Precision: 0.6978 | Recall: 0.8089 | F1: 0.7493
2026-02-10 10:47:52,420 - INFO - [Metrics for 'normal'] | Precision: 0.8089 | Recall: 0.6978 | F1: 0.7493
2026-02-10 10:47:52,421 - INFO - --------------------------------------------------
2026-02-10 10:47:52,421 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 10:47:54,973 - INFO - [Train] [36/90] | Loss: 0.4794 | Train Acc: 81.55%
2026-02-10 10:47:55,506 - INFO - [Valid] [36/90] | Loss: 0.5319 | Val Acc: 76.11%
2026-02-10 10:47:55,509 - INFO - [Metrics for 'abnormal'] | Precision: 0.7436 | Recall: 0.7389 | F1: 0.7412
2026-02-10 10:47:55,509 - INFO - [Metrics for 'normal'] | Precision: 0.7760 | Recall: 0.7802 | F1: 0.7781
2026-02-10 10:47:55,510 - INFO - --------------------------------------------------
2026-02-10 10:47:55,511 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 10:47:58,070 - INFO - [Train] [37/90] | Loss: 0.4773 | Train Acc: 81.40%
2026-02-10 10:47:58,624 - INFO - [Valid] [37/90] | Loss: 0.5363 | Val Acc: 76.40%
2026-02-10 10:47:58,627 - INFO - [Metrics for 'abnormal'] | Precision: 0.7452 | Recall: 0.7452 | F1: 0.7452
2026-02-10 10:47:58,627 - INFO - [Metrics for 'normal'] | Precision: 0.7802 | Recall: 0.7802 | F1: 0.7802
2026-02-10 10:47:58,628 - INFO - --------------------------------------------------
2026-02-10 10:47:58,629 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 10:48:01,152 - INFO - [Train] [38/90] | Loss: 0.4871 | Train Acc: 81.70%
2026-02-10 10:48:01,685 - INFO - [Valid] [38/90] | Loss: 0.5344 | Val Acc: 76.40%
2026-02-10 10:48:01,688 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.7707 | F1: 0.7516
2026-02-10 10:48:01,688 - INFO - [Metrics for 'normal'] | Precision: 0.7931 | Recall: 0.7582 | F1: 0.7753
2026-02-10 10:48:01,689 - INFO - --------------------------------------------------
2026-02-10 10:48:01,690 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 10:48:04,315 - INFO - [Train] [39/90] | Loss: 0.4836 | Train Acc: 82.14%
2026-02-10 10:48:04,920 - INFO - [Valid] [39/90] | Loss: 0.5404 | Val Acc: 76.99%
2026-02-10 10:48:04,923 - INFO - [Metrics for 'abnormal'] | Precision: 0.7453 | Recall: 0.7643 | F1: 0.7547
2026-02-10 10:48:04,923 - INFO - [Metrics for 'normal'] | Precision: 0.7921 | Recall: 0.7747 | F1: 0.7833
2026-02-10 10:48:04,924 - INFO - --------------------------------------------------
2026-02-10 10:48:04,924 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 10:48:07,498 - INFO - [Train] [40/90] | Loss: 0.4858 | Train Acc: 81.77%
2026-02-10 10:48:08,121 - INFO - [Valid] [40/90] | Loss: 0.5218 | Val Acc: 78.17%
2026-02-10 10:48:08,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7902 | Recall: 0.7197 | F1: 0.7533
2026-02-10 10:48:08,124 - INFO - [Metrics for 'normal'] | Precision: 0.7755 | Recall: 0.8352 | F1: 0.8042
2026-02-10 10:48:08,130 - INFO - [Best Model Saved] (val loss: 0.5218) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:08,130 - INFO - --------------------------------------------------
2026-02-10 10:48:08,131 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 10:48:10,688 - INFO - [Train] [41/90] | Loss: 0.4795 | Train Acc: 81.62%
2026-02-10 10:48:11,237 - INFO - [Valid] [41/90] | Loss: 0.5205 | Val Acc: 77.58%
2026-02-10 10:48:11,240 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.7452 | F1: 0.7548
2026-02-10 10:48:11,240 - INFO - [Metrics for 'normal'] | Precision: 0.7849 | Recall: 0.8022 | F1: 0.7935
2026-02-10 10:48:11,247 - INFO - [Best Model Saved] (val loss: 0.5205) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:11,247 - INFO - --------------------------------------------------
2026-02-10 10:48:11,247 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 10:48:13,760 - INFO - [Train] [42/90] | Loss: 0.4721 | Train Acc: 82.29%
2026-02-10 10:48:14,293 - INFO - [Valid] [42/90] | Loss: 0.5260 | Val Acc: 79.35%
2026-02-10 10:48:14,296 - INFO - [Metrics for 'abnormal'] | Precision: 0.8321 | Recall: 0.6943 | F1: 0.7569
2026-02-10 10:48:14,296 - INFO - [Metrics for 'normal'] | Precision: 0.7692 | Recall: 0.8791 | F1: 0.8205
2026-02-10 10:48:14,297 - INFO - --------------------------------------------------
2026-02-10 10:48:14,297 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 10:48:16,882 - INFO - [Train] [43/90] | Loss: 0.4739 | Train Acc: 81.77%
2026-02-10 10:48:17,407 - INFO - [Valid] [43/90] | Loss: 0.5204 | Val Acc: 78.47%
2026-02-10 10:48:17,410 - INFO - [Metrics for 'abnormal'] | Precision: 0.7917 | Recall: 0.7261 | F1: 0.7575
2026-02-10 10:48:17,410 - INFO - [Metrics for 'normal'] | Precision: 0.7795 | Recall: 0.8352 | F1: 0.8064
2026-02-10 10:48:17,417 - INFO - [Best Model Saved] (val loss: 0.5204) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:17,417 - INFO - --------------------------------------------------
2026-02-10 10:48:17,417 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 10:48:19,949 - INFO - [Train] [44/90] | Loss: 0.4682 | Train Acc: 81.55%
2026-02-10 10:48:20,489 - INFO - [Valid] [44/90] | Loss: 0.5156 | Val Acc: 77.58%
2026-02-10 10:48:20,492 - INFO - [Metrics for 'abnormal'] | Precision: 0.7682 | Recall: 0.7389 | F1: 0.7532
2026-02-10 10:48:20,492 - INFO - [Metrics for 'normal'] | Precision: 0.7819 | Recall: 0.8077 | F1: 0.7946
2026-02-10 10:48:20,499 - INFO - [Best Model Saved] (val loss: 0.5156) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:20,499 - INFO - --------------------------------------------------
2026-02-10 10:48:20,499 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 10:48:23,021 - INFO - [Train] [45/90] | Loss: 0.4673 | Train Acc: 82.51%
2026-02-10 10:48:23,541 - INFO - [Valid] [45/90] | Loss: 0.5269 | Val Acc: 76.99%
2026-02-10 10:48:23,543 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7580 | F1: 0.7532
2026-02-10 10:48:23,543 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.7802 | F1: 0.7845
2026-02-10 10:48:23,544 - INFO - --------------------------------------------------
2026-02-10 10:48:23,545 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 10:48:26,102 - INFO - [Train] [46/90] | Loss: 0.4761 | Train Acc: 81.92%
2026-02-10 10:48:26,635 - INFO - [Valid] [46/90] | Loss: 0.5169 | Val Acc: 78.47%
2026-02-10 10:48:26,637 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.7580 | F1: 0.7653
2026-02-10 10:48:26,637 - INFO - [Metrics for 'normal'] | Precision: 0.7946 | Recall: 0.8077 | F1: 0.8011
2026-02-10 10:48:26,638 - INFO - --------------------------------------------------
2026-02-10 10:48:26,639 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 10:48:29,213 - INFO - [Train] [47/90] | Loss: 0.4613 | Train Acc: 83.26%
2026-02-10 10:48:29,742 - INFO - [Valid] [47/90] | Loss: 0.5368 | Val Acc: 78.17%
2026-02-10 10:48:29,745 - INFO - [Metrics for 'abnormal'] | Precision: 0.7371 | Recall: 0.8217 | F1: 0.7771
2026-02-10 10:48:29,745 - INFO - [Metrics for 'normal'] | Precision: 0.8293 | Recall: 0.7473 | F1: 0.7861
2026-02-10 10:48:29,746 - INFO - --------------------------------------------------
2026-02-10 10:48:29,746 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 10:48:32,353 - INFO - [Train] [48/90] | Loss: 0.4655 | Train Acc: 81.92%
2026-02-10 10:48:32,888 - INFO - [Valid] [48/90] | Loss: 0.5130 | Val Acc: 78.76%
2026-02-10 10:48:32,891 - INFO - [Metrics for 'abnormal'] | Precision: 0.8058 | Recall: 0.7134 | F1: 0.7568
2026-02-10 10:48:32,891 - INFO - [Metrics for 'normal'] | Precision: 0.7750 | Recall: 0.8516 | F1: 0.8115
2026-02-10 10:48:32,897 - INFO - [Best Model Saved] (val loss: 0.5130) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:32,897 - INFO - --------------------------------------------------
2026-02-10 10:48:32,897 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 10:48:35,434 - INFO - [Train] [49/90] | Loss: 0.4657 | Train Acc: 83.11%
2026-02-10 10:48:35,975 - INFO - [Valid] [49/90] | Loss: 0.5156 | Val Acc: 77.58%
2026-02-10 10:48:35,978 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.7452 | F1: 0.7548
2026-02-10 10:48:35,978 - INFO - [Metrics for 'normal'] | Precision: 0.7849 | Recall: 0.8022 | F1: 0.7935
2026-02-10 10:48:35,979 - INFO - --------------------------------------------------
2026-02-10 10:48:35,979 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 10:48:38,522 - INFO - [Train] [50/90] | Loss: 0.4663 | Train Acc: 83.26%
2026-02-10 10:48:39,051 - INFO - [Valid] [50/90] | Loss: 0.5152 | Val Acc: 78.17%
2026-02-10 10:48:39,054 - INFO - [Metrics for 'abnormal'] | Precision: 0.7902 | Recall: 0.7197 | F1: 0.7533
2026-02-10 10:48:39,054 - INFO - [Metrics for 'normal'] | Precision: 0.7755 | Recall: 0.8352 | F1: 0.8042
2026-02-10 10:48:39,055 - INFO - --------------------------------------------------
2026-02-10 10:48:39,055 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 10:48:41,569 - INFO - [Train] [51/90] | Loss: 0.4613 | Train Acc: 82.89%
2026-02-10 10:48:42,075 - INFO - [Valid] [51/90] | Loss: 0.5178 | Val Acc: 77.88%
2026-02-10 10:48:42,078 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.7389 | F1: 0.7557
2026-02-10 10:48:42,078 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.8132 | F1: 0.7978
2026-02-10 10:48:42,079 - INFO - --------------------------------------------------
2026-02-10 10:48:42,079 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 10:48:44,715 - INFO - [Train] [52/90] | Loss: 0.4664 | Train Acc: 82.81%
2026-02-10 10:48:45,241 - INFO - [Valid] [52/90] | Loss: 0.5132 | Val Acc: 77.29%
2026-02-10 10:48:45,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.7597 | Recall: 0.7452 | F1: 0.7524
2026-02-10 10:48:45,243 - INFO - [Metrics for 'normal'] | Precision: 0.7838 | Recall: 0.7967 | F1: 0.7902
2026-02-10 10:48:45,244 - INFO - --------------------------------------------------
2026-02-10 10:48:45,245 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 10:48:47,774 - INFO - [Train] [53/90] | Loss: 0.4620 | Train Acc: 82.81%
2026-02-10 10:48:48,305 - INFO - [Valid] [53/90] | Loss: 0.5125 | Val Acc: 78.17%
2026-02-10 10:48:48,308 - INFO - [Metrics for 'abnormal'] | Precision: 0.7712 | Recall: 0.7516 | F1: 0.7613
2026-02-10 10:48:48,308 - INFO - [Metrics for 'normal'] | Precision: 0.7903 | Recall: 0.8077 | F1: 0.7989
2026-02-10 10:48:48,315 - INFO - [Best Model Saved] (val loss: 0.5125) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:48,315 - INFO - --------------------------------------------------
2026-02-10 10:48:48,316 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 10:48:50,898 - INFO - [Train] [54/90] | Loss: 0.4736 | Train Acc: 82.14%
2026-02-10 10:48:51,460 - INFO - [Valid] [54/90] | Loss: 0.5198 | Val Acc: 78.76%
2026-02-10 10:48:51,463 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.8089 | F1: 0.7791
2026-02-10 10:48:51,463 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.7692 | F1: 0.7955
2026-02-10 10:48:51,464 - INFO - --------------------------------------------------
2026-02-10 10:48:51,464 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 10:48:54,051 - INFO - [Train] [55/90] | Loss: 0.4652 | Train Acc: 82.14%
2026-02-10 10:48:54,657 - INFO - [Valid] [55/90] | Loss: 0.5108 | Val Acc: 78.76%
2026-02-10 10:48:54,660 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-02-10 10:48:54,660 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-02-10 10:48:54,667 - INFO - [Best Model Saved] (val loss: 0.5108) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:54,667 - INFO - --------------------------------------------------
2026-02-10 10:48:54,668 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 10:48:57,258 - INFO - [Train] [56/90] | Loss: 0.4692 | Train Acc: 82.66%
2026-02-10 10:48:57,898 - INFO - [Valid] [56/90] | Loss: 0.5088 | Val Acc: 78.76%
2026-02-10 10:48:57,903 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.7452 | F1: 0.7647
2026-02-10 10:48:57,903 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.8242 | F1: 0.8065
2026-02-10 10:48:57,913 - INFO - [Best Model Saved] (val loss: 0.5088) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:48:57,913 - INFO - --------------------------------------------------
2026-02-10 10:48:57,914 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 10:49:00,373 - INFO - [Train] [57/90] | Loss: 0.4616 | Train Acc: 82.81%
2026-02-10 10:49:00,985 - INFO - [Valid] [57/90] | Loss: 0.5074 | Val Acc: 78.17%
2026-02-10 10:49:00,989 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7261 | F1: 0.7550
2026-02-10 10:49:00,989 - INFO - [Metrics for 'normal'] | Precision: 0.7784 | Recall: 0.8297 | F1: 0.8032
2026-02-10 10:49:00,999 - INFO - [Best Model Saved] (val loss: 0.5074) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:49:00,999 - INFO - --------------------------------------------------
2026-02-10 10:49:01,000 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 10:49:03,542 - INFO - [Train] [58/90] | Loss: 0.4585 | Train Acc: 83.33%
2026-02-10 10:49:04,084 - INFO - [Valid] [58/90] | Loss: 0.5067 | Val Acc: 79.35%
2026-02-10 10:49:04,087 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-02-10 10:49:04,087 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-02-10 10:49:04,095 - INFO - [Best Model Saved] (val loss: 0.5067) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:49:04,095 - INFO - --------------------------------------------------
2026-02-10 10:49:04,095 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 10:49:06,673 - INFO - [Train] [59/90] | Loss: 0.4545 | Train Acc: 82.66%
2026-02-10 10:49:07,228 - INFO - [Valid] [59/90] | Loss: 0.5124 | Val Acc: 79.35%
2026-02-10 10:49:07,233 - INFO - [Metrics for 'abnormal'] | Precision: 0.8042 | Recall: 0.7325 | F1: 0.7667
2026-02-10 10:49:07,233 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.8462 | F1: 0.8148
2026-02-10 10:49:07,234 - INFO - --------------------------------------------------
2026-02-10 10:49:07,235 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 10:49:09,643 - INFO - [Train] [60/90] | Loss: 0.4517 | Train Acc: 83.26%
2026-02-10 10:49:10,183 - INFO - [Valid] [60/90] | Loss: 0.5109 | Val Acc: 79.06%
2026-02-10 10:49:10,187 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-02-10 10:49:10,187 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-02-10 10:49:10,188 - INFO - --------------------------------------------------
2026-02-10 10:49:10,189 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 10:49:12,663 - INFO - [Train] [61/90] | Loss: 0.4500 | Train Acc: 83.18%
2026-02-10 10:49:13,282 - INFO - [Valid] [61/90] | Loss: 0.5214 | Val Acc: 79.35%
2026-02-10 10:49:13,286 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-02-10 10:49:13,286 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-02-10 10:49:13,288 - INFO - --------------------------------------------------
2026-02-10 10:49:13,289 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 10:49:15,744 - INFO - [Train] [62/90] | Loss: 0.4602 | Train Acc: 82.89%
2026-02-10 10:49:16,341 - INFO - [Valid] [62/90] | Loss: 0.5089 | Val Acc: 79.06%
2026-02-10 10:49:16,345 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-02-10 10:49:16,345 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-02-10 10:49:16,347 - INFO - --------------------------------------------------
2026-02-10 10:49:16,347 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 10:49:18,838 - INFO - [Train] [63/90] | Loss: 0.4542 | Train Acc: 83.04%
2026-02-10 10:49:19,446 - INFO - [Valid] [63/90] | Loss: 0.5157 | Val Acc: 79.06%
2026-02-10 10:49:19,450 - INFO - [Metrics for 'abnormal'] | Precision: 0.7722 | Recall: 0.7771 | F1: 0.7746
2026-02-10 10:49:19,450 - INFO - [Metrics for 'normal'] | Precision: 0.8066 | Recall: 0.8022 | F1: 0.8044
2026-02-10 10:49:19,451 - INFO - --------------------------------------------------
2026-02-10 10:49:19,452 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 10:49:21,976 - INFO - [Train] [64/90] | Loss: 0.4587 | Train Acc: 83.04%
2026-02-10 10:49:22,577 - INFO - [Valid] [64/90] | Loss: 0.5131 | Val Acc: 79.06%
2026-02-10 10:49:22,581 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-02-10 10:49:22,581 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-02-10 10:49:22,583 - INFO - --------------------------------------------------
2026-02-10 10:49:22,583 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 10:49:25,122 - INFO - [Train] [65/90] | Loss: 0.4619 | Train Acc: 83.11%
2026-02-10 10:49:25,732 - INFO - [Valid] [65/90] | Loss: 0.5179 | Val Acc: 79.94%
2026-02-10 10:49:25,736 - INFO - [Metrics for 'abnormal'] | Precision: 0.8296 | Recall: 0.7134 | F1: 0.7671
2026-02-10 10:49:25,736 - INFO - [Metrics for 'normal'] | Precision: 0.7794 | Recall: 0.8736 | F1: 0.8238
2026-02-10 10:49:25,737 - INFO - --------------------------------------------------
2026-02-10 10:49:25,738 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 10:49:28,326 - INFO - [Train] [66/90] | Loss: 0.4605 | Train Acc: 83.18%
2026-02-10 10:49:28,883 - INFO - [Valid] [66/90] | Loss: 0.5141 | Val Acc: 80.24%
2026-02-10 10:49:28,887 - INFO - [Metrics for 'abnormal'] | Precision: 0.8041 | Recall: 0.7580 | F1: 0.7803
2026-02-10 10:49:28,887 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8407 | F1: 0.8204
2026-02-10 10:49:28,888 - INFO - --------------------------------------------------
2026-02-10 10:49:28,889 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 10:49:31,375 - INFO - [Train] [67/90] | Loss: 0.4550 | Train Acc: 82.74%
2026-02-10 10:49:31,960 - INFO - [Valid] [67/90] | Loss: 0.5055 | Val Acc: 79.65%
2026-02-10 10:49:31,963 - INFO - [Metrics for 'abnormal'] | Precision: 0.7973 | Recall: 0.7516 | F1: 0.7738
2026-02-10 10:49:31,964 - INFO - [Metrics for 'normal'] | Precision: 0.7958 | Recall: 0.8352 | F1: 0.8150
2026-02-10 10:49:31,971 - INFO - [Best Model Saved] (val loss: 0.5055) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:49:31,971 - INFO - --------------------------------------------------
2026-02-10 10:49:31,971 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 10:49:34,483 - INFO - [Train] [68/90] | Loss: 0.4508 | Train Acc: 83.93%
2026-02-10 10:49:35,115 - INFO - [Valid] [68/90] | Loss: 0.5096 | Val Acc: 79.35%
2026-02-10 10:49:35,119 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-02-10 10:49:35,119 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-02-10 10:49:35,120 - INFO - --------------------------------------------------
2026-02-10 10:49:35,121 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 10:49:37,600 - INFO - [Train] [69/90] | Loss: 0.4468 | Train Acc: 84.75%
2026-02-10 10:49:38,157 - INFO - [Valid] [69/90] | Loss: 0.5082 | Val Acc: 79.35%
2026-02-10 10:49:38,160 - INFO - [Metrics for 'abnormal'] | Precision: 0.8042 | Recall: 0.7325 | F1: 0.7667
2026-02-10 10:49:38,160 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.8462 | F1: 0.8148
2026-02-10 10:49:38,161 - INFO - --------------------------------------------------
2026-02-10 10:49:38,162 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 10:49:40,683 - INFO - [Train] [70/90] | Loss: 0.4422 | Train Acc: 84.23%
2026-02-10 10:49:41,315 - INFO - [Valid] [70/90] | Loss: 0.5065 | Val Acc: 78.76%
2026-02-10 10:49:41,319 - INFO - [Metrics for 'abnormal'] | Precision: 0.7931 | Recall: 0.7325 | F1: 0.7616
2026-02-10 10:49:41,319 - INFO - [Metrics for 'normal'] | Precision: 0.7835 | Recall: 0.8352 | F1: 0.8085
2026-02-10 10:49:41,321 - INFO - --------------------------------------------------
2026-02-10 10:49:41,322 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 10:49:43,826 - INFO - [Train] [71/90] | Loss: 0.4486 | Train Acc: 83.48%
2026-02-10 10:49:44,448 - INFO - [Valid] [71/90] | Loss: 0.5148 | Val Acc: 78.76%
2026-02-10 10:49:44,451 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-02-10 10:49:44,451 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-02-10 10:49:44,452 - INFO - --------------------------------------------------
2026-02-10 10:49:44,452 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 10:49:47,056 - INFO - [Train] [72/90] | Loss: 0.4507 | Train Acc: 84.15%
2026-02-10 10:49:47,604 - INFO - [Valid] [72/90] | Loss: 0.5124 | Val Acc: 80.24%
2026-02-10 10:49:47,608 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-02-10 10:49:47,608 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-02-10 10:49:47,610 - INFO - --------------------------------------------------
2026-02-10 10:49:47,611 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 10:49:50,181 - INFO - [Train] [73/90] | Loss: 0.4446 | Train Acc: 83.56%
2026-02-10 10:49:50,693 - INFO - [Valid] [73/90] | Loss: 0.5123 | Val Acc: 77.88%
2026-02-10 10:49:50,697 - INFO - [Metrics for 'abnormal'] | Precision: 0.7887 | Recall: 0.7134 | F1: 0.7492
2026-02-10 10:49:50,698 - INFO - [Metrics for 'normal'] | Precision: 0.7716 | Recall: 0.8352 | F1: 0.8021
2026-02-10 10:49:50,699 - INFO - --------------------------------------------------
2026-02-10 10:49:50,700 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 10:49:53,200 - INFO - [Train] [74/90] | Loss: 0.4394 | Train Acc: 84.52%
2026-02-10 10:49:53,750 - INFO - [Valid] [74/90] | Loss: 0.5143 | Val Acc: 80.53%
2026-02-10 10:49:53,755 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:49:53,755 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:49:53,756 - INFO - --------------------------------------------------
2026-02-10 10:49:53,757 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 10:49:56,197 - INFO - [Train] [75/90] | Loss: 0.4409 | Train Acc: 84.75%
2026-02-10 10:49:56,850 - INFO - [Valid] [75/90] | Loss: 0.5104 | Val Acc: 79.65%
2026-02-10 10:49:56,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-02-10 10:49:56,854 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-02-10 10:49:56,856 - INFO - --------------------------------------------------
2026-02-10 10:49:56,856 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 10:49:59,363 - INFO - [Train] [76/90] | Loss: 0.4495 | Train Acc: 84.38%
2026-02-10 10:49:59,937 - INFO - [Valid] [76/90] | Loss: 0.5128 | Val Acc: 79.06%
2026-02-10 10:49:59,941 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-02-10 10:49:59,941 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-02-10 10:49:59,943 - INFO - --------------------------------------------------
2026-02-10 10:49:59,943 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 10:50:02,556 - INFO - [Train] [77/90] | Loss: 0.4495 | Train Acc: 83.33%
2026-02-10 10:50:03,071 - INFO - [Valid] [77/90] | Loss: 0.5114 | Val Acc: 80.83%
2026-02-10 10:50:03,076 - INFO - [Metrics for 'abnormal'] | Precision: 0.7949 | Recall: 0.7898 | F1: 0.7923
2026-02-10 10:50:03,076 - INFO - [Metrics for 'normal'] | Precision: 0.8197 | Recall: 0.8242 | F1: 0.8219
2026-02-10 10:50:03,077 - INFO - --------------------------------------------------
2026-02-10 10:50:03,078 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 10:50:05,569 - INFO - [Train] [78/90] | Loss: 0.4420 | Train Acc: 84.90%
2026-02-10 10:50:06,144 - INFO - [Valid] [78/90] | Loss: 0.5081 | Val Acc: 78.76%
2026-02-10 10:50:06,148 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.7452 | F1: 0.7647
2026-02-10 10:50:06,148 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.8242 | F1: 0.8065
2026-02-10 10:50:06,150 - INFO - --------------------------------------------------
2026-02-10 10:50:06,150 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 10:50:08,605 - INFO - [Train] [79/90] | Loss: 0.4637 | Train Acc: 82.74%
2026-02-10 10:50:09,180 - INFO - [Valid] [79/90] | Loss: 0.5106 | Val Acc: 78.76%
2026-02-10 10:50:09,184 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-02-10 10:50:09,184 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-02-10 10:50:09,186 - INFO - --------------------------------------------------
2026-02-10 10:50:09,186 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 10:50:11,717 - INFO - [Train] [80/90] | Loss: 0.4540 | Train Acc: 82.96%
2026-02-10 10:50:12,341 - INFO - [Valid] [80/90] | Loss: 0.5087 | Val Acc: 79.35%
2026-02-10 10:50:12,345 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-02-10 10:50:12,345 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-02-10 10:50:12,347 - INFO - --------------------------------------------------
2026-02-10 10:50:12,347 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 10:50:14,848 - INFO - [Train] [81/90] | Loss: 0.4458 | Train Acc: 83.63%
2026-02-10 10:50:15,398 - INFO - [Valid] [81/90] | Loss: 0.5069 | Val Acc: 79.06%
2026-02-10 10:50:15,402 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-02-10 10:50:15,402 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-02-10 10:50:15,403 - INFO - --------------------------------------------------
2026-02-10 10:50:15,404 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 10:50:17,926 - INFO - [Train] [82/90] | Loss: 0.4421 | Train Acc: 84.52%
2026-02-10 10:50:18,471 - INFO - [Valid] [82/90] | Loss: 0.5045 | Val Acc: 79.06%
2026-02-10 10:50:18,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-02-10 10:50:18,475 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-02-10 10:50:18,485 - INFO - [Best Model Saved] (val loss: 0.5045) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:50:18,486 - INFO - --------------------------------------------------
2026-02-10 10:50:18,486 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 10:50:20,961 - INFO - [Train] [83/90] | Loss: 0.4471 | Train Acc: 83.56%
2026-02-10 10:50:21,561 - INFO - [Valid] [83/90] | Loss: 0.5005 | Val Acc: 79.35%
2026-02-10 10:50:21,566 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.7580 | F1: 0.7727
2026-02-10 10:50:21,566 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8242 | F1: 0.8108
2026-02-10 10:50:21,576 - INFO - [Best Model Saved] (val loss: 0.5005) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:50:21,576 - INFO - --------------------------------------------------
2026-02-10 10:50:21,577 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 10:50:24,093 - INFO - [Train] [84/90] | Loss: 0.4456 | Train Acc: 83.85%
2026-02-10 10:50:24,704 - INFO - [Valid] [84/90] | Loss: 0.5033 | Val Acc: 80.24%
2026-02-10 10:50:24,709 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-02-10 10:50:24,709 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-02-10 10:50:24,710 - INFO - --------------------------------------------------
2026-02-10 10:50:24,711 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 10:50:27,168 - INFO - [Train] [85/90] | Loss: 0.4477 | Train Acc: 83.63%
2026-02-10 10:50:27,702 - INFO - [Valid] [85/90] | Loss: 0.5004 | Val Acc: 79.65%
2026-02-10 10:50:27,705 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-02-10 10:50:27,705 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-02-10 10:50:27,711 - INFO - [Best Model Saved] (val loss: 0.5004) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:50:27,711 - INFO - --------------------------------------------------
2026-02-10 10:50:27,712 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 10:50:30,286 - INFO - [Train] [86/90] | Loss: 0.4430 | Train Acc: 83.85%
2026-02-10 10:50:30,824 - INFO - [Valid] [86/90] | Loss: 0.4987 | Val Acc: 80.53%
2026-02-10 10:50:30,826 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:50:30,827 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:50:30,833 - INFO - [Best Model Saved] (val loss: 0.4987) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:50:30,833 - INFO - --------------------------------------------------
2026-02-10 10:50:30,834 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 10:50:33,344 - INFO - [Train] [87/90] | Loss: 0.4411 | Train Acc: 84.00%
2026-02-10 10:50:33,876 - INFO - [Valid] [87/90] | Loss: 0.5005 | Val Acc: 79.94%
2026-02-10 10:50:33,878 - INFO - [Metrics for 'abnormal'] | Precision: 0.7947 | Recall: 0.7643 | F1: 0.7792
2026-02-10 10:50:33,879 - INFO - [Metrics for 'normal'] | Precision: 0.8032 | Recall: 0.8297 | F1: 0.8162
2026-02-10 10:50:33,879 - INFO - --------------------------------------------------
2026-02-10 10:50:33,880 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 10:50:36,448 - INFO - [Train] [88/90] | Loss: 0.4439 | Train Acc: 84.23%
2026-02-10 10:50:36,977 - INFO - [Valid] [88/90] | Loss: 0.5012 | Val Acc: 79.35%
2026-02-10 10:50:36,979 - INFO - [Metrics for 'abnormal'] | Precision: 0.7919 | Recall: 0.7516 | F1: 0.7712
2026-02-10 10:50:36,979 - INFO - [Metrics for 'normal'] | Precision: 0.7947 | Recall: 0.8297 | F1: 0.8118
2026-02-10 10:50:36,980 - INFO - --------------------------------------------------
2026-02-10 10:50:36,981 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 10:50:39,546 - INFO - [Train] [89/90] | Loss: 0.4374 | Train Acc: 84.15%
2026-02-10 10:50:40,067 - INFO - [Valid] [89/90] | Loss: 0.5003 | Val Acc: 79.65%
2026-02-10 10:50:40,070 - INFO - [Metrics for 'abnormal'] | Precision: 0.7973 | Recall: 0.7516 | F1: 0.7738
2026-02-10 10:50:40,070 - INFO - [Metrics for 'normal'] | Precision: 0.7958 | Recall: 0.8352 | F1: 0.8150
2026-02-10 10:50:40,071 - INFO - --------------------------------------------------
2026-02-10 10:50:40,071 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 10:50:42,596 - INFO - [Train] [90/90] | Loss: 0.4406 | Train Acc: 84.08%
2026-02-10 10:50:43,129 - INFO - [Valid] [90/90] | Loss: 0.5048 | Val Acc: 79.65%
2026-02-10 10:50:43,132 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-02-10 10:50:43,132 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-02-10 10:50:43,133 - INFO - ==================================================
2026-02-10 10:50:43,133 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 10:50:43,133 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 10:50:43,133 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 10:50:43,169 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 10:50:43,170 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 10:50:43,170 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 10:50:43,170 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 10:50:43,171 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 10:50:45,069 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:50:45,070 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:50:45,499 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 10:50:45,500 - INFO - ==================================================
2026-02-10 10:50:45,514 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/best_model.pth'
2026-02-10 10:50:45,514 - INFO - ==================================================
2026-02-10 10:50:45,514 - INFO - Test 모드를 시작합니다.
2026-02-10 10:50:45,593 - INFO - 연산량 (MACs): 0.0082 GMACs per sample
2026-02-10 10:50:45,593 - INFO - 연산량 (FLOPs): 0.0163 GFLOPs per sample
2026-02-10 10:50:45,593 - INFO - ==================================================
2026-02-10 10:50:45,593 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 10:50:46,169 - INFO - 샘플 당 평균 Forward Pass 시간: 1.56ms (std: 0.21ms), FPS: 657.10 (std: 117.16) (1개 샘플 x 100회 반복)
2026-02-10 10:50:46,169 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 104.54 MB
2026-02-10 10:50:46,169 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 10:50:46,778 - INFO - [Test] Loss: 0.4398 | Test Acc: 80.53%
2026-02-10 10:50:46,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:50:46,782 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:50:46,907 - INFO - ==================================================
2026-02-10 10:50:46,908 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/confusion_matrix_20260210_103635.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/confusion_matrix_20260210_103635.pdf'
2026-02-10 10:50:46,908 - INFO - ==================================================
2026-02-10 10:50:46,908 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 10:50:47,042 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/model_fp32_20260210_103635.onnx'에 저장되었습니다. (크기: 0.30 MB)
2026-02-10 10:50:47,294 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 9.56 MB
2026-02-10 10:50:47,295 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 10:50:47,815 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 2.52ms (std: 1.94ms)
2026-02-10 10:50:47,816 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 437.25 FPS (std: 54.00) (1개 샘플 x 100회 반복)
2026-02-10 10:50:47,816 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 3.94 MB
2026-02-10 10:50:47,816 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 13.46 MB
2026-02-10 10:50:50,435 - INFO - [Test (ONNX)] | Test Acc (ONNX): 80.53%
2026-02-10 10:50:50,439 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:50:50,439 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:50:50,623 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/val_acc.pdf'
2026-02-10 10:50:50,780 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/train_val_acc.pdf'
2026-02-10 10:50:50,910 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/F1_normal.pdf'
2026-02-10 10:50:51,057 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/val_loss.pdf'
2026-02-10 10:50:51,190 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/learning_rate.pdf'
2026-02-10 10:50:52,232 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260210_103635/graph_20260210_103635/compile.pdf'
