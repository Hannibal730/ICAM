2026-02-10 08:54:07,099 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/log_20260210_085407.log'에 저장됩니다.
2026-02-10 08:54:07,102 - INFO - ==================================================
2026-02-10 08:54:07,102 - INFO - config.yaml:
2026-02-10 08:54:07,102 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: mobile_vit_xxs
  use_fpgm_pruning: true
  pruning_params_target: 0.047585

2026-02-10 08:54:07,102 - INFO - ==================================================
2026-02-10 08:54:07,142 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 08:54:07,145 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 08:54:07,145 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 08:54:07,151 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 08:54:07,152 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 08:54:07,152 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 08:54:07,152 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 08:54:07,355 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 08:54:07,370 - INFO - ==================================================
2026-02-10 08:54:07,371 - INFO - 모델 파라미터 수:
2026-02-10 08:54:07,371 - INFO -   - 총 파라미터: 951,666 개
2026-02-10 08:54:07,371 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-02-10 08:54:07,371 - INFO - ================================================================================
2026-02-10 08:54:07,371 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 08:54:07,371 - INFO - ================================================================================
2026-02-10 08:54:07,371 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 08:54:07,372 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 08:54:07,372 - INFO - ==================================================
2026-02-10 08:54:07,372 - INFO - train 모드를 시작합니다.
2026-02-10 08:54:07,372 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 08:54:07,372 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 08:54:07,372 - INFO - --------------------------------------------------
2026-02-10 08:54:07,373 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 08:54:15,444 - INFO - [Train] [1/10] | Loss: 0.5205 | Train Acc: 78.35%
2026-02-10 08:54:17,658 - INFO - [Valid] [1/10] | Loss: 0.5404 | Val Acc: 81.42%
2026-02-10 08:54:17,667 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 08:54:17,667 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 08:54:17,694 - INFO - [Best Model Saved] (val loss: 0.5404) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:54:17,694 - INFO - --------------------------------------------------
2026-02-10 08:54:17,695 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 08:54:24,890 - INFO - [Train] [2/10] | Loss: 0.4617 | Train Acc: 83.33%
2026-02-10 08:54:26,406 - INFO - [Valid] [2/10] | Loss: 0.5170 | Val Acc: 82.60%
2026-02-10 08:54:26,411 - INFO - [Metrics for 'abnormal'] | Precision: 0.8267 | Recall: 0.7898 | F1: 0.8078
2026-02-10 08:54:26,411 - INFO - [Metrics for 'normal'] | Precision: 0.8254 | Recall: 0.8571 | F1: 0.8410
2026-02-10 08:54:26,447 - INFO - [Best Model Saved] (val loss: 0.5170) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:54:26,447 - INFO - --------------------------------------------------
2026-02-10 08:54:26,449 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 08:54:33,172 - INFO - [Train] [3/10] | Loss: 0.4278 | Train Acc: 86.38%
2026-02-10 08:54:34,716 - INFO - [Valid] [3/10] | Loss: 0.5161 | Val Acc: 81.42%
2026-02-10 08:54:34,721 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-02-10 08:54:34,722 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-02-10 08:54:34,771 - INFO - [Best Model Saved] (val loss: 0.5161) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:54:34,772 - INFO - --------------------------------------------------
2026-02-10 08:54:34,773 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 08:54:41,449 - INFO - [Train] [4/10] | Loss: 0.3948 | Train Acc: 87.65%
2026-02-10 08:54:43,089 - INFO - [Valid] [4/10] | Loss: 0.5044 | Val Acc: 81.71%
2026-02-10 08:54:43,094 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-02-10 08:54:43,094 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-02-10 08:54:43,123 - INFO - [Best Model Saved] (val loss: 0.5044) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:54:43,123 - INFO - --------------------------------------------------
2026-02-10 08:54:43,125 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 08:54:49,519 - INFO - [Train] [5/10] | Loss: 0.3827 | Train Acc: 88.39%
2026-02-10 08:54:51,084 - INFO - [Valid] [5/10] | Loss: 0.5930 | Val Acc: 80.53%
2026-02-10 08:54:51,089 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-02-10 08:54:51,089 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-02-10 08:54:51,091 - INFO - --------------------------------------------------
2026-02-10 08:54:51,092 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 08:54:58,191 - INFO - [Train] [6/10] | Loss: 0.3556 | Train Acc: 90.18%
2026-02-10 08:54:59,738 - INFO - [Valid] [6/10] | Loss: 0.5121 | Val Acc: 81.42%
2026-02-10 08:54:59,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-02-10 08:54:59,744 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-02-10 08:54:59,745 - INFO - --------------------------------------------------
2026-02-10 08:54:59,747 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 08:55:06,624 - INFO - [Train] [7/10] | Loss: 0.3049 | Train Acc: 94.12%
2026-02-10 08:55:08,153 - INFO - [Valid] [7/10] | Loss: 0.5070 | Val Acc: 82.30%
2026-02-10 08:55:08,158 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-02-10 08:55:08,158 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-02-10 08:55:08,159 - INFO - --------------------------------------------------
2026-02-10 08:55:08,161 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 08:55:15,001 - INFO - [Train] [8/10] | Loss: 0.2848 | Train Acc: 95.98%
2026-02-10 08:55:16,379 - INFO - [Valid] [8/10] | Loss: 0.5375 | Val Acc: 81.42%
2026-02-10 08:55:16,383 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.8471 | F1: 0.8085
2026-02-10 08:55:16,383 - INFO - [Metrics for 'normal'] | Precision: 0.8563 | Recall: 0.7857 | F1: 0.8195
2026-02-10 08:55:16,385 - INFO - --------------------------------------------------
2026-02-10 08:55:16,386 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 08:55:22,004 - INFO - [Train] [9/10] | Loss: 0.2642 | Train Acc: 97.32%
2026-02-10 08:55:23,384 - INFO - [Valid] [9/10] | Loss: 0.5068 | Val Acc: 82.60%
2026-02-10 08:55:23,388 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-02-10 08:55:23,389 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-02-10 08:55:23,390 - INFO - --------------------------------------------------
2026-02-10 08:55:23,392 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 08:55:29,108 - INFO - [Train] [10/10] | Loss: 0.2548 | Train Acc: 97.62%
2026-02-10 08:55:30,307 - INFO - [Valid] [10/10] | Loss: 0.5141 | Val Acc: 82.60%
2026-02-10 08:55:30,311 - INFO - [Metrics for 'abnormal'] | Precision: 0.8063 | Recall: 0.8217 | F1: 0.8139
2026-02-10 08:55:30,311 - INFO - [Metrics for 'normal'] | Precision: 0.8436 | Recall: 0.8297 | F1: 0.8366
2026-02-10 08:55:30,313 - INFO - ================================================================================
2026-02-10 08:55:30,313 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 08:55:30,313 - INFO - ================================================================================
2026-02-10 08:55:30,367 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'을(를) 불러왔습니다.
2026-02-10 08:55:30,368 - INFO - ================================================================================
2026-02-10 08:55:30,368 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 08:55:30,369 - INFO - 원본 모델 파라미터: 0.9517M
2026-02-10 08:55:30,419 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:30,419 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,420 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,941 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 08:55:30,942 - INFO - ==================================================
2026-02-10 08:55:30,943 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.3049M (감소율: 67.96%)
2026-02-10 08:55:30,969 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:30,969 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,970 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:31,753 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:31,753 - INFO - ==================================================
2026-02-10 08:55:31,756 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1109M (감소율: 88.35%)
2026-02-10 08:55:31,787 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:31,787 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:31,788 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 08:55:32,141 - INFO - ==================================================
2026-02-10 08:55:32,143 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0459M (감소율: 95.18%)
2026-02-10 08:55:32,177 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:32,178 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,179 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,564 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.804375)에 맞춰 변경되었습니다.
2026-02-10 08:55:32,564 - INFO - ==================================================
2026-02-10 08:55:32,566 - INFO -   [탐색  4] 희소도: 0.8044 -> 파라미터: 0.0757M (감소율: 92.04%)
2026-02-10 08:55:32,596 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:32,597 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,597 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,986 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8353124999999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:32,986 - INFO - ==================================================
2026-02-10 08:55:32,988 - INFO -   [탐색  5] 희소도: 0.8353 -> 파라미터: 0.0610M (감소율: 93.59%)
2026-02-10 08:55:33,019 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:33,019 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,019 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,399 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8507812499999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:33,400 - INFO - ==================================================
2026-02-10 08:55:33,401 - INFO -   [탐색  6] 희소도: 0.8508 -> 파라미터: 0.0530M (감소율: 94.43%)
2026-02-10 08:55:33,430 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:33,430 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,431 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,803 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8585156249999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:33,803 - INFO - ==================================================
2026-02-10 08:55:33,805 - INFO -   [탐색  7] 희소도: 0.8585 -> 파라미터: 0.0509M (감소율: 94.65%)
2026-02-10 08:55:34,331 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:34,331 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:34,331 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:34,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8623828124999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:34,682 - INFO - ==================================================
2026-02-10 08:55:34,684 - INFO -   [탐색  8] 희소도: 0.8624 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:34,713 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:34,713 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:34,714 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,134 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 08:55:35,134 - INFO - ==================================================
2026-02-10 08:55:35,136 - INFO -   [탐색  9] 희소도: 0.8643 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:35,165 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:35,166 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,166 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,533 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8633496093749999)에 맞춰 변경되었습니다.
2026-02-10 08:55:35,534 - INFO - ==================================================
2026-02-10 08:55:35,535 - INFO -   [탐색 10] 희소도: 0.8633 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:35,565 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:35,565 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,566 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8628662109374999)에 맞춰 변경되었습니다.
2026-02-10 08:55:35,970 - INFO - ==================================================
2026-02-10 08:55:35,972 - INFO -   [탐색 11] 희소도: 0.8629 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:36,001 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:36,001 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,002 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,385 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8626245117187499)에 맞춰 변경되었습니다.
2026-02-10 08:55:36,385 - INFO - ==================================================
2026-02-10 08:55:36,387 - INFO -   [탐색 12] 희소도: 0.8626 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:36,942 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:36,943 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,943 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,338 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625036621093749)에 맞춰 변경되었습니다.
2026-02-10 08:55:37,338 - INFO - ==================================================
2026-02-10 08:55:37,340 - INFO -   [탐색 13] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:37,369 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:37,369 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,370 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,766 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624432373046874)에 맞춰 변경되었습니다.
2026-02-10 08:55:37,766 - INFO - ==================================================
2026-02-10 08:55:37,767 - INFO -   [탐색 14] 희소도: 0.8624 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:37,799 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:37,799 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,800 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624734497070312)에 맞춰 변경되었습니다.
2026-02-10 08:55:38,177 - INFO - ==================================================
2026-02-10 08:55:38,180 - INFO -   [탐색 15] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:38,209 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:38,210 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,210 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,577 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624885559082031)에 맞춰 변경되었습니다.
2026-02-10 08:55:38,578 - INFO - ==================================================
2026-02-10 08:55:38,580 - INFO -   [탐색 16] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:38,610 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:38,610 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,611 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:39,010 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862496109008789)에 맞춰 변경되었습니다.
2026-02-10 08:55:39,011 - INFO - ==================================================
2026-02-10 08:55:39,013 - INFO -   [탐색 17] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:39,589 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:39,589 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:39,590 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,080 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499885559082)에 맞춰 변경되었습니다.
2026-02-10 08:55:40,080 - INFO - ==================================================
2026-02-10 08:55:40,084 - INFO -   [탐색 18] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:40,115 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:40,115 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,116 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,525 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625017738342284)에 맞춰 변경되었습니다.
2026-02-10 08:55:40,526 - INFO - ==================================================
2026-02-10 08:55:40,528 - INFO -   [탐색 19] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:40,561 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:40,561 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,562 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,996 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625008296966552)에 맞춰 변경되었습니다.
2026-02-10 08:55:40,997 - INFO - ==================================================
2026-02-10 08:55:41,000 - INFO -   [탐색 20] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:41,030 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:41,031 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,031 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,452 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625003576278686)에 맞춰 변경되었습니다.
2026-02-10 08:55:41,453 - INFO - ==================================================
2026-02-10 08:55:41,455 - INFO -   [탐색 21] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:41,484 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:41,485 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,485 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,784 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625001215934753)에 맞춰 변경되었습니다.
2026-02-10 08:55:41,784 - INFO - ==================================================
2026-02-10 08:55:41,786 - INFO -   [탐색 22] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:42,306 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:42,306 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:42,307 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:42,663 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000035762787)에 맞춰 변경되었습니다.
2026-02-10 08:55:42,664 - INFO - ==================================================
2026-02-10 08:55:42,666 - INFO -   [탐색 23] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:42,696 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:42,696 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:42,697 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,063 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999445676803)에 맞춰 변경되었습니다.
2026-02-10 08:55:43,064 - INFO - ==================================================
2026-02-10 08:55:43,067 - INFO -   [탐색 24] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:43,101 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:43,102 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,102 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,499 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999740719794)에 맞춰 변경되었습니다.
2026-02-10 08:55:43,499 - INFO - ==================================================
2026-02-10 08:55:43,501 - INFO -   [탐색 25] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:43,530 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:43,530 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,531 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,920 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499988824129)에 맞춰 변경되었습니다.
2026-02-10 08:55:43,920 - INFO - ==================================================
2026-02-10 08:55:43,922 - INFO -   [탐색 26] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:43,952 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:43,953 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,954 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:44,320 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999962002038)에 맞춰 변경되었습니다.
2026-02-10 08:55:44,320 - INFO - ==================================================
2026-02-10 08:55:44,322 - INFO -   [탐색 27] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:44,895 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:44,895 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:44,896 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999998882412)에 맞춰 변경되었습니다.
2026-02-10 08:55:45,349 - INFO - ==================================================
2026-02-10 08:55:45,352 - INFO -   [탐색 28] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:45,382 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:45,382 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,383 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,783 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000017322599)에 맞춰 변경되었습니다.
2026-02-10 08:55:45,783 - INFO - ==================================================
2026-02-10 08:55:45,785 - INFO -   [탐색 29] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:45,814 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:45,815 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,816 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,223 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000008102506)에 맞춰 변경되었습니다.
2026-02-10 08:55:46,223 - INFO - ==================================================
2026-02-10 08:55:46,225 - INFO -   [탐색 30] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:46,254 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:46,254 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,255 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,609 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000003492459)에 맞춰 변경되었습니다.
2026-02-10 08:55:46,609 - INFO - ==================================================
2026-02-10 08:55:46,611 - INFO -   [탐색 31] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:46,641 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:46,641 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,642 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:47,012 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000001187435)에 맞춰 변경되었습니다.
2026-02-10 08:55:47,013 - INFO - ==================================================
2026-02-10 08:55:47,015 - INFO -   [탐색 32] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:47,589 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:47,589 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:47,590 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,035 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000034924)에 맞춰 변경되었습니다.
2026-02-10 08:55:48,036 - INFO - ==================================================
2026-02-10 08:55:48,039 - INFO -   [탐색 33] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:48,069 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:48,070 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,070 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,451 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999458668)에 맞춰 변경되었습니다.
2026-02-10 08:55:48,451 - INFO - ==================================================
2026-02-10 08:55:48,453 - INFO -   [탐색 34] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:48,483 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:48,483 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,483 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,900 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999746796)에 맞춰 변경되었습니다.
2026-02-10 08:55:48,900 - INFO - ==================================================
2026-02-10 08:55:48,902 - INFO -   [탐색 35] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:48,934 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:48,934 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,935 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499999989086)에 맞춰 변경되었습니다.
2026-02-10 08:55:49,354 - INFO - ==================================================
2026-02-10 08:55:49,356 - INFO -   [탐색 36] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:49,385 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:49,385 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,386 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,807 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999962892)에 맞춰 변경되었습니다.
2026-02-10 08:55:49,807 - INFO - ==================================================
2026-02-10 08:55:49,809 - INFO -   [탐색 37] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:49,834 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:49,835 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,835 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:50,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999998908)에 맞춰 변경되었습니다.
2026-02-10 08:55:50,750 - INFO - ==================================================
2026-02-10 08:55:50,753 - INFO -   [탐색 38] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:50,786 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:50,786 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:50,787 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000016916)에 맞춰 변경되었습니다.
2026-02-10 08:55:51,190 - INFO - ==================================================
2026-02-10 08:55:51,192 - INFO -   [탐색 39] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:51,224 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:51,224 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,225 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,622 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000007912)에 맞춰 변경되었습니다.
2026-02-10 08:55:51,622 - INFO - ==================================================
2026-02-10 08:55:51,624 - INFO -   [탐색 40] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:51,654 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:51,654 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,655 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:52,044 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862500000000341)에 맞춰 변경되었습니다.
2026-02-10 08:55:52,044 - INFO - ==================================================
2026-02-10 08:55:52,046 - INFO -   [탐색 41] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:52,074 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:52,074 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:52,075 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:52,420 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862500000000116)에 맞춰 변경되었습니다.
2026-02-10 08:55:52,420 - INFO - ==================================================
2026-02-10 08:55:52,422 - INFO -   [탐색 42] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:52,447 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:52,447 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:52,448 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,393 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000034)에 맞춰 변경되었습니다.
2026-02-10 08:55:53,393 - INFO - ==================================================
2026-02-10 08:55:53,396 - INFO -   [탐색 43] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:53,424 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:53,425 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,425 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,838 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999471)에 맞춰 변경되었습니다.
2026-02-10 08:55:53,838 - INFO - ==================================================
2026-02-10 08:55:53,840 - INFO -   [탐색 44] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:53,872 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:53,872 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,873 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,275 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999752)에 맞춰 변경되었습니다.
2026-02-10 08:55:54,275 - INFO - ==================================================
2026-02-10 08:55:54,278 - INFO -   [탐색 45] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:54,307 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:54,308 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,308 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999893)에 맞춰 변경되었습니다.
2026-02-10 08:55:54,749 - INFO - ==================================================
2026-02-10 08:55:54,752 - INFO -   [탐색 46] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:54,781 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:54,781 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,782 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:55,061 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999963)에 맞춰 변경되었습니다.
2026-02-10 08:55:55,061 - INFO - ==================================================
2026-02-10 08:55:55,063 - INFO -   [탐색 47] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:55,091 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:55,091 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:55,092 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,040 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999998)에 맞춰 변경되었습니다.
2026-02-10 08:55:56,040 - INFO - ==================================================
2026-02-10 08:55:56,043 - INFO -   [탐색 48] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:56,075 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:56,076 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,076 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,488 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000016)에 맞춰 변경되었습니다.
2026-02-10 08:55:56,488 - INFO - ==================================================
2026-02-10 08:55:56,490 - INFO -   [탐색 49] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:56,522 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:56,522 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,523 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,937 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000007)에 맞춰 변경되었습니다.
2026-02-10 08:55:56,937 - INFO - ==================================================
2026-02-10 08:55:56,939 - INFO -   [탐색 50] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:56,971 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:56,971 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,972 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,285 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000003)에 맞춰 변경되었습니다.
2026-02-10 08:55:57,285 - INFO - ==================================================
2026-02-10 08:55:57,287 - INFO -   [탐색 51] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:57,315 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:57,315 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,316 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,633 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:57,633 - INFO - ==================================================
2026-02-10 08:55:57,636 - INFO -   [탐색 52] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:57,663 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:57,664 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,664 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:58,595 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:58,595 - INFO - ==================================================
2026-02-10 08:55:58,598 - INFO -   [탐색 53] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:58,629 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:58,629 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:58,630 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,044 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:59,044 - INFO - ==================================================
2026-02-10 08:55:59,047 - INFO -   [탐색 54] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:59,079 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:59,079 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,080 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,528 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:59,528 - INFO - ==================================================
2026-02-10 08:55:59,530 - INFO -   [탐색 55] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:59,560 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:59,560 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,561 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,922 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:59,922 - INFO - ==================================================
2026-02-10 08:55:59,924 - INFO -   [탐색 56] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:59,951 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:55:59,951 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,951 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:00,287 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:00,288 - INFO - ==================================================
2026-02-10 08:56:00,290 - INFO -   [탐색 57] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:00,321 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:00,321 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:00,322 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,209 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:01,209 - INFO - ==================================================
2026-02-10 08:56:01,213 - INFO -   [탐색 58] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:01,242 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:01,242 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,243 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,639 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:01,639 - INFO - ==================================================
2026-02-10 08:56:01,642 - INFO -   [탐색 59] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:01,670 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:01,670 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,671 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,027 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:02,027 - INFO - ==================================================
2026-02-10 08:56:02,029 - INFO -   [탐색 60] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:02,061 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:02,061 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,062 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,469 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:02,469 - INFO - ==================================================
2026-02-10 08:56:02,471 - INFO -   [탐색 61] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:02,501 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:02,501 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,502 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:02,822 - INFO - ==================================================
2026-02-10 08:56:02,823 - INFO -   [탐색 62] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:02,850 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:02,851 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,851 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,822 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:03,822 - INFO - ==================================================
2026-02-10 08:56:03,825 - INFO -   [탐색 63] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:03,858 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:03,858 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,859 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:04,307 - INFO - ==================================================
2026-02-10 08:56:04,309 - INFO -   [탐색 64] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:04,340 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:04,340 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,341 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,725 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:04,726 - INFO - ==================================================
2026-02-10 08:56:04,728 - INFO -   [탐색 65] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:04,758 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:04,758 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,759 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:05,176 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:05,177 - INFO - ==================================================
2026-02-10 08:56:05,178 - INFO -   [탐색 66] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:05,204 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:05,204 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:05,204 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:05,482 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:05,483 - INFO - ==================================================
2026-02-10 08:56:05,484 - INFO -   [탐색 67] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:05,509 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:05,509 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:05,510 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,442 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:06,442 - INFO - ==================================================
2026-02-10 08:56:06,446 - INFO -   [탐색 68] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:06,478 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:06,479 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,479 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,906 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:06,906 - INFO - ==================================================
2026-02-10 08:56:06,908 - INFO -   [탐색 69] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:06,938 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:06,938 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,939 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:07,351 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:07,351 - INFO - ==================================================
2026-02-10 08:56:07,353 - INFO -   [탐색 70] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:07,383 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:07,383 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:07,384 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:07,741 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:07,741 - INFO - ==================================================
2026-02-10 08:56:07,744 - INFO -   [탐색 71] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:07,772 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:07,773 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:07,773 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:08,166 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:08,166 - INFO - ==================================================
2026-02-10 08:56:08,168 - INFO -   [탐색 72] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:08,198 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:08,199 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:08,199 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:09,216 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:09,216 - INFO - ==================================================
2026-02-10 08:56:09,220 - INFO -   [탐색 73] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:09,250 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:09,250 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:09,251 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:09,751 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:09,751 - INFO - ==================================================
2026-02-10 08:56:09,753 - INFO -   [탐색 74] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:09,784 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:09,784 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:09,784 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:10,210 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:10,210 - INFO - ==================================================
2026-02-10 08:56:10,212 - INFO -   [탐색 75] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:10,242 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:10,243 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:10,243 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:10,624 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:10,625 - INFO - ==================================================
2026-02-10 08:56:10,627 - INFO -   [탐색 76] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:10,660 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:10,661 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:10,661 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:11,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:11,059 - INFO - ==================================================
2026-02-10 08:56:11,061 - INFO -   [탐색 77] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:11,090 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:11,091 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:11,091 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:12,114 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:12,114 - INFO - ==================================================
2026-02-10 08:56:12,117 - INFO -   [탐색 78] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:12,148 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:12,148 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:12,149 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:12,668 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:12,668 - INFO - ==================================================
2026-02-10 08:56:12,670 - INFO -   [탐색 79] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:12,700 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:12,700 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:12,701 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:13,108 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:13,108 - INFO - ==================================================
2026-02-10 08:56:13,110 - INFO -   [탐색 80] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:13,141 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:13,141 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:13,142 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:13,557 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:13,558 - INFO - ==================================================
2026-02-10 08:56:13,560 - INFO -   [탐색 81] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:13,596 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:13,596 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:13,597 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:14,014 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:14,014 - INFO - ==================================================
2026-02-10 08:56:14,016 - INFO -   [탐색 82] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:14,046 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:14,046 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:14,047 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:15,013 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:15,014 - INFO - ==================================================
2026-02-10 08:56:15,017 - INFO -   [탐색 83] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:15,048 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:15,049 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:15,049 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:15,442 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:15,442 - INFO - ==================================================
2026-02-10 08:56:15,445 - INFO -   [탐색 84] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:15,475 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:15,476 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:15,476 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:15,893 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:15,893 - INFO - ==================================================
2026-02-10 08:56:15,896 - INFO -   [탐색 85] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:15,924 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:15,924 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:15,925 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:16,396 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:16,396 - INFO - ==================================================
2026-02-10 08:56:16,398 - INFO -   [탐색 86] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:16,429 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:16,430 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:16,431 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:16,803 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:16,804 - INFO - ==================================================
2026-02-10 08:56:16,806 - INFO -   [탐색 87] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:16,840 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:16,840 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:16,841 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:17,257 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:17,258 - INFO - ==================================================
2026-02-10 08:56:17,260 - INFO -   [탐색 88] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:17,856 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:17,857 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:17,857 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:18,234 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:18,234 - INFO - ==================================================
2026-02-10 08:56:18,239 - INFO -   [탐색 89] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:18,272 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:18,273 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:18,273 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:18,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:18,683 - INFO - ==================================================
2026-02-10 08:56:18,685 - INFO -   [탐색 90] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:18,714 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:18,715 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:18,715 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:19,145 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:19,145 - INFO - ==================================================
2026-02-10 08:56:19,147 - INFO -   [탐색 91] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:19,177 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:19,178 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:19,178 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:19,782 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:19,782 - INFO - ==================================================
2026-02-10 08:56:19,784 - INFO -   [탐색 92] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:19,813 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:19,813 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:19,814 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:20,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:20,156 - INFO - ==================================================
2026-02-10 08:56:20,159 - INFO -   [탐색 93] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:20,754 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:20,754 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:20,755 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:21,238 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:21,239 - INFO - ==================================================
2026-02-10 08:56:21,242 - INFO -   [탐색 94] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:21,274 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:21,274 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:21,275 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:21,657 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:21,658 - INFO - ==================================================
2026-02-10 08:56:21,660 - INFO -   [탐색 95] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:21,692 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:21,693 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:21,693 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:22,075 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:22,075 - INFO - ==================================================
2026-02-10 08:56:22,077 - INFO -   [탐색 96] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:22,114 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:22,115 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:22,115 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:22,527 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:22,527 - INFO - ==================================================
2026-02-10 08:56:22,529 - INFO -   [탐색 97] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:22,560 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:22,560 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:22,561 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:22,992 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:22,993 - INFO - ==================================================
2026-02-10 08:56:22,995 - INFO -   [탐색 98] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:23,576 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:23,576 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:23,577 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:24,004 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:24,005 - INFO - ==================================================
2026-02-10 08:56:24,009 - INFO -   [탐색 99] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:24,045 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:24,045 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:24,046 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:24,587 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:24,587 - INFO - ==================================================
2026-02-10 08:56:24,589 - INFO -   [탐색 100] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:24,589 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.8643 입니다.
2026-02-10 08:56:24,589 - INFO - ================================================================================
2026-02-10 08:56:24,592 - INFO - 계산된 Pruning 정보(희소도: 0.8643)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/pruning_info.yaml'에 저장했습니다.
2026-02-10 08:56:24,634 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 08:56:24,723 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:56:24,723 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:24,724 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:25,160 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 08:56:25,160 - INFO - ==================================================
2026-02-10 08:56:25,162 - INFO - ==================================================
2026-02-10 08:56:25,162 - INFO - 모델 파라미터 수:
2026-02-10 08:56:25,162 - INFO -   - 총 파라미터: 47,330 개
2026-02-10 08:56:25,162 - INFO -   - 학습 가능한 파라미터: 47,330 개
2026-02-10 08:56:25,230 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 08:56:25,314 - INFO - FLOPs가 0.5384 GFLOPs에서 0.0262 GFLOPs로 감소했습니다 (감소율: 95.12%).
2026-02-10 08:56:25,314 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 08:56:25,314 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 08:56:25,315 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 08:56:25,315 - INFO - ==================================================
2026-02-10 08:56:25,315 - INFO - train 모드를 시작합니다.
2026-02-10 08:56:25,315 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 08:56:25,315 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 08:56:25,316 - INFO - --------------------------------------------------
2026-02-10 08:56:25,317 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 08:56:32,366 - INFO - [Train] [11/90] | Loss: 0.5970 | Train Acc: 70.54%
2026-02-10 08:56:33,847 - INFO - [Valid] [11/90] | Loss: 0.5588 | Val Acc: 75.52%
2026-02-10 08:56:33,851 - INFO - [Metrics for 'abnormal'] | Precision: 0.7033 | Recall: 0.8153 | F1: 0.7552
2026-02-10 08:56:33,852 - INFO - [Metrics for 'normal'] | Precision: 0.8153 | Recall: 0.7033 | F1: 0.7552
2026-02-10 08:56:33,882 - INFO - [Best Model Saved] (val loss: 0.5588) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:56:33,883 - INFO - --------------------------------------------------
2026-02-10 08:56:33,885 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 08:56:40,291 - INFO - [Train] [12/90] | Loss: 0.5174 | Train Acc: 77.23%
2026-02-10 08:56:41,786 - INFO - [Valid] [12/90] | Loss: 0.5552 | Val Acc: 77.88%
2026-02-10 08:56:41,792 - INFO - [Metrics for 'abnormal'] | Precision: 0.7595 | Recall: 0.7643 | F1: 0.7619
2026-02-10 08:56:41,792 - INFO - [Metrics for 'normal'] | Precision: 0.7956 | Recall: 0.7912 | F1: 0.7934
2026-02-10 08:56:41,813 - INFO - [Best Model Saved] (val loss: 0.5552) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:56:41,813 - INFO - --------------------------------------------------
2026-02-10 08:56:41,815 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 08:56:49,061 - INFO - [Train] [13/90] | Loss: 0.5029 | Train Acc: 79.09%
2026-02-10 08:56:50,731 - INFO - [Valid] [13/90] | Loss: 0.5133 | Val Acc: 78.47%
2026-02-10 08:56:50,741 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.6879 | F1: 0.7474
2026-02-10 08:56:50,741 - INFO - [Metrics for 'normal'] | Precision: 0.7633 | Recall: 0.8681 | F1: 0.8123
2026-02-10 08:56:50,764 - INFO - [Best Model Saved] (val loss: 0.5133) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:56:50,764 - INFO - --------------------------------------------------
2026-02-10 08:56:50,766 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 08:56:57,538 - INFO - [Train] [14/90] | Loss: 0.4933 | Train Acc: 79.24%
2026-02-10 08:56:59,093 - INFO - [Valid] [14/90] | Loss: 0.5306 | Val Acc: 79.94%
2026-02-10 08:56:59,098 - INFO - [Metrics for 'abnormal'] | Precision: 0.8296 | Recall: 0.7134 | F1: 0.7671
2026-02-10 08:56:59,098 - INFO - [Metrics for 'normal'] | Precision: 0.7794 | Recall: 0.8736 | F1: 0.8238
2026-02-10 08:56:59,100 - INFO - --------------------------------------------------
2026-02-10 08:56:59,102 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 08:57:05,660 - INFO - [Train] [15/90] | Loss: 0.4762 | Train Acc: 81.62%
2026-02-10 08:57:07,161 - INFO - [Valid] [15/90] | Loss: 0.5110 | Val Acc: 80.24%
2026-02-10 08:57:07,166 - INFO - [Metrics for 'abnormal'] | Precision: 0.8041 | Recall: 0.7580 | F1: 0.7803
2026-02-10 08:57:07,167 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8407 | F1: 0.8204
2026-02-10 08:57:07,192 - INFO - [Best Model Saved] (val loss: 0.5110) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:57:07,192 - INFO - --------------------------------------------------
2026-02-10 08:57:07,194 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 08:57:14,728 - INFO - [Train] [16/90] | Loss: 0.4558 | Train Acc: 82.74%
2026-02-10 08:57:16,202 - INFO - [Valid] [16/90] | Loss: 0.5383 | Val Acc: 79.06%
2026-02-10 08:57:16,208 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-02-10 08:57:16,208 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-02-10 08:57:16,210 - INFO - --------------------------------------------------
2026-02-10 08:57:16,212 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 08:57:23,545 - INFO - [Train] [17/90] | Loss: 0.4700 | Train Acc: 82.89%
2026-02-10 08:57:24,618 - INFO - [Valid] [17/90] | Loss: 0.5056 | Val Acc: 80.24%
2026-02-10 08:57:24,623 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-02-10 08:57:24,623 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-02-10 08:57:24,642 - INFO - [Best Model Saved] (val loss: 0.5056) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:57:24,643 - INFO - --------------------------------------------------
2026-02-10 08:57:24,644 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 08:57:32,027 - INFO - [Train] [18/90] | Loss: 0.4457 | Train Acc: 84.38%
2026-02-10 08:57:33,694 - INFO - [Valid] [18/90] | Loss: 0.5001 | Val Acc: 80.53%
2026-02-10 08:57:33,699 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-02-10 08:57:33,699 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-02-10 08:57:33,723 - INFO - [Best Model Saved] (val loss: 0.5001) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 08:57:33,723 - INFO - --------------------------------------------------
2026-02-10 08:57:33,725 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 08:57:41,250 - INFO - [Train] [19/90] | Loss: 0.4360 | Train Acc: 84.97%
2026-02-10 08:57:42,881 - INFO - [Valid] [19/90] | Loss: 0.5253 | Val Acc: 78.76%
2026-02-10 08:57:42,886 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.7580 | F1: 0.7677
2026-02-10 08:57:42,887 - INFO - [Metrics for 'normal'] | Precision: 0.7957 | Recall: 0.8132 | F1: 0.8043
2026-02-10 08:57:42,888 - INFO - --------------------------------------------------
2026-02-10 08:57:42,890 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 08:57:49,857 - INFO - [Train] [20/90] | Loss: 0.4407 | Train Acc: 84.90%
2026-02-10 08:57:51,495 - INFO - [Valid] [20/90] | Loss: 0.5321 | Val Acc: 77.29%
2026-02-10 08:57:51,499 - INFO - [Metrics for 'abnormal'] | Precision: 0.7083 | Recall: 0.8662 | F1: 0.7794
2026-02-10 08:57:51,500 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.6923 | F1: 0.7660
2026-02-10 08:57:51,501 - INFO - --------------------------------------------------
2026-02-10 08:57:51,504 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 08:57:58,267 - INFO - [Train] [21/90] | Loss: 0.4343 | Train Acc: 86.09%
2026-02-10 08:57:59,732 - INFO - [Valid] [21/90] | Loss: 0.5265 | Val Acc: 78.47%
2026-02-10 08:57:59,736 - INFO - [Metrics for 'abnormal'] | Precision: 0.7958 | Recall: 0.7197 | F1: 0.7559
2026-02-10 08:57:59,737 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8407 | F1: 0.8074
2026-02-10 08:57:59,738 - INFO - --------------------------------------------------
2026-02-10 08:57:59,739 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 08:58:06,609 - INFO - [Train] [22/90] | Loss: 0.4202 | Train Acc: 86.90%
2026-02-10 08:58:08,250 - INFO - [Valid] [22/90] | Loss: 0.5219 | Val Acc: 77.58%
2026-02-10 08:58:08,255 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.7452 | F1: 0.7548
2026-02-10 08:58:08,255 - INFO - [Metrics for 'normal'] | Precision: 0.7849 | Recall: 0.8022 | F1: 0.7935
2026-02-10 08:58:08,257 - INFO - --------------------------------------------------
2026-02-10 08:58:08,259 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 08:58:15,706 - INFO - [Train] [23/90] | Loss: 0.4214 | Train Acc: 86.16%
2026-02-10 08:58:17,068 - INFO - [Valid] [23/90] | Loss: 0.5242 | Val Acc: 77.58%
2026-02-10 08:58:17,073 - INFO - [Metrics for 'abnormal'] | Precision: 0.7238 | Recall: 0.8344 | F1: 0.7751
2026-02-10 08:58:17,074 - INFO - [Metrics for 'normal'] | Precision: 0.8354 | Recall: 0.7253 | F1: 0.7765
2026-02-10 08:58:17,076 - INFO - --------------------------------------------------
2026-02-10 08:58:17,078 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 08:58:24,266 - INFO - [Train] [24/90] | Loss: 0.4206 | Train Acc: 86.98%
2026-02-10 08:58:25,791 - INFO - [Valid] [24/90] | Loss: 0.5566 | Val Acc: 78.76%
2026-02-10 08:58:25,800 - INFO - [Metrics for 'abnormal'] | Precision: 0.7607 | Recall: 0.7898 | F1: 0.7750
2026-02-10 08:58:25,800 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.7857 | F1: 0.7989
2026-02-10 08:58:25,802 - INFO - --------------------------------------------------
2026-02-10 08:58:25,803 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 08:58:33,442 - INFO - [Train] [25/90] | Loss: 0.4112 | Train Acc: 86.46%
2026-02-10 08:58:35,054 - INFO - [Valid] [25/90] | Loss: 0.5562 | Val Acc: 78.76%
2026-02-10 08:58:35,059 - INFO - [Metrics for 'abnormal'] | Precision: 0.8400 | Recall: 0.6688 | F1: 0.7447
2026-02-10 08:58:35,059 - INFO - [Metrics for 'normal'] | Precision: 0.7570 | Recall: 0.8901 | F1: 0.8182
2026-02-10 08:58:35,060 - INFO - --------------------------------------------------
2026-02-10 08:58:35,062 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 08:58:42,209 - INFO - [Train] [26/90] | Loss: 0.4042 | Train Acc: 86.76%
2026-02-10 08:58:43,647 - INFO - [Valid] [26/90] | Loss: 0.5189 | Val Acc: 79.94%
2026-02-10 08:58:43,657 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-02-10 08:58:43,657 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-02-10 08:58:43,659 - INFO - --------------------------------------------------
2026-02-10 08:58:43,661 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 08:58:50,792 - INFO - [Train] [27/90] | Loss: 0.4045 | Train Acc: 86.83%
2026-02-10 08:58:52,273 - INFO - [Valid] [27/90] | Loss: 0.5326 | Val Acc: 77.88%
2026-02-10 08:58:52,278 - INFO - [Metrics for 'abnormal'] | Precision: 0.7228 | Recall: 0.8471 | F1: 0.7801
2026-02-10 08:58:52,278 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7198 | F1: 0.7774
2026-02-10 08:58:52,284 - INFO - --------------------------------------------------
2026-02-10 08:58:52,286 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 08:58:58,787 - INFO - [Train] [28/90] | Loss: 0.3860 | Train Acc: 88.91%
2026-02-10 08:58:59,976 - INFO - [Valid] [28/90] | Loss: 0.5913 | Val Acc: 80.83%
2026-02-10 08:58:59,982 - INFO - [Metrics for 'abnormal'] | Precision: 0.8710 | Recall: 0.6879 | F1: 0.7687
2026-02-10 08:58:59,982 - INFO - [Metrics for 'normal'] | Precision: 0.7721 | Recall: 0.9121 | F1: 0.8363
2026-02-10 08:58:59,984 - INFO - --------------------------------------------------
2026-02-10 08:58:59,986 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 08:59:06,957 - INFO - [Train] [29/90] | Loss: 0.3798 | Train Acc: 89.29%
2026-02-10 08:59:08,421 - INFO - [Valid] [29/90] | Loss: 0.5257 | Val Acc: 78.17%
2026-02-10 08:59:08,430 - INFO - [Metrics for 'abnormal'] | Precision: 0.7456 | Recall: 0.8025 | F1: 0.7730
2026-02-10 08:59:08,430 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.7637 | F1: 0.7898
2026-02-10 08:59:08,433 - INFO - --------------------------------------------------
2026-02-10 08:59:08,435 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 08:59:15,451 - INFO - [Train] [30/90] | Loss: 0.3804 | Train Acc: 89.58%
2026-02-10 08:59:16,987 - INFO - [Valid] [30/90] | Loss: 0.5732 | Val Acc: 79.35%
2026-02-10 08:59:16,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-02-10 08:59:16,992 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-02-10 08:59:16,994 - INFO - --------------------------------------------------
2026-02-10 08:59:16,996 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 08:59:23,678 - INFO - [Train] [31/90] | Loss: 0.3729 | Train Acc: 89.14%
2026-02-10 08:59:24,906 - INFO - [Valid] [31/90] | Loss: 0.5439 | Val Acc: 77.88%
2026-02-10 08:59:24,910 - INFO - [Metrics for 'abnormal'] | Precision: 0.7887 | Recall: 0.7134 | F1: 0.7492
2026-02-10 08:59:24,910 - INFO - [Metrics for 'normal'] | Precision: 0.7716 | Recall: 0.8352 | F1: 0.8021
2026-02-10 08:59:24,912 - INFO - --------------------------------------------------
2026-02-10 08:59:24,914 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 08:59:32,388 - INFO - [Train] [32/90] | Loss: 0.3595 | Train Acc: 90.40%
2026-02-10 08:59:33,778 - INFO - [Valid] [32/90] | Loss: 0.5706 | Val Acc: 78.17%
2026-02-10 08:59:33,783 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.7898 | F1: 0.7702
2026-02-10 08:59:33,784 - INFO - [Metrics for 'normal'] | Precision: 0.8103 | Recall: 0.7747 | F1: 0.7921
2026-02-10 08:59:33,785 - INFO - --------------------------------------------------
2026-02-10 08:59:33,787 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 08:59:41,039 - INFO - [Train] [33/90] | Loss: 0.3531 | Train Acc: 90.40%
2026-02-10 08:59:42,265 - INFO - [Valid] [33/90] | Loss: 0.5969 | Val Acc: 78.76%
2026-02-10 08:59:42,271 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.8153 | F1: 0.7805
2026-02-10 08:59:42,271 - INFO - [Metrics for 'normal'] | Precision: 0.8274 | Recall: 0.7637 | F1: 0.7943
2026-02-10 08:59:42,272 - INFO - --------------------------------------------------
2026-02-10 08:59:42,274 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 08:59:49,751 - INFO - [Train] [34/90] | Loss: 0.3615 | Train Acc: 89.81%
2026-02-10 08:59:51,027 - INFO - [Valid] [34/90] | Loss: 0.5690 | Val Acc: 79.65%
2026-02-10 08:59:51,032 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-02-10 08:59:51,032 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-02-10 08:59:51,034 - INFO - --------------------------------------------------
2026-02-10 08:59:51,036 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 08:59:58,360 - INFO - [Train] [35/90] | Loss: 0.3680 | Train Acc: 90.03%
2026-02-10 08:59:59,955 - INFO - [Valid] [35/90] | Loss: 0.5714 | Val Acc: 76.40%
2026-02-10 08:59:59,960 - INFO - [Metrics for 'abnormal'] | Precision: 0.6842 | Recall: 0.9108 | F1: 0.7814
2026-02-10 08:59:59,961 - INFO - [Metrics for 'normal'] | Precision: 0.8923 | Recall: 0.6374 | F1: 0.7436
2026-02-10 08:59:59,962 - INFO - --------------------------------------------------
2026-02-10 08:59:59,964 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 09:00:07,021 - INFO - [Train] [36/90] | Loss: 0.3516 | Train Acc: 90.77%
2026-02-10 09:00:08,245 - INFO - [Valid] [36/90] | Loss: 0.5790 | Val Acc: 78.76%
2026-02-10 09:00:08,254 - INFO - [Metrics for 'abnormal'] | Precision: 0.8346 | Recall: 0.6752 | F1: 0.7465
2026-02-10 09:00:08,254 - INFO - [Metrics for 'normal'] | Precision: 0.7594 | Recall: 0.8846 | F1: 0.8173
2026-02-10 09:00:08,256 - INFO - --------------------------------------------------
2026-02-10 09:00:08,257 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 09:00:15,081 - INFO - [Train] [37/90] | Loss: 0.3455 | Train Acc: 91.89%
2026-02-10 09:00:16,361 - INFO - [Valid] [37/90] | Loss: 0.5393 | Val Acc: 79.94%
2026-02-10 09:00:16,367 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-02-10 09:00:16,367 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-02-10 09:00:16,368 - INFO - --------------------------------------------------
2026-02-10 09:00:16,370 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 09:00:23,760 - INFO - [Train] [38/90] | Loss: 0.3333 | Train Acc: 91.59%
2026-02-10 09:00:25,034 - INFO - [Valid] [38/90] | Loss: 0.5910 | Val Acc: 78.76%
2026-02-10 09:00:25,042 - INFO - [Metrics for 'abnormal'] | Precision: 0.8058 | Recall: 0.7134 | F1: 0.7568
2026-02-10 09:00:25,043 - INFO - [Metrics for 'normal'] | Precision: 0.7750 | Recall: 0.8516 | F1: 0.8115
2026-02-10 09:00:25,045 - INFO - --------------------------------------------------
2026-02-10 09:00:25,048 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 09:00:32,583 - INFO - [Train] [39/90] | Loss: 0.3369 | Train Acc: 91.89%
2026-02-10 09:00:34,167 - INFO - [Valid] [39/90] | Loss: 0.5970 | Val Acc: 74.34%
2026-02-10 09:00:34,172 - INFO - [Metrics for 'abnormal'] | Precision: 0.6823 | Recall: 0.8344 | F1: 0.7507
2026-02-10 09:00:34,172 - INFO - [Metrics for 'normal'] | Precision: 0.8231 | Recall: 0.6648 | F1: 0.7356
2026-02-10 09:00:34,174 - INFO - --------------------------------------------------
2026-02-10 09:00:34,176 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 09:00:41,087 - INFO - [Train] [40/90] | Loss: 0.3265 | Train Acc: 92.11%
2026-02-10 09:00:42,492 - INFO - [Valid] [40/90] | Loss: 0.5394 | Val Acc: 78.76%
2026-02-10 09:00:42,496 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-02-10 09:00:42,496 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-02-10 09:00:42,498 - INFO - --------------------------------------------------
2026-02-10 09:00:42,500 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 09:00:49,720 - INFO - [Train] [41/90] | Loss: 0.3295 | Train Acc: 92.41%
2026-02-10 09:00:51,207 - INFO - [Valid] [41/90] | Loss: 0.5741 | Val Acc: 78.76%
2026-02-10 09:00:51,212 - INFO - [Metrics for 'abnormal'] | Precision: 0.7607 | Recall: 0.7898 | F1: 0.7750
2026-02-10 09:00:51,212 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.7857 | F1: 0.7989
2026-02-10 09:00:51,214 - INFO - --------------------------------------------------
2026-02-10 09:00:51,216 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 09:00:57,430 - INFO - [Train] [42/90] | Loss: 0.3349 | Train Acc: 91.74%
2026-02-10 09:00:58,680 - INFO - [Valid] [42/90] | Loss: 0.6080 | Val Acc: 75.22%
2026-02-10 09:00:58,683 - INFO - [Metrics for 'abnormal'] | Precision: 0.6714 | Recall: 0.9108 | F1: 0.7730
2026-02-10 09:00:58,683 - INFO - [Metrics for 'normal'] | Precision: 0.8889 | Recall: 0.6154 | F1: 0.7273
2026-02-10 09:00:58,685 - INFO - --------------------------------------------------
2026-02-10 09:00:58,686 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 09:01:05,069 - INFO - [Train] [43/90] | Loss: 0.3266 | Train Acc: 92.86%
2026-02-10 09:01:06,662 - INFO - [Valid] [43/90] | Loss: 0.6370 | Val Acc: 77.58%
2026-02-10 09:01:06,666 - INFO - [Metrics for 'abnormal'] | Precision: 0.8293 | Recall: 0.6497 | F1: 0.7286
2026-02-10 09:01:06,667 - INFO - [Metrics for 'normal'] | Precision: 0.7454 | Recall: 0.8846 | F1: 0.8090
2026-02-10 09:01:06,668 - INFO - --------------------------------------------------
2026-02-10 09:01:06,669 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 09:01:12,354 - INFO - [Train] [44/90] | Loss: 0.3255 | Train Acc: 92.86%
2026-02-10 09:01:13,454 - INFO - [Valid] [44/90] | Loss: 0.5588 | Val Acc: 77.29%
2026-02-10 09:01:13,459 - INFO - [Metrics for 'abnormal'] | Precision: 0.7083 | Recall: 0.8662 | F1: 0.7794
2026-02-10 09:01:13,459 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.6923 | F1: 0.7660
2026-02-10 09:01:13,461 - INFO - --------------------------------------------------
2026-02-10 09:01:13,462 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 09:01:19,448 - INFO - [Train] [45/90] | Loss: 0.3160 | Train Acc: 92.63%
2026-02-10 09:01:20,674 - INFO - [Valid] [45/90] | Loss: 0.5484 | Val Acc: 77.88%
2026-02-10 09:01:20,681 - INFO - [Metrics for 'abnormal'] | Precision: 0.7303 | Recall: 0.8280 | F1: 0.7761
2026-02-10 09:01:20,685 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7363 | F1: 0.7813
2026-02-10 09:01:20,687 - INFO - --------------------------------------------------
2026-02-10 09:01:20,690 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 09:01:26,413 - INFO - [Train] [46/90] | Loss: 0.3189 | Train Acc: 92.56%
2026-02-10 09:01:27,238 - INFO - [Valid] [46/90] | Loss: 0.5619 | Val Acc: 77.29%
2026-02-10 09:01:27,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-02-10 09:01:27,244 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-02-10 09:01:27,245 - INFO - --------------------------------------------------
2026-02-10 09:01:27,247 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 09:01:33,015 - INFO - [Train] [47/90] | Loss: 0.3228 | Train Acc: 92.56%
2026-02-10 09:01:34,050 - INFO - [Valid] [47/90] | Loss: 0.5431 | Val Acc: 79.06%
2026-02-10 09:01:34,057 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.8471 | F1: 0.7893
2026-02-10 09:01:34,057 - INFO - [Metrics for 'normal'] | Precision: 0.8491 | Recall: 0.7418 | F1: 0.7918
2026-02-10 09:01:34,059 - INFO - --------------------------------------------------
2026-02-10 09:01:34,061 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 09:01:39,786 - INFO - [Train] [48/90] | Loss: 0.3181 | Train Acc: 92.86%
2026-02-10 09:01:40,609 - INFO - [Valid] [48/90] | Loss: 0.5296 | Val Acc: 80.24%
2026-02-10 09:01:40,614 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-02-10 09:01:40,614 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-02-10 09:01:40,615 - INFO - --------------------------------------------------
2026-02-10 09:01:40,617 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 09:01:46,325 - INFO - [Train] [49/90] | Loss: 0.3044 | Train Acc: 94.27%
2026-02-10 09:01:47,443 - INFO - [Valid] [49/90] | Loss: 0.5742 | Val Acc: 79.35%
2026-02-10 09:01:47,448 - INFO - [Metrics for 'abnormal'] | Precision: 0.7702 | Recall: 0.7898 | F1: 0.7799
2026-02-10 09:01:47,449 - INFO - [Metrics for 'normal'] | Precision: 0.8146 | Recall: 0.7967 | F1: 0.8056
2026-02-10 09:01:47,451 - INFO - --------------------------------------------------
2026-02-10 09:01:47,453 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 09:01:53,126 - INFO - [Train] [50/90] | Loss: 0.2853 | Train Acc: 95.01%
2026-02-10 09:01:53,910 - INFO - [Valid] [50/90] | Loss: 0.5762 | Val Acc: 79.94%
2026-02-10 09:01:53,915 - INFO - [Metrics for 'abnormal'] | Precision: 0.7354 | Recall: 0.8854 | F1: 0.8035
2026-02-10 09:01:53,916 - INFO - [Metrics for 'normal'] | Precision: 0.8800 | Recall: 0.7253 | F1: 0.7952
2026-02-10 09:01:53,917 - INFO - --------------------------------------------------
2026-02-10 09:01:53,919 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 09:01:59,792 - INFO - [Train] [51/90] | Loss: 0.2990 | Train Acc: 94.49%
2026-02-10 09:02:00,868 - INFO - [Valid] [51/90] | Loss: 0.5656 | Val Acc: 79.65%
2026-02-10 09:02:00,873 - INFO - [Metrics for 'abnormal'] | Precision: 0.7472 | Recall: 0.8471 | F1: 0.7940
2026-02-10 09:02:00,873 - INFO - [Metrics for 'normal'] | Precision: 0.8509 | Recall: 0.7527 | F1: 0.7988
2026-02-10 09:02:00,874 - INFO - --------------------------------------------------
2026-02-10 09:02:00,877 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 09:02:06,392 - INFO - [Train] [52/90] | Loss: 0.3014 | Train Acc: 94.12%
2026-02-10 09:02:07,575 - INFO - [Valid] [52/90] | Loss: 0.6708 | Val Acc: 76.11%
2026-02-10 09:02:07,579 - INFO - [Metrics for 'abnormal'] | Precision: 0.8276 | Recall: 0.6115 | F1: 0.7033
2026-02-10 09:02:07,579 - INFO - [Metrics for 'normal'] | Precision: 0.7265 | Recall: 0.8901 | F1: 0.8000
2026-02-10 09:02:07,580 - INFO - --------------------------------------------------
2026-02-10 09:02:07,582 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 09:02:13,078 - INFO - [Train] [53/90] | Loss: 0.3051 | Train Acc: 94.20%
2026-02-10 09:02:14,032 - INFO - [Valid] [53/90] | Loss: 0.5499 | Val Acc: 79.06%
2026-02-10 09:02:14,037 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8217 | F1: 0.7842
2026-02-10 09:02:14,037 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7637 | F1: 0.7966
2026-02-10 09:02:14,039 - INFO - --------------------------------------------------
2026-02-10 09:02:14,040 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 09:02:19,936 - INFO - [Train] [54/90] | Loss: 0.3045 | Train Acc: 94.12%
2026-02-10 09:02:20,882 - INFO - [Valid] [54/90] | Loss: 0.5919 | Val Acc: 76.70%
2026-02-10 09:02:20,888 - INFO - [Metrics for 'abnormal'] | Precision: 0.6912 | Recall: 0.8981 | F1: 0.7812
2026-02-10 09:02:20,888 - INFO - [Metrics for 'normal'] | Precision: 0.8815 | Recall: 0.6538 | F1: 0.7508
2026-02-10 09:02:20,889 - INFO - --------------------------------------------------
2026-02-10 09:02:20,891 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 09:02:26,554 - INFO - [Train] [55/90] | Loss: 0.2984 | Train Acc: 94.72%
2026-02-10 09:02:27,679 - INFO - [Valid] [55/90] | Loss: 0.5545 | Val Acc: 81.12%
2026-02-10 09:02:27,685 - INFO - [Metrics for 'abnormal'] | Precision: 0.7657 | Recall: 0.8535 | F1: 0.8072
2026-02-10 09:02:27,685 - INFO - [Metrics for 'normal'] | Precision: 0.8598 | Recall: 0.7747 | F1: 0.8150
2026-02-10 09:02:27,687 - INFO - --------------------------------------------------
2026-02-10 09:02:27,689 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 09:02:33,513 - INFO - [Train] [56/90] | Loss: 0.2824 | Train Acc: 95.91%
2026-02-10 09:02:34,787 - INFO - [Valid] [56/90] | Loss: 0.5595 | Val Acc: 79.06%
2026-02-10 09:02:34,792 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.7834 | F1: 0.7760
2026-02-10 09:02:34,792 - INFO - [Metrics for 'normal'] | Precision: 0.8101 | Recall: 0.7967 | F1: 0.8033
2026-02-10 09:02:34,793 - INFO - --------------------------------------------------
2026-02-10 09:02:34,795 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 09:02:40,091 - INFO - [Train] [57/90] | Loss: 0.2907 | Train Acc: 94.72%
2026-02-10 09:02:40,829 - INFO - [Valid] [57/90] | Loss: 0.5490 | Val Acc: 80.24%
2026-02-10 09:02:40,834 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-02-10 09:02:40,834 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-02-10 09:02:40,836 - INFO - --------------------------------------------------
2026-02-10 09:02:40,839 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 09:02:46,664 - INFO - [Train] [58/90] | Loss: 0.2879 | Train Acc: 95.24%
2026-02-10 09:02:47,950 - INFO - [Valid] [58/90] | Loss: 0.5689 | Val Acc: 78.47%
2026-02-10 09:02:47,959 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8025 | F1: 0.7754
2026-02-10 09:02:47,959 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.7692 | F1: 0.7932
2026-02-10 09:02:47,962 - INFO - --------------------------------------------------
2026-02-10 09:02:47,963 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 09:02:53,795 - INFO - [Train] [59/90] | Loss: 0.2831 | Train Acc: 95.24%
2026-02-10 09:02:55,146 - INFO - [Valid] [59/90] | Loss: 0.5658 | Val Acc: 81.42%
2026-02-10 09:02:55,151 - INFO - [Metrics for 'abnormal'] | Precision: 0.8219 | Recall: 0.7643 | F1: 0.7921
2026-02-10 09:02:55,151 - INFO - [Metrics for 'normal'] | Precision: 0.8083 | Recall: 0.8571 | F1: 0.8320
2026-02-10 09:02:55,153 - INFO - --------------------------------------------------
2026-02-10 09:02:55,154 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 09:03:01,734 - INFO - [Train] [60/90] | Loss: 0.2612 | Train Acc: 96.88%
2026-02-10 09:03:03,276 - INFO - [Valid] [60/90] | Loss: 0.5546 | Val Acc: 81.71%
2026-02-10 09:03:03,281 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-02-10 09:03:03,281 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-02-10 09:03:03,283 - INFO - --------------------------------------------------
2026-02-10 09:03:03,285 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 09:03:10,563 - INFO - [Train] [61/90] | Loss: 0.2734 | Train Acc: 96.43%
2026-02-10 09:03:11,828 - INFO - [Valid] [61/90] | Loss: 0.5434 | Val Acc: 79.35%
2026-02-10 09:03:11,833 - INFO - [Metrics for 'abnormal'] | Precision: 0.7702 | Recall: 0.7898 | F1: 0.7799
2026-02-10 09:03:11,833 - INFO - [Metrics for 'normal'] | Precision: 0.8146 | Recall: 0.7967 | F1: 0.8056
2026-02-10 09:03:11,835 - INFO - --------------------------------------------------
2026-02-10 09:03:11,837 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 09:03:18,700 - INFO - [Train] [62/90] | Loss: 0.2751 | Train Acc: 95.91%
2026-02-10 09:03:20,272 - INFO - [Valid] [62/90] | Loss: 0.5670 | Val Acc: 80.83%
2026-02-10 09:03:20,281 - INFO - [Metrics for 'abnormal'] | Precision: 0.8067 | Recall: 0.7707 | F1: 0.7883
2026-02-10 09:03:20,281 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.8407 | F1: 0.8248
2026-02-10 09:03:20,287 - INFO - --------------------------------------------------
2026-02-10 09:03:20,288 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 09:03:27,271 - INFO - [Train] [63/90] | Loss: 0.2756 | Train Acc: 96.43%
2026-02-10 09:03:28,797 - INFO - [Valid] [63/90] | Loss: 0.5863 | Val Acc: 77.88%
2026-02-10 09:03:28,803 - INFO - [Metrics for 'abnormal'] | Precision: 0.7303 | Recall: 0.8280 | F1: 0.7761
2026-02-10 09:03:28,804 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7363 | F1: 0.7813
2026-02-10 09:03:28,806 - INFO - --------------------------------------------------
2026-02-10 09:03:28,808 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 09:03:35,724 - INFO - [Train] [64/90] | Loss: 0.2631 | Train Acc: 97.02%
2026-02-10 09:03:37,041 - INFO - [Valid] [64/90] | Loss: 0.5842 | Val Acc: 78.17%
2026-02-10 09:03:37,046 - INFO - [Metrics for 'abnormal'] | Precision: 0.7371 | Recall: 0.8217 | F1: 0.7771
2026-02-10 09:03:37,046 - INFO - [Metrics for 'normal'] | Precision: 0.8293 | Recall: 0.7473 | F1: 0.7861
2026-02-10 09:03:37,047 - INFO - --------------------------------------------------
2026-02-10 09:03:37,049 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 09:03:43,921 - INFO - [Train] [65/90] | Loss: 0.2666 | Train Acc: 97.10%
2026-02-10 09:03:45,405 - INFO - [Valid] [65/90] | Loss: 0.6313 | Val Acc: 78.47%
2026-02-10 09:03:45,409 - INFO - [Metrics for 'abnormal'] | Precision: 0.7530 | Recall: 0.7962 | F1: 0.7740
2026-02-10 09:03:45,410 - INFO - [Metrics for 'normal'] | Precision: 0.8150 | Recall: 0.7747 | F1: 0.7944
2026-02-10 09:03:45,411 - INFO - --------------------------------------------------
2026-02-10 09:03:45,413 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 09:03:51,940 - INFO - [Train] [66/90] | Loss: 0.2687 | Train Acc: 96.28%
2026-02-10 09:03:53,251 - INFO - [Valid] [66/90] | Loss: 0.5558 | Val Acc: 79.65%
2026-02-10 09:03:53,261 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-02-10 09:03:53,261 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-02-10 09:03:53,263 - INFO - --------------------------------------------------
2026-02-10 09:03:53,264 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 09:04:00,158 - INFO - [Train] [67/90] | Loss: 0.2680 | Train Acc: 96.43%
2026-02-10 09:04:01,497 - INFO - [Valid] [67/90] | Loss: 0.5834 | Val Acc: 79.94%
2026-02-10 09:04:01,501 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-02-10 09:04:01,501 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-02-10 09:04:01,502 - INFO - --------------------------------------------------
2026-02-10 09:04:01,504 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 09:04:08,730 - INFO - [Train] [68/90] | Loss: 0.2560 | Train Acc: 97.54%
2026-02-10 09:04:10,246 - INFO - [Valid] [68/90] | Loss: 0.6096 | Val Acc: 77.88%
2026-02-10 09:04:10,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.7412 | Recall: 0.8025 | F1: 0.7706
2026-02-10 09:04:10,251 - INFO - [Metrics for 'normal'] | Precision: 0.8166 | Recall: 0.7582 | F1: 0.7863
2026-02-10 09:04:10,253 - INFO - --------------------------------------------------
2026-02-10 09:04:10,254 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 09:04:16,831 - INFO - [Train] [69/90] | Loss: 0.2479 | Train Acc: 97.99%
2026-02-10 09:04:18,259 - INFO - [Valid] [69/90] | Loss: 0.5929 | Val Acc: 79.65%
2026-02-10 09:04:18,264 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-02-10 09:04:18,264 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-02-10 09:04:18,266 - INFO - --------------------------------------------------
2026-02-10 09:04:18,267 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 09:04:25,395 - INFO - [Train] [70/90] | Loss: 0.2636 | Train Acc: 96.88%
2026-02-10 09:04:26,660 - INFO - [Valid] [70/90] | Loss: 0.5711 | Val Acc: 80.83%
2026-02-10 09:04:26,665 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-02-10 09:04:26,665 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-02-10 09:04:26,666 - INFO - --------------------------------------------------
2026-02-10 09:04:26,668 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 09:04:33,292 - INFO - [Train] [71/90] | Loss: 0.2655 | Train Acc: 96.88%
2026-02-10 09:04:34,737 - INFO - [Valid] [71/90] | Loss: 0.5952 | Val Acc: 76.99%
2026-02-10 09:04:34,742 - INFO - [Metrics for 'abnormal'] | Precision: 0.7283 | Recall: 0.8025 | F1: 0.7636
2026-02-10 09:04:34,742 - INFO - [Metrics for 'normal'] | Precision: 0.8133 | Recall: 0.7418 | F1: 0.7759
2026-02-10 09:04:34,744 - INFO - --------------------------------------------------
2026-02-10 09:04:34,746 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 09:04:41,660 - INFO - [Train] [72/90] | Loss: 0.2624 | Train Acc: 96.65%
2026-02-10 09:04:43,091 - INFO - [Valid] [72/90] | Loss: 0.5603 | Val Acc: 80.24%
2026-02-10 09:04:43,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-02-10 09:04:43,096 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-02-10 09:04:43,097 - INFO - --------------------------------------------------
2026-02-10 09:04:43,099 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 09:04:49,817 - INFO - [Train] [73/90] | Loss: 0.2412 | Train Acc: 98.29%
2026-02-10 09:04:51,387 - INFO - [Valid] [73/90] | Loss: 0.5993 | Val Acc: 80.53%
2026-02-10 09:04:51,392 - INFO - [Metrics for 'abnormal'] | Precision: 0.7725 | Recall: 0.8217 | F1: 0.7963
2026-02-10 09:04:51,392 - INFO - [Metrics for 'normal'] | Precision: 0.8372 | Recall: 0.7912 | F1: 0.8136
2026-02-10 09:04:51,393 - INFO - --------------------------------------------------
2026-02-10 09:04:51,395 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 09:04:57,736 - INFO - [Train] [74/90] | Loss: 0.2499 | Train Acc: 97.92%
2026-02-10 09:04:59,197 - INFO - [Valid] [74/90] | Loss: 0.5849 | Val Acc: 80.53%
2026-02-10 09:04:59,215 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-02-10 09:04:59,216 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-02-10 09:04:59,217 - INFO - --------------------------------------------------
2026-02-10 09:04:59,220 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 09:05:06,361 - INFO - [Train] [75/90] | Loss: 0.2689 | Train Acc: 96.58%
2026-02-10 09:05:07,805 - INFO - [Valid] [75/90] | Loss: 0.5905 | Val Acc: 79.65%
2026-02-10 09:05:07,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-02-10 09:05:07,809 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-02-10 09:05:07,810 - INFO - --------------------------------------------------
2026-02-10 09:05:07,811 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 09:05:14,118 - INFO - [Train] [76/90] | Loss: 0.2435 | Train Acc: 97.99%
2026-02-10 09:05:15,535 - INFO - [Valid] [76/90] | Loss: 0.5666 | Val Acc: 79.65%
2026-02-10 09:05:15,540 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.8153 | F1: 0.7877
2026-02-10 09:05:15,540 - INFO - [Metrics for 'normal'] | Precision: 0.8304 | Recall: 0.7802 | F1: 0.8045
2026-02-10 09:05:15,542 - INFO - --------------------------------------------------
2026-02-10 09:05:15,543 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 09:05:22,568 - INFO - [Train] [77/90] | Loss: 0.2480 | Train Acc: 97.54%
2026-02-10 09:05:23,814 - INFO - [Valid] [77/90] | Loss: 0.5802 | Val Acc: 78.76%
2026-02-10 09:05:23,824 - INFO - [Metrics for 'abnormal'] | Precision: 0.7401 | Recall: 0.8344 | F1: 0.7844
2026-02-10 09:05:23,824 - INFO - [Metrics for 'normal'] | Precision: 0.8395 | Recall: 0.7473 | F1: 0.7907
2026-02-10 09:05:23,827 - INFO - --------------------------------------------------
2026-02-10 09:05:23,828 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 09:05:30,717 - INFO - [Train] [78/90] | Loss: 0.2490 | Train Acc: 97.99%
2026-02-10 09:05:32,182 - INFO - [Valid] [78/90] | Loss: 0.5945 | Val Acc: 78.47%
2026-02-10 09:05:32,188 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-02-10 09:05:32,188 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-02-10 09:05:32,190 - INFO - --------------------------------------------------
2026-02-10 09:05:32,191 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 09:05:39,149 - INFO - [Train] [79/90] | Loss: 0.2520 | Train Acc: 97.92%
2026-02-10 09:05:40,571 - INFO - [Valid] [79/90] | Loss: 0.5856 | Val Acc: 79.35%
2026-02-10 09:05:40,575 - INFO - [Metrics for 'abnormal'] | Precision: 0.7636 | Recall: 0.8025 | F1: 0.7826
2026-02-10 09:05:40,576 - INFO - [Metrics for 'normal'] | Precision: 0.8218 | Recall: 0.7857 | F1: 0.8034
2026-02-10 09:05:40,577 - INFO - --------------------------------------------------
2026-02-10 09:05:40,580 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 09:05:47,193 - INFO - [Train] [80/90] | Loss: 0.2423 | Train Acc: 97.92%
2026-02-10 09:05:48,637 - INFO - [Valid] [80/90] | Loss: 0.5728 | Val Acc: 78.17%
2026-02-10 09:05:48,642 - INFO - [Metrics for 'abnormal'] | Precision: 0.7943 | Recall: 0.7134 | F1: 0.7517
2026-02-10 09:05:48,642 - INFO - [Metrics for 'normal'] | Precision: 0.7727 | Recall: 0.8407 | F1: 0.8053
2026-02-10 09:05:48,644 - INFO - --------------------------------------------------
2026-02-10 09:05:48,645 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 09:05:55,486 - INFO - [Train] [81/90] | Loss: 0.2501 | Train Acc: 97.92%
2026-02-10 09:05:57,026 - INFO - [Valid] [81/90] | Loss: 0.5745 | Val Acc: 79.35%
2026-02-10 09:05:57,031 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-02-10 09:05:57,032 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-02-10 09:05:57,033 - INFO - --------------------------------------------------
2026-02-10 09:05:57,035 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 09:06:04,252 - INFO - [Train] [82/90] | Loss: 0.2479 | Train Acc: 98.14%
2026-02-10 09:06:05,748 - INFO - [Valid] [82/90] | Loss: 0.5833 | Val Acc: 79.94%
2026-02-10 09:06:05,753 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-02-10 09:06:05,753 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-02-10 09:06:05,755 - INFO - --------------------------------------------------
2026-02-10 09:06:05,757 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 09:06:13,108 - INFO - [Train] [83/90] | Loss: 0.2401 | Train Acc: 98.07%
2026-02-10 09:06:14,750 - INFO - [Valid] [83/90] | Loss: 0.6065 | Val Acc: 79.35%
2026-02-10 09:06:14,755 - INFO - [Metrics for 'abnormal'] | Precision: 0.7458 | Recall: 0.8408 | F1: 0.7904
2026-02-10 09:06:14,756 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.7527 | F1: 0.7965
2026-02-10 09:06:14,758 - INFO - --------------------------------------------------
2026-02-10 09:06:14,759 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 09:06:21,538 - INFO - [Train] [84/90] | Loss: 0.2387 | Train Acc: 98.59%
2026-02-10 09:06:22,991 - INFO - [Valid] [84/90] | Loss: 0.5968 | Val Acc: 79.35%
2026-02-10 09:06:22,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.7702 | Recall: 0.7898 | F1: 0.7799
2026-02-10 09:06:22,997 - INFO - [Metrics for 'normal'] | Precision: 0.8146 | Recall: 0.7967 | F1: 0.8056
2026-02-10 09:06:22,998 - INFO - --------------------------------------------------
2026-02-10 09:06:23,000 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 09:06:29,760 - INFO - [Train] [85/90] | Loss: 0.2342 | Train Acc: 98.66%
2026-02-10 09:06:31,192 - INFO - [Valid] [85/90] | Loss: 0.5966 | Val Acc: 79.94%
2026-02-10 09:06:31,197 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-02-10 09:06:31,197 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-02-10 09:06:31,198 - INFO - --------------------------------------------------
2026-02-10 09:06:31,200 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 09:06:38,493 - INFO - [Train] [86/90] | Loss: 0.2342 | Train Acc: 98.74%
2026-02-10 09:06:40,040 - INFO - [Valid] [86/90] | Loss: 0.5968 | Val Acc: 79.94%
2026-02-10 09:06:40,045 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-02-10 09:06:40,045 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-02-10 09:06:40,047 - INFO - --------------------------------------------------
2026-02-10 09:06:40,049 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 09:06:47,178 - INFO - [Train] [87/90] | Loss: 0.2506 | Train Acc: 98.07%
2026-02-10 09:06:48,613 - INFO - [Valid] [87/90] | Loss: 0.5958 | Val Acc: 78.76%
2026-02-10 09:06:48,618 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-02-10 09:06:48,618 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-02-10 09:06:48,620 - INFO - --------------------------------------------------
2026-02-10 09:06:48,622 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 09:06:54,851 - INFO - [Train] [88/90] | Loss: 0.2378 | Train Acc: 98.51%
2026-02-10 09:06:56,351 - INFO - [Valid] [88/90] | Loss: 0.5866 | Val Acc: 79.06%
2026-02-10 09:06:56,355 - INFO - [Metrics for 'abnormal'] | Precision: 0.7654 | Recall: 0.7898 | F1: 0.7774
2026-02-10 09:06:56,355 - INFO - [Metrics for 'normal'] | Precision: 0.8136 | Recall: 0.7912 | F1: 0.8022
2026-02-10 09:06:56,357 - INFO - --------------------------------------------------
2026-02-10 09:06:56,358 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 09:07:01,930 - INFO - [Train] [89/90] | Loss: 0.2387 | Train Acc: 98.59%
2026-02-10 09:07:03,370 - INFO - [Valid] [89/90] | Loss: 0.5863 | Val Acc: 78.76%
2026-02-10 09:07:03,374 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-02-10 09:07:03,374 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-02-10 09:07:03,375 - INFO - --------------------------------------------------
2026-02-10 09:07:03,377 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 09:07:09,748 - INFO - [Train] [90/90] | Loss: 0.2485 | Train Acc: 98.07%
2026-02-10 09:07:11,121 - INFO - [Valid] [90/90] | Loss: 0.5796 | Val Acc: 79.65%
2026-02-10 09:07:11,125 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-02-10 09:07:11,125 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-02-10 09:07:11,127 - INFO - ==================================================
2026-02-10 09:07:11,127 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 09:07:11,127 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 09:07:11,128 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:07:11,168 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 09:07:11,183 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 09:07:11,184 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:07:11,184 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:07:11,184 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:07:11,618 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 09:07:11,618 - INFO - ==================================================
2026-02-10 09:07:11,680 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/best_model.pth'
2026-02-10 09:07:11,680 - INFO - ==================================================
2026-02-10 09:07:11,680 - INFO - Test 모드를 시작합니다.
2026-02-10 09:07:11,904 - INFO - 연산량 (MACs): 0.0131 GMACs per sample
2026-02-10 09:07:11,904 - INFO - 연산량 (FLOPs): 0.0262 GFLOPs per sample
2026-02-10 09:07:11,904 - INFO - ==================================================
2026-02-10 09:07:11,904 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 09:07:13,294 - INFO - 샘플 당 평균 Forward Pass 시간: 5.96ms (std: 1.54ms), FPS: 176.83 (std: 36.79) (1개 샘플 x 100회 반복)
2026-02-10 09:07:13,295 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 38.54 MB
2026-02-10 09:07:13,295 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 09:07:15,181 - INFO - [Test] Loss: 0.4345 | Test Acc: 80.53%
2026-02-10 09:07:15,187 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-02-10 09:07:15,187 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-02-10 09:07:15,484 - INFO - ==================================================
2026-02-10 09:07:15,484 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/confusion_matrix_20260210_085407.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/confusion_matrix_20260210_085407.pdf'
2026-02-10 09:07:15,484 - INFO - ==================================================
2026-02-10 09:07:15,484 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 09:07:18,777 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/model_fp32_20260210_085407.onnx'에 저장되었습니다. (크기: 0.36 MB)
2026-02-10 09:07:19,411 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 9.00 MB
2026-02-10 09:07:19,411 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 09:07:22,236 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 22.14ms (std: 9.29ms)
2026-02-10 09:07:22,236 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 55.89 FPS (std: 31.10) (1개 샘플 x 100회 반복)
2026-02-10 09:07:22,236 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 12.00 MB
2026-02-10 09:07:22,236 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 20.91 MB
2026-02-10 09:07:30,062 - INFO - [Test (ONNX)] | Test Acc (ONNX): 80.53%
2026-02-10 09:07:30,084 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-02-10 09:07:30,089 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-02-10 09:07:30,351 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/val_acc.pdf'
2026-02-10 09:07:30,581 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/train_val_acc.pdf'
2026-02-10 09:07:30,765 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/F1_normal.pdf'
2026-02-10 09:07:30,989 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/val_loss.pdf'
2026-02-10 09:07:31,197 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/learning_rate.pdf'
2026-02-10 09:07:33,515 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260210_085407/graph_20260210_085407/compile.pdf'
