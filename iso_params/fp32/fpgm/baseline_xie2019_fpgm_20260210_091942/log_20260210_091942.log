2026-02-10 09:19:42,126 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/log_20260210_091942.log'에 저장됩니다.
2026-02-10 09:19:42,128 - INFO - ==================================================
2026-02-10 09:19:42,128 - INFO - config.yaml:
2026-02-10 09:19:42,128 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: xie2019
  use_fpgm_pruning: true
  pruning_params_target: 0.047585

2026-02-10 09:19:42,128 - INFO - ==================================================
2026-02-10 09:19:42,154 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 09:19:42,154 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 09:19:42,154 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 09:19:42,158 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 09:19:42,158 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 09:19:42,158 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 09:19:42,158 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:19:42,303 - INFO - ==================================================
2026-02-10 09:19:42,304 - INFO - 모델 파라미터 수:
2026-02-10 09:19:42,304 - INFO -   - 총 파라미터: 9,160,194 개
2026-02-10 09:19:42,304 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-02-10 09:19:42,304 - INFO - ================================================================================
2026-02-10 09:19:42,304 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 09:19:42,304 - INFO - ================================================================================
2026-02-10 09:19:42,304 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 09:19:42,304 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 09:19:42,304 - INFO - ==================================================
2026-02-10 09:19:42,304 - INFO - train 모드를 시작합니다.
2026-02-10 09:19:42,304 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 09:19:42,304 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 09:19:42,304 - INFO - --------------------------------------------------
2026-02-10 09:19:42,304 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 09:19:45,224 - INFO - [Train] [1/10] | Loss: 0.5868 | Train Acc: 74.93%
2026-02-10 09:19:46,361 - INFO - [Valid] [1/10] | Loss: 0.5795 | Val Acc: 74.93%
2026-02-10 09:19:46,365 - INFO - [Metrics for 'abnormal'] | Precision: 0.8333 | Recall: 0.5732 | F1: 0.6792
2026-02-10 09:19:46,366 - INFO - [Metrics for 'normal'] | Precision: 0.7100 | Recall: 0.9011 | F1: 0.7942
2026-02-10 09:19:46,392 - INFO - [Best Model Saved] (val loss: 0.5795) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:19:46,392 - INFO - --------------------------------------------------
2026-02-10 09:19:46,392 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 09:19:48,530 - INFO - [Train] [2/10] | Loss: 0.5538 | Train Acc: 79.02%
2026-02-10 09:19:49,235 - INFO - [Valid] [2/10] | Loss: 0.6084 | Val Acc: 69.91%
2026-02-10 09:19:49,239 - INFO - [Metrics for 'abnormal'] | Precision: 0.6355 | Recall: 0.8217 | F1: 0.7167
2026-02-10 09:19:49,239 - INFO - [Metrics for 'normal'] | Precision: 0.7941 | Recall: 0.5934 | F1: 0.6792
2026-02-10 09:19:49,240 - INFO - --------------------------------------------------
2026-02-10 09:19:49,240 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 09:19:51,405 - INFO - [Train] [3/10] | Loss: 0.5326 | Train Acc: 79.99%
2026-02-10 09:19:52,103 - INFO - [Valid] [3/10] | Loss: 0.5538 | Val Acc: 74.34%
2026-02-10 09:19:52,106 - INFO - [Metrics for 'abnormal'] | Precision: 0.6902 | Recall: 0.8089 | F1: 0.7449
2026-02-10 09:19:52,106 - INFO - [Metrics for 'normal'] | Precision: 0.8065 | Recall: 0.6868 | F1: 0.7418
2026-02-10 09:19:52,152 - INFO - [Best Model Saved] (val loss: 0.5538) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:19:52,152 - INFO - --------------------------------------------------
2026-02-10 09:19:52,152 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 09:19:54,124 - INFO - [Train] [4/10] | Loss: 0.5030 | Train Acc: 81.25%
2026-02-10 09:19:54,763 - INFO - [Valid] [4/10] | Loss: 0.5630 | Val Acc: 76.70%
2026-02-10 09:19:54,766 - INFO - [Metrics for 'abnormal'] | Precision: 0.8197 | Recall: 0.6369 | F1: 0.7168
2026-02-10 09:19:54,766 - INFO - [Metrics for 'normal'] | Precision: 0.7373 | Recall: 0.8791 | F1: 0.8020
2026-02-10 09:19:54,767 - INFO - --------------------------------------------------
2026-02-10 09:19:54,767 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 09:19:56,725 - INFO - [Train] [5/10] | Loss: 0.4867 | Train Acc: 80.80%
2026-02-10 09:19:57,405 - INFO - [Valid] [5/10] | Loss: 0.5253 | Val Acc: 77.29%
2026-02-10 09:19:57,408 - INFO - [Metrics for 'abnormal'] | Precision: 0.7247 | Recall: 0.8217 | F1: 0.7701
2026-02-10 09:19:57,408 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.7308 | F1: 0.7755
2026-02-10 09:19:57,456 - INFO - [Best Model Saved] (val loss: 0.5253) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:19:57,456 - INFO - --------------------------------------------------
2026-02-10 09:19:57,456 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 09:19:59,602 - INFO - [Train] [6/10] | Loss: 0.4784 | Train Acc: 83.48%
2026-02-10 09:20:00,185 - INFO - [Valid] [6/10] | Loss: 0.5109 | Val Acc: 80.24%
2026-02-10 09:20:00,188 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-02-10 09:20:00,188 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-02-10 09:20:00,222 - INFO - [Best Model Saved] (val loss: 0.5109) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:00,222 - INFO - --------------------------------------------------
2026-02-10 09:20:00,223 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 09:20:02,377 - INFO - [Train] [7/10] | Loss: 0.4650 | Train Acc: 83.63%
2026-02-10 09:20:02,914 - INFO - [Valid] [7/10] | Loss: 0.5302 | Val Acc: 77.58%
2026-02-10 09:20:02,916 - INFO - [Metrics for 'abnormal'] | Precision: 0.7580 | Recall: 0.7580 | F1: 0.7580
2026-02-10 09:20:02,916 - INFO - [Metrics for 'normal'] | Precision: 0.7912 | Recall: 0.7912 | F1: 0.7912
2026-02-10 09:20:02,917 - INFO - --------------------------------------------------
2026-02-10 09:20:02,917 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 09:20:05,065 - INFO - [Train] [8/10] | Loss: 0.4495 | Train Acc: 84.30%
2026-02-10 09:20:05,645 - INFO - [Valid] [8/10] | Loss: 0.5236 | Val Acc: 76.11%
2026-02-10 09:20:05,647 - INFO - [Metrics for 'abnormal'] | Precision: 0.6979 | Recall: 0.8535 | F1: 0.7679
2026-02-10 09:20:05,647 - INFO - [Metrics for 'normal'] | Precision: 0.8435 | Recall: 0.6813 | F1: 0.7538
2026-02-10 09:20:05,648 - INFO - --------------------------------------------------
2026-02-10 09:20:05,648 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 09:20:07,954 - INFO - [Train] [9/10] | Loss: 0.4488 | Train Acc: 83.85%
2026-02-10 09:20:08,379 - INFO - [Valid] [9/10] | Loss: 0.4964 | Val Acc: 81.71%
2026-02-10 09:20:08,382 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-02-10 09:20:08,390 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-02-10 09:20:08,423 - INFO - [Best Model Saved] (val loss: 0.4964) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:08,423 - INFO - --------------------------------------------------
2026-02-10 09:20:08,423 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 09:20:10,557 - INFO - [Train] [10/10] | Loss: 0.4366 | Train Acc: 84.67%
2026-02-10 09:20:11,102 - INFO - [Valid] [10/10] | Loss: 0.4970 | Val Acc: 81.42%
2026-02-10 09:20:11,105 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-02-10 09:20:11,105 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-02-10 09:20:11,106 - INFO - ================================================================================
2026-02-10 09:20:11,106 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 09:20:11,106 - INFO - ================================================================================
2026-02-10 09:20:11,120 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'을(를) 불러왔습니다.
2026-02-10 09:20:11,120 - INFO - ================================================================================
2026-02-10 09:20:11,120 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 09:20:11,120 - INFO - 원본 모델 파라미터: 9.1602M
2026-02-10 09:20:11,122 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:11,122 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:11,390 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 09:20:11,390 - INFO - ==================================================
2026-02-10 09:20:11,391 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 2.3194M (감소율: 74.68%)
2026-02-10 09:20:11,392 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:11,392 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:11,771 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 09:20:11,772 - INFO - ==================================================
2026-02-10 09:20:11,772 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.5934M (감소율: 93.52%)
2026-02-10 09:20:11,774 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:11,774 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:12,197 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 09:20:12,197 - INFO - ==================================================
2026-02-10 09:20:12,198 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.1643M (감소율: 98.21%)
2026-02-10 09:20:12,199 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:12,199 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:12,525 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 09:20:12,525 - INFO - ==================================================
2026-02-10 09:20:12,525 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:12,527 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:12,527 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:12,760 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-02-10 09:20:12,760 - INFO - ==================================================
2026-02-10 09:20:12,761 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0975M (감소율: 98.94%)
2026-02-10 09:20:12,762 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:12,762 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:13,231 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-02-10 09:20:13,231 - INFO - ==================================================
2026-02-10 09:20:13,231 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0702M (감소율: 99.23%)
2026-02-10 09:20:13,233 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:13,233 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:13,642 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.920390625)에 맞춰 변경되었습니다.
2026-02-10 09:20:13,642 - INFO - ==================================================
2026-02-10 09:20:13,642 - INFO -   [탐색  7] 희소도: 0.9204 -> 파라미터: 0.0585M (감소율: 99.36%)
2026-02-10 09:20:13,644 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:13,654 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:14,064 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9242578125)에 맞춰 변경되었습니다.
2026-02-10 09:20:14,064 - INFO - ==================================================
2026-02-10 09:20:14,065 - INFO -   [탐색  8] 희소도: 0.9243 -> 파라미터: 0.0500M (감소율: 99.45%)
2026-02-10 09:20:14,066 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:14,066 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:14,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9261914062500001)에 맞춰 변경되었습니다.
2026-02-10 09:20:14,347 - INFO - ==================================================
2026-02-10 09:20:14,347 - INFO -   [탐색  9] 희소도: 0.9262 -> 파라미터: 0.0487M (감소율: 99.47%)
2026-02-10 09:20:14,348 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:14,348 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:14,554 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9271582031250001)에 맞춰 변경되었습니다.
2026-02-10 09:20:14,554 - INFO - ==================================================
2026-02-10 09:20:14,555 - INFO -   [탐색 10] 희소도: 0.9272 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:14,556 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:14,556 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:14,796 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9276416015625)에 맞춰 변경되었습니다.
2026-02-10 09:20:14,796 - INFO - ==================================================
2026-02-10 09:20:14,796 - INFO -   [탐색 11] 희소도: 0.9276 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:14,797 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:14,798 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:15,369 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9278833007812499)에 맞춰 변경되었습니다.
2026-02-10 09:20:15,369 - INFO - ==================================================
2026-02-10 09:20:15,369 - INFO -   [탐색 12] 희소도: 0.9279 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:15,370 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:15,370 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:15,687 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927762451171875)에 맞춰 변경되었습니다.
2026-02-10 09:20:15,687 - INFO - ==================================================
2026-02-10 09:20:15,688 - INFO -   [탐색 13] 희소도: 0.9278 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:15,689 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:15,689 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:15,986 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277020263671875)에 맞춰 변경되었습니다.
2026-02-10 09:20:15,986 - INFO - ==================================================
2026-02-10 09:20:15,986 - INFO -   [탐색 14] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:15,987 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:15,987 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:16,197 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277322387695313)에 맞춰 변경되었습니다.
2026-02-10 09:20:16,198 - INFO - ==================================================
2026-02-10 09:20:16,198 - INFO -   [탐색 15] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:16,199 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:16,199 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:16,426 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277473449707031)에 맞춰 변경되었습니다.
2026-02-10 09:20:16,426 - INFO - ==================================================
2026-02-10 09:20:16,426 - INFO -   [탐색 16] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:16,427 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:16,427 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:16,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277397918701171)에 맞춰 변경되었습니다.
2026-02-10 09:20:16,795 - INFO - ==================================================
2026-02-10 09:20:16,795 - INFO -   [탐색 17] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:16,797 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:16,797 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:17,175 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277360153198242)에 맞춰 변경되었습니다.
2026-02-10 09:20:17,175 - INFO - ==================================================
2026-02-10 09:20:17,176 - INFO -   [탐색 18] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:17,177 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:17,178 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:17,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277341270446777)에 맞춰 변경되었습니다.
2026-02-10 09:20:17,681 - INFO - ==================================================
2026-02-10 09:20:17,681 - INFO -   [탐색 19] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:17,682 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:17,683 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:17,896 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927735071182251)에 맞춰 변경되었습니다.
2026-02-10 09:20:17,896 - INFO - ==================================================
2026-02-10 09:20:17,896 - INFO -   [탐색 20] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:17,897 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:17,897 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:18,125 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277345991134643)에 맞춰 변경되었습니다.
2026-02-10 09:20:18,125 - INFO - ==================================================
2026-02-10 09:20:18,126 - INFO -   [탐색 21] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:18,127 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:18,127 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:18,453 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343630790711)에 맞춰 변경되었습니다.
2026-02-10 09:20:18,453 - INFO - ==================================================
2026-02-10 09:20:18,453 - INFO -   [탐색 22] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:18,455 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:18,455 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:18,791 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277344810962678)에 맞춰 변경되었습니다.
2026-02-10 09:20:18,791 - INFO - ==================================================
2026-02-10 09:20:18,791 - INFO -   [탐색 23] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:18,792 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:18,802 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:19,197 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277344220876694)에 맞춰 변경되었습니다.
2026-02-10 09:20:19,197 - INFO - ==================================================
2026-02-10 09:20:19,197 - INFO -   [탐색 24] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:19,198 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:19,198 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:19,586 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343925833703)에 맞춰 변경되었습니다.
2026-02-10 09:20:19,587 - INFO - ==================================================
2026-02-10 09:20:19,587 - INFO -   [탐색 25] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:19,588 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:19,588 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:19,843 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343778312207)에 맞춰 변경되었습니다.
2026-02-10 09:20:19,843 - INFO - ==================================================
2026-02-10 09:20:19,843 - INFO -   [탐색 26] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:19,845 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:19,845 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:20,222 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734370455146)에 맞춰 변경되었습니다.
2026-02-10 09:20:20,222 - INFO - ==================================================
2026-02-10 09:20:20,222 - INFO -   [탐색 27] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:20,223 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:20,224 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:20,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343741431834)에 맞춰 변경되었습니다.
2026-02-10 09:20:20,568 - INFO - ==================================================
2026-02-10 09:20:20,568 - INFO -   [탐색 28] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:20,569 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:20,569 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:20,896 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343759872021)에 맞춰 변경되었습니다.
2026-02-10 09:20:20,896 - INFO - ==================================================
2026-02-10 09:20:20,897 - INFO -   [탐색 29] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:20,898 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:20,898 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:21,148 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750651927)에 맞춰 변경되었습니다.
2026-02-10 09:20:21,148 - INFO - ==================================================
2026-02-10 09:20:21,148 - INFO -   [탐색 30] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:21,149 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:21,149 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:21,360 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343746041881)에 맞춰 변경되었습니다.
2026-02-10 09:20:21,360 - INFO - ==================================================
2026-02-10 09:20:21,360 - INFO -   [탐색 31] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:21,361 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:21,361 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:21,868 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343748346905)에 맞춰 변경되었습니다.
2026-02-10 09:20:21,869 - INFO - ==================================================
2026-02-10 09:20:21,869 - INFO -   [탐색 32] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:21,870 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:21,870 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:22,189 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749499416)에 맞춰 변경되었습니다.
2026-02-10 09:20:22,189 - INFO - ==================================================
2026-02-10 09:20:22,189 - INFO -   [탐색 33] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:22,191 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:22,191 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:22,516 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750075672)에 맞춰 변경되었습니다.
2026-02-10 09:20:22,516 - INFO - ==================================================
2026-02-10 09:20:22,516 - INFO -   [탐색 34] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:22,517 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:22,517 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:22,794 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749787543)에 맞춰 변경되었습니다.
2026-02-10 09:20:22,794 - INFO - ==================================================
2026-02-10 09:20:22,794 - INFO -   [탐색 35] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:22,795 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:22,796 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:23,000 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749931608)에 맞춰 변경되었습니다.
2026-02-10 09:20:23,000 - INFO - ==================================================
2026-02-10 09:20:23,000 - INFO -   [탐색 36] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:23,001 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:23,002 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:23,273 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750003639)에 맞춰 변경되었습니다.
2026-02-10 09:20:23,273 - INFO - ==================================================
2026-02-10 09:20:23,273 - INFO -   [탐색 37] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:23,274 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:23,274 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:23,928 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749967624)에 맞춰 변경되었습니다.
2026-02-10 09:20:23,930 - INFO - ==================================================
2026-02-10 09:20:23,930 - INFO -   [탐색 38] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:23,932 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:23,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:24,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749985631)에 맞춰 변경되었습니다.
2026-02-10 09:20:24,269 - INFO - ==================================================
2026-02-10 09:20:24,269 - INFO -   [탐색 39] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:24,270 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:24,270 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:24,532 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749994635)에 맞춰 변경되었습니다.
2026-02-10 09:20:24,532 - INFO - ==================================================
2026-02-10 09:20:24,532 - INFO -   [탐색 40] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:24,533 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:24,533 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:24,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749999137)에 맞춰 변경되었습니다.
2026-02-10 09:20:24,749 - INFO - ==================================================
2026-02-10 09:20:24,749 - INFO -   [탐색 41] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:24,750 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:24,750 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:25,125 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750001388)에 맞춰 변경되었습니다.
2026-02-10 09:20:25,125 - INFO - ==================================================
2026-02-10 09:20:25,125 - INFO -   [탐색 42] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:25,127 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:25,127 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:25,499 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000262)에 맞춰 변경되었습니다.
2026-02-10 09:20:25,499 - INFO - ==================================================
2026-02-10 09:20:25,499 - INFO -   [탐색 43] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:25,501 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:25,501 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:25,842 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.92773437499997)에 맞춰 변경되었습니다.
2026-02-10 09:20:25,842 - INFO - ==================================================
2026-02-10 09:20:25,842 - INFO -   [탐색 44] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:25,844 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:25,844 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:26,283 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749999981)에 맞춰 변경되었습니다.
2026-02-10 09:20:26,283 - INFO - ==================================================
2026-02-10 09:20:26,283 - INFO -   [탐색 45] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:26,284 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:26,284 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:26,507 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000122)에 맞춰 변경되었습니다.
2026-02-10 09:20:26,507 - INFO - ==================================================
2026-02-10 09:20:26,507 - INFO -   [탐색 46] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:26,508 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:26,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:26,857 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000051)에 맞춰 변경되었습니다.
2026-02-10 09:20:26,857 - INFO - ==================================================
2026-02-10 09:20:26,857 - INFO -   [탐색 47] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:26,859 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:26,859 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:27,291 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000016)에 맞춰 변경되었습니다.
2026-02-10 09:20:27,291 - INFO - ==================================================
2026-02-10 09:20:27,291 - INFO -   [탐색 48] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:27,293 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:27,293 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:27,655 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343749999998)에 맞춰 변경되었습니다.
2026-02-10 09:20:27,655 - INFO - ==================================================
2026-02-10 09:20:27,655 - INFO -   [탐색 49] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:27,657 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:27,657 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:27,895 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000007)에 맞춰 변경되었습니다.
2026-02-10 09:20:27,895 - INFO - ==================================================
2026-02-10 09:20:27,895 - INFO -   [탐색 50] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:27,896 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:27,896 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:28,312 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000002)에 맞춰 변경되었습니다.
2026-02-10 09:20:28,312 - INFO - ==================================================
2026-02-10 09:20:28,312 - INFO -   [탐색 51] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:28,314 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:28,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:28,634 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:28,634 - INFO - ==================================================
2026-02-10 09:20:28,635 - INFO -   [탐색 52] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:28,636 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:28,636 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:28,975 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9277343750000001)에 맞춰 변경되었습니다.
2026-02-10 09:20:28,975 - INFO - ==================================================
2026-02-10 09:20:28,975 - INFO -   [탐색 53] 희소도: 0.9277 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-02-10 09:20:28,988 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:28,988 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:29,361 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:29,362 - INFO - ==================================================
2026-02-10 09:20:29,362 - INFO -   [탐색 54] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:29,363 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:29,363 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:29,596 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:29,596 - INFO - ==================================================
2026-02-10 09:20:29,596 - INFO -   [탐색 55] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:29,597 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:29,597 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:29,808 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:29,808 - INFO - ==================================================
2026-02-10 09:20:29,808 - INFO -   [탐색 56] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:29,809 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:29,809 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:30,022 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:30,022 - INFO - ==================================================
2026-02-10 09:20:30,022 - INFO -   [탐색 57] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:30,023 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:30,023 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:30,683 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:30,684 - INFO - ==================================================
2026-02-10 09:20:30,684 - INFO -   [탐색 58] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:30,686 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:30,686 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:31,094 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:31,094 - INFO - ==================================================
2026-02-10 09:20:31,094 - INFO -   [탐색 59] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:31,096 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:31,096 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:31,385 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:31,386 - INFO - ==================================================
2026-02-10 09:20:31,386 - INFO -   [탐색 60] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:31,387 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:31,387 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:31,592 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:31,592 - INFO - ==================================================
2026-02-10 09:20:31,593 - INFO -   [탐색 61] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:31,594 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:31,594 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:31,833 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:31,833 - INFO - ==================================================
2026-02-10 09:20:31,833 - INFO -   [탐색 62] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:31,834 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:31,834 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:32,161 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:32,161 - INFO - ==================================================
2026-02-10 09:20:32,162 - INFO -   [탐색 63] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:32,163 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:32,163 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:32,765 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:32,765 - INFO - ==================================================
2026-02-10 09:20:32,765 - INFO -   [탐색 64] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:32,766 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:32,767 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:33,063 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:33,063 - INFO - ==================================================
2026-02-10 09:20:33,063 - INFO -   [탐색 65] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:33,064 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:33,064 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:33,271 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:33,271 - INFO - ==================================================
2026-02-10 09:20:33,271 - INFO -   [탐색 66] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:33,272 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:33,272 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:33,537 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:33,537 - INFO - ==================================================
2026-02-10 09:20:33,537 - INFO -   [탐색 67] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:33,539 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:33,539 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:33,887 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:33,887 - INFO - ==================================================
2026-02-10 09:20:33,887 - INFO -   [탐색 68] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:33,888 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:33,888 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:34,219 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:34,219 - INFO - ==================================================
2026-02-10 09:20:34,220 - INFO -   [탐색 69] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:34,221 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:34,221 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:34,554 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:34,554 - INFO - ==================================================
2026-02-10 09:20:34,554 - INFO -   [탐색 70] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:34,556 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:34,556 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:34,969 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:34,969 - INFO - ==================================================
2026-02-10 09:20:34,969 - INFO -   [탐색 71] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:34,970 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:34,970 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:35,185 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:35,186 - INFO - ==================================================
2026-02-10 09:20:35,186 - INFO -   [탐색 72] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:35,187 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:35,187 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:35,542 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:35,542 - INFO - ==================================================
2026-02-10 09:20:35,542 - INFO -   [탐색 73] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:35,544 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:35,544 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:35,930 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:35,931 - INFO - ==================================================
2026-02-10 09:20:35,931 - INFO -   [탐색 74] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:35,932 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:35,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:36,266 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:36,267 - INFO - ==================================================
2026-02-10 09:20:36,267 - INFO -   [탐색 75] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:36,269 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:36,269 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:36,540 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:36,540 - INFO - ==================================================
2026-02-10 09:20:36,540 - INFO -   [탐색 76] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:36,541 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:36,541 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:36,912 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:36,912 - INFO - ==================================================
2026-02-10 09:20:36,913 - INFO -   [탐색 77] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:36,914 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:36,914 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:37,235 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:37,235 - INFO - ==================================================
2026-02-10 09:20:37,235 - INFO -   [탐색 78] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:37,237 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:37,237 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:37,567 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:37,567 - INFO - ==================================================
2026-02-10 09:20:37,567 - INFO -   [탐색 79] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:37,568 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:37,568 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:37,889 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:37,890 - INFO - ==================================================
2026-02-10 09:20:37,890 - INFO -   [탐색 80] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:37,891 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:37,891 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:38,185 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:38,185 - INFO - ==================================================
2026-02-10 09:20:38,185 - INFO -   [탐색 81] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:38,187 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:38,187 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:38,404 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:38,404 - INFO - ==================================================
2026-02-10 09:20:38,404 - INFO -   [탐색 82] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:38,405 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:38,405 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:38,631 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:38,631 - INFO - ==================================================
2026-02-10 09:20:38,631 - INFO -   [탐색 83] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:38,633 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:38,633 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:39,198 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:39,198 - INFO - ==================================================
2026-02-10 09:20:39,198 - INFO -   [탐색 84] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:39,199 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:39,200 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:39,536 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:39,536 - INFO - ==================================================
2026-02-10 09:20:39,537 - INFO -   [탐색 85] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:39,538 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:39,538 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:39,858 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:39,858 - INFO - ==================================================
2026-02-10 09:20:39,858 - INFO -   [탐색 86] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:39,860 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:39,860 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:40,073 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:40,073 - INFO - ==================================================
2026-02-10 09:20:40,073 - INFO -   [탐색 87] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:40,074 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:40,074 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:40,286 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:40,286 - INFO - ==================================================
2026-02-10 09:20:40,286 - INFO -   [탐색 88] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:40,288 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:40,288 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:40,657 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:40,657 - INFO - ==================================================
2026-02-10 09:20:40,657 - INFO -   [탐색 89] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:40,659 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:40,659 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:41,382 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:41,382 - INFO - ==================================================
2026-02-10 09:20:41,383 - INFO -   [탐색 90] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:41,384 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:41,384 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:41,630 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:41,630 - INFO - ==================================================
2026-02-10 09:20:41,630 - INFO -   [탐색 91] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:41,631 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:41,631 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:41,835 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:41,835 - INFO - ==================================================
2026-02-10 09:20:41,835 - INFO -   [탐색 92] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:41,836 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:41,836 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:42,102 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:42,102 - INFO - ==================================================
2026-02-10 09:20:42,102 - INFO -   [탐색 93] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:42,104 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:42,104 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:42,537 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:42,537 - INFO - ==================================================
2026-02-10 09:20:42,537 - INFO -   [탐색 94] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:42,539 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:42,539 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:42,882 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:42,882 - INFO - ==================================================
2026-02-10 09:20:42,882 - INFO -   [탐색 95] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:42,883 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:42,884 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:43,202 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:43,202 - INFO - ==================================================
2026-02-10 09:20:43,202 - INFO -   [탐색 96] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:43,203 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:43,203 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:43,573 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:43,573 - INFO - ==================================================
2026-02-10 09:20:43,574 - INFO -   [탐색 97] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:43,575 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:43,575 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:43,827 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:43,827 - INFO - ==================================================
2026-02-10 09:20:43,828 - INFO -   [탐색 98] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:43,829 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:43,829 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:44,174 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:44,174 - INFO - ==================================================
2026-02-10 09:20:44,175 - INFO -   [탐색 99] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:44,176 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:44,176 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:44,604 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.927734375)에 맞춰 변경되었습니다.
2026-02-10 09:20:44,604 - INFO - ==================================================
2026-02-10 09:20:44,604 - INFO -   [탐색 100] 희소도: 0.9277 -> 파라미터: 0.0481M (감소율: 99.48%)
2026-02-10 09:20:44,604 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.9281 입니다.
2026-02-10 09:20:44,604 - INFO - ================================================================================
2026-02-10 09:20:44,605 - INFO - 계산된 Pruning 정보(희소도: 0.9281)를 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/pruning_info.yaml'에 저장했습니다.
2026-02-10 09:20:44,609 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 09:20:44,614 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:20:44,614 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:20:44,968 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 09:20:44,969 - INFO - ==================================================
2026-02-10 09:20:44,969 - INFO - ==================================================
2026-02-10 09:20:44,969 - INFO - 모델 파라미터 수:
2026-02-10 09:20:44,969 - INFO -   - 총 파라미터: 47,386 개
2026-02-10 09:20:44,969 - INFO -   - 학습 가능한 파라미터: 47,386 개
2026-02-10 09:20:44,972 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 09:20:44,975 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1481 GFLOPs로 감소했습니다 (감소율: 94.84%).
2026-02-10 09:20:44,975 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 09:20:44,975 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 09:20:44,975 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 09:20:44,975 - INFO - ==================================================
2026-02-10 09:20:44,975 - INFO - train 모드를 시작합니다.
2026-02-10 09:20:44,975 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 09:20:44,975 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 09:20:44,975 - INFO - --------------------------------------------------
2026-02-10 09:20:44,975 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 09:20:47,082 - INFO - [Train] [11/90] | Loss: 0.5580 | Train Acc: 77.08%
2026-02-10 09:20:47,685 - INFO - [Valid] [11/90] | Loss: 0.5515 | Val Acc: 73.16%
2026-02-10 09:20:47,689 - INFO - [Metrics for 'abnormal'] | Precision: 0.6774 | Recall: 0.8025 | F1: 0.7347
2026-02-10 09:20:47,689 - INFO - [Metrics for 'normal'] | Precision: 0.7974 | Recall: 0.6703 | F1: 0.7284
2026-02-10 09:20:47,693 - INFO - [Best Model Saved] (val loss: 0.5515) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:47,693 - INFO - --------------------------------------------------
2026-02-10 09:20:47,693 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 09:20:49,796 - INFO - [Train] [12/90] | Loss: 0.5166 | Train Acc: 80.28%
2026-02-10 09:20:50,369 - INFO - [Valid] [12/90] | Loss: 0.5495 | Val Acc: 72.86%
2026-02-10 09:20:50,373 - INFO - [Metrics for 'abnormal'] | Precision: 0.6650 | Recall: 0.8344 | F1: 0.7401
2026-02-10 09:20:50,373 - INFO - [Metrics for 'normal'] | Precision: 0.8169 | Recall: 0.6374 | F1: 0.7160
2026-02-10 09:20:50,375 - INFO - [Best Model Saved] (val loss: 0.5495) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:50,375 - INFO - --------------------------------------------------
2026-02-10 09:20:50,376 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 09:20:52,524 - INFO - [Train] [13/90] | Loss: 0.5076 | Train Acc: 80.95%
2026-02-10 09:20:53,084 - INFO - [Valid] [13/90] | Loss: 0.5389 | Val Acc: 76.40%
2026-02-10 09:20:53,087 - INFO - [Metrics for 'abnormal'] | Precision: 0.7584 | Recall: 0.7197 | F1: 0.7386
2026-02-10 09:20:53,087 - INFO - [Metrics for 'normal'] | Precision: 0.7684 | Recall: 0.8022 | F1: 0.7849
2026-02-10 09:20:53,089 - INFO - [Best Model Saved] (val loss: 0.5389) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:53,089 - INFO - --------------------------------------------------
2026-02-10 09:20:53,089 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 09:20:55,432 - INFO - [Train] [14/90] | Loss: 0.4996 | Train Acc: 81.40%
2026-02-10 09:20:55,846 - INFO - [Valid] [14/90] | Loss: 0.5373 | Val Acc: 76.70%
2026-02-10 09:20:55,849 - INFO - [Metrics for 'abnormal'] | Precision: 0.7671 | Recall: 0.7134 | F1: 0.7393
2026-02-10 09:20:55,849 - INFO - [Metrics for 'normal'] | Precision: 0.7668 | Recall: 0.8132 | F1: 0.7893
2026-02-10 09:20:55,851 - INFO - [Best Model Saved] (val loss: 0.5373) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:55,851 - INFO - --------------------------------------------------
2026-02-10 09:20:55,851 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 09:20:58,220 - INFO - [Train] [15/90] | Loss: 0.4846 | Train Acc: 81.99%
2026-02-10 09:20:58,633 - INFO - [Valid] [15/90] | Loss: 0.5204 | Val Acc: 77.58%
2026-02-10 09:20:58,635 - INFO - [Metrics for 'abnormal'] | Precision: 0.7455 | Recall: 0.7834 | F1: 0.7640
2026-02-10 09:20:58,635 - INFO - [Metrics for 'normal'] | Precision: 0.8046 | Recall: 0.7692 | F1: 0.7865
2026-02-10 09:20:58,637 - INFO - [Best Model Saved] (val loss: 0.5204) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:20:58,637 - INFO - --------------------------------------------------
2026-02-10 09:20:58,637 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 09:21:01,039 - INFO - [Train] [16/90] | Loss: 0.4856 | Train Acc: 83.18%
2026-02-10 09:21:01,465 - INFO - [Valid] [16/90] | Loss: 0.5182 | Val Acc: 76.99%
2026-02-10 09:21:01,469 - INFO - [Metrics for 'abnormal'] | Precision: 0.7283 | Recall: 0.8025 | F1: 0.7636
2026-02-10 09:21:01,469 - INFO - [Metrics for 'normal'] | Precision: 0.8133 | Recall: 0.7418 | F1: 0.7759
2026-02-10 09:21:01,472 - INFO - [Best Model Saved] (val loss: 0.5182) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:21:01,472 - INFO - --------------------------------------------------
2026-02-10 09:21:01,472 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 09:21:03,932 - INFO - [Train] [17/90] | Loss: 0.4841 | Train Acc: 81.99%
2026-02-10 09:21:04,519 - INFO - [Valid] [17/90] | Loss: 0.5255 | Val Acc: 79.35%
2026-02-10 09:21:04,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.8372 | Recall: 0.6879 | F1: 0.7552
2026-02-10 09:21:04,524 - INFO - [Metrics for 'normal'] | Precision: 0.7667 | Recall: 0.8846 | F1: 0.8214
2026-02-10 09:21:04,525 - INFO - --------------------------------------------------
2026-02-10 09:21:04,525 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 09:21:06,706 - INFO - [Train] [18/90] | Loss: 0.4766 | Train Acc: 83.41%
2026-02-10 09:21:07,498 - INFO - [Valid] [18/90] | Loss: 0.4986 | Val Acc: 79.35%
2026-02-10 09:21:07,502 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8280 | F1: 0.7879
2026-02-10 09:21:07,502 - INFO - [Metrics for 'normal'] | Precision: 0.8373 | Recall: 0.7637 | F1: 0.7989
2026-02-10 09:21:07,504 - INFO - [Best Model Saved] (val loss: 0.4986) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:21:07,504 - INFO - --------------------------------------------------
2026-02-10 09:21:07,504 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 09:21:09,501 - INFO - [Train] [19/90] | Loss: 0.4778 | Train Acc: 83.04%
2026-02-10 09:21:10,222 - INFO - [Valid] [19/90] | Loss: 0.5270 | Val Acc: 75.52%
2026-02-10 09:21:10,226 - INFO - [Metrics for 'abnormal'] | Precision: 0.6907 | Recall: 0.8535 | F1: 0.7635
2026-02-10 09:21:10,226 - INFO - [Metrics for 'normal'] | Precision: 0.8414 | Recall: 0.6703 | F1: 0.7462
2026-02-10 09:21:10,227 - INFO - --------------------------------------------------
2026-02-10 09:21:10,228 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 09:21:12,305 - INFO - [Train] [20/90] | Loss: 0.4682 | Train Acc: 83.93%
2026-02-10 09:21:13,023 - INFO - [Valid] [20/90] | Loss: 0.5568 | Val Acc: 79.35%
2026-02-10 09:21:13,027 - INFO - [Metrics for 'abnormal'] | Precision: 0.8042 | Recall: 0.7325 | F1: 0.7667
2026-02-10 09:21:13,027 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.8462 | F1: 0.8148
2026-02-10 09:21:13,029 - INFO - --------------------------------------------------
2026-02-10 09:21:13,029 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 09:21:14,978 - INFO - [Train] [21/90] | Loss: 0.4669 | Train Acc: 83.48%
2026-02-10 09:21:15,684 - INFO - [Valid] [21/90] | Loss: 0.5095 | Val Acc: 80.83%
2026-02-10 09:21:15,688 - INFO - [Metrics for 'abnormal'] | Precision: 0.8433 | Recall: 0.7197 | F1: 0.7766
2026-02-10 09:21:15,689 - INFO - [Metrics for 'normal'] | Precision: 0.7854 | Recall: 0.8846 | F1: 0.8320
2026-02-10 09:21:15,690 - INFO - --------------------------------------------------
2026-02-10 09:21:15,690 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 09:21:17,803 - INFO - [Train] [22/90] | Loss: 0.4643 | Train Acc: 83.48%
2026-02-10 09:21:18,500 - INFO - [Valid] [22/90] | Loss: 0.4999 | Val Acc: 79.06%
2026-02-10 09:21:18,503 - INFO - [Metrics for 'abnormal'] | Precision: 0.7443 | Recall: 0.8344 | F1: 0.7868
2026-02-10 09:21:18,503 - INFO - [Metrics for 'normal'] | Precision: 0.8405 | Recall: 0.7527 | F1: 0.7942
2026-02-10 09:21:18,504 - INFO - --------------------------------------------------
2026-02-10 09:21:18,504 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 09:21:20,561 - INFO - [Train] [23/90] | Loss: 0.4682 | Train Acc: 84.67%
2026-02-10 09:21:21,199 - INFO - [Valid] [23/90] | Loss: 0.5002 | Val Acc: 78.17%
2026-02-10 09:21:21,202 - INFO - [Metrics for 'abnormal'] | Precision: 0.7345 | Recall: 0.8280 | F1: 0.7784
2026-02-10 09:21:21,203 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7418 | F1: 0.7849
2026-02-10 09:21:21,204 - INFO - --------------------------------------------------
2026-02-10 09:21:21,204 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 09:21:23,339 - INFO - [Train] [24/90] | Loss: 0.4630 | Train Acc: 83.78%
2026-02-10 09:21:23,895 - INFO - [Valid] [24/90] | Loss: 0.5062 | Val Acc: 77.58%
2026-02-10 09:21:23,898 - INFO - [Metrics for 'abnormal'] | Precision: 0.7288 | Recall: 0.8217 | F1: 0.7725
2026-02-10 09:21:23,898 - INFO - [Metrics for 'normal'] | Precision: 0.8272 | Recall: 0.7363 | F1: 0.7791
2026-02-10 09:21:23,899 - INFO - --------------------------------------------------
2026-02-10 09:21:23,899 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 09:21:26,045 - INFO - [Train] [25/90] | Loss: 0.4502 | Train Acc: 84.52%
2026-02-10 09:21:26,602 - INFO - [Valid] [25/90] | Loss: 0.4959 | Val Acc: 81.42%
2026-02-10 09:21:26,604 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.7707 | F1: 0.7934
2026-02-10 09:21:26,604 - INFO - [Metrics for 'normal'] | Precision: 0.8115 | Recall: 0.8516 | F1: 0.8311
2026-02-10 09:21:26,606 - INFO - [Best Model Saved] (val loss: 0.4959) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:21:26,607 - INFO - --------------------------------------------------
2026-02-10 09:21:26,607 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 09:21:28,820 - INFO - [Train] [26/90] | Loss: 0.4423 | Train Acc: 84.90%
2026-02-10 09:21:29,301 - INFO - [Valid] [26/90] | Loss: 0.5410 | Val Acc: 76.99%
2026-02-10 09:21:29,303 - INFO - [Metrics for 'abnormal'] | Precision: 0.7135 | Recall: 0.8408 | F1: 0.7719
2026-02-10 09:21:29,303 - INFO - [Metrics for 'normal'] | Precision: 0.8377 | Recall: 0.7088 | F1: 0.7679
2026-02-10 09:21:29,304 - INFO - --------------------------------------------------
2026-02-10 09:21:29,304 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 09:21:31,687 - INFO - [Train] [27/90] | Loss: 0.4461 | Train Acc: 84.97%
2026-02-10 09:21:32,113 - INFO - [Valid] [27/90] | Loss: 0.4970 | Val Acc: 81.71%
2026-02-10 09:21:32,118 - INFO - [Metrics for 'abnormal'] | Precision: 0.8369 | Recall: 0.7516 | F1: 0.7919
2026-02-10 09:21:32,118 - INFO - [Metrics for 'normal'] | Precision: 0.8030 | Recall: 0.8736 | F1: 0.8368
2026-02-10 09:21:32,119 - INFO - --------------------------------------------------
2026-02-10 09:21:32,119 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 09:21:34,492 - INFO - [Train] [28/90] | Loss: 0.4462 | Train Acc: 84.60%
2026-02-10 09:21:34,977 - INFO - [Valid] [28/90] | Loss: 0.5085 | Val Acc: 77.88%
2026-02-10 09:21:34,982 - INFO - [Metrics for 'abnormal'] | Precision: 0.7228 | Recall: 0.8471 | F1: 0.7801
2026-02-10 09:21:34,982 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7198 | F1: 0.7774
2026-02-10 09:21:34,983 - INFO - --------------------------------------------------
2026-02-10 09:21:34,984 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 09:21:37,248 - INFO - [Train] [29/90] | Loss: 0.4392 | Train Acc: 85.94%
2026-02-10 09:21:37,805 - INFO - [Valid] [29/90] | Loss: 0.4936 | Val Acc: 83.19%
2026-02-10 09:21:37,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.8247 | Recall: 0.8089 | F1: 0.8167
2026-02-10 09:21:37,809 - INFO - [Metrics for 'normal'] | Precision: 0.8378 | Recall: 0.8516 | F1: 0.8447
2026-02-10 09:21:37,812 - INFO - [Best Model Saved] (val loss: 0.4936) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:21:37,812 - INFO - --------------------------------------------------
2026-02-10 09:21:37,812 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 09:21:39,930 - INFO - [Train] [30/90] | Loss: 0.4382 | Train Acc: 85.42%
2026-02-10 09:21:40,754 - INFO - [Valid] [30/90] | Loss: 0.5088 | Val Acc: 80.24%
2026-02-10 09:21:40,758 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-02-10 09:21:40,758 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-02-10 09:21:40,759 - INFO - --------------------------------------------------
2026-02-10 09:21:40,759 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 09:21:42,818 - INFO - [Train] [31/90] | Loss: 0.4406 | Train Acc: 85.79%
2026-02-10 09:21:43,512 - INFO - [Valid] [31/90] | Loss: 0.4978 | Val Acc: 80.24%
2026-02-10 09:21:43,517 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-02-10 09:21:43,517 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-02-10 09:21:43,518 - INFO - --------------------------------------------------
2026-02-10 09:21:43,518 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 09:21:45,588 - INFO - [Train] [32/90] | Loss: 0.4315 | Train Acc: 85.49%
2026-02-10 09:21:46,302 - INFO - [Valid] [32/90] | Loss: 0.4902 | Val Acc: 82.89%
2026-02-10 09:21:46,306 - INFO - [Metrics for 'abnormal'] | Precision: 0.8561 | Recall: 0.7580 | F1: 0.8041
2026-02-10 09:21:46,306 - INFO - [Metrics for 'normal'] | Precision: 0.8100 | Recall: 0.8901 | F1: 0.8482
2026-02-10 09:21:46,309 - INFO - [Best Model Saved] (val loss: 0.4902) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:21:46,309 - INFO - --------------------------------------------------
2026-02-10 09:21:46,309 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 09:21:48,360 - INFO - [Train] [33/90] | Loss: 0.4327 | Train Acc: 86.53%
2026-02-10 09:21:49,082 - INFO - [Valid] [33/90] | Loss: 0.4969 | Val Acc: 79.35%
2026-02-10 09:21:49,087 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8344 | F1: 0.7892
2026-02-10 09:21:49,087 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.7582 | F1: 0.7977
2026-02-10 09:21:49,088 - INFO - --------------------------------------------------
2026-02-10 09:21:49,088 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 09:21:50,997 - INFO - [Train] [34/90] | Loss: 0.4199 | Train Acc: 86.76%
2026-02-10 09:21:51,708 - INFO - [Valid] [34/90] | Loss: 0.5075 | Val Acc: 79.65%
2026-02-10 09:21:51,712 - INFO - [Metrics for 'abnormal'] | Precision: 0.7529 | Recall: 0.8344 | F1: 0.7915
2026-02-10 09:21:51,712 - INFO - [Metrics for 'normal'] | Precision: 0.8424 | Recall: 0.7637 | F1: 0.8012
2026-02-10 09:21:51,714 - INFO - --------------------------------------------------
2026-02-10 09:21:51,714 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 09:21:53,603 - INFO - [Train] [35/90] | Loss: 0.4246 | Train Acc: 86.68%
2026-02-10 09:21:54,365 - INFO - [Valid] [35/90] | Loss: 0.5026 | Val Acc: 80.53%
2026-02-10 09:21:54,369 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-02-10 09:21:54,370 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-02-10 09:21:54,371 - INFO - --------------------------------------------------
2026-02-10 09:21:54,372 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 09:21:56,320 - INFO - [Train] [36/90] | Loss: 0.4167 | Train Acc: 87.50%
2026-02-10 09:21:56,966 - INFO - [Valid] [36/90] | Loss: 0.5049 | Val Acc: 79.06%
2026-02-10 09:21:56,971 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8217 | F1: 0.7842
2026-02-10 09:21:56,971 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7637 | F1: 0.7966
2026-02-10 09:21:56,972 - INFO - --------------------------------------------------
2026-02-10 09:21:56,972 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 09:21:58,912 - INFO - [Train] [37/90] | Loss: 0.4096 | Train Acc: 87.80%
2026-02-10 09:21:59,609 - INFO - [Valid] [37/90] | Loss: 0.5147 | Val Acc: 79.65%
2026-02-10 09:21:59,613 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.8153 | F1: 0.7877
2026-02-10 09:21:59,613 - INFO - [Metrics for 'normal'] | Precision: 0.8304 | Recall: 0.7802 | F1: 0.8045
2026-02-10 09:21:59,615 - INFO - --------------------------------------------------
2026-02-10 09:21:59,615 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 09:22:01,922 - INFO - [Train] [38/90] | Loss: 0.4134 | Train Acc: 86.16%
2026-02-10 09:22:02,444 - INFO - [Valid] [38/90] | Loss: 0.5042 | Val Acc: 81.12%
2026-02-10 09:22:02,447 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-02-10 09:22:02,447 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-02-10 09:22:02,448 - INFO - --------------------------------------------------
2026-02-10 09:22:02,448 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 09:22:04,658 - INFO - [Train] [39/90] | Loss: 0.4097 | Train Acc: 87.57%
2026-02-10 09:22:05,135 - INFO - [Valid] [39/90] | Loss: 0.4860 | Val Acc: 81.71%
2026-02-10 09:22:05,137 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-02-10 09:22:05,137 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-02-10 09:22:05,139 - INFO - [Best Model Saved] (val loss: 0.4860) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:22:05,139 - INFO - --------------------------------------------------
2026-02-10 09:22:05,139 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 09:22:07,499 - INFO - [Train] [40/90] | Loss: 0.4007 | Train Acc: 87.50%
2026-02-10 09:22:07,927 - INFO - [Valid] [40/90] | Loss: 0.4945 | Val Acc: 82.60%
2026-02-10 09:22:07,931 - INFO - [Metrics for 'abnormal'] | Precision: 0.8267 | Recall: 0.7898 | F1: 0.8078
2026-02-10 09:22:07,931 - INFO - [Metrics for 'normal'] | Precision: 0.8254 | Recall: 0.8571 | F1: 0.8410
2026-02-10 09:22:07,933 - INFO - --------------------------------------------------
2026-02-10 09:22:07,933 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 09:22:10,347 - INFO - [Train] [41/90] | Loss: 0.4029 | Train Acc: 87.28%
2026-02-10 09:22:10,774 - INFO - [Valid] [41/90] | Loss: 0.4955 | Val Acc: 80.83%
2026-02-10 09:22:10,779 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-02-10 09:22:10,779 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-02-10 09:22:10,780 - INFO - --------------------------------------------------
2026-02-10 09:22:10,781 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 09:22:13,193 - INFO - [Train] [42/90] | Loss: 0.4039 | Train Acc: 88.69%
2026-02-10 09:22:13,758 - INFO - [Valid] [42/90] | Loss: 0.5152 | Val Acc: 80.53%
2026-02-10 09:22:13,762 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-02-10 09:22:13,762 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-02-10 09:22:13,764 - INFO - --------------------------------------------------
2026-02-10 09:22:13,764 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 09:22:15,902 - INFO - [Train] [43/90] | Loss: 0.4032 | Train Acc: 88.32%
2026-02-10 09:22:16,692 - INFO - [Valid] [43/90] | Loss: 0.5018 | Val Acc: 81.42%
2026-02-10 09:22:16,696 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.7834 | F1: 0.7961
2026-02-10 09:22:16,696 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.8407 | F1: 0.8293
2026-02-10 09:22:16,697 - INFO - --------------------------------------------------
2026-02-10 09:22:16,697 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 09:22:18,666 - INFO - [Train] [44/90] | Loss: 0.3953 | Train Acc: 88.76%
2026-02-10 09:22:19,390 - INFO - [Valid] [44/90] | Loss: 0.5216 | Val Acc: 79.94%
2026-02-10 09:22:19,393 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-02-10 09:22:19,393 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-02-10 09:22:19,394 - INFO - --------------------------------------------------
2026-02-10 09:22:19,394 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 09:22:21,490 - INFO - [Train] [45/90] | Loss: 0.3852 | Train Acc: 90.18%
2026-02-10 09:22:22,205 - INFO - [Valid] [45/90] | Loss: 0.4914 | Val Acc: 82.01%
2026-02-10 09:22:22,209 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-02-10 09:22:22,210 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-02-10 09:22:22,211 - INFO - --------------------------------------------------
2026-02-10 09:22:22,211 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 09:22:24,268 - INFO - [Train] [46/90] | Loss: 0.3972 | Train Acc: 87.80%
2026-02-10 09:22:25,011 - INFO - [Valid] [46/90] | Loss: 0.5051 | Val Acc: 79.35%
2026-02-10 09:22:25,015 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-02-10 09:22:25,015 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-02-10 09:22:25,016 - INFO - --------------------------------------------------
2026-02-10 09:22:25,017 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 09:22:27,056 - INFO - [Train] [47/90] | Loss: 0.3965 | Train Acc: 89.73%
2026-02-10 09:22:27,747 - INFO - [Valid] [47/90] | Loss: 0.4906 | Val Acc: 81.71%
2026-02-10 09:22:27,749 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-02-10 09:22:27,749 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-02-10 09:22:27,750 - INFO - --------------------------------------------------
2026-02-10 09:22:27,750 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 09:22:29,841 - INFO - [Train] [48/90] | Loss: 0.3912 | Train Acc: 89.51%
2026-02-10 09:22:30,431 - INFO - [Valid] [48/90] | Loss: 0.4939 | Val Acc: 80.83%
2026-02-10 09:22:30,433 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-02-10 09:22:30,433 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-02-10 09:22:30,434 - INFO - --------------------------------------------------
2026-02-10 09:22:30,434 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 09:22:32,377 - INFO - [Train] [49/90] | Loss: 0.3837 | Train Acc: 89.88%
2026-02-10 09:22:33,073 - INFO - [Valid] [49/90] | Loss: 0.5094 | Val Acc: 79.94%
2026-02-10 09:22:33,076 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-02-10 09:22:33,076 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-02-10 09:22:33,077 - INFO - --------------------------------------------------
2026-02-10 09:22:33,077 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 09:22:35,251 - INFO - [Train] [50/90] | Loss: 0.3871 | Train Acc: 90.33%
2026-02-10 09:22:35,816 - INFO - [Valid] [50/90] | Loss: 0.4983 | Val Acc: 80.24%
2026-02-10 09:22:35,819 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-02-10 09:22:35,819 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-02-10 09:22:35,819 - INFO - --------------------------------------------------
2026-02-10 09:22:35,819 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 09:22:38,092 - INFO - [Train] [51/90] | Loss: 0.3804 | Train Acc: 90.40%
2026-02-10 09:22:38,541 - INFO - [Valid] [51/90] | Loss: 0.4758 | Val Acc: 82.60%
2026-02-10 09:22:38,543 - INFO - [Metrics for 'abnormal'] | Precision: 0.8224 | Recall: 0.7962 | F1: 0.8091
2026-02-10 09:22:38,543 - INFO - [Metrics for 'normal'] | Precision: 0.8289 | Recall: 0.8516 | F1: 0.8401
2026-02-10 09:22:38,545 - INFO - [Best Model Saved] (val loss: 0.4758) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:22:38,545 - INFO - --------------------------------------------------
2026-02-10 09:22:38,545 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 09:22:40,680 - INFO - [Train] [52/90] | Loss: 0.3801 | Train Acc: 90.18%
2026-02-10 09:22:41,256 - INFO - [Valid] [52/90] | Loss: 0.5167 | Val Acc: 80.53%
2026-02-10 09:22:41,258 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 09:22:41,258 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 09:22:41,259 - INFO - --------------------------------------------------
2026-02-10 09:22:41,259 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 09:22:43,484 - INFO - [Train] [53/90] | Loss: 0.3699 | Train Acc: 90.03%
2026-02-10 09:22:43,989 - INFO - [Valid] [53/90] | Loss: 0.4868 | Val Acc: 83.48%
2026-02-10 09:22:43,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.8435 | Recall: 0.7898 | F1: 0.8158
2026-02-10 09:22:43,992 - INFO - [Metrics for 'normal'] | Precision: 0.8281 | Recall: 0.8736 | F1: 0.8503
2026-02-10 09:22:43,993 - INFO - --------------------------------------------------
2026-02-10 09:22:43,993 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 09:22:46,301 - INFO - [Train] [54/90] | Loss: 0.3791 | Train Acc: 89.96%
2026-02-10 09:22:46,721 - INFO - [Valid] [54/90] | Loss: 0.4925 | Val Acc: 82.01%
2026-02-10 09:22:46,724 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-02-10 09:22:46,724 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-02-10 09:22:46,725 - INFO - --------------------------------------------------
2026-02-10 09:22:46,725 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 09:22:49,068 - INFO - [Train] [55/90] | Loss: 0.3707 | Train Acc: 90.62%
2026-02-10 09:22:49,487 - INFO - [Valid] [55/90] | Loss: 0.4781 | Val Acc: 82.60%
2026-02-10 09:22:49,490 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.8025 | F1: 0.8103
2026-02-10 09:22:49,490 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8462 | F1: 0.8392
2026-02-10 09:22:49,491 - INFO - --------------------------------------------------
2026-02-10 09:22:49,491 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 09:22:51,875 - INFO - [Train] [56/90] | Loss: 0.3656 | Train Acc: 90.85%
2026-02-10 09:22:52,286 - INFO - [Valid] [56/90] | Loss: 0.4815 | Val Acc: 81.12%
2026-02-10 09:22:52,290 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-02-10 09:22:52,290 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-02-10 09:22:52,291 - INFO - --------------------------------------------------
2026-02-10 09:22:52,292 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 09:22:54,688 - INFO - [Train] [57/90] | Loss: 0.3585 | Train Acc: 92.19%
2026-02-10 09:22:55,163 - INFO - [Valid] [57/90] | Loss: 0.4913 | Val Acc: 82.01%
2026-02-10 09:22:55,167 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-02-10 09:22:55,167 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-02-10 09:22:55,169 - INFO - --------------------------------------------------
2026-02-10 09:22:55,169 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 09:22:57,507 - INFO - [Train] [58/90] | Loss: 0.3676 | Train Acc: 91.82%
2026-02-10 09:22:58,163 - INFO - [Valid] [58/90] | Loss: 0.4838 | Val Acc: 82.30%
2026-02-10 09:22:58,167 - INFO - [Metrics for 'abnormal'] | Precision: 0.8299 | Recall: 0.7771 | F1: 0.8026
2026-02-10 09:22:58,167 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8626 | F1: 0.8396
2026-02-10 09:22:58,169 - INFO - --------------------------------------------------
2026-02-10 09:22:58,169 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 09:23:00,290 - INFO - [Train] [59/90] | Loss: 0.3570 | Train Acc: 92.26%
2026-02-10 09:23:01,070 - INFO - [Valid] [59/90] | Loss: 0.4965 | Val Acc: 81.42%
2026-02-10 09:23:01,074 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-02-10 09:23:01,074 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-02-10 09:23:01,076 - INFO - --------------------------------------------------
2026-02-10 09:23:01,076 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 09:23:03,169 - INFO - [Train] [60/90] | Loss: 0.3526 | Train Acc: 91.52%
2026-02-10 09:23:03,915 - INFO - [Valid] [60/90] | Loss: 0.4902 | Val Acc: 82.01%
2026-02-10 09:23:03,919 - INFO - [Metrics for 'abnormal'] | Precision: 0.8200 | Recall: 0.7834 | F1: 0.8013
2026-02-10 09:23:03,919 - INFO - [Metrics for 'normal'] | Precision: 0.8201 | Recall: 0.8516 | F1: 0.8356
2026-02-10 09:23:03,920 - INFO - --------------------------------------------------
2026-02-10 09:23:03,920 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 09:23:06,041 - INFO - [Train] [61/90] | Loss: 0.3564 | Train Acc: 91.00%
2026-02-10 09:23:06,781 - INFO - [Valid] [61/90] | Loss: 0.4864 | Val Acc: 81.42%
2026-02-10 09:23:06,784 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 09:23:06,784 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 09:23:06,785 - INFO - --------------------------------------------------
2026-02-10 09:23:06,785 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 09:23:08,539 - INFO - [Train] [62/90] | Loss: 0.3596 | Train Acc: 91.37%
2026-02-10 09:23:09,251 - INFO - [Valid] [62/90] | Loss: 0.4972 | Val Acc: 81.71%
2026-02-10 09:23:09,256 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-02-10 09:23:09,256 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-02-10 09:23:09,257 - INFO - --------------------------------------------------
2026-02-10 09:23:09,258 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 09:23:11,235 - INFO - [Train] [63/90] | Loss: 0.3516 | Train Acc: 91.96%
2026-02-10 09:23:11,935 - INFO - [Valid] [63/90] | Loss: 0.5001 | Val Acc: 81.71%
2026-02-10 09:23:11,939 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-02-10 09:23:11,940 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-02-10 09:23:11,941 - INFO - --------------------------------------------------
2026-02-10 09:23:11,941 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 09:23:13,995 - INFO - [Train] [64/90] | Loss: 0.3415 | Train Acc: 93.45%
2026-02-10 09:23:14,699 - INFO - [Valid] [64/90] | Loss: 0.4911 | Val Acc: 82.01%
2026-02-10 09:23:14,702 - INFO - [Metrics for 'abnormal'] | Precision: 0.8288 | Recall: 0.7707 | F1: 0.7987
2026-02-10 09:23:14,702 - INFO - [Metrics for 'normal'] | Precision: 0.8135 | Recall: 0.8626 | F1: 0.8373
2026-02-10 09:23:14,703 - INFO - --------------------------------------------------
2026-02-10 09:23:14,703 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 09:23:16,800 - INFO - [Train] [65/90] | Loss: 0.3472 | Train Acc: 93.45%
2026-02-10 09:23:17,422 - INFO - [Valid] [65/90] | Loss: 0.5025 | Val Acc: 81.71%
2026-02-10 09:23:17,425 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-02-10 09:23:17,425 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-02-10 09:23:17,426 - INFO - --------------------------------------------------
2026-02-10 09:23:17,426 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 09:23:19,651 - INFO - [Train] [66/90] | Loss: 0.3421 | Train Acc: 92.78%
2026-02-10 09:23:20,169 - INFO - [Valid] [66/90] | Loss: 0.5027 | Val Acc: 81.12%
2026-02-10 09:23:20,172 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-02-10 09:23:20,173 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-02-10 09:23:20,173 - INFO - --------------------------------------------------
2026-02-10 09:23:20,173 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 09:23:22,452 - INFO - [Train] [67/90] | Loss: 0.3441 | Train Acc: 93.08%
2026-02-10 09:23:22,878 - INFO - [Valid] [67/90] | Loss: 0.4982 | Val Acc: 81.42%
2026-02-10 09:23:22,882 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.7834 | F1: 0.7961
2026-02-10 09:23:22,882 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.8407 | F1: 0.8293
2026-02-10 09:23:22,883 - INFO - --------------------------------------------------
2026-02-10 09:23:22,883 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 09:23:25,155 - INFO - [Train] [68/90] | Loss: 0.3488 | Train Acc: 92.41%
2026-02-10 09:23:25,591 - INFO - [Valid] [68/90] | Loss: 0.4992 | Val Acc: 81.71%
2026-02-10 09:23:25,594 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-02-10 09:23:25,594 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-02-10 09:23:25,595 - INFO - --------------------------------------------------
2026-02-10 09:23:25,595 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 09:23:27,992 - INFO - [Train] [69/90] | Loss: 0.3408 | Train Acc: 92.86%
2026-02-10 09:23:28,404 - INFO - [Valid] [69/90] | Loss: 0.4945 | Val Acc: 81.42%
2026-02-10 09:23:28,408 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-02-10 09:23:28,408 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-02-10 09:23:28,409 - INFO - --------------------------------------------------
2026-02-10 09:23:28,409 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 09:23:30,886 - INFO - [Train] [70/90] | Loss: 0.3416 | Train Acc: 92.71%
2026-02-10 09:23:31,360 - INFO - [Valid] [70/90] | Loss: 0.4975 | Val Acc: 81.42%
2026-02-10 09:23:31,364 - INFO - [Metrics for 'abnormal'] | Precision: 0.8133 | Recall: 0.7771 | F1: 0.7948
2026-02-10 09:23:31,364 - INFO - [Metrics for 'normal'] | Precision: 0.8148 | Recall: 0.8462 | F1: 0.8302
2026-02-10 09:23:31,365 - INFO - --------------------------------------------------
2026-02-10 09:23:31,366 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 09:23:33,622 - INFO - [Train] [71/90] | Loss: 0.3433 | Train Acc: 92.71%
2026-02-10 09:23:34,114 - INFO - [Valid] [71/90] | Loss: 0.4989 | Val Acc: 80.83%
2026-02-10 09:23:34,118 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-02-10 09:23:34,118 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-02-10 09:23:34,120 - INFO - --------------------------------------------------
2026-02-10 09:23:34,120 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 09:23:36,382 - INFO - [Train] [72/90] | Loss: 0.3436 | Train Acc: 92.56%
2026-02-10 09:23:36,836 - INFO - [Valid] [72/90] | Loss: 0.4972 | Val Acc: 81.12%
2026-02-10 09:23:36,840 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-02-10 09:23:36,840 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-02-10 09:23:36,841 - INFO - --------------------------------------------------
2026-02-10 09:23:36,842 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 09:23:39,170 - INFO - [Train] [73/90] | Loss: 0.3312 | Train Acc: 93.68%
2026-02-10 09:23:39,717 - INFO - [Valid] [73/90] | Loss: 0.4911 | Val Acc: 81.42%
2026-02-10 09:23:39,722 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 09:23:39,722 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 09:23:39,723 - INFO - --------------------------------------------------
2026-02-10 09:23:39,723 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 09:23:41,868 - INFO - [Train] [74/90] | Loss: 0.3380 | Train Acc: 93.38%
2026-02-10 09:23:42,440 - INFO - [Valid] [74/90] | Loss: 0.5008 | Val Acc: 80.53%
2026-02-10 09:23:42,444 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-02-10 09:23:42,444 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-02-10 09:23:42,446 - INFO - --------------------------------------------------
2026-02-10 09:23:42,446 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 09:23:44,737 - INFO - [Train] [75/90] | Loss: 0.3340 | Train Acc: 93.08%
2026-02-10 09:23:45,411 - INFO - [Valid] [75/90] | Loss: 0.4949 | Val Acc: 81.12%
2026-02-10 09:23:45,414 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 09:23:45,414 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 09:23:45,415 - INFO - --------------------------------------------------
2026-02-10 09:23:45,415 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 09:23:47,490 - INFO - [Train] [76/90] | Loss: 0.3328 | Train Acc: 93.30%
2026-02-10 09:23:48,209 - INFO - [Valid] [76/90] | Loss: 0.4958 | Val Acc: 81.42%
2026-02-10 09:23:48,213 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 09:23:48,213 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 09:23:48,215 - INFO - --------------------------------------------------
2026-02-10 09:23:48,215 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 09:23:50,145 - INFO - [Train] [77/90] | Loss: 0.3303 | Train Acc: 93.60%
2026-02-10 09:23:50,899 - INFO - [Valid] [77/90] | Loss: 0.4968 | Val Acc: 81.42%
2026-02-10 09:23:50,902 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-02-10 09:23:50,902 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-02-10 09:23:50,903 - INFO - --------------------------------------------------
2026-02-10 09:23:50,904 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 09:23:52,823 - INFO - [Train] [78/90] | Loss: 0.3387 | Train Acc: 93.90%
2026-02-10 09:23:53,524 - INFO - [Valid] [78/90] | Loss: 0.4920 | Val Acc: 81.12%
2026-02-10 09:23:53,528 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-02-10 09:23:53,528 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-02-10 09:23:53,530 - INFO - --------------------------------------------------
2026-02-10 09:23:53,530 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 09:23:55,532 - INFO - [Train] [79/90] | Loss: 0.3317 | Train Acc: 93.97%
2026-02-10 09:23:56,284 - INFO - [Valid] [79/90] | Loss: 0.4974 | Val Acc: 81.42%
2026-02-10 09:23:56,289 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-02-10 09:23:56,289 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-02-10 09:23:56,290 - INFO - --------------------------------------------------
2026-02-10 09:23:56,290 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 09:23:58,510 - INFO - [Train] [80/90] | Loss: 0.3278 | Train Acc: 93.97%
2026-02-10 09:23:59,204 - INFO - [Valid] [80/90] | Loss: 0.4959 | Val Acc: 80.83%
2026-02-10 09:23:59,207 - INFO - [Metrics for 'abnormal'] | Precision: 0.8026 | Recall: 0.7771 | F1: 0.7896
2026-02-10 09:23:59,207 - INFO - [Metrics for 'normal'] | Precision: 0.8128 | Recall: 0.8352 | F1: 0.8238
2026-02-10 09:23:59,208 - INFO - --------------------------------------------------
2026-02-10 09:23:59,208 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 09:24:01,252 - INFO - [Train] [81/90] | Loss: 0.3410 | Train Acc: 92.63%
2026-02-10 09:24:01,979 - INFO - [Valid] [81/90] | Loss: 0.4987 | Val Acc: 81.42%
2026-02-10 09:24:01,983 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-02-10 09:24:01,983 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-02-10 09:24:01,985 - INFO - --------------------------------------------------
2026-02-10 09:24:01,985 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 09:24:04,114 - INFO - [Train] [82/90] | Loss: 0.3290 | Train Acc: 93.45%
2026-02-10 09:24:04,829 - INFO - [Valid] [82/90] | Loss: 0.4919 | Val Acc: 81.42%
2026-02-10 09:24:04,833 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.7834 | F1: 0.7961
2026-02-10 09:24:04,833 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.8407 | F1: 0.8293
2026-02-10 09:24:04,834 - INFO - --------------------------------------------------
2026-02-10 09:24:04,834 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 09:24:06,844 - INFO - [Train] [83/90] | Loss: 0.3241 | Train Acc: 94.12%
2026-02-10 09:24:07,553 - INFO - [Valid] [83/90] | Loss: 0.4996 | Val Acc: 80.24%
2026-02-10 09:24:07,557 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-02-10 09:24:07,557 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-02-10 09:24:07,558 - INFO - --------------------------------------------------
2026-02-10 09:24:07,558 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 09:24:09,764 - INFO - [Train] [84/90] | Loss: 0.3249 | Train Acc: 94.49%
2026-02-10 09:24:10,418 - INFO - [Valid] [84/90] | Loss: 0.4991 | Val Acc: 80.53%
2026-02-10 09:24:10,422 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-02-10 09:24:10,422 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-02-10 09:24:10,424 - INFO - --------------------------------------------------
2026-02-10 09:24:10,424 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 09:24:12,337 - INFO - [Train] [85/90] | Loss: 0.3287 | Train Acc: 93.90%
2026-02-10 09:24:13,044 - INFO - [Valid] [85/90] | Loss: 0.4959 | Val Acc: 80.53%
2026-02-10 09:24:13,050 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 09:24:13,050 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 09:24:13,051 - INFO - --------------------------------------------------
2026-02-10 09:24:13,052 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 09:24:15,213 - INFO - [Train] [86/90] | Loss: 0.3320 | Train Acc: 93.90%
2026-02-10 09:24:15,941 - INFO - [Valid] [86/90] | Loss: 0.4924 | Val Acc: 80.83%
2026-02-10 09:24:15,945 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-02-10 09:24:15,946 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-02-10 09:24:15,947 - INFO - --------------------------------------------------
2026-02-10 09:24:15,947 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 09:24:18,103 - INFO - [Train] [87/90] | Loss: 0.3163 | Train Acc: 94.49%
2026-02-10 09:24:18,772 - INFO - [Valid] [87/90] | Loss: 0.4896 | Val Acc: 81.12%
2026-02-10 09:24:18,776 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-02-10 09:24:18,777 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-02-10 09:24:18,778 - INFO - --------------------------------------------------
2026-02-10 09:24:18,778 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 09:24:20,906 - INFO - [Train] [88/90] | Loss: 0.3227 | Train Acc: 94.57%
2026-02-10 09:24:21,611 - INFO - [Valid] [88/90] | Loss: 0.4971 | Val Acc: 81.42%
2026-02-10 09:24:21,614 - INFO - [Metrics for 'abnormal'] | Precision: 0.8133 | Recall: 0.7771 | F1: 0.7948
2026-02-10 09:24:21,614 - INFO - [Metrics for 'normal'] | Precision: 0.8148 | Recall: 0.8462 | F1: 0.8302
2026-02-10 09:24:21,614 - INFO - --------------------------------------------------
2026-02-10 09:24:21,615 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 09:24:23,708 - INFO - [Train] [89/90] | Loss: 0.3255 | Train Acc: 94.27%
2026-02-10 09:24:24,417 - INFO - [Valid] [89/90] | Loss: 0.4932 | Val Acc: 80.24%
2026-02-10 09:24:24,421 - INFO - [Metrics for 'abnormal'] | Precision: 0.7812 | Recall: 0.7962 | F1: 0.7886
2026-02-10 09:24:24,421 - INFO - [Metrics for 'normal'] | Precision: 0.8212 | Recall: 0.8077 | F1: 0.8144
2026-02-10 09:24:24,423 - INFO - --------------------------------------------------
2026-02-10 09:24:24,423 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 09:24:26,611 - INFO - [Train] [90/90] | Loss: 0.3273 | Train Acc: 94.12%
2026-02-10 09:24:27,291 - INFO - [Valid] [90/90] | Loss: 0.4918 | Val Acc: 81.42%
2026-02-10 09:24:27,296 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 09:24:27,296 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 09:24:27,297 - INFO - ==================================================
2026-02-10 09:24:27,297 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 09:24:27,297 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 09:24:27,297 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:24:27,348 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 09:24:27,349 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:24:27,349 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:24:27,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 09:24:27,862 - INFO - ==================================================
2026-02-10 09:24:27,864 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/best_model.pth'
2026-02-10 09:24:27,864 - INFO - ==================================================
2026-02-10 09:24:27,864 - INFO - Test 모드를 시작합니다.
2026-02-10 09:24:27,926 - INFO - 연산량 (MACs): 0.0741 GMACs per sample
2026-02-10 09:24:27,926 - INFO - 연산량 (FLOPs): 0.1481 GFLOPs per sample
2026-02-10 09:24:27,926 - INFO - ==================================================
2026-02-10 09:24:27,926 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 09:24:28,333 - INFO - 샘플 당 평균 Forward Pass 시간: 0.12ms (std: 0.05ms), FPS: 8391.15 (std: 858.63) (1개 샘플 x 100회 반복)
2026-02-10 09:24:28,334 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 159.82 MB
2026-02-10 09:24:28,334 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 09:24:29,555 - INFO - [Test] Loss: 0.4050 | Test Acc: 82.60%
2026-02-10 09:24:29,560 - INFO - [Metrics for 'abnormal'] | Precision: 0.8224 | Recall: 0.7962 | F1: 0.8091
2026-02-10 09:24:29,561 - INFO - [Metrics for 'normal'] | Precision: 0.8289 | Recall: 0.8516 | F1: 0.8401
2026-02-10 09:24:29,731 - INFO - ==================================================
2026-02-10 09:24:29,731 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/confusion_matrix_20260210_091942.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/confusion_matrix_20260210_091942.pdf'
2026-02-10 09:24:29,731 - INFO - ==================================================
2026-02-10 09:24:29,731 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 09:24:29,754 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/model_fp32_20260210_091942.onnx'에 저장되었습니다. (크기: 0.18 MB)
2026-02-10 09:24:29,940 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 9.38 MB
2026-02-10 09:24:29,940 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 09:24:30,355 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 1.71ms (std: 3.46ms)
2026-02-10 09:24:30,355 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 1751.59 FPS (std: 678.74) (1개 샘플 x 100회 반복)
2026-02-10 09:24:30,355 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 4.88 MB
2026-02-10 09:24:30,355 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 14.62 MB
2026-02-10 09:24:31,304 - INFO - [Test (ONNX)] | Test Acc (ONNX): 82.60%
2026-02-10 09:24:31,313 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8224 | Recall: 0.7962 | F1: 0.8091
2026-02-10 09:24:31,313 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8289 | Recall: 0.8516 | F1: 0.8401
2026-02-10 09:24:31,463 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/val_acc.pdf'
2026-02-10 09:24:31,606 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/train_val_acc.pdf'
2026-02-10 09:24:31,729 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/F1_normal.pdf'
2026-02-10 09:24:31,867 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/val_loss.pdf'
2026-02-10 09:24:31,987 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/learning_rate.pdf'
2026-02-10 09:24:33,170 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260210_091942/graph_20260210_091942/compile.pdf'
