2026-02-10 08:52:25,543 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/log_20260210_085225.log'에 저장됩니다.
2026-02-10 08:52:25,545 - INFO - ==================================================
2026-02-10 08:52:25,545 - INFO - config.yaml:
2026-02-10 08:52:25,545 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: mobilenet_v4_s
  use_fpgm_pruning: true
  pruning_params_target: 0.047585

2026-02-10 08:52:25,545 - INFO - ==================================================
2026-02-10 08:52:25,690 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 08:52:25,690 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 08:52:25,690 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 08:52:25,704 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 08:52:25,704 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 08:52:25,704 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 08:52:25,704 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 08:52:25,818 - INFO - ==================================================
2026-02-10 08:52:25,819 - INFO - 모델 파라미터 수:
2026-02-10 08:52:25,819 - INFO -   - 총 파라미터: 2,495,586 개
2026-02-10 08:52:25,819 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-02-10 08:52:25,819 - INFO - ================================================================================
2026-02-10 08:52:25,819 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 08:52:25,819 - INFO - ================================================================================
2026-02-10 08:52:25,819 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 08:52:25,819 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 08:52:25,819 - INFO - ==================================================
2026-02-10 08:52:25,819 - INFO - train 모드를 시작합니다.
2026-02-10 08:52:25,819 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 08:52:25,819 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 08:52:25,819 - INFO - --------------------------------------------------
2026-02-10 08:52:25,819 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 08:52:27,630 - INFO - [Train] [1/10] | Loss: 2.8920 | Train Acc: 65.33%
2026-02-10 08:52:28,230 - INFO - [Valid] [1/10] | Loss: 1.5233 | Val Acc: 63.72%
2026-02-10 08:52:28,233 - INFO - [Metrics for 'abnormal'] | Precision: 0.8148 | Recall: 0.2803 | F1: 0.4171
2026-02-10 08:52:28,233 - INFO - [Metrics for 'normal'] | Precision: 0.6035 | Recall: 0.9451 | F1: 0.7366
2026-02-10 08:52:28,247 - INFO - [Best Model Saved] (val loss: 1.5233) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:28,247 - INFO - --------------------------------------------------
2026-02-10 08:52:28,248 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 08:52:29,741 - INFO - [Train] [2/10] | Loss: 0.7492 | Train Acc: 70.46%
2026-02-10 08:52:30,141 - INFO - [Valid] [2/10] | Loss: 1.1084 | Val Acc: 58.70%
2026-02-10 08:52:30,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.5300 | Recall: 0.9554 | F1: 0.6818
2026-02-10 08:52:30,143 - INFO - [Metrics for 'normal'] | Precision: 0.8750 | Recall: 0.2692 | F1: 0.4118
2026-02-10 08:52:30,158 - INFO - [Best Model Saved] (val loss: 1.1084) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:30,158 - INFO - --------------------------------------------------
2026-02-10 08:52:30,158 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 08:52:31,654 - INFO - [Train] [3/10] | Loss: 0.6644 | Train Acc: 73.66%
2026-02-10 08:52:32,047 - INFO - [Valid] [3/10] | Loss: 0.8023 | Val Acc: 64.90%
2026-02-10 08:52:32,049 - INFO - [Metrics for 'abnormal'] | Precision: 0.5990 | Recall: 0.7325 | F1: 0.6590
2026-02-10 08:52:32,049 - INFO - [Metrics for 'normal'] | Precision: 0.7143 | Recall: 0.5769 | F1: 0.6383
2026-02-10 08:52:32,063 - INFO - [Best Model Saved] (val loss: 0.8023) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:32,063 - INFO - --------------------------------------------------
2026-02-10 08:52:32,063 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 08:52:33,516 - INFO - [Train] [4/10] | Loss: 0.6000 | Train Acc: 75.15%
2026-02-10 08:52:33,900 - INFO - [Valid] [4/10] | Loss: 0.6333 | Val Acc: 75.22%
2026-02-10 08:52:33,903 - INFO - [Metrics for 'abnormal'] | Precision: 0.7517 | Recall: 0.6943 | F1: 0.7219
2026-02-10 08:52:33,903 - INFO - [Metrics for 'normal'] | Precision: 0.7526 | Recall: 0.8022 | F1: 0.7766
2026-02-10 08:52:33,919 - INFO - [Best Model Saved] (val loss: 0.6333) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:33,919 - INFO - --------------------------------------------------
2026-02-10 08:52:33,919 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 08:52:35,356 - INFO - [Train] [5/10] | Loss: 0.5782 | Train Acc: 75.52%
2026-02-10 08:52:35,749 - INFO - [Valid] [5/10] | Loss: 1.1989 | Val Acc: 49.26%
2026-02-10 08:52:35,752 - INFO - [Metrics for 'abnormal'] | Precision: 0.4740 | Recall: 0.8726 | F1: 0.6143
2026-02-10 08:52:35,752 - INFO - [Metrics for 'normal'] | Precision: 0.6000 | Recall: 0.1648 | F1: 0.2586
2026-02-10 08:52:35,753 - INFO - --------------------------------------------------
2026-02-10 08:52:35,753 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 08:52:37,202 - INFO - [Train] [6/10] | Loss: 0.5606 | Train Acc: 75.67%
2026-02-10 08:52:37,605 - INFO - [Valid] [6/10] | Loss: 0.6515 | Val Acc: 76.70%
2026-02-10 08:52:37,607 - INFO - [Metrics for 'abnormal'] | Precision: 0.6970 | Recall: 0.8790 | F1: 0.7775
2026-02-10 08:52:37,607 - INFO - [Metrics for 'normal'] | Precision: 0.8652 | Recall: 0.6703 | F1: 0.7554
2026-02-10 08:52:37,608 - INFO - --------------------------------------------------
2026-02-10 08:52:37,608 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 08:52:39,024 - INFO - [Train] [7/10] | Loss: 0.5206 | Train Acc: 79.54%
2026-02-10 08:52:39,426 - INFO - [Valid] [7/10] | Loss: 0.5752 | Val Acc: 77.29%
2026-02-10 08:52:39,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.8774 | Recall: 0.5924 | F1: 0.7072
2026-02-10 08:52:39,429 - INFO - [Metrics for 'normal'] | Precision: 0.7253 | Recall: 0.9286 | F1: 0.8145
2026-02-10 08:52:39,444 - INFO - [Best Model Saved] (val loss: 0.5752) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:39,444 - INFO - --------------------------------------------------
2026-02-10 08:52:39,444 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 08:52:40,948 - INFO - [Train] [8/10] | Loss: 0.4972 | Train Acc: 81.25%
2026-02-10 08:52:41,348 - INFO - [Valid] [8/10] | Loss: 0.5361 | Val Acc: 79.35%
2026-02-10 08:52:41,350 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-02-10 08:52:41,350 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-02-10 08:52:41,366 - INFO - [Best Model Saved] (val loss: 0.5361) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:41,366 - INFO - --------------------------------------------------
2026-02-10 08:52:41,367 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 08:52:42,896 - INFO - [Train] [9/10] | Loss: 0.4740 | Train Acc: 82.59%
2026-02-10 08:52:43,302 - INFO - [Valid] [9/10] | Loss: 0.5449 | Val Acc: 77.29%
2026-02-10 08:52:43,305 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.7643 | F1: 0.7571
2026-02-10 08:52:43,305 - INFO - [Metrics for 'normal'] | Precision: 0.7933 | Recall: 0.7802 | F1: 0.7867
2026-02-10 08:52:43,306 - INFO - --------------------------------------------------
2026-02-10 08:52:43,306 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 08:52:44,815 - INFO - [Train] [10/10] | Loss: 0.4664 | Train Acc: 83.56%
2026-02-10 08:52:45,223 - INFO - [Valid] [10/10] | Loss: 0.5347 | Val Acc: 79.06%
2026-02-10 08:52:45,225 - INFO - [Metrics for 'abnormal'] | Precision: 0.7529 | Recall: 0.8153 | F1: 0.7829
2026-02-10 08:52:45,225 - INFO - [Metrics for 'normal'] | Precision: 0.8284 | Recall: 0.7692 | F1: 0.7977
2026-02-10 08:52:45,242 - INFO - [Best Model Saved] (val loss: 0.5347) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:45,243 - INFO - ================================================================================
2026-02-10 08:52:45,243 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 08:52:45,243 - INFO - ================================================================================
2026-02-10 08:52:45,267 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'을(를) 불러왔습니다.
2026-02-10 08:52:45,267 - INFO - ================================================================================
2026-02-10 08:52:45,267 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 08:52:45,267 - INFO - 원본 모델 파라미터: 2.4956M
2026-02-10 08:52:45,292 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:45,292 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:45,426 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 08:52:45,426 - INFO - ==================================================
2026-02-10 08:52:45,427 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.6554M (감소율: 73.74%)
2026-02-10 08:52:45,447 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:45,447 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:45,505 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 08:52:45,505 - INFO - ==================================================
2026-02-10 08:52:45,506 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1807M (감소율: 92.76%)
2026-02-10 08:52:45,529 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:45,529 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:45,581 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 08:52:45,581 - INFO - ==================================================
2026-02-10 08:52:45,582 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0548M (감소율: 97.80%)
2026-02-10 08:52:45,599 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:45,599 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:45,672 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 08:52:45,672 - INFO - ==================================================
2026-02-10 08:52:45,673 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0186M (감소율: 99.25%)
2026-02-10 08:52:45,694 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:45,695 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,013 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,013 - INFO - ==================================================
2026-02-10 08:52:46,015 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0343M (감소율: 98.63%)
2026-02-10 08:52:46,031 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,031 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,122 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.88171875)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,123 - INFO - ==================================================
2026-02-10 08:52:46,124 - INFO -   [탐색  6] 희소도: 0.8817 -> 파라미터: 0.0441M (감소율: 98.23%)
2026-02-10 08:52:46,139 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,140 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,228 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.873984375)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,228 - INFO - ==================================================
2026-02-10 08:52:46,229 - INFO -   [탐색  7] 희소도: 0.8740 -> 파라미터: 0.0497M (감소율: 98.01%)
2026-02-10 08:52:46,246 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,247 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,336 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8778515625000001)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,336 - INFO - ==================================================
2026-02-10 08:52:46,337 - INFO -   [탐색  8] 희소도: 0.8779 -> 파라미터: 0.0461M (감소율: 98.15%)
2026-02-10 08:52:46,353 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,353 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,447 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.87591796875)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,447 - INFO - ==================================================
2026-02-10 08:52:46,449 - INFO -   [탐색  9] 희소도: 0.8759 -> 파라미터: 0.0470M (감소율: 98.12%)
2026-02-10 08:52:46,466 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,466 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,562 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.874951171875)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,563 - INFO - ==================================================
2026-02-10 08:52:46,564 - INFO -   [탐색 10] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:46,581 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,581 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,672 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8754345703125)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,672 - INFO - ==================================================
2026-02-10 08:52:46,673 - INFO -   [탐색 11] 희소도: 0.8754 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:46,687 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,687 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,739 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.87519287109375)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,739 - INFO - ==================================================
2026-02-10 08:52:46,740 - INFO -   [탐색 12] 희소도: 0.8752 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:46,753 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,753 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,848 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875072021484375)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,849 - INFO - ==================================================
2026-02-10 08:52:46,849 - INFO -   [탐색 13] 희소도: 0.8751 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:46,860 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,861 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,899 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750115966796875)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,899 - INFO - ==================================================
2026-02-10 08:52:46,899 - INFO -   [탐색 14] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:46,911 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,911 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:46,960 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749813842773437)에 맞춰 변경되었습니다.
2026-02-10 08:52:46,960 - INFO - ==================================================
2026-02-10 08:52:46,961 - INFO -   [탐색 15] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:46,972 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:46,972 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,009 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749964904785157)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,009 - INFO - ==================================================
2026-02-10 08:52:47,009 - INFO -   [탐색 16] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,020 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,020 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,056 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750040435791016)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,056 - INFO - ==================================================
2026-02-10 08:52:47,057 - INFO -   [탐색 17] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:47,068 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,068 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,104 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750002670288086)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,104 - INFO - ==================================================
2026-02-10 08:52:47,105 - INFO -   [탐색 18] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:47,115 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,115 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,443 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749983787536622)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,444 - INFO - ==================================================
2026-02-10 08:52:47,445 - INFO -   [탐색 19] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,456 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,457 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,496 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749993228912354)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,496 - INFO - ==================================================
2026-02-10 08:52:47,497 - INFO -   [탐색 20] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,511 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,511 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,560 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.874999794960022)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,560 - INFO - ==================================================
2026-02-10 08:52:47,561 - INFO -   [탐색 21] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,571 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,571 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,610 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000309944153)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,610 - INFO - ==================================================
2026-02-10 08:52:47,611 - INFO -   [탐색 22] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:47,624 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,624 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,666 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999129772186)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,666 - INFO - ==================================================
2026-02-10 08:52:47,667 - INFO -   [탐색 23] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,680 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,680 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,723 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999719858169)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,724 - INFO - ==================================================
2026-02-10 08:52:47,725 - INFO -   [탐색 24] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,738 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,738 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,781 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875000001490116)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,781 - INFO - ==================================================
2026-02-10 08:52:47,783 - INFO -   [탐색 25] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:47,800 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,801 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,868 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999867379665)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,869 - INFO - ==================================================
2026-02-10 08:52:47,870 - INFO -   [탐색 26] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,884 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,885 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:47,975 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999941140413)에 맞춰 변경되었습니다.
2026-02-10 08:52:47,975 - INFO - ==================================================
2026-02-10 08:52:47,976 - INFO -   [탐색 27] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:47,990 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:47,990 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:48,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999978020786)에 맞춰 변경되었습니다.
2026-02-10 08:52:48,059 - INFO - ==================================================
2026-02-10 08:52:48,061 - INFO -   [탐색 28] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:48,083 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:48,083 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:48,182 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999996460973)에 맞춰 변경되었습니다.
2026-02-10 08:52:48,182 - INFO - ==================================================
2026-02-10 08:52:48,183 - INFO -   [탐색 29] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:48,203 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:48,203 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:48,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000005681067)에 맞춰 변경되었습니다.
2026-02-10 08:52:48,307 - INFO - ==================================================
2026-02-10 08:52:48,309 - INFO -   [탐색 30] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:48,329 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:48,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:48,811 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875000000107102)에 맞춰 변경되었습니다.
2026-02-10 08:52:48,811 - INFO - ==================================================
2026-02-10 08:52:48,812 - INFO -   [탐색 31] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:48,825 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:48,826 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:48,870 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999998765996)에 맞춰 변경되었습니다.
2026-02-10 08:52:48,870 - INFO - ==================================================
2026-02-10 08:52:48,870 - INFO -   [탐색 32] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:48,882 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:48,882 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:48,934 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999918507)에 맞춰 변경되었습니다.
2026-02-10 08:52:48,934 - INFO - ==================================================
2026-02-10 08:52:48,935 - INFO -   [탐색 33] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:48,946 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:48,946 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,016 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000494764)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,016 - INFO - ==================================================
2026-02-10 08:52:49,016 - INFO -   [탐색 34] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,027 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,027 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,063 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000206636)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,063 - INFO - ==================================================
2026-02-10 08:52:49,064 - INFO -   [탐색 35] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,074 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,074 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,115 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000062572)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,115 - INFO - ==================================================
2026-02-10 08:52:49,116 - INFO -   [탐색 36] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,129 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,129 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,171 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.874999999999054)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,172 - INFO - ==================================================
2026-02-10 08:52:49,173 - INFO -   [탐색 37] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:49,187 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,187 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,231 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000026557)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,231 - INFO - ==================================================
2026-02-10 08:52:49,232 - INFO -   [탐색 38] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,246 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,246 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,291 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000008549)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,291 - INFO - ==================================================
2026-02-10 08:52:49,293 - INFO -   [탐색 39] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,308 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,308 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,381 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999545)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,381 - INFO - ==================================================
2026-02-10 08:52:49,382 - INFO -   [탐색 40] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:49,394 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,394 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,432 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000004047)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,432 - INFO - ==================================================
2026-02-10 08:52:49,433 - INFO -   [탐색 41] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,445 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,445 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,733 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000001796)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,734 - INFO - ==================================================
2026-02-10 08:52:49,735 - INFO -   [탐색 42] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,751 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,751 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,820 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000671)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,820 - INFO - ==================================================
2026-02-10 08:52:49,821 - INFO -   [탐색 43] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,835 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,835 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:49,927 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000108)에 맞춰 변경되었습니다.
2026-02-10 08:52:49,927 - INFO - ==================================================
2026-02-10 08:52:49,928 - INFO -   [탐색 44] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:49,944 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:49,945 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,003 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999827)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,003 - INFO - ==================================================
2026-02-10 08:52:50,004 - INFO -   [탐색 45] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:50,019 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,019 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,071 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999967)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,072 - INFO - ==================================================
2026-02-10 08:52:50,073 - INFO -   [탐색 46] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:50,089 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,089 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,197 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000038)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,197 - INFO - ==================================================
2026-02-10 08:52:50,199 - INFO -   [탐색 47] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:50,221 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,221 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,296 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000002)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,296 - INFO - ==================================================
2026-02-10 08:52:50,297 - INFO -   [탐색 48] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:50,321 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,321 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,441 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999984)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,442 - INFO - ==================================================
2026-02-10 08:52:50,443 - INFO -   [탐색 49] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:50,463 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,463 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,544 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999993)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,544 - INFO - ==================================================
2026-02-10 08:52:50,546 - INFO -   [탐색 50] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:50,566 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,566 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,667 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999998)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,667 - INFO - ==================================================
2026-02-10 08:52:50,668 - INFO -   [탐색 51] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:50,684 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,685 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,770 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,771 - INFO - ==================================================
2026-02-10 08:52:50,771 - INFO -   [탐색 52] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:50,784 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,784 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:50,824 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000001)에 맞춰 변경되었습니다.
2026-02-10 08:52:50,825 - INFO - ==================================================
2026-02-10 08:52:50,826 - INFO -   [탐색 53] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 08:52:50,838 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:50,838 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,133 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,133 - INFO - ==================================================
2026-02-10 08:52:51,135 - INFO -   [탐색 54] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,156 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,156 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,227 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,228 - INFO - ==================================================
2026-02-10 08:52:51,229 - INFO -   [탐색 55] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,252 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,252 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,309 - INFO - ==================================================
2026-02-10 08:52:51,310 - INFO -   [탐색 56] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,322 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,322 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,361 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,361 - INFO - ==================================================
2026-02-10 08:52:51,362 - INFO -   [탐색 57] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,374 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,417 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,417 - INFO - ==================================================
2026-02-10 08:52:51,418 - INFO -   [탐색 58] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,429 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,429 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,468 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,469 - INFO - ==================================================
2026-02-10 08:52:51,470 - INFO -   [탐색 59] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,483 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,483 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,525 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,525 - INFO - ==================================================
2026-02-10 08:52:51,526 - INFO -   [탐색 60] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,540 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,540 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,582 - INFO - ==================================================
2026-02-10 08:52:51,583 - INFO -   [탐색 61] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,596 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,597 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,640 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,640 - INFO - ==================================================
2026-02-10 08:52:51,641 - INFO -   [탐색 62] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,661 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,661 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,707 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,707 - INFO - ==================================================
2026-02-10 08:52:51,709 - INFO -   [탐색 63] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,728 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,728 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,822 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,822 - INFO - ==================================================
2026-02-10 08:52:51,823 - INFO -   [탐색 64] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,837 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,837 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,904 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,904 - INFO - ==================================================
2026-02-10 08:52:51,906 - INFO -   [탐색 65] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:51,921 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:51,921 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:51,969 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:51,969 - INFO - ==================================================
2026-02-10 08:52:51,970 - INFO -   [탐색 66] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,324 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,324 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,439 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,439 - INFO - ==================================================
2026-02-10 08:52:52,441 - INFO -   [탐색 67] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,462 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,462 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,562 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,563 - INFO - ==================================================
2026-02-10 08:52:52,564 - INFO -   [탐색 68] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,585 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,585 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,685 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,685 - INFO - ==================================================
2026-02-10 08:52:52,686 - INFO -   [탐색 69] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,699 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,699 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,750 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,750 - INFO - ==================================================
2026-02-10 08:52:52,751 - INFO -   [탐색 70] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,763 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,764 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,854 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,854 - INFO - ==================================================
2026-02-10 08:52:52,855 - INFO -   [탐색 71] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,865 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,866 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,901 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,902 - INFO - ==================================================
2026-02-10 08:52:52,902 - INFO -   [탐색 72] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,913 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,913 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:52,962 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:52,962 - INFO - ==================================================
2026-02-10 08:52:52,964 - INFO -   [탐색 73] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:52,977 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:52,977 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,021 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,021 - INFO - ==================================================
2026-02-10 08:52:53,022 - INFO -   [탐색 74] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,036 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,036 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,087 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,087 - INFO - ==================================================
2026-02-10 08:52:53,088 - INFO -   [탐색 75] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,107 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,108 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,175 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,175 - INFO - ==================================================
2026-02-10 08:52:53,176 - INFO -   [탐색 76] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,191 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,191 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,240 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,240 - INFO - ==================================================
2026-02-10 08:52:53,241 - INFO -   [탐색 77] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,253 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,253 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,292 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,292 - INFO - ==================================================
2026-02-10 08:52:53,293 - INFO -   [탐색 78] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,304 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,603 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,604 - INFO - ==================================================
2026-02-10 08:52:53,606 - INFO -   [탐색 79] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,624 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,624 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,682 - INFO - ==================================================
2026-02-10 08:52:53,683 - INFO -   [탐색 80] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,697 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,697 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,794 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,794 - INFO - ==================================================
2026-02-10 08:52:53,795 - INFO -   [탐색 81] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,809 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,810 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,873 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,873 - INFO - ==================================================
2026-02-10 08:52:53,875 - INFO -   [탐색 82] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,894 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,894 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:53,957 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:53,957 - INFO - ==================================================
2026-02-10 08:52:53,959 - INFO -   [탐색 83] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:53,975 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:53,975 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,073 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,073 - INFO - ==================================================
2026-02-10 08:52:54,074 - INFO -   [탐색 84] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,091 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,091 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,169 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,169 - INFO - ==================================================
2026-02-10 08:52:54,171 - INFO -   [탐색 85] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,191 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,191 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,305 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,306 - INFO - ==================================================
2026-02-10 08:52:54,307 - INFO -   [탐색 86] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,327 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,327 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,427 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,428 - INFO - ==================================================
2026-02-10 08:52:54,429 - INFO -   [탐색 87] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,444 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,444 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,515 - INFO - ==================================================
2026-02-10 08:52:54,517 - INFO -   [탐색 88] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,535 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,535 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,636 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,637 - INFO - ==================================================
2026-02-10 08:52:54,637 - INFO -   [탐색 89] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,653 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,654 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,767 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,767 - INFO - ==================================================
2026-02-10 08:52:54,768 - INFO -   [탐색 90] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,779 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,779 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,816 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,816 - INFO - ==================================================
2026-02-10 08:52:54,817 - INFO -   [탐색 91] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,828 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,828 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:54,882 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:54,882 - INFO - ==================================================
2026-02-10 08:52:54,883 - INFO -   [탐색 92] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:54,894 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:54,895 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,214 - INFO - ==================================================
2026-02-10 08:52:55,215 - INFO -   [탐색 93] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,226 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,226 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,266 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,266 - INFO - ==================================================
2026-02-10 08:52:55,267 - INFO -   [탐색 94] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,279 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,279 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,318 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,318 - INFO - ==================================================
2026-02-10 08:52:55,319 - INFO -   [탐색 95] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,333 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,333 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,376 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,376 - INFO - ==================================================
2026-02-10 08:52:55,377 - INFO -   [탐색 96] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,393 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,394 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,460 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,460 - INFO - ==================================================
2026-02-10 08:52:55,462 - INFO -   [탐색 97] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,480 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,481 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,565 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,565 - INFO - ==================================================
2026-02-10 08:52:55,567 - INFO -   [탐색 98] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,590 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,590 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,707 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,707 - INFO - ==================================================
2026-02-10 08:52:55,708 - INFO -   [탐색 99] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,730 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,730 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:55,809 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 08:52:55,809 - INFO - ==================================================
2026-02-10 08:52:55,811 - INFO -   [탐색 100] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 08:52:55,811 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.8754 입니다.
2026-02-10 08:52:55,811 - INFO - ================================================================================
2026-02-10 08:52:55,813 - INFO - 계산된 Pruning 정보(희소도: 0.8754)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/pruning_info.yaml'에 저장했습니다.
2026-02-10 08:52:55,840 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 08:52:55,895 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 08:52:55,895 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:52:56,019 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8754345703125)에 맞춰 변경되었습니다.
2026-02-10 08:52:56,019 - INFO - ==================================================
2026-02-10 08:52:56,020 - INFO - ==================================================
2026-02-10 08:52:56,020 - INFO - 모델 파라미터 수:
2026-02-10 08:52:56,020 - INFO -   - 총 파라미터: 47,152 개
2026-02-10 08:52:56,020 - INFO -   - 학습 가능한 파라미터: 47,152 개
2026-02-10 08:52:56,053 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 08:52:56,103 - INFO - FLOPs가 0.3853 GFLOPs에서 0.0095 GFLOPs로 감소했습니다 (감소율: 97.52%).
2026-02-10 08:52:56,104 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 08:52:56,104 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 08:52:56,105 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 08:52:56,105 - INFO - ==================================================
2026-02-10 08:52:56,105 - INFO - train 모드를 시작합니다.
2026-02-10 08:52:56,106 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 08:52:56,106 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 08:52:56,106 - INFO - --------------------------------------------------
2026-02-10 08:52:56,106 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 08:52:58,390 - INFO - [Train] [11/90] | Loss: 0.7938 | Train Acc: 67.41%
2026-02-10 08:52:59,157 - INFO - [Valid] [11/90] | Loss: 0.7322 | Val Acc: 59.00%
2026-02-10 08:52:59,162 - INFO - [Metrics for 'abnormal'] | Precision: 0.5312 | Recall: 0.9745 | F1: 0.6876
2026-02-10 08:52:59,162 - INFO - [Metrics for 'normal'] | Precision: 0.9216 | Recall: 0.2582 | F1: 0.4034
2026-02-10 08:52:59,178 - INFO - [Best Model Saved] (val loss: 0.7322) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:52:59,178 - INFO - --------------------------------------------------
2026-02-10 08:52:59,179 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 08:53:01,327 - INFO - [Train] [12/90] | Loss: 0.5711 | Train Acc: 73.96%
2026-02-10 08:53:02,082 - INFO - [Valid] [12/90] | Loss: 0.6677 | Val Acc: 63.13%
2026-02-10 08:53:02,087 - INFO - [Metrics for 'abnormal'] | Precision: 0.5597 | Recall: 0.9554 | F1: 0.7059
2026-02-10 08:53:02,088 - INFO - [Metrics for 'normal'] | Precision: 0.9014 | Recall: 0.3516 | F1: 0.5059
2026-02-10 08:53:02,104 - INFO - [Best Model Saved] (val loss: 0.6677) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:53:02,104 - INFO - --------------------------------------------------
2026-02-10 08:53:02,106 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 08:53:04,247 - INFO - [Train] [13/90] | Loss: 0.5604 | Train Acc: 75.97%
2026-02-10 08:53:04,952 - INFO - [Valid] [13/90] | Loss: 0.5385 | Val Acc: 78.17%
2026-02-10 08:53:04,956 - INFO - [Metrics for 'abnormal'] | Precision: 0.7748 | Recall: 0.7452 | F1: 0.7597
2026-02-10 08:53:04,956 - INFO - [Metrics for 'normal'] | Precision: 0.7872 | Recall: 0.8132 | F1: 0.8000
2026-02-10 08:53:04,971 - INFO - [Best Model Saved] (val loss: 0.5385) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:53:04,971 - INFO - --------------------------------------------------
2026-02-10 08:53:04,973 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 08:53:07,226 - INFO - [Train] [14/90] | Loss: 0.5659 | Train Acc: 75.07%
2026-02-10 08:53:07,928 - INFO - [Valid] [14/90] | Loss: 0.5599 | Val Acc: 78.17%
2026-02-10 08:53:07,933 - INFO - [Metrics for 'abnormal'] | Precision: 0.7578 | Recall: 0.7771 | F1: 0.7673
2026-02-10 08:53:07,933 - INFO - [Metrics for 'normal'] | Precision: 0.8034 | Recall: 0.7857 | F1: 0.7944
2026-02-10 08:53:07,934 - INFO - --------------------------------------------------
2026-02-10 08:53:07,936 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 08:53:10,060 - INFO - [Train] [15/90] | Loss: 0.5327 | Train Acc: 77.31%
2026-02-10 08:53:10,762 - INFO - [Valid] [15/90] | Loss: 0.5566 | Val Acc: 76.11%
2026-02-10 08:53:10,767 - INFO - [Metrics for 'abnormal'] | Precision: 0.8115 | Recall: 0.6306 | F1: 0.7097
2026-02-10 08:53:10,767 - INFO - [Metrics for 'normal'] | Precision: 0.7327 | Recall: 0.8736 | F1: 0.7970
2026-02-10 08:53:10,769 - INFO - --------------------------------------------------
2026-02-10 08:53:10,770 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 08:53:13,126 - INFO - [Train] [16/90] | Loss: 0.5361 | Train Acc: 78.27%
2026-02-10 08:53:13,795 - INFO - [Valid] [16/90] | Loss: 0.5417 | Val Acc: 75.81%
2026-02-10 08:53:13,798 - INFO - [Metrics for 'abnormal'] | Precision: 0.7451 | Recall: 0.7261 | F1: 0.7355
2026-02-10 08:53:13,798 - INFO - [Metrics for 'normal'] | Precision: 0.7688 | Recall: 0.7857 | F1: 0.7772
2026-02-10 08:53:13,798 - INFO - --------------------------------------------------
2026-02-10 08:53:13,799 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 08:53:16,226 - INFO - [Train] [17/90] | Loss: 0.5266 | Train Acc: 77.83%
2026-02-10 08:53:16,739 - INFO - [Valid] [17/90] | Loss: 0.5421 | Val Acc: 76.70%
2026-02-10 08:53:16,747 - INFO - [Metrics for 'abnormal'] | Precision: 0.7786 | Recall: 0.6943 | F1: 0.7340
2026-02-10 08:53:16,747 - INFO - [Metrics for 'normal'] | Precision: 0.7588 | Recall: 0.8297 | F1: 0.7927
2026-02-10 08:53:16,748 - INFO - --------------------------------------------------
2026-02-10 08:53:16,749 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 08:53:19,085 - INFO - [Train] [18/90] | Loss: 0.5201 | Train Acc: 78.20%
2026-02-10 08:53:19,853 - INFO - [Valid] [18/90] | Loss: 0.6174 | Val Acc: 73.16%
2026-02-10 08:53:19,858 - INFO - [Metrics for 'abnormal'] | Precision: 0.6542 | Recall: 0.8917 | F1: 0.7547
2026-02-10 08:53:19,858 - INFO - [Metrics for 'normal'] | Precision: 0.8640 | Recall: 0.5934 | F1: 0.7036
2026-02-10 08:53:19,859 - INFO - --------------------------------------------------
2026-02-10 08:53:19,860 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 08:53:22,269 - INFO - [Train] [19/90] | Loss: 0.5099 | Train Acc: 80.51%
2026-02-10 08:53:22,980 - INFO - [Valid] [19/90] | Loss: 0.5566 | Val Acc: 78.47%
2026-02-10 08:53:22,983 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-02-10 08:53:22,983 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-02-10 08:53:22,984 - INFO - --------------------------------------------------
2026-02-10 08:53:22,985 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 08:53:25,324 - INFO - [Train] [20/90] | Loss: 0.5050 | Train Acc: 80.58%
2026-02-10 08:53:25,802 - INFO - [Valid] [20/90] | Loss: 0.5199 | Val Acc: 80.83%
2026-02-10 08:53:25,805 - INFO - [Metrics for 'abnormal'] | Precision: 0.8382 | Recall: 0.7261 | F1: 0.7782
2026-02-10 08:53:25,806 - INFO - [Metrics for 'normal'] | Precision: 0.7882 | Recall: 0.8791 | F1: 0.8312
2026-02-10 08:53:25,820 - INFO - [Best Model Saved] (val loss: 0.5199) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:53:25,820 - INFO - --------------------------------------------------
2026-02-10 08:53:25,821 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 08:53:28,213 - INFO - [Train] [21/90] | Loss: 0.5037 | Train Acc: 79.46%
2026-02-10 08:53:29,000 - INFO - [Valid] [21/90] | Loss: 0.5354 | Val Acc: 78.47%
2026-02-10 08:53:29,005 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.7643 | F1: 0.7668
2026-02-10 08:53:29,005 - INFO - [Metrics for 'normal'] | Precision: 0.7978 | Recall: 0.8022 | F1: 0.8000
2026-02-10 08:53:29,006 - INFO - --------------------------------------------------
2026-02-10 08:53:29,007 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 08:53:31,450 - INFO - [Train] [22/90] | Loss: 0.4940 | Train Acc: 81.03%
2026-02-10 08:53:32,138 - INFO - [Valid] [22/90] | Loss: 0.5520 | Val Acc: 79.35%
2026-02-10 08:53:32,142 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-02-10 08:53:32,142 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-02-10 08:53:32,143 - INFO - --------------------------------------------------
2026-02-10 08:53:32,144 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 08:53:34,582 - INFO - [Train] [23/90] | Loss: 0.4879 | Train Acc: 81.03%
2026-02-10 08:53:35,288 - INFO - [Valid] [23/90] | Loss: 0.5240 | Val Acc: 80.24%
2026-02-10 08:53:35,292 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-02-10 08:53:35,292 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-02-10 08:53:35,294 - INFO - --------------------------------------------------
2026-02-10 08:53:35,295 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 08:53:38,796 - INFO - [Train] [24/90] | Loss: 0.4956 | Train Acc: 81.47%
2026-02-10 08:53:39,335 - INFO - [Valid] [24/90] | Loss: 0.5083 | Val Acc: 79.94%
2026-02-10 08:53:39,341 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-02-10 08:53:39,341 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-02-10 08:53:39,362 - INFO - [Best Model Saved] (val loss: 0.5083) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:53:39,363 - INFO - --------------------------------------------------
2026-02-10 08:53:39,364 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 08:53:42,936 - INFO - [Train] [25/90] | Loss: 0.4774 | Train Acc: 82.81%
2026-02-10 08:53:43,957 - INFO - [Valid] [25/90] | Loss: 0.5361 | Val Acc: 80.53%
2026-02-10 08:53:43,961 - INFO - [Metrics for 'abnormal'] | Precision: 0.8527 | Recall: 0.7006 | F1: 0.7692
2026-02-10 08:53:43,961 - INFO - [Metrics for 'normal'] | Precision: 0.7762 | Recall: 0.8956 | F1: 0.8316
2026-02-10 08:53:43,962 - INFO - --------------------------------------------------
2026-02-10 08:53:43,963 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 08:53:47,291 - INFO - [Train] [26/90] | Loss: 0.4813 | Train Acc: 81.85%
2026-02-10 08:53:48,460 - INFO - [Valid] [26/90] | Loss: 0.5767 | Val Acc: 77.29%
2026-02-10 08:53:48,465 - INFO - [Metrics for 'abnormal'] | Precision: 0.8175 | Recall: 0.6561 | F1: 0.7279
2026-02-10 08:53:48,465 - INFO - [Metrics for 'normal'] | Precision: 0.7465 | Recall: 0.8736 | F1: 0.8051
2026-02-10 08:53:48,466 - INFO - --------------------------------------------------
2026-02-10 08:53:48,467 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 08:53:51,903 - INFO - [Train] [27/90] | Loss: 0.4627 | Train Acc: 83.63%
2026-02-10 08:53:53,067 - INFO - [Valid] [27/90] | Loss: 0.5519 | Val Acc: 78.17%
2026-02-10 08:53:53,073 - INFO - [Metrics for 'abnormal'] | Precision: 0.7748 | Recall: 0.7452 | F1: 0.7597
2026-02-10 08:53:53,074 - INFO - [Metrics for 'normal'] | Precision: 0.7872 | Recall: 0.8132 | F1: 0.8000
2026-02-10 08:53:53,076 - INFO - --------------------------------------------------
2026-02-10 08:53:53,077 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 08:53:57,281 - INFO - [Train] [28/90] | Loss: 0.4676 | Train Acc: 83.33%
2026-02-10 08:53:58,416 - INFO - [Valid] [28/90] | Loss: 0.5040 | Val Acc: 79.35%
2026-02-10 08:53:58,423 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-02-10 08:53:58,424 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-02-10 08:53:58,441 - INFO - [Best Model Saved] (val loss: 0.5040) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:53:58,441 - INFO - --------------------------------------------------
2026-02-10 08:53:58,443 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 08:54:03,053 - INFO - [Train] [29/90] | Loss: 0.4499 | Train Acc: 83.18%
2026-02-10 08:54:04,245 - INFO - [Valid] [29/90] | Loss: 0.5979 | Val Acc: 74.04%
2026-02-10 08:54:04,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.8966 | Recall: 0.4968 | F1: 0.6393
2026-02-10 08:54:04,257 - INFO - [Metrics for 'normal'] | Precision: 0.6865 | Recall: 0.9505 | F1: 0.7972
2026-02-10 08:54:04,260 - INFO - --------------------------------------------------
2026-02-10 08:54:04,262 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 08:54:08,750 - INFO - [Train] [30/90] | Loss: 0.4467 | Train Acc: 84.45%
2026-02-10 08:54:10,318 - INFO - [Valid] [30/90] | Loss: 0.5306 | Val Acc: 77.29%
2026-02-10 08:54:10,323 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-02-10 08:54:10,323 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-02-10 08:54:10,325 - INFO - --------------------------------------------------
2026-02-10 08:54:10,326 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 08:54:15,632 - INFO - [Train] [31/90] | Loss: 0.4596 | Train Acc: 83.48%
2026-02-10 08:54:16,841 - INFO - [Valid] [31/90] | Loss: 0.6105 | Val Acc: 79.65%
2026-02-10 08:54:16,850 - INFO - [Metrics for 'abnormal'] | Precision: 0.8438 | Recall: 0.6879 | F1: 0.7579
2026-02-10 08:54:16,850 - INFO - [Metrics for 'normal'] | Precision: 0.7678 | Recall: 0.8901 | F1: 0.8244
2026-02-10 08:54:16,852 - INFO - --------------------------------------------------
2026-02-10 08:54:16,854 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 08:54:22,552 - INFO - [Train] [32/90] | Loss: 0.4473 | Train Acc: 84.30%
2026-02-10 08:54:24,115 - INFO - [Valid] [32/90] | Loss: 0.5256 | Val Acc: 77.58%
2026-02-10 08:54:24,120 - INFO - [Metrics for 'abnormal'] | Precision: 0.7396 | Recall: 0.7962 | F1: 0.7669
2026-02-10 08:54:24,120 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.7582 | F1: 0.7841
2026-02-10 08:54:24,121 - INFO - --------------------------------------------------
2026-02-10 08:54:24,123 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 08:54:30,183 - INFO - [Train] [33/90] | Loss: 0.4290 | Train Acc: 85.71%
2026-02-10 08:54:31,747 - INFO - [Valid] [33/90] | Loss: 0.4908 | Val Acc: 81.42%
2026-02-10 08:54:31,752 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.7707 | F1: 0.7934
2026-02-10 08:54:31,752 - INFO - [Metrics for 'normal'] | Precision: 0.8115 | Recall: 0.8516 | F1: 0.8311
2026-02-10 08:54:31,771 - INFO - [Best Model Saved] (val loss: 0.4908) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:54:31,772 - INFO - --------------------------------------------------
2026-02-10 08:54:31,773 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 08:54:37,788 - INFO - [Train] [34/90] | Loss: 0.4346 | Train Acc: 86.16%
2026-02-10 08:54:38,924 - INFO - [Valid] [34/90] | Loss: 0.5252 | Val Acc: 79.35%
2026-02-10 08:54:38,929 - INFO - [Metrics for 'abnormal'] | Precision: 0.8129 | Recall: 0.7197 | F1: 0.7635
2026-02-10 08:54:38,929 - INFO - [Metrics for 'normal'] | Precision: 0.7800 | Recall: 0.8571 | F1: 0.8168
2026-02-10 08:54:38,931 - INFO - --------------------------------------------------
2026-02-10 08:54:38,932 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 08:54:45,088 - INFO - [Train] [35/90] | Loss: 0.4422 | Train Acc: 84.90%
2026-02-10 08:54:46,518 - INFO - [Valid] [35/90] | Loss: 0.5009 | Val Acc: 80.53%
2026-02-10 08:54:46,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-02-10 08:54:46,523 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-02-10 08:54:46,525 - INFO - --------------------------------------------------
2026-02-10 08:54:46,526 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 08:54:51,730 - INFO - [Train] [36/90] | Loss: 0.4319 | Train Acc: 85.42%
2026-02-10 08:54:53,212 - INFO - [Valid] [36/90] | Loss: 0.4885 | Val Acc: 79.94%
2026-02-10 08:54:53,220 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-02-10 08:54:53,221 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-02-10 08:54:53,245 - INFO - [Best Model Saved] (val loss: 0.4885) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:54:53,245 - INFO - --------------------------------------------------
2026-02-10 08:54:53,246 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 08:54:59,126 - INFO - [Train] [37/90] | Loss: 0.4282 | Train Acc: 85.86%
2026-02-10 08:55:00,621 - INFO - [Valid] [37/90] | Loss: 0.5249 | Val Acc: 79.65%
2026-02-10 08:55:00,628 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8408 | F1: 0.7928
2026-02-10 08:55:00,628 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.7582 | F1: 0.8000
2026-02-10 08:55:00,631 - INFO - --------------------------------------------------
2026-02-10 08:55:00,634 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 08:55:06,352 - INFO - [Train] [38/90] | Loss: 0.4216 | Train Acc: 86.01%
2026-02-10 08:55:07,850 - INFO - [Valid] [38/90] | Loss: 0.5055 | Val Acc: 78.76%
2026-02-10 08:55:07,855 - INFO - [Metrics for 'abnormal'] | Precision: 0.7815 | Recall: 0.7516 | F1: 0.7662
2026-02-10 08:55:07,855 - INFO - [Metrics for 'normal'] | Precision: 0.7926 | Recall: 0.8187 | F1: 0.8054
2026-02-10 08:55:07,857 - INFO - --------------------------------------------------
2026-02-10 08:55:07,858 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 08:55:13,847 - INFO - [Train] [39/90] | Loss: 0.4225 | Train Acc: 86.46%
2026-02-10 08:55:14,844 - INFO - [Valid] [39/90] | Loss: 0.5358 | Val Acc: 79.35%
2026-02-10 08:55:14,849 - INFO - [Metrics for 'abnormal'] | Precision: 0.8425 | Recall: 0.6815 | F1: 0.7535
2026-02-10 08:55:14,849 - INFO - [Metrics for 'normal'] | Precision: 0.7642 | Recall: 0.8901 | F1: 0.8223
2026-02-10 08:55:14,850 - INFO - --------------------------------------------------
2026-02-10 08:55:14,851 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 08:55:20,091 - INFO - [Train] [40/90] | Loss: 0.4168 | Train Acc: 86.90%
2026-02-10 08:55:21,192 - INFO - [Valid] [40/90] | Loss: 0.4915 | Val Acc: 81.12%
2026-02-10 08:55:21,197 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 08:55:21,197 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 08:55:21,198 - INFO - --------------------------------------------------
2026-02-10 08:55:21,200 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 08:55:25,951 - INFO - [Train] [41/90] | Loss: 0.4039 | Train Acc: 88.10%
2026-02-10 08:55:27,126 - INFO - [Valid] [41/90] | Loss: 0.5045 | Val Acc: 80.53%
2026-02-10 08:55:27,131 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-02-10 08:55:27,131 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-02-10 08:55:27,133 - INFO - --------------------------------------------------
2026-02-10 08:55:27,134 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 08:55:31,279 - INFO - [Train] [42/90] | Loss: 0.4030 | Train Acc: 87.50%
2026-02-10 08:55:32,402 - INFO - [Valid] [42/90] | Loss: 0.5252 | Val Acc: 79.65%
2026-02-10 08:55:32,411 - INFO - [Metrics for 'abnormal'] | Precision: 0.8385 | Recall: 0.6943 | F1: 0.7596
2026-02-10 08:55:32,412 - INFO - [Metrics for 'normal'] | Precision: 0.7703 | Recall: 0.8846 | F1: 0.8235
2026-02-10 08:55:32,413 - INFO - --------------------------------------------------
2026-02-10 08:55:32,414 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 08:55:36,227 - INFO - [Train] [43/90] | Loss: 0.3961 | Train Acc: 88.69%
2026-02-10 08:55:37,418 - INFO - [Valid] [43/90] | Loss: 0.5364 | Val Acc: 79.35%
2026-02-10 08:55:37,422 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8344 | F1: 0.7892
2026-02-10 08:55:37,422 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.7582 | F1: 0.7977
2026-02-10 08:55:37,423 - INFO - --------------------------------------------------
2026-02-10 08:55:37,424 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 08:55:41,049 - INFO - [Train] [44/90] | Loss: 0.3943 | Train Acc: 88.02%
2026-02-10 08:55:41,701 - INFO - [Valid] [44/90] | Loss: 0.4880 | Val Acc: 79.35%
2026-02-10 08:55:41,706 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-02-10 08:55:41,706 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-02-10 08:55:41,722 - INFO - [Best Model Saved] (val loss: 0.4880) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 08:55:41,722 - INFO - --------------------------------------------------
2026-02-10 08:55:41,723 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 08:55:45,544 - INFO - [Train] [45/90] | Loss: 0.4055 | Train Acc: 87.50%
2026-02-10 08:55:46,514 - INFO - [Valid] [45/90] | Loss: 0.5306 | Val Acc: 78.17%
2026-02-10 08:55:46,519 - INFO - [Metrics for 'abnormal'] | Precision: 0.7399 | Recall: 0.8153 | F1: 0.7758
2026-02-10 08:55:46,519 - INFO - [Metrics for 'normal'] | Precision: 0.8253 | Recall: 0.7527 | F1: 0.7874
2026-02-10 08:55:46,521 - INFO - --------------------------------------------------
2026-02-10 08:55:46,522 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 08:55:50,460 - INFO - [Train] [46/90] | Loss: 0.3948 | Train Acc: 87.95%
2026-02-10 08:55:51,578 - INFO - [Valid] [46/90] | Loss: 0.5246 | Val Acc: 81.12%
2026-02-10 08:55:51,583 - INFO - [Metrics for 'abnormal'] | Precision: 0.8079 | Recall: 0.7771 | F1: 0.7922
2026-02-10 08:55:51,583 - INFO - [Metrics for 'normal'] | Precision: 0.8138 | Recall: 0.8407 | F1: 0.8270
2026-02-10 08:55:51,585 - INFO - --------------------------------------------------
2026-02-10 08:55:51,586 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 08:55:54,739 - INFO - [Train] [47/90] | Loss: 0.3752 | Train Acc: 89.66%
2026-02-10 08:55:55,925 - INFO - [Valid] [47/90] | Loss: 0.5432 | Val Acc: 77.88%
2026-02-10 08:55:55,930 - INFO - [Metrics for 'abnormal'] | Precision: 0.7847 | Recall: 0.7197 | F1: 0.7508
2026-02-10 08:55:55,931 - INFO - [Metrics for 'normal'] | Precision: 0.7744 | Recall: 0.8297 | F1: 0.8011
2026-02-10 08:55:55,932 - INFO - --------------------------------------------------
2026-02-10 08:55:55,934 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 08:55:59,652 - INFO - [Train] [48/90] | Loss: 0.3747 | Train Acc: 88.84%
2026-02-10 08:56:00,587 - INFO - [Valid] [48/90] | Loss: 0.5468 | Val Acc: 77.58%
2026-02-10 08:56:00,595 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.6752 | F1: 0.7361
2026-02-10 08:56:00,596 - INFO - [Metrics for 'normal'] | Precision: 0.7548 | Recall: 0.8626 | F1: 0.8051
2026-02-10 08:56:00,597 - INFO - --------------------------------------------------
2026-02-10 08:56:00,599 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 08:56:04,386 - INFO - [Train] [49/90] | Loss: 0.3674 | Train Acc: 89.81%
2026-02-10 08:56:05,333 - INFO - [Valid] [49/90] | Loss: 0.5374 | Val Acc: 79.94%
2026-02-10 08:56:05,337 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-02-10 08:56:05,337 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-02-10 08:56:05,339 - INFO - --------------------------------------------------
2026-02-10 08:56:05,340 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 08:56:09,746 - INFO - [Train] [50/90] | Loss: 0.3687 | Train Acc: 89.66%
2026-02-10 08:56:10,924 - INFO - [Valid] [50/90] | Loss: 0.5156 | Val Acc: 83.48%
2026-02-10 08:56:10,931 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.8280 | F1: 0.8228
2026-02-10 08:56:10,932 - INFO - [Metrics for 'normal'] | Precision: 0.8500 | Recall: 0.8407 | F1: 0.8453
2026-02-10 08:56:10,933 - INFO - --------------------------------------------------
2026-02-10 08:56:10,935 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 08:56:15,949 - INFO - [Train] [51/90] | Loss: 0.3814 | Train Acc: 89.21%
2026-02-10 08:56:17,286 - INFO - [Valid] [51/90] | Loss: 0.5338 | Val Acc: 78.47%
2026-02-10 08:56:17,291 - INFO - [Metrics for 'abnormal'] | Precision: 0.7258 | Recall: 0.8599 | F1: 0.7872
2026-02-10 08:56:17,291 - INFO - [Metrics for 'normal'] | Precision: 0.8562 | Recall: 0.7198 | F1: 0.7821
2026-02-10 08:56:17,293 - INFO - --------------------------------------------------
2026-02-10 08:56:17,294 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 08:56:21,726 - INFO - [Train] [52/90] | Loss: 0.3522 | Train Acc: 90.85%
2026-02-10 08:56:23,183 - INFO - [Valid] [52/90] | Loss: 0.5158 | Val Acc: 81.12%
2026-02-10 08:56:23,188 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 08:56:23,188 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 08:56:23,190 - INFO - --------------------------------------------------
2026-02-10 08:56:23,191 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 08:56:27,801 - INFO - [Train] [53/90] | Loss: 0.3587 | Train Acc: 90.85%
2026-02-10 08:56:29,423 - INFO - [Valid] [53/90] | Loss: 0.5811 | Val Acc: 79.65%
2026-02-10 08:56:29,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.8188 | Recall: 0.7197 | F1: 0.7661
2026-02-10 08:56:29,430 - INFO - [Metrics for 'normal'] | Precision: 0.7811 | Recall: 0.8626 | F1: 0.8198
2026-02-10 08:56:29,431 - INFO - --------------------------------------------------
2026-02-10 08:56:29,433 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 08:56:35,264 - INFO - [Train] [54/90] | Loss: 0.3450 | Train Acc: 91.37%
2026-02-10 08:56:36,741 - INFO - [Valid] [54/90] | Loss: 0.5501 | Val Acc: 81.71%
2026-02-10 08:56:36,746 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-02-10 08:56:36,746 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-02-10 08:56:36,748 - INFO - --------------------------------------------------
2026-02-10 08:56:36,753 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 08:56:42,441 - INFO - [Train] [55/90] | Loss: 0.3404 | Train Acc: 92.41%
2026-02-10 08:56:43,796 - INFO - [Valid] [55/90] | Loss: 0.5603 | Val Acc: 78.47%
2026-02-10 08:56:43,803 - INFO - [Metrics for 'abnormal'] | Precision: 0.7763 | Recall: 0.7516 | F1: 0.7638
2026-02-10 08:56:43,804 - INFO - [Metrics for 'normal'] | Precision: 0.7914 | Recall: 0.8132 | F1: 0.8022
2026-02-10 08:56:43,806 - INFO - --------------------------------------------------
2026-02-10 08:56:43,807 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 08:56:49,283 - INFO - [Train] [56/90] | Loss: 0.3328 | Train Acc: 92.41%
2026-02-10 08:56:50,856 - INFO - [Valid] [56/90] | Loss: 0.6066 | Val Acc: 79.65%
2026-02-10 08:56:50,867 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 08:56:50,867 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 08:56:50,868 - INFO - --------------------------------------------------
2026-02-10 08:56:50,869 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 08:56:56,748 - INFO - [Train] [57/90] | Loss: 0.3302 | Train Acc: 93.01%
2026-02-10 08:56:58,115 - INFO - [Valid] [57/90] | Loss: 0.5623 | Val Acc: 81.12%
2026-02-10 08:56:58,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-02-10 08:56:58,124 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-02-10 08:56:58,125 - INFO - --------------------------------------------------
2026-02-10 08:56:58,126 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 08:57:03,495 - INFO - [Train] [58/90] | Loss: 0.3386 | Train Acc: 91.96%
2026-02-10 08:57:05,038 - INFO - [Valid] [58/90] | Loss: 0.5539 | Val Acc: 80.24%
2026-02-10 08:57:05,044 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-02-10 08:57:05,044 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-02-10 08:57:05,046 - INFO - --------------------------------------------------
2026-02-10 08:57:05,047 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 08:57:10,324 - INFO - [Train] [59/90] | Loss: 0.3333 | Train Acc: 92.71%
2026-02-10 08:57:11,986 - INFO - [Valid] [59/90] | Loss: 0.5983 | Val Acc: 79.94%
2026-02-10 08:57:11,993 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-02-10 08:57:11,993 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-02-10 08:57:11,994 - INFO - --------------------------------------------------
2026-02-10 08:57:11,995 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 08:57:17,846 - INFO - [Train] [60/90] | Loss: 0.3288 | Train Acc: 93.15%
2026-02-10 08:57:19,164 - INFO - [Valid] [60/90] | Loss: 0.5407 | Val Acc: 82.30%
2026-02-10 08:57:19,170 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-02-10 08:57:19,170 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-02-10 08:57:19,171 - INFO - --------------------------------------------------
2026-02-10 08:57:19,172 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 08:57:24,775 - INFO - [Train] [61/90] | Loss: 0.3251 | Train Acc: 93.08%
2026-02-10 08:57:26,371 - INFO - [Valid] [61/90] | Loss: 0.5443 | Val Acc: 81.71%
2026-02-10 08:57:26,375 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-02-10 08:57:26,375 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-02-10 08:57:26,377 - INFO - --------------------------------------------------
2026-02-10 08:57:26,379 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 08:57:32,065 - INFO - [Train] [62/90] | Loss: 0.3117 | Train Acc: 93.75%
2026-02-10 08:57:33,569 - INFO - [Valid] [62/90] | Loss: 0.6074 | Val Acc: 82.30%
2026-02-10 08:57:33,576 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-02-10 08:57:33,577 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-02-10 08:57:33,578 - INFO - --------------------------------------------------
2026-02-10 08:57:33,580 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 08:57:39,596 - INFO - [Train] [63/90] | Loss: 0.3047 | Train Acc: 94.27%
2026-02-10 08:57:40,902 - INFO - [Valid] [63/90] | Loss: 0.5968 | Val Acc: 81.12%
2026-02-10 08:57:40,907 - INFO - [Metrics for 'abnormal'] | Precision: 0.8444 | Recall: 0.7261 | F1: 0.7808
2026-02-10 08:57:40,907 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8846 | F1: 0.8342
2026-02-10 08:57:40,909 - INFO - --------------------------------------------------
2026-02-10 08:57:40,910 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 08:57:46,898 - INFO - [Train] [64/90] | Loss: 0.3090 | Train Acc: 94.57%
2026-02-10 08:57:48,386 - INFO - [Valid] [64/90] | Loss: 0.5668 | Val Acc: 81.12%
2026-02-10 08:57:48,391 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-02-10 08:57:48,392 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-02-10 08:57:48,393 - INFO - --------------------------------------------------
2026-02-10 08:57:48,395 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 08:57:53,866 - INFO - [Train] [65/90] | Loss: 0.3196 | Train Acc: 93.08%
2026-02-10 08:57:55,448 - INFO - [Valid] [65/90] | Loss: 0.5566 | Val Acc: 81.42%
2026-02-10 08:57:55,453 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 08:57:55,453 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 08:57:55,457 - INFO - --------------------------------------------------
2026-02-10 08:57:55,458 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 08:58:00,869 - INFO - [Train] [66/90] | Loss: 0.3088 | Train Acc: 93.82%
2026-02-10 08:58:02,542 - INFO - [Valid] [66/90] | Loss: 0.5710 | Val Acc: 82.60%
2026-02-10 08:58:02,547 - INFO - [Metrics for 'abnormal'] | Precision: 0.8224 | Recall: 0.7962 | F1: 0.8091
2026-02-10 08:58:02,547 - INFO - [Metrics for 'normal'] | Precision: 0.8289 | Recall: 0.8516 | F1: 0.8401
2026-02-10 08:58:02,549 - INFO - --------------------------------------------------
2026-02-10 08:58:02,550 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 08:58:08,070 - INFO - [Train] [67/90] | Loss: 0.3134 | Train Acc: 93.53%
2026-02-10 08:58:09,075 - INFO - [Valid] [67/90] | Loss: 0.5415 | Val Acc: 82.60%
2026-02-10 08:58:09,080 - INFO - [Metrics for 'abnormal'] | Precision: 0.8311 | Recall: 0.7834 | F1: 0.8066
2026-02-10 08:58:09,081 - INFO - [Metrics for 'normal'] | Precision: 0.8220 | Recall: 0.8626 | F1: 0.8418
2026-02-10 08:58:09,083 - INFO - --------------------------------------------------
2026-02-10 08:58:09,084 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 08:58:15,234 - INFO - [Train] [68/90] | Loss: 0.2848 | Train Acc: 96.28%
2026-02-10 08:58:16,570 - INFO - [Valid] [68/90] | Loss: 0.5841 | Val Acc: 80.83%
2026-02-10 08:58:16,574 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-02-10 08:58:16,575 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-02-10 08:58:16,576 - INFO - --------------------------------------------------
2026-02-10 08:58:16,577 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 08:58:22,658 - INFO - [Train] [69/90] | Loss: 0.3079 | Train Acc: 94.42%
2026-02-10 08:58:23,940 - INFO - [Valid] [69/90] | Loss: 0.5432 | Val Acc: 82.60%
2026-02-10 08:58:23,945 - INFO - [Metrics for 'abnormal'] | Precision: 0.8063 | Recall: 0.8217 | F1: 0.8139
2026-02-10 08:58:23,945 - INFO - [Metrics for 'normal'] | Precision: 0.8436 | Recall: 0.8297 | F1: 0.8366
2026-02-10 08:58:23,947 - INFO - --------------------------------------------------
2026-02-10 08:58:23,948 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 08:58:29,508 - INFO - [Train] [70/90] | Loss: 0.2910 | Train Acc: 95.01%
2026-02-10 08:58:31,046 - INFO - [Valid] [70/90] | Loss: 0.5655 | Val Acc: 82.01%
2026-02-10 08:58:31,057 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-02-10 08:58:31,057 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-02-10 08:58:31,058 - INFO - --------------------------------------------------
2026-02-10 08:58:31,060 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 08:58:36,573 - INFO - [Train] [71/90] | Loss: 0.2885 | Train Acc: 95.76%
2026-02-10 08:58:38,202 - INFO - [Valid] [71/90] | Loss: 0.5312 | Val Acc: 82.30%
2026-02-10 08:58:38,208 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-02-10 08:58:38,208 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-02-10 08:58:38,210 - INFO - --------------------------------------------------
2026-02-10 08:58:38,211 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 08:58:42,949 - INFO - [Train] [72/90] | Loss: 0.2968 | Train Acc: 94.79%
2026-02-10 08:58:44,360 - INFO - [Valid] [72/90] | Loss: 0.5914 | Val Acc: 80.53%
2026-02-10 08:58:44,365 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-02-10 08:58:44,365 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-02-10 08:58:44,367 - INFO - --------------------------------------------------
2026-02-10 08:58:44,369 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 08:58:50,165 - INFO - [Train] [73/90] | Loss: 0.2805 | Train Acc: 96.06%
2026-02-10 08:58:51,633 - INFO - [Valid] [73/90] | Loss: 0.6302 | Val Acc: 81.12%
2026-02-10 08:58:51,644 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-02-10 08:58:51,645 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-02-10 08:58:51,647 - INFO - --------------------------------------------------
2026-02-10 08:58:51,650 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 08:58:57,241 - INFO - [Train] [74/90] | Loss: 0.2855 | Train Acc: 96.28%
2026-02-10 08:58:58,713 - INFO - [Valid] [74/90] | Loss: 0.5965 | Val Acc: 81.12%
2026-02-10 08:58:58,719 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 08:58:58,719 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 08:58:58,721 - INFO - --------------------------------------------------
2026-02-10 08:58:58,722 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 08:59:03,545 - INFO - [Train] [75/90] | Loss: 0.2780 | Train Acc: 96.13%
2026-02-10 08:59:05,287 - INFO - [Valid] [75/90] | Loss: 0.5608 | Val Acc: 82.60%
2026-02-10 08:59:05,291 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.8025 | F1: 0.8103
2026-02-10 08:59:05,292 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8462 | F1: 0.8392
2026-02-10 08:59:05,293 - INFO - --------------------------------------------------
2026-02-10 08:59:05,298 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 08:59:10,995 - INFO - [Train] [76/90] | Loss: 0.2892 | Train Acc: 95.76%
2026-02-10 08:59:12,325 - INFO - [Valid] [76/90] | Loss: 0.5655 | Val Acc: 82.60%
2026-02-10 08:59:12,329 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-02-10 08:59:12,330 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-02-10 08:59:12,335 - INFO - --------------------------------------------------
2026-02-10 08:59:12,336 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 08:59:17,924 - INFO - [Train] [77/90] | Loss: 0.2813 | Train Acc: 96.28%
2026-02-10 08:59:19,479 - INFO - [Valid] [77/90] | Loss: 0.5793 | Val Acc: 80.83%
2026-02-10 08:59:19,484 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-02-10 08:59:19,484 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-02-10 08:59:19,485 - INFO - --------------------------------------------------
2026-02-10 08:59:19,487 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 08:59:24,848 - INFO - [Train] [78/90] | Loss: 0.2620 | Train Acc: 97.32%
2026-02-10 08:59:26,250 - INFO - [Valid] [78/90] | Loss: 0.6109 | Val Acc: 80.53%
2026-02-10 08:59:26,260 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-02-10 08:59:26,260 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-02-10 08:59:26,261 - INFO - --------------------------------------------------
2026-02-10 08:59:26,263 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 08:59:32,270 - INFO - [Train] [79/90] | Loss: 0.2729 | Train Acc: 96.80%
2026-02-10 08:59:33,828 - INFO - [Valid] [79/90] | Loss: 0.6121 | Val Acc: 79.35%
2026-02-10 08:59:33,836 - INFO - [Metrics for 'abnormal'] | Precision: 0.8129 | Recall: 0.7197 | F1: 0.7635
2026-02-10 08:59:33,837 - INFO - [Metrics for 'normal'] | Precision: 0.7800 | Recall: 0.8571 | F1: 0.8168
2026-02-10 08:59:33,839 - INFO - --------------------------------------------------
2026-02-10 08:59:33,840 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 08:59:39,889 - INFO - [Train] [80/90] | Loss: 0.2688 | Train Acc: 97.10%
2026-02-10 08:59:41,207 - INFO - [Valid] [80/90] | Loss: 0.5917 | Val Acc: 80.83%
2026-02-10 08:59:41,211 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-02-10 08:59:41,211 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-02-10 08:59:41,213 - INFO - --------------------------------------------------
2026-02-10 08:59:41,214 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 08:59:47,035 - INFO - [Train] [81/90] | Loss: 0.2778 | Train Acc: 96.21%
2026-02-10 08:59:48,586 - INFO - [Valid] [81/90] | Loss: 0.5716 | Val Acc: 82.30%
2026-02-10 08:59:48,592 - INFO - [Metrics for 'abnormal'] | Precision: 0.8212 | Recall: 0.7898 | F1: 0.8052
2026-02-10 08:59:48,592 - INFO - [Metrics for 'normal'] | Precision: 0.8245 | Recall: 0.8516 | F1: 0.8378
2026-02-10 08:59:48,594 - INFO - --------------------------------------------------
2026-02-10 08:59:48,596 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 08:59:54,469 - INFO - [Train] [82/90] | Loss: 0.2666 | Train Acc: 97.02%
2026-02-10 08:59:55,963 - INFO - [Valid] [82/90] | Loss: 0.6251 | Val Acc: 80.83%
2026-02-10 08:59:55,969 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-02-10 08:59:55,970 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-02-10 08:59:55,971 - INFO - --------------------------------------------------
2026-02-10 08:59:55,973 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 09:00:01,601 - INFO - [Train] [83/90] | Loss: 0.2686 | Train Acc: 96.65%
2026-02-10 09:00:03,103 - INFO - [Valid] [83/90] | Loss: 0.5971 | Val Acc: 79.06%
2026-02-10 09:00:03,112 - INFO - [Metrics for 'abnormal'] | Precision: 0.7529 | Recall: 0.8153 | F1: 0.7829
2026-02-10 09:00:03,112 - INFO - [Metrics for 'normal'] | Precision: 0.8284 | Recall: 0.7692 | F1: 0.7977
2026-02-10 09:00:03,118 - INFO - --------------------------------------------------
2026-02-10 09:00:03,119 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 09:00:08,346 - INFO - [Train] [84/90] | Loss: 0.2626 | Train Acc: 97.17%
2026-02-10 09:00:09,857 - INFO - [Valid] [84/90] | Loss: 0.6096 | Val Acc: 80.83%
2026-02-10 09:00:09,865 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-02-10 09:00:09,865 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-02-10 09:00:09,867 - INFO - --------------------------------------------------
2026-02-10 09:00:09,868 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 09:00:15,467 - INFO - [Train] [85/90] | Loss: 0.2685 | Train Acc: 96.88%
2026-02-10 09:00:16,881 - INFO - [Valid] [85/90] | Loss: 0.5740 | Val Acc: 81.42%
2026-02-10 09:00:16,889 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.7834 | F1: 0.7961
2026-02-10 09:00:16,889 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.8407 | F1: 0.8293
2026-02-10 09:00:16,890 - INFO - --------------------------------------------------
2026-02-10 09:00:16,891 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 09:00:23,005 - INFO - [Train] [86/90] | Loss: 0.2530 | Train Acc: 97.84%
2026-02-10 09:00:23,992 - INFO - [Valid] [86/90] | Loss: 0.5901 | Val Acc: 81.71%
2026-02-10 09:00:23,997 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-02-10 09:00:23,997 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-02-10 09:00:23,999 - INFO - --------------------------------------------------
2026-02-10 09:00:24,001 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 09:00:29,807 - INFO - [Train] [87/90] | Loss: 0.2608 | Train Acc: 97.47%
2026-02-10 09:00:31,254 - INFO - [Valid] [87/90] | Loss: 0.6024 | Val Acc: 80.53%
2026-02-10 09:00:31,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-02-10 09:00:31,259 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-02-10 09:00:31,261 - INFO - --------------------------------------------------
2026-02-10 09:00:31,262 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 09:00:37,092 - INFO - [Train] [88/90] | Loss: 0.2643 | Train Acc: 97.02%
2026-02-10 09:00:38,730 - INFO - [Valid] [88/90] | Loss: 0.6062 | Val Acc: 80.24%
2026-02-10 09:00:38,739 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-02-10 09:00:38,740 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-02-10 09:00:38,741 - INFO - --------------------------------------------------
2026-02-10 09:00:38,743 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 09:00:44,007 - INFO - [Train] [89/90] | Loss: 0.2649 | Train Acc: 96.88%
2026-02-10 09:00:45,537 - INFO - [Valid] [89/90] | Loss: 0.6040 | Val Acc: 79.65%
2026-02-10 09:00:45,542 - INFO - [Metrics for 'abnormal'] | Precision: 0.7785 | Recall: 0.7834 | F1: 0.7810
2026-02-10 09:00:45,542 - INFO - [Metrics for 'normal'] | Precision: 0.8122 | Recall: 0.8077 | F1: 0.8099
2026-02-10 09:00:45,543 - INFO - --------------------------------------------------
2026-02-10 09:00:45,545 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 09:00:50,935 - INFO - [Train] [90/90] | Loss: 0.2589 | Train Acc: 97.47%
2026-02-10 09:00:52,378 - INFO - [Valid] [90/90] | Loss: 0.5868 | Val Acc: 79.06%
2026-02-10 09:00:52,384 - INFO - [Metrics for 'abnormal'] | Precision: 0.7622 | Recall: 0.7962 | F1: 0.7788
2026-02-10 09:00:52,386 - INFO - [Metrics for 'normal'] | Precision: 0.8171 | Recall: 0.7857 | F1: 0.8011
2026-02-10 09:00:52,389 - INFO - ==================================================
2026-02-10 09:00:52,389 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 09:00:52,389 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 09:00:52,390 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:00:52,455 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 09:00:52,457 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 09:00:52,457 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:00:52,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8754345703125)에 맞춰 변경되었습니다.
2026-02-10 09:00:52,582 - INFO - ==================================================
2026-02-10 09:00:52,679 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/best_model.pth'
2026-02-10 09:00:52,679 - INFO - ==================================================
2026-02-10 09:00:52,679 - INFO - Test 모드를 시작합니다.
2026-02-10 09:00:52,827 - INFO - 연산량 (MACs): 0.0048 GMACs per sample
2026-02-10 09:00:52,828 - INFO - 연산량 (FLOPs): 0.0095 GFLOPs per sample
2026-02-10 09:00:52,828 - INFO - ==================================================
2026-02-10 09:00:52,829 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 09:00:54,082 - INFO - 샘플 당 평균 Forward Pass 시간: 2.90ms (std: 0.67ms), FPS: 376.48 (std: 198.46) (1개 샘플 x 100회 반복)
2026-02-10 09:00:54,082 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 58.12 MB
2026-02-10 09:00:54,082 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 09:00:56,598 - INFO - [Test] Loss: 0.4251 | Test Acc: 79.35%
2026-02-10 09:00:56,604 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-02-10 09:00:56,604 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-02-10 09:00:56,913 - INFO - ==================================================
2026-02-10 09:00:56,913 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/confusion_matrix_20260210_085225.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/confusion_matrix_20260210_085225.pdf'
2026-02-10 09:00:56,913 - INFO - ==================================================
2026-02-10 09:00:56,913 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 09:00:59,244 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/model_fp32_20260210_085225.onnx'에 저장되었습니다. (크기: 0.20 MB)
2026-02-10 09:00:59,757 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 8.44 MB
2026-02-10 09:00:59,758 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 09:01:00,655 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 3.53ms (std: 5.12ms)
2026-02-10 09:01:00,656 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 875.05 FPS (std: 613.17) (1개 샘플 x 100회 반복)
2026-02-10 09:01:00,656 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 3.75 MB
2026-02-10 09:01:00,657 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 12.47 MB
2026-02-10 09:01:03,473 - INFO - [Test (ONNX)] | Test Acc (ONNX): 79.35%
2026-02-10 09:01:03,492 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-02-10 09:01:03,493 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-02-10 09:01:03,760 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/val_acc.pdf'
2026-02-10 09:01:04,003 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/train_val_acc.pdf'
2026-02-10 09:01:04,208 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/F1_normal.pdf'
2026-02-10 09:01:04,403 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/val_loss.pdf'
2026-02-10 09:01:04,590 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/learning_rate.pdf'
2026-02-10 09:01:06,762 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260210_085225/graph_20260210_085225/compile.pdf'
