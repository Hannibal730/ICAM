2026-02-10 10:26:40,456 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/log_20260210_102640.log'에 저장됩니다.
2026-02-10 10:26:40,458 - INFO - ==================================================
2026-02-10 10:26:40,458 - INFO - config.yaml:
2026-02-10 10:26:40,458 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: deit_tiny
  use_fpgm_pruning: true
  pruning_params_target: 0.047585

2026-02-10 10:26:40,458 - INFO - ==================================================
2026-02-10 10:26:40,616 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 10:26:40,617 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 10:26:40,617 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 10:26:40,620 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 10:26:40,620 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 10:26:40,620 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 10:26:40,620 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 10:26:40,739 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 10:26:40,740 - INFO - ==================================================
2026-02-10 10:26:40,740 - INFO - 모델 파라미터 수:
2026-02-10 10:26:40,740 - INFO -   - 총 파라미터: 5,524,802 개
2026-02-10 10:26:40,740 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-02-10 10:26:40,740 - INFO - ================================================================================
2026-02-10 10:26:40,740 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 10:26:40,740 - INFO - ================================================================================
2026-02-10 10:26:40,740 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 10:26:40,740 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 10:26:40,740 - INFO - ==================================================
2026-02-10 10:26:40,740 - INFO - train 모드를 시작합니다.
2026-02-10 10:26:40,740 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 10:26:40,740 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 10:26:40,740 - INFO - --------------------------------------------------
2026-02-10 10:26:40,741 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 10:26:42,564 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-02-10 10:26:43,206 - INFO - [Valid] [1/10] | Loss: 0.6724 | Val Acc: 59.88%
2026-02-10 10:26:43,210 - INFO - [Metrics for 'abnormal'] | Precision: 0.5488 | Recall: 0.7516 | F1: 0.6344
2026-02-10 10:26:43,210 - INFO - [Metrics for 'normal'] | Precision: 0.6855 | Recall: 0.4670 | F1: 0.5556
2026-02-10 10:26:43,225 - INFO - [Best Model Saved] (val loss: 0.6724) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:26:43,225 - INFO - --------------------------------------------------
2026-02-10 10:26:43,226 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 10:26:44,777 - INFO - [Train] [2/10] | Loss: 0.6464 | Train Acc: 64.43%
2026-02-10 10:26:45,184 - INFO - [Valid] [2/10] | Loss: 0.6629 | Val Acc: 61.65%
2026-02-10 10:26:45,186 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.2548 | F1: 0.3810
2026-02-10 10:26:45,186 - INFO - [Metrics for 'normal'] | Precision: 0.5909 | Recall: 0.9286 | F1: 0.7222
2026-02-10 10:26:45,220 - INFO - [Best Model Saved] (val loss: 0.6629) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:26:45,221 - INFO - --------------------------------------------------
2026-02-10 10:26:45,221 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 10:26:47,759 - INFO - [Train] [3/10] | Loss: 0.5956 | Train Acc: 68.90%
2026-02-10 10:26:48,209 - INFO - [Valid] [3/10] | Loss: 0.5660 | Val Acc: 74.93%
2026-02-10 10:26:48,212 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.6497 | F1: 0.7059
2026-02-10 10:26:48,212 - INFO - [Metrics for 'normal'] | Precision: 0.7343 | Recall: 0.8352 | F1: 0.7815
2026-02-10 10:26:48,243 - INFO - [Best Model Saved] (val loss: 0.5660) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:26:48,243 - INFO - --------------------------------------------------
2026-02-10 10:26:48,243 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 10:26:50,801 - INFO - [Train] [4/10] | Loss: 0.5630 | Train Acc: 75.82%
2026-02-10 10:26:51,382 - INFO - [Valid] [4/10] | Loss: 0.5505 | Val Acc: 74.04%
2026-02-10 10:26:51,384 - INFO - [Metrics for 'abnormal'] | Precision: 0.7117 | Recall: 0.7389 | F1: 0.7250
2026-02-10 10:26:51,384 - INFO - [Metrics for 'normal'] | Precision: 0.7670 | Recall: 0.7418 | F1: 0.7542
2026-02-10 10:26:51,415 - INFO - [Best Model Saved] (val loss: 0.5505) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:26:51,415 - INFO - --------------------------------------------------
2026-02-10 10:26:51,415 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 10:26:54,076 - INFO - [Train] [5/10] | Loss: 0.5155 | Train Acc: 78.94%
2026-02-10 10:26:54,579 - INFO - [Valid] [5/10] | Loss: 0.5579 | Val Acc: 74.63%
2026-02-10 10:26:54,581 - INFO - [Metrics for 'abnormal'] | Precision: 0.7126 | Recall: 0.7580 | F1: 0.7346
2026-02-10 10:26:54,581 - INFO - [Metrics for 'normal'] | Precision: 0.7791 | Recall: 0.7363 | F1: 0.7571
2026-02-10 10:26:54,582 - INFO - --------------------------------------------------
2026-02-10 10:26:54,583 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 10:26:57,333 - INFO - [Train] [6/10] | Loss: 0.5177 | Train Acc: 78.50%
2026-02-10 10:26:57,765 - INFO - [Valid] [6/10] | Loss: 0.5393 | Val Acc: 74.63%
2026-02-10 10:26:57,768 - INFO - [Metrics for 'abnormal'] | Precision: 0.6940 | Recall: 0.8089 | F1: 0.7471
2026-02-10 10:26:57,768 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.6923 | F1: 0.7456
2026-02-10 10:26:57,795 - INFO - [Best Model Saved] (val loss: 0.5393) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:26:57,796 - INFO - --------------------------------------------------
2026-02-10 10:26:57,797 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 10:27:00,548 - INFO - [Train] [7/10] | Loss: 0.4901 | Train Acc: 81.32%
2026-02-10 10:27:01,005 - INFO - [Valid] [7/10] | Loss: 0.5521 | Val Acc: 76.99%
2026-02-10 10:27:01,009 - INFO - [Metrics for 'abnormal'] | Precision: 0.8264 | Recall: 0.6369 | F1: 0.7194
2026-02-10 10:27:01,009 - INFO - [Metrics for 'normal'] | Precision: 0.7385 | Recall: 0.8846 | F1: 0.8050
2026-02-10 10:27:01,011 - INFO - --------------------------------------------------
2026-02-10 10:27:01,012 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 10:27:03,735 - INFO - [Train] [8/10] | Loss: 0.4861 | Train Acc: 81.70%
2026-02-10 10:27:04,204 - INFO - [Valid] [8/10] | Loss: 0.5293 | Val Acc: 77.29%
2026-02-10 10:27:04,208 - INFO - [Metrics for 'abnormal'] | Precision: 0.8175 | Recall: 0.6561 | F1: 0.7279
2026-02-10 10:27:04,209 - INFO - [Metrics for 'normal'] | Precision: 0.7465 | Recall: 0.8736 | F1: 0.8051
2026-02-10 10:27:04,241 - INFO - [Best Model Saved] (val loss: 0.5293) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:04,241 - INFO - --------------------------------------------------
2026-02-10 10:27:04,242 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 10:27:06,943 - INFO - [Train] [9/10] | Loss: 0.4830 | Train Acc: 80.88%
2026-02-10 10:27:07,429 - INFO - [Valid] [9/10] | Loss: 0.5372 | Val Acc: 76.40%
2026-02-10 10:27:07,436 - INFO - [Metrics for 'abnormal'] | Precision: 0.7655 | Recall: 0.7070 | F1: 0.7351
2026-02-10 10:27:07,436 - INFO - [Metrics for 'normal'] | Precision: 0.7629 | Recall: 0.8132 | F1: 0.7872
2026-02-10 10:27:07,438 - INFO - --------------------------------------------------
2026-02-10 10:27:07,439 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 10:27:10,141 - INFO - [Train] [10/10] | Loss: 0.4752 | Train Acc: 82.29%
2026-02-10 10:27:10,655 - INFO - [Valid] [10/10] | Loss: 0.5302 | Val Acc: 76.70%
2026-02-10 10:27:10,658 - INFO - [Metrics for 'abnormal'] | Precision: 0.7378 | Recall: 0.7707 | F1: 0.7539
2026-02-10 10:27:10,658 - INFO - [Metrics for 'normal'] | Precision: 0.7943 | Recall: 0.7637 | F1: 0.7787
2026-02-10 10:27:10,659 - INFO - ================================================================================
2026-02-10 10:27:10,659 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 10:27:10,659 - INFO - ================================================================================
2026-02-10 10:27:10,718 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'을(를) 불러왔습니다.
2026-02-10 10:27:10,718 - INFO - ================================================================================
2026-02-10 10:27:10,718 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 10:27:10,718 - INFO - 원본 모델 파라미터: 5.5248M
2026-02-10 10:27:10,733 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:10,733 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:10,733 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:10,901 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 10:27:10,901 - INFO - ==================================================
2026-02-10 10:27:10,902 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.8881M (감소율: 65.83%)
2026-02-10 10:27:10,915 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:10,916 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:10,916 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:11,402 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 10:27:11,402 - INFO - ==================================================
2026-02-10 10:27:11,403 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.7436M (감소율: 86.54%)
2026-02-10 10:27:11,414 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:11,415 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:11,415 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:11,586 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 10:27:11,586 - INFO - ==================================================
2026-02-10 10:27:11,586 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.3258M (감소율: 94.10%)
2026-02-10 10:27:11,597 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:11,597 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:11,597 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:11,830 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 10:27:11,830 - INFO - ==================================================
2026-02-10 10:27:11,831 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.1581M (감소율: 97.14%)
2026-02-10 10:27:11,845 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:11,845 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:11,846 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-02-10 10:27:12,110 - INFO - ==================================================
2026-02-10 10:27:12,110 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0843M (감소율: 98.47%)
2026-02-10 10:27:12,120 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:12,120 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,120 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,376 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97453125)에 맞춰 변경되었습니다.
2026-02-10 10:27:12,376 - INFO - ==================================================
2026-02-10 10:27:12,377 - INFO -   [탐색  6] 희소도: 0.9745 -> 파라미터: 0.0500M (감소율: 99.09%)
2026-02-10 10:27:12,384 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:12,384 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,384 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,784 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9822656249999999)에 맞춰 변경되었습니다.
2026-02-10 10:27:12,784 - INFO - ==================================================
2026-02-10 10:27:12,784 - INFO -   [탐색  7] 희소도: 0.9823 -> 파라미터: 0.0388M (감소율: 99.30%)
2026-02-10 10:27:12,792 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:12,792 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,792 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 10:27:12,905 - INFO - ==================================================
2026-02-10 10:27:12,906 - INFO -   [탐색  8] 희소도: 0.9784 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:12,914 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:12,914 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:12,914 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:13,083 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9803320312499999)에 맞춰 변경되었습니다.
2026-02-10 10:27:13,084 - INFO - ==================================================
2026-02-10 10:27:13,085 - INFO -   [탐색  9] 희소도: 0.9803 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:13,096 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:13,097 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:13,097 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:13,292 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9793652343749999)에 맞춰 변경되었습니다.
2026-02-10 10:27:13,293 - INFO - ==================================================
2026-02-10 10:27:13,293 - INFO -   [탐색 10] 희소도: 0.9794 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:13,303 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:13,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:13,304 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:13,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9788818359374999)에 맞춰 변경되었습니다.
2026-02-10 10:27:13,515 - INFO - ==================================================
2026-02-10 10:27:13,516 - INFO -   [탐색 11] 희소도: 0.9789 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:13,528 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:13,529 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:13,529 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,052 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97912353515625)에 맞춰 변경되었습니다.
2026-02-10 10:27:14,052 - INFO - ==================================================
2026-02-10 10:27:14,053 - INFO -   [탐색 12] 희소도: 0.9791 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:14,062 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:14,063 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,063 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,365 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9792443847656249)에 맞춰 변경되었습니다.
2026-02-10 10:27:14,365 - INFO - ==================================================
2026-02-10 10:27:14,366 - INFO -   [탐색 13] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:14,380 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:14,380 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,381 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,580 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791839599609374)에 맞춰 변경되었습니다.
2026-02-10 10:27:14,580 - INFO - ==================================================
2026-02-10 10:27:14,581 - INFO -   [탐색 14] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:14,589 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:14,589 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,590 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,709 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791537475585936)에 맞춰 변경되었습니다.
2026-02-10 10:27:14,709 - INFO - ==================================================
2026-02-10 10:27:14,710 - INFO -   [탐색 15] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:14,717 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:14,718 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,718 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,825 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791688537597656)에 맞춰 변경되었습니다.
2026-02-10 10:27:14,825 - INFO - ==================================================
2026-02-10 10:27:14,825 - INFO -   [탐색 16] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:14,832 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:14,832 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:14,832 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,091 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791613006591796)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,091 - INFO - ==================================================
2026-02-10 10:27:15,092 - INFO -   [탐색 17] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:15,099 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,099 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,099 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,209 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791650772094727)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,209 - INFO - ==================================================
2026-02-10 10:27:15,209 - INFO -   [탐색 18] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:15,216 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,216 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,216 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,328 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791669654846191)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,328 - INFO - ==================================================
2026-02-10 10:27:15,329 - INFO -   [탐색 19] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:15,335 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,335 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,335 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,447 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791660213470459)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,447 - INFO - ==================================================
2026-02-10 10:27:15,447 - INFO -   [탐색 20] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:15,454 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,454 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,454 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,564 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791664934158325)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,565 - INFO - ==================================================
2026-02-10 10:27:15,565 - INFO -   [탐색 21] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:15,571 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,571 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,571 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,832 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791667294502258)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,832 - INFO - ==================================================
2026-02-10 10:27:15,833 - INFO -   [탐색 22] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:15,840 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,840 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,840 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,943 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666114330291)에 맞춰 변경되었습니다.
2026-02-10 10:27:15,943 - INFO - ==================================================
2026-02-10 10:27:15,943 - INFO -   [탐색 23] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:15,950 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:15,950 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:15,950 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,052 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666704416274)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,052 - INFO - ==================================================
2026-02-10 10:27:16,052 - INFO -   [탐색 24] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:16,059 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,059 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,059 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,161 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666409373283)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,161 - INFO - ==================================================
2026-02-10 10:27:16,161 - INFO -   [탐색 25] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:16,168 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,168 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,168 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666556894778)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,268 - INFO - ==================================================
2026-02-10 10:27:16,268 - INFO -   [탐색 26] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:16,275 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,275 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,275 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,537 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666630655527)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,537 - INFO - ==================================================
2026-02-10 10:27:16,538 - INFO -   [탐색 27] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:16,544 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,544 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,544 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,646 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666667535901)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,646 - INFO - ==================================================
2026-02-10 10:27:16,646 - INFO -   [탐색 28] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:16,653 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,653 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,653 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,753 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666649095714)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,753 - INFO - ==================================================
2026-02-10 10:27:16,754 - INFO -   [탐색 29] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:16,760 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,765 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,765 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,864 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666658315807)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,864 - INFO - ==================================================
2026-02-10 10:27:16,865 - INFO -   [탐색 30] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:16,871 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,871 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,871 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666662925854)에 맞춰 변경되었습니다.
2026-02-10 10:27:16,970 - INFO - ==================================================
2026-02-10 10:27:16,971 - INFO -   [탐색 31] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:16,977 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:16,977 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:16,977 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,238 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666665230878)에 맞춰 변경되었습니다.
2026-02-10 10:27:17,238 - INFO - ==================================================
2026-02-10 10:27:17,238 - INFO -   [탐색 32] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:17,245 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:17,245 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,245 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,346 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.979166666638339)에 맞춰 변경되었습니다.
2026-02-10 10:27:17,346 - INFO - ==================================================
2026-02-10 10:27:17,347 - INFO -   [탐색 33] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:17,353 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:17,353 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,353 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,454 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666959645)에 맞춰 변경되었습니다.
2026-02-10 10:27:17,454 - INFO - ==================================================
2026-02-10 10:27:17,454 - INFO -   [탐색 34] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:17,461 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:17,461 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,461 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,567 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666671517)에 맞춰 변경되었습니다.
2026-02-10 10:27:17,567 - INFO - ==================================================
2026-02-10 10:27:17,567 - INFO -   [탐색 35] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:17,574 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:17,574 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,574 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666527453)에 맞춰 변경되었습니다.
2026-02-10 10:27:17,681 - INFO - ==================================================
2026-02-10 10:27:17,682 - INFO -   [탐색 36] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:17,688 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:17,688 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,688 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666599486)에 맞춰 변경되었습니다.
2026-02-10 10:27:17,951 - INFO - ==================================================
2026-02-10 10:27:17,951 - INFO -   [탐색 37] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:17,958 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:17,958 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:17,958 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666635501)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,060 - INFO - ==================================================
2026-02-10 10:27:18,061 - INFO -   [탐색 38] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:18,067 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,067 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,067 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,168 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666653509)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,168 - INFO - ==================================================
2026-02-10 10:27:18,169 - INFO -   [탐색 39] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:18,175 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,175 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,175 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,282 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666662513)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,282 - INFO - ==================================================
2026-02-10 10:27:18,283 - INFO -   [탐색 40] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:18,289 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,289 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,289 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,396 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666667015)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,396 - INFO - ==================================================
2026-02-10 10:27:18,396 - INFO -   [탐색 41] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:18,403 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,403 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,403 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,665 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666664764)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,665 - INFO - ==================================================
2026-02-10 10:27:18,666 - INFO -   [탐색 42] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:18,672 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,672 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,673 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,773 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.979166666666589)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,774 - INFO - ==================================================
2026-02-10 10:27:18,774 - INFO -   [탐색 43] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:18,780 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,781 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,781 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,883 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666452)에 맞춰 변경되었습니다.
2026-02-10 10:27:18,883 - INFO - ==================================================
2026-02-10 10:27:18,883 - INFO -   [탐색 44] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:18,890 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:18,890 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:18,890 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,000 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666734)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,000 - INFO - ==================================================
2026-02-10 10:27:19,000 - INFO -   [탐색 45] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:19,007 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,007 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,007 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,115 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666593)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,115 - INFO - ==================================================
2026-02-10 10:27:19,115 - INFO -   [탐색 46] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:19,122 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,122 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,122 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,383 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666663)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,383 - INFO - ==================================================
2026-02-10 10:27:19,383 - INFO -   [탐색 47] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:19,390 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,390 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,390 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666698)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,492 - INFO - ==================================================
2026-02-10 10:27:19,492 - INFO -   [탐색 48] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:19,498 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,498 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,499 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,599 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666681)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,599 - INFO - ==================================================
2026-02-10 10:27:19,600 - INFO -   [탐색 49] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:19,606 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,606 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,606 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,706 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666672)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,706 - INFO - ==================================================
2026-02-10 10:27:19,706 - INFO -   [탐색 50] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:19,713 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,713 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,713 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,812 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:19,812 - INFO - ==================================================
2026-02-10 10:27:19,812 - INFO -   [탐색 51] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:19,819 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:19,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:19,819 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,080 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666665)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,080 - INFO - ==================================================
2026-02-10 10:27:20,081 - INFO -   [탐색 52] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:20,088 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,088 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,088 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666666)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,190 - INFO - ==================================================
2026-02-10 10:27:20,190 - INFO -   [탐색 53] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 10:27:20,196 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,196 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,197 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,297 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,297 - INFO - ==================================================
2026-02-10 10:27:20,297 - INFO -   [탐색 54] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:20,304 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,304 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,403 - INFO - ==================================================
2026-02-10 10:27:20,403 - INFO -   [탐색 55] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:20,410 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,410 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,410 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,509 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,510 - INFO - ==================================================
2026-02-10 10:27:20,510 - INFO -   [탐색 56] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:20,516 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,516 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,516 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,777 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,777 - INFO - ==================================================
2026-02-10 10:27:20,778 - INFO -   [탐색 57] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:20,784 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,784 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,785 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,886 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,886 - INFO - ==================================================
2026-02-10 10:27:20,886 - INFO -   [탐색 58] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:20,893 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:20,893 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,893 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:20,994 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:20,994 - INFO - ==================================================
2026-02-10 10:27:20,994 - INFO -   [탐색 59] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,001 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,001 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,001 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,100 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,100 - INFO - ==================================================
2026-02-10 10:27:21,100 - INFO -   [탐색 60] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,106 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,106 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,107 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,208 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,208 - INFO - ==================================================
2026-02-10 10:27:21,209 - INFO -   [탐색 61] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,215 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,215 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,215 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,477 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,477 - INFO - ==================================================
2026-02-10 10:27:21,478 - INFO -   [탐색 62] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,484 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,484 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,485 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,585 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,585 - INFO - ==================================================
2026-02-10 10:27:21,586 - INFO -   [탐색 63] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,592 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,592 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,592 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,700 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,701 - INFO - ==================================================
2026-02-10 10:27:21,701 - INFO -   [탐색 64] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,707 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,707 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,708 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,815 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,815 - INFO - ==================================================
2026-02-10 10:27:21,815 - INFO -   [탐색 65] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,822 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,822 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,822 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,923 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:21,923 - INFO - ==================================================
2026-02-10 10:27:21,923 - INFO -   [탐색 66] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:21,930 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:21,930 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:21,930 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:22,190 - INFO - ==================================================
2026-02-10 10:27:22,191 - INFO -   [탐색 67] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:22,198 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:22,198 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,198 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,304 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:22,304 - INFO - ==================================================
2026-02-10 10:27:22,304 - INFO -   [탐색 68] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:22,311 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:22,311 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,311 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,417 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:22,417 - INFO - ==================================================
2026-02-10 10:27:22,418 - INFO -   [탐색 69] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:22,424 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:22,424 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,424 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,530 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:22,530 - INFO - ==================================================
2026-02-10 10:27:22,530 - INFO -   [탐색 70] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:22,537 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:22,537 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,537 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,642 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:22,643 - INFO - ==================================================
2026-02-10 10:27:22,643 - INFO -   [탐색 71] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:22,649 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:22,649 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,649 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,912 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:22,912 - INFO - ==================================================
2026-02-10 10:27:22,913 - INFO -   [탐색 72] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:22,920 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:22,920 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:22,920 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,022 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,022 - INFO - ==================================================
2026-02-10 10:27:23,022 - INFO -   [탐색 73] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,029 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,029 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,029 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,129 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,129 - INFO - ==================================================
2026-02-10 10:27:23,130 - INFO -   [탐색 74] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,136 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,136 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,136 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,238 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,238 - INFO - ==================================================
2026-02-10 10:27:23,239 - INFO -   [탐색 75] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,245 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,245 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,245 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,354 - INFO - ==================================================
2026-02-10 10:27:23,354 - INFO -   [탐색 76] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,361 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,361 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,361 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,621 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,621 - INFO - ==================================================
2026-02-10 10:27:23,622 - INFO -   [탐색 77] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,628 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,628 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,629 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,730 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,730 - INFO - ==================================================
2026-02-10 10:27:23,730 - INFO -   [탐색 78] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,737 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,737 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,737 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,837 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,837 - INFO - ==================================================
2026-02-10 10:27:23,837 - INFO -   [탐색 79] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,844 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,844 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,844 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,946 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:23,946 - INFO - ==================================================
2026-02-10 10:27:23,946 - INFO -   [탐색 80] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:23,953 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:23,953 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:23,953 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,062 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:24,062 - INFO - ==================================================
2026-02-10 10:27:24,062 - INFO -   [탐색 81] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:24,069 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:24,069 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,069 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,331 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:24,331 - INFO - ==================================================
2026-02-10 10:27:24,331 - INFO -   [탐색 82] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:24,338 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:24,338 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,338 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,441 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:24,441 - INFO - ==================================================
2026-02-10 10:27:24,441 - INFO -   [탐색 83] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:24,448 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:24,448 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,448 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,548 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:24,548 - INFO - ==================================================
2026-02-10 10:27:24,549 - INFO -   [탐색 84] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:24,555 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:24,555 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,555 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,655 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:24,655 - INFO - ==================================================
2026-02-10 10:27:24,656 - INFO -   [탐색 85] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:24,662 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:24,662 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,662 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,768 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:24,768 - INFO - ==================================================
2026-02-10 10:27:24,768 - INFO -   [탐색 86] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:24,775 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:24,775 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:24,775 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,036 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,036 - INFO - ==================================================
2026-02-10 10:27:25,037 - INFO -   [탐색 87] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,043 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,043 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,044 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,145 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,145 - INFO - ==================================================
2026-02-10 10:27:25,146 - INFO -   [탐색 88] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,152 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,152 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,152 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,253 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,253 - INFO - ==================================================
2026-02-10 10:27:25,253 - INFO -   [탐색 89] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,259 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,259 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,260 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,359 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,359 - INFO - ==================================================
2026-02-10 10:27:25,360 - INFO -   [탐색 90] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,366 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,366 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,366 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,466 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,466 - INFO - ==================================================
2026-02-10 10:27:25,467 - INFO -   [탐색 91] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,473 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,473 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,473 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,735 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,735 - INFO - ==================================================
2026-02-10 10:27:25,736 - INFO -   [탐색 92] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,743 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,743 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,743 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,844 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,844 - INFO - ==================================================
2026-02-10 10:27:25,845 - INFO -   [탐색 93] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,851 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,851 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,851 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:25,951 - INFO - ==================================================
2026-02-10 10:27:25,952 - INFO -   [탐색 94] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:25,958 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:25,958 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:25,958 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,060 - INFO - ==================================================
2026-02-10 10:27:26,060 - INFO -   [탐색 95] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:26,067 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:26,067 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,067 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,176 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,176 - INFO - ==================================================
2026-02-10 10:27:26,177 - INFO -   [탐색 96] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:26,183 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:26,184 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,184 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,446 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,446 - INFO - ==================================================
2026-02-10 10:27:26,446 - INFO -   [탐색 97] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:26,453 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:26,453 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,453 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,555 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,555 - INFO - ==================================================
2026-02-10 10:27:26,555 - INFO -   [탐색 98] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:26,562 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:26,562 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,562 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,662 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,662 - INFO - ==================================================
2026-02-10 10:27:26,662 - INFO -   [탐색 99] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:26,669 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:26,669 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,669 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,771 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,771 - INFO - ==================================================
2026-02-10 10:27:26,771 - INFO -   [탐색 100] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 10:27:26,771 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.9784 입니다.
2026-02-10 10:27:26,771 - INFO - ================================================================================
2026-02-10 10:27:26,772 - INFO - 계산된 Pruning 정보(희소도: 0.9784)를 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/pruning_info.yaml'에 저장했습니다.
2026-02-10 10:27:26,781 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 10:27:26,799 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:27:26,799 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,800 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:27:26,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 10:27:26,906 - INFO - ==================================================
2026-02-10 10:27:26,906 - INFO - ==================================================
2026-02-10 10:27:26,906 - INFO - 모델 파라미터 수:
2026-02-10 10:27:26,906 - INFO -   - 총 파라미터: 49,678 개
2026-02-10 10:27:26,906 - INFO -   - 학습 가능한 파라미터: 49,678 개
2026-02-10 10:27:26,916 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 10:27:26,934 - INFO - FLOPs가 2.1493 GFLOPs에서 0.0163 GFLOPs로 감소했습니다 (감소율: 99.24%).
2026-02-10 10:27:26,935 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 10:27:26,935 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 10:27:26,935 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 10:27:26,935 - INFO - ==================================================
2026-02-10 10:27:26,935 - INFO - train 모드를 시작합니다.
2026-02-10 10:27:26,935 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 10:27:26,935 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 10:27:26,935 - INFO - --------------------------------------------------
2026-02-10 10:27:26,935 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 10:27:28,507 - INFO - [Train] [11/90] | Loss: 0.6682 | Train Acc: 66.29%
2026-02-10 10:27:28,921 - INFO - [Valid] [11/90] | Loss: 0.6551 | Val Acc: 64.01%
2026-02-10 10:27:28,923 - INFO - [Metrics for 'abnormal'] | Precision: 0.5989 | Recall: 0.6752 | F1: 0.6347
2026-02-10 10:27:28,924 - INFO - [Metrics for 'normal'] | Precision: 0.6852 | Recall: 0.6099 | F1: 0.6453
2026-02-10 10:27:28,931 - INFO - [Best Model Saved] (val loss: 0.6551) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:28,931 - INFO - --------------------------------------------------
2026-02-10 10:27:28,931 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 10:27:30,500 - INFO - [Train] [12/90] | Loss: 0.6131 | Train Acc: 71.65%
2026-02-10 10:27:31,258 - INFO - [Valid] [12/90] | Loss: 0.6260 | Val Acc: 67.55%
2026-02-10 10:27:31,262 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.4331 | F1: 0.5528
2026-02-10 10:27:31,263 - INFO - [Metrics for 'normal'] | Precision: 0.6440 | Recall: 0.8846 | F1: 0.7454
2026-02-10 10:27:31,273 - INFO - [Best Model Saved] (val loss: 0.6260) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:31,273 - INFO - --------------------------------------------------
2026-02-10 10:27:31,274 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 10:27:33,500 - INFO - [Train] [13/90] | Loss: 0.5847 | Train Acc: 73.66%
2026-02-10 10:27:34,085 - INFO - [Valid] [13/90] | Loss: 0.5998 | Val Acc: 70.21%
2026-02-10 10:27:34,089 - INFO - [Metrics for 'abnormal'] | Precision: 0.6918 | Recall: 0.6433 | F1: 0.6667
2026-02-10 10:27:34,089 - INFO - [Metrics for 'normal'] | Precision: 0.7098 | Recall: 0.7527 | F1: 0.7307
2026-02-10 10:27:34,100 - INFO - [Best Model Saved] (val loss: 0.5998) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:34,100 - INFO - --------------------------------------------------
2026-02-10 10:27:34,101 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 10:27:36,478 - INFO - [Train] [14/90] | Loss: 0.5504 | Train Acc: 76.86%
2026-02-10 10:27:37,009 - INFO - [Valid] [14/90] | Loss: 0.5664 | Val Acc: 75.52%
2026-02-10 10:27:37,014 - INFO - [Metrics for 'abnormal'] | Precision: 0.7434 | Recall: 0.7197 | F1: 0.7314
2026-02-10 10:27:37,014 - INFO - [Metrics for 'normal'] | Precision: 0.7647 | Recall: 0.7857 | F1: 0.7751
2026-02-10 10:27:37,029 - INFO - [Best Model Saved] (val loss: 0.5664) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:37,029 - INFO - --------------------------------------------------
2026-02-10 10:27:37,030 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 10:27:39,485 - INFO - [Train] [15/90] | Loss: 0.5265 | Train Acc: 78.42%
2026-02-10 10:27:39,998 - INFO - [Valid] [15/90] | Loss: 0.5696 | Val Acc: 73.75%
2026-02-10 10:27:40,002 - INFO - [Metrics for 'abnormal'] | Precision: 0.6771 | Recall: 0.8280 | F1: 0.7450
2026-02-10 10:27:40,002 - INFO - [Metrics for 'normal'] | Precision: 0.8163 | Recall: 0.6593 | F1: 0.7295
2026-02-10 10:27:40,003 - INFO - --------------------------------------------------
2026-02-10 10:27:40,004 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 10:27:42,474 - INFO - [Train] [16/90] | Loss: 0.5092 | Train Acc: 80.06%
2026-02-10 10:27:43,095 - INFO - [Valid] [16/90] | Loss: 0.5566 | Val Acc: 74.63%
2026-02-10 10:27:43,100 - INFO - [Metrics for 'abnormal'] | Precision: 0.6898 | Recall: 0.8217 | F1: 0.7500
2026-02-10 10:27:43,100 - INFO - [Metrics for 'normal'] | Precision: 0.8158 | Recall: 0.6813 | F1: 0.7425
2026-02-10 10:27:43,111 - INFO - [Best Model Saved] (val loss: 0.5566) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:43,111 - INFO - --------------------------------------------------
2026-02-10 10:27:43,112 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 10:27:45,606 - INFO - [Train] [17/90] | Loss: 0.5160 | Train Acc: 79.24%
2026-02-10 10:27:46,227 - INFO - [Valid] [17/90] | Loss: 0.5440 | Val Acc: 75.52%
2026-02-10 10:27:46,232 - INFO - [Metrics for 'abnormal'] | Precision: 0.7256 | Recall: 0.7580 | F1: 0.7414
2026-02-10 10:27:46,232 - INFO - [Metrics for 'normal'] | Precision: 0.7829 | Recall: 0.7527 | F1: 0.7675
2026-02-10 10:27:46,243 - INFO - [Best Model Saved] (val loss: 0.5440) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:46,243 - INFO - --------------------------------------------------
2026-02-10 10:27:46,244 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 10:27:48,833 - INFO - [Train] [18/90] | Loss: 0.5002 | Train Acc: 80.13%
2026-02-10 10:27:49,449 - INFO - [Valid] [18/90] | Loss: 0.5353 | Val Acc: 78.76%
2026-02-10 10:27:49,453 - INFO - [Metrics for 'abnormal'] | Precision: 0.7972 | Recall: 0.7261 | F1: 0.7600
2026-02-10 10:27:49,453 - INFO - [Metrics for 'normal'] | Precision: 0.7806 | Recall: 0.8407 | F1: 0.8095
2026-02-10 10:27:49,463 - INFO - [Best Model Saved] (val loss: 0.5353) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:49,463 - INFO - --------------------------------------------------
2026-02-10 10:27:49,464 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 10:27:51,911 - INFO - [Train] [19/90] | Loss: 0.4953 | Train Acc: 80.95%
2026-02-10 10:27:52,545 - INFO - [Valid] [19/90] | Loss: 0.5436 | Val Acc: 75.22%
2026-02-10 10:27:52,548 - INFO - [Metrics for 'abnormal'] | Precision: 0.7212 | Recall: 0.7580 | F1: 0.7391
2026-02-10 10:27:52,548 - INFO - [Metrics for 'normal'] | Precision: 0.7816 | Recall: 0.7473 | F1: 0.7640
2026-02-10 10:27:52,549 - INFO - --------------------------------------------------
2026-02-10 10:27:52,550 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 10:27:55,122 - INFO - [Train] [20/90] | Loss: 0.4941 | Train Acc: 80.95%
2026-02-10 10:27:55,763 - INFO - [Valid] [20/90] | Loss: 0.5354 | Val Acc: 76.70%
2026-02-10 10:27:55,767 - INFO - [Metrics for 'abnormal'] | Precision: 0.7407 | Recall: 0.7643 | F1: 0.7524
2026-02-10 10:27:55,767 - INFO - [Metrics for 'normal'] | Precision: 0.7910 | Recall: 0.7692 | F1: 0.7799
2026-02-10 10:27:55,768 - INFO - --------------------------------------------------
2026-02-10 10:27:55,769 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 10:27:58,367 - INFO - [Train] [21/90] | Loss: 0.4899 | Train Acc: 81.18%
2026-02-10 10:27:58,881 - INFO - [Valid] [21/90] | Loss: 0.5334 | Val Acc: 76.99%
2026-02-10 10:27:58,886 - INFO - [Metrics for 'abnormal'] | Precision: 0.7548 | Recall: 0.7452 | F1: 0.7500
2026-02-10 10:27:58,886 - INFO - [Metrics for 'normal'] | Precision: 0.7826 | Recall: 0.7912 | F1: 0.7869
2026-02-10 10:27:58,896 - INFO - [Best Model Saved] (val loss: 0.5334) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:27:58,896 - INFO - --------------------------------------------------
2026-02-10 10:27:58,897 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 10:28:01,390 - INFO - [Train] [22/90] | Loss: 0.4873 | Train Acc: 80.88%
2026-02-10 10:28:01,930 - INFO - [Valid] [22/90] | Loss: 0.5256 | Val Acc: 78.17%
2026-02-10 10:28:01,935 - INFO - [Metrics for 'abnormal'] | Precision: 0.7823 | Recall: 0.7325 | F1: 0.7566
2026-02-10 10:28:01,935 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.8242 | F1: 0.8021
2026-02-10 10:28:01,944 - INFO - [Best Model Saved] (val loss: 0.5256) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:01,945 - INFO - --------------------------------------------------
2026-02-10 10:28:01,946 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 10:28:04,432 - INFO - [Train] [23/90] | Loss: 0.4772 | Train Acc: 82.07%
2026-02-10 10:28:05,055 - INFO - [Valid] [23/90] | Loss: 0.5284 | Val Acc: 77.29%
2026-02-10 10:28:05,059 - INFO - [Metrics for 'abnormal'] | Precision: 0.7857 | Recall: 0.7006 | F1: 0.7407
2026-02-10 10:28:05,059 - INFO - [Metrics for 'normal'] | Precision: 0.7638 | Recall: 0.8352 | F1: 0.7979
2026-02-10 10:28:05,061 - INFO - --------------------------------------------------
2026-02-10 10:28:05,061 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 10:28:07,590 - INFO - [Train] [24/90] | Loss: 0.4845 | Train Acc: 81.92%
2026-02-10 10:28:08,157 - INFO - [Valid] [24/90] | Loss: 0.5252 | Val Acc: 78.47%
2026-02-10 10:28:08,162 - INFO - [Metrics for 'abnormal'] | Precision: 0.7530 | Recall: 0.7962 | F1: 0.7740
2026-02-10 10:28:08,162 - INFO - [Metrics for 'normal'] | Precision: 0.8150 | Recall: 0.7747 | F1: 0.7944
2026-02-10 10:28:08,172 - INFO - [Best Model Saved] (val loss: 0.5252) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:08,172 - INFO - --------------------------------------------------
2026-02-10 10:28:08,174 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 10:28:10,665 - INFO - [Train] [25/90] | Loss: 0.4775 | Train Acc: 82.22%
2026-02-10 10:28:11,248 - INFO - [Valid] [25/90] | Loss: 0.5207 | Val Acc: 78.76%
2026-02-10 10:28:11,252 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-02-10 10:28:11,253 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-02-10 10:28:11,263 - INFO - [Best Model Saved] (val loss: 0.5207) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:11,263 - INFO - --------------------------------------------------
2026-02-10 10:28:11,263 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 10:28:13,810 - INFO - [Train] [26/90] | Loss: 0.4828 | Train Acc: 81.32%
2026-02-10 10:28:14,435 - INFO - [Valid] [26/90] | Loss: 0.5191 | Val Acc: 78.17%
2026-02-10 10:28:14,439 - INFO - [Metrics for 'abnormal'] | Precision: 0.7578 | Recall: 0.7771 | F1: 0.7673
2026-02-10 10:28:14,439 - INFO - [Metrics for 'normal'] | Precision: 0.8034 | Recall: 0.7857 | F1: 0.7944
2026-02-10 10:28:14,450 - INFO - [Best Model Saved] (val loss: 0.5191) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:14,450 - INFO - --------------------------------------------------
2026-02-10 10:28:14,450 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 10:28:17,014 - INFO - [Train] [27/90] | Loss: 0.4750 | Train Acc: 82.14%
2026-02-10 10:28:17,583 - INFO - [Valid] [27/90] | Loss: 0.5180 | Val Acc: 79.35%
2026-02-10 10:28:17,587 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-02-10 10:28:17,587 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-02-10 10:28:17,597 - INFO - [Best Model Saved] (val loss: 0.5180) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:17,598 - INFO - --------------------------------------------------
2026-02-10 10:28:17,598 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 10:28:20,117 - INFO - [Train] [28/90] | Loss: 0.4673 | Train Acc: 83.18%
2026-02-10 10:28:20,715 - INFO - [Valid] [28/90] | Loss: 0.5217 | Val Acc: 79.35%
2026-02-10 10:28:20,720 - INFO - [Metrics for 'abnormal'] | Precision: 0.7843 | Recall: 0.7643 | F1: 0.7742
2026-02-10 10:28:20,720 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.8187 | F1: 0.8098
2026-02-10 10:28:20,722 - INFO - --------------------------------------------------
2026-02-10 10:28:20,722 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 10:28:23,257 - INFO - [Train] [29/90] | Loss: 0.4709 | Train Acc: 82.81%
2026-02-10 10:28:23,789 - INFO - [Valid] [29/90] | Loss: 0.5232 | Val Acc: 79.65%
2026-02-10 10:28:23,793 - INFO - [Metrics for 'abnormal'] | Precision: 0.7716 | Recall: 0.7962 | F1: 0.7837
2026-02-10 10:28:23,793 - INFO - [Metrics for 'normal'] | Precision: 0.8192 | Recall: 0.7967 | F1: 0.8078
2026-02-10 10:28:23,795 - INFO - --------------------------------------------------
2026-02-10 10:28:23,795 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 10:28:26,327 - INFO - [Train] [30/90] | Loss: 0.4651 | Train Acc: 83.18%
2026-02-10 10:28:26,965 - INFO - [Valid] [30/90] | Loss: 0.5214 | Val Acc: 78.76%
2026-02-10 10:28:26,969 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-02-10 10:28:26,969 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-02-10 10:28:26,971 - INFO - --------------------------------------------------
2026-02-10 10:28:26,972 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 10:28:29,513 - INFO - [Train] [31/90] | Loss: 0.4623 | Train Acc: 83.48%
2026-02-10 10:28:30,059 - INFO - [Valid] [31/90] | Loss: 0.5636 | Val Acc: 74.34%
2026-02-10 10:28:30,063 - INFO - [Metrics for 'abnormal'] | Precision: 0.6750 | Recall: 0.8599 | F1: 0.7563
2026-02-10 10:28:30,064 - INFO - [Metrics for 'normal'] | Precision: 0.8417 | Recall: 0.6429 | F1: 0.7290
2026-02-10 10:28:30,065 - INFO - --------------------------------------------------
2026-02-10 10:28:30,066 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 10:28:32,620 - INFO - [Train] [32/90] | Loss: 0.4614 | Train Acc: 82.59%
2026-02-10 10:28:33,151 - INFO - [Valid] [32/90] | Loss: 0.5160 | Val Acc: 78.17%
2026-02-10 10:28:33,155 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.7898 | F1: 0.7702
2026-02-10 10:28:33,155 - INFO - [Metrics for 'normal'] | Precision: 0.8103 | Recall: 0.7747 | F1: 0.7921
2026-02-10 10:28:33,165 - INFO - [Best Model Saved] (val loss: 0.5160) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:33,165 - INFO - --------------------------------------------------
2026-02-10 10:28:33,166 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 10:28:35,722 - INFO - [Train] [33/90] | Loss: 0.4595 | Train Acc: 82.66%
2026-02-10 10:28:36,243 - INFO - [Valid] [33/90] | Loss: 0.5166 | Val Acc: 78.47%
2026-02-10 10:28:36,247 - INFO - [Metrics for 'abnormal'] | Precision: 0.7471 | Recall: 0.8089 | F1: 0.7768
2026-02-10 10:28:36,247 - INFO - [Metrics for 'normal'] | Precision: 0.8225 | Recall: 0.7637 | F1: 0.7920
2026-02-10 10:28:36,249 - INFO - --------------------------------------------------
2026-02-10 10:28:36,249 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 10:28:38,710 - INFO - [Train] [34/90] | Loss: 0.4672 | Train Acc: 82.74%
2026-02-10 10:28:39,317 - INFO - [Valid] [34/90] | Loss: 0.5140 | Val Acc: 78.47%
2026-02-10 10:28:39,322 - INFO - [Metrics for 'abnormal'] | Precision: 0.7530 | Recall: 0.7962 | F1: 0.7740
2026-02-10 10:28:39,322 - INFO - [Metrics for 'normal'] | Precision: 0.8150 | Recall: 0.7747 | F1: 0.7944
2026-02-10 10:28:39,333 - INFO - [Best Model Saved] (val loss: 0.5140) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:39,333 - INFO - --------------------------------------------------
2026-02-10 10:28:39,334 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 10:28:41,935 - INFO - [Train] [35/90] | Loss: 0.4548 | Train Acc: 83.33%
2026-02-10 10:28:42,532 - INFO - [Valid] [35/90] | Loss: 0.5190 | Val Acc: 78.47%
2026-02-10 10:28:42,536 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8025 | F1: 0.7754
2026-02-10 10:28:42,536 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.7692 | F1: 0.7932
2026-02-10 10:28:42,537 - INFO - --------------------------------------------------
2026-02-10 10:28:42,538 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 10:28:45,058 - INFO - [Train] [36/90] | Loss: 0.4556 | Train Acc: 82.66%
2026-02-10 10:28:45,617 - INFO - [Valid] [36/90] | Loss: 0.5171 | Val Acc: 79.06%
2026-02-10 10:28:45,621 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8217 | F1: 0.7842
2026-02-10 10:28:45,621 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7637 | F1: 0.7966
2026-02-10 10:28:45,622 - INFO - --------------------------------------------------
2026-02-10 10:28:45,623 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 10:28:48,163 - INFO - [Train] [37/90] | Loss: 0.4638 | Train Acc: 82.59%
2026-02-10 10:28:48,740 - INFO - [Valid] [37/90] | Loss: 0.5277 | Val Acc: 76.99%
2026-02-10 10:28:48,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.7135 | Recall: 0.8408 | F1: 0.7719
2026-02-10 10:28:48,744 - INFO - [Metrics for 'normal'] | Precision: 0.8377 | Recall: 0.7088 | F1: 0.7679
2026-02-10 10:28:48,745 - INFO - --------------------------------------------------
2026-02-10 10:28:48,746 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 10:28:51,220 - INFO - [Train] [38/90] | Loss: 0.4604 | Train Acc: 82.74%
2026-02-10 10:28:51,850 - INFO - [Valid] [38/90] | Loss: 0.5095 | Val Acc: 79.06%
2026-02-10 10:28:51,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-02-10 10:28:51,854 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-02-10 10:28:51,864 - INFO - [Best Model Saved] (val loss: 0.5095) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:51,864 - INFO - --------------------------------------------------
2026-02-10 10:28:51,865 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 10:28:54,400 - INFO - [Train] [39/90] | Loss: 0.4562 | Train Acc: 83.41%
2026-02-10 10:28:54,929 - INFO - [Valid] [39/90] | Loss: 0.5083 | Val Acc: 78.47%
2026-02-10 10:28:54,933 - INFO - [Metrics for 'abnormal'] | Precision: 0.7442 | Recall: 0.8153 | F1: 0.7781
2026-02-10 10:28:54,933 - INFO - [Metrics for 'normal'] | Precision: 0.8263 | Recall: 0.7582 | F1: 0.7908
2026-02-10 10:28:54,943 - INFO - [Best Model Saved] (val loss: 0.5083) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:28:54,943 - INFO - --------------------------------------------------
2026-02-10 10:28:54,944 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 10:28:57,463 - INFO - [Train] [40/90] | Loss: 0.4507 | Train Acc: 83.78%
2026-02-10 10:28:58,043 - INFO - [Valid] [40/90] | Loss: 0.5191 | Val Acc: 79.06%
2026-02-10 10:28:58,047 - INFO - [Metrics for 'abnormal'] | Precision: 0.8162 | Recall: 0.7070 | F1: 0.7577
2026-02-10 10:28:58,047 - INFO - [Metrics for 'normal'] | Precision: 0.7734 | Recall: 0.8626 | F1: 0.8156
2026-02-10 10:28:58,048 - INFO - --------------------------------------------------
2026-02-10 10:28:58,049 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 10:29:00,517 - INFO - [Train] [41/90] | Loss: 0.4572 | Train Acc: 84.00%
2026-02-10 10:29:01,132 - INFO - [Valid] [41/90] | Loss: 0.5084 | Val Acc: 78.47%
2026-02-10 10:29:01,137 - INFO - [Metrics for 'abnormal'] | Precision: 0.7442 | Recall: 0.8153 | F1: 0.7781
2026-02-10 10:29:01,137 - INFO - [Metrics for 'normal'] | Precision: 0.8263 | Recall: 0.7582 | F1: 0.7908
2026-02-10 10:29:01,138 - INFO - --------------------------------------------------
2026-02-10 10:29:01,139 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 10:29:03,667 - INFO - [Train] [42/90] | Loss: 0.4521 | Train Acc: 82.96%
2026-02-10 10:29:04,228 - INFO - [Valid] [42/90] | Loss: 0.4989 | Val Acc: 80.83%
2026-02-10 10:29:04,232 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-02-10 10:29:04,232 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-02-10 10:29:04,242 - INFO - [Best Model Saved] (val loss: 0.4989) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:29:04,243 - INFO - --------------------------------------------------
2026-02-10 10:29:04,243 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 10:29:06,699 - INFO - [Train] [43/90] | Loss: 0.4468 | Train Acc: 83.85%
2026-02-10 10:29:07,339 - INFO - [Valid] [43/90] | Loss: 0.4985 | Val Acc: 79.35%
2026-02-10 10:29:07,344 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.7580 | F1: 0.7727
2026-02-10 10:29:07,344 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8242 | F1: 0.8108
2026-02-10 10:29:07,355 - INFO - [Best Model Saved] (val loss: 0.4985) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:29:07,355 - INFO - --------------------------------------------------
2026-02-10 10:29:07,355 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 10:29:09,903 - INFO - [Train] [44/90] | Loss: 0.4460 | Train Acc: 83.63%
2026-02-10 10:29:10,497 - INFO - [Valid] [44/90] | Loss: 0.4981 | Val Acc: 79.35%
2026-02-10 10:29:10,502 - INFO - [Metrics for 'abnormal'] | Precision: 0.7702 | Recall: 0.7898 | F1: 0.7799
2026-02-10 10:29:10,502 - INFO - [Metrics for 'normal'] | Precision: 0.8146 | Recall: 0.7967 | F1: 0.8056
2026-02-10 10:29:10,513 - INFO - [Best Model Saved] (val loss: 0.4981) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:29:10,513 - INFO - --------------------------------------------------
2026-02-10 10:29:10,513 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 10:29:13,109 - INFO - [Train] [45/90] | Loss: 0.4475 | Train Acc: 84.30%
2026-02-10 10:29:13,710 - INFO - [Valid] [45/90] | Loss: 0.4996 | Val Acc: 78.47%
2026-02-10 10:29:13,714 - INFO - [Metrics for 'abnormal'] | Precision: 0.7838 | Recall: 0.7389 | F1: 0.7607
2026-02-10 10:29:13,715 - INFO - [Metrics for 'normal'] | Precision: 0.7853 | Recall: 0.8242 | F1: 0.8043
2026-02-10 10:29:13,716 - INFO - --------------------------------------------------
2026-02-10 10:29:13,717 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 10:29:16,192 - INFO - [Train] [46/90] | Loss: 0.4528 | Train Acc: 82.66%
2026-02-10 10:29:16,847 - INFO - [Valid] [46/90] | Loss: 0.4903 | Val Acc: 79.06%
2026-02-10 10:29:16,851 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-02-10 10:29:16,852 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-02-10 10:29:16,862 - INFO - [Best Model Saved] (val loss: 0.4903) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:29:16,862 - INFO - --------------------------------------------------
2026-02-10 10:29:16,863 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 10:29:19,322 - INFO - [Train] [47/90] | Loss: 0.4381 | Train Acc: 84.38%
2026-02-10 10:29:19,918 - INFO - [Valid] [47/90] | Loss: 0.4931 | Val Acc: 81.42%
2026-02-10 10:29:19,923 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-02-10 10:29:19,923 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-02-10 10:29:19,924 - INFO - --------------------------------------------------
2026-02-10 10:29:19,925 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 10:29:22,450 - INFO - [Train] [48/90] | Loss: 0.4456 | Train Acc: 83.71%
2026-02-10 10:29:23,031 - INFO - [Valid] [48/90] | Loss: 0.4887 | Val Acc: 79.35%
2026-02-10 10:29:23,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-02-10 10:29:23,036 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-02-10 10:29:23,046 - INFO - [Best Model Saved] (val loss: 0.4887) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:29:23,047 - INFO - --------------------------------------------------
2026-02-10 10:29:23,047 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 10:29:25,550 - INFO - [Train] [49/90] | Loss: 0.4443 | Train Acc: 83.63%
2026-02-10 10:29:26,140 - INFO - [Valid] [49/90] | Loss: 0.4897 | Val Acc: 81.71%
2026-02-10 10:29:26,144 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-02-10 10:29:26,145 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-02-10 10:29:26,146 - INFO - --------------------------------------------------
2026-02-10 10:29:26,147 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 10:29:28,628 - INFO - [Train] [50/90] | Loss: 0.4370 | Train Acc: 84.60%
2026-02-10 10:29:29,248 - INFO - [Valid] [50/90] | Loss: 0.5164 | Val Acc: 78.47%
2026-02-10 10:29:29,252 - INFO - [Metrics for 'abnormal'] | Precision: 0.7958 | Recall: 0.7197 | F1: 0.7559
2026-02-10 10:29:29,252 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8407 | F1: 0.8074
2026-02-10 10:29:29,254 - INFO - --------------------------------------------------
2026-02-10 10:29:29,254 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 10:29:31,728 - INFO - [Train] [51/90] | Loss: 0.4316 | Train Acc: 84.90%
2026-02-10 10:29:32,386 - INFO - [Valid] [51/90] | Loss: 0.5092 | Val Acc: 80.83%
2026-02-10 10:29:32,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.8286 | Recall: 0.7389 | F1: 0.7811
2026-02-10 10:29:32,390 - INFO - [Metrics for 'normal'] | Precision: 0.7940 | Recall: 0.8681 | F1: 0.8294
2026-02-10 10:29:32,392 - INFO - --------------------------------------------------
2026-02-10 10:29:32,393 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 10:29:34,883 - INFO - [Train] [52/90] | Loss: 0.4391 | Train Acc: 84.38%
2026-02-10 10:29:35,561 - INFO - [Valid] [52/90] | Loss: 0.4932 | Val Acc: 79.65%
2026-02-10 10:29:35,565 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-02-10 10:29:35,565 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-02-10 10:29:35,566 - INFO - --------------------------------------------------
2026-02-10 10:29:35,567 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 10:29:38,065 - INFO - [Train] [53/90] | Loss: 0.4348 | Train Acc: 84.75%
2026-02-10 10:29:38,683 - INFO - [Valid] [53/90] | Loss: 0.4955 | Val Acc: 79.65%
2026-02-10 10:29:38,688 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-02-10 10:29:38,688 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-02-10 10:29:38,689 - INFO - --------------------------------------------------
2026-02-10 10:29:38,690 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 10:29:41,199 - INFO - [Train] [54/90] | Loss: 0.4270 | Train Acc: 85.57%
2026-02-10 10:29:41,804 - INFO - [Valid] [54/90] | Loss: 0.4820 | Val Acc: 80.83%
2026-02-10 10:29:41,808 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-02-10 10:29:41,808 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-02-10 10:29:41,820 - INFO - [Best Model Saved] (val loss: 0.4820) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:29:41,821 - INFO - --------------------------------------------------
2026-02-10 10:29:41,822 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 10:29:44,299 - INFO - [Train] [55/90] | Loss: 0.4315 | Train Acc: 85.27%
2026-02-10 10:29:44,894 - INFO - [Valid] [55/90] | Loss: 0.4933 | Val Acc: 80.24%
2026-02-10 10:29:44,898 - INFO - [Metrics for 'abnormal'] | Precision: 0.8125 | Recall: 0.7452 | F1: 0.7774
2026-02-10 10:29:44,899 - INFO - [Metrics for 'normal'] | Precision: 0.7949 | Recall: 0.8516 | F1: 0.8223
2026-02-10 10:29:44,900 - INFO - --------------------------------------------------
2026-02-10 10:29:44,901 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 10:29:47,493 - INFO - [Train] [56/90] | Loss: 0.4265 | Train Acc: 84.67%
2026-02-10 10:29:48,043 - INFO - [Valid] [56/90] | Loss: 0.4842 | Val Acc: 80.24%
2026-02-10 10:29:48,048 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-02-10 10:29:48,048 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-02-10 10:29:48,049 - INFO - --------------------------------------------------
2026-02-10 10:29:48,051 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 10:29:50,585 - INFO - [Train] [57/90] | Loss: 0.4249 | Train Acc: 85.19%
2026-02-10 10:29:51,182 - INFO - [Valid] [57/90] | Loss: 0.4845 | Val Acc: 82.60%
2026-02-10 10:29:51,186 - INFO - [Metrics for 'abnormal'] | Precision: 0.7816 | Recall: 0.8662 | F1: 0.8218
2026-02-10 10:29:51,187 - INFO - [Metrics for 'normal'] | Precision: 0.8727 | Recall: 0.7912 | F1: 0.8300
2026-02-10 10:29:51,188 - INFO - --------------------------------------------------
2026-02-10 10:29:51,189 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 10:29:53,599 - INFO - [Train] [58/90] | Loss: 0.4227 | Train Acc: 85.42%
2026-02-10 10:29:54,181 - INFO - [Valid] [58/90] | Loss: 0.4861 | Val Acc: 80.24%
2026-02-10 10:29:54,185 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-02-10 10:29:54,185 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-02-10 10:29:54,186 - INFO - --------------------------------------------------
2026-02-10 10:29:54,187 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 10:29:56,651 - INFO - [Train] [59/90] | Loss: 0.4183 | Train Acc: 86.24%
2026-02-10 10:29:57,219 - INFO - [Valid] [59/90] | Loss: 0.4841 | Val Acc: 80.83%
2026-02-10 10:29:57,223 - INFO - [Metrics for 'abnormal'] | Precision: 0.8151 | Recall: 0.7580 | F1: 0.7855
2026-02-10 10:29:57,223 - INFO - [Metrics for 'normal'] | Precision: 0.8031 | Recall: 0.8516 | F1: 0.8267
2026-02-10 10:29:57,224 - INFO - --------------------------------------------------
2026-02-10 10:29:57,225 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 10:29:59,649 - INFO - [Train] [60/90] | Loss: 0.4182 | Train Acc: 85.49%
2026-02-10 10:30:00,164 - INFO - [Valid] [60/90] | Loss: 0.4855 | Val Acc: 80.24%
2026-02-10 10:30:00,169 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-02-10 10:30:00,169 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-02-10 10:30:00,170 - INFO - --------------------------------------------------
2026-02-10 10:30:00,171 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 10:30:02,642 - INFO - [Train] [61/90] | Loss: 0.4153 | Train Acc: 85.86%
2026-02-10 10:30:03,232 - INFO - [Valid] [61/90] | Loss: 0.4851 | Val Acc: 80.24%
2026-02-10 10:30:03,236 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-02-10 10:30:03,237 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-02-10 10:30:03,238 - INFO - --------------------------------------------------
2026-02-10 10:30:03,239 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 10:30:05,767 - INFO - [Train] [62/90] | Loss: 0.4187 | Train Acc: 86.09%
2026-02-10 10:30:06,344 - INFO - [Valid] [62/90] | Loss: 0.4835 | Val Acc: 81.12%
2026-02-10 10:30:06,349 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-02-10 10:30:06,349 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-02-10 10:30:06,350 - INFO - --------------------------------------------------
2026-02-10 10:30:06,351 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 10:30:08,834 - INFO - [Train] [63/90] | Loss: 0.4122 | Train Acc: 86.01%
2026-02-10 10:30:09,417 - INFO - [Valid] [63/90] | Loss: 0.4935 | Val Acc: 80.83%
2026-02-10 10:30:09,421 - INFO - [Metrics for 'abnormal'] | Precision: 0.7949 | Recall: 0.7898 | F1: 0.7923
2026-02-10 10:30:09,421 - INFO - [Metrics for 'normal'] | Precision: 0.8197 | Recall: 0.8242 | F1: 0.8219
2026-02-10 10:30:09,422 - INFO - --------------------------------------------------
2026-02-10 10:30:09,423 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 10:30:12,037 - INFO - [Train] [64/90] | Loss: 0.4143 | Train Acc: 85.64%
2026-02-10 10:30:12,576 - INFO - [Valid] [64/90] | Loss: 0.4775 | Val Acc: 82.30%
2026-02-10 10:30:12,581 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-02-10 10:30:12,581 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-02-10 10:30:12,596 - INFO - [Best Model Saved] (val loss: 0.4775) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:30:12,597 - INFO - --------------------------------------------------
2026-02-10 10:30:12,598 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 10:30:15,006 - INFO - [Train] [65/90] | Loss: 0.4189 | Train Acc: 85.49%
2026-02-10 10:30:15,550 - INFO - [Valid] [65/90] | Loss: 0.4708 | Val Acc: 81.12%
2026-02-10 10:30:15,554 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-02-10 10:30:15,554 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-02-10 10:30:15,565 - INFO - [Best Model Saved] (val loss: 0.4708) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:30:15,565 - INFO - --------------------------------------------------
2026-02-10 10:30:15,566 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 10:30:18,100 - INFO - [Train] [66/90] | Loss: 0.4062 | Train Acc: 86.53%
2026-02-10 10:30:18,623 - INFO - [Valid] [66/90] | Loss: 0.4787 | Val Acc: 80.53%
2026-02-10 10:30:18,627 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:30:18,627 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:30:18,629 - INFO - --------------------------------------------------
2026-02-10 10:30:18,629 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 10:30:21,146 - INFO - [Train] [67/90] | Loss: 0.4165 | Train Acc: 86.16%
2026-02-10 10:30:21,715 - INFO - [Valid] [67/90] | Loss: 0.4831 | Val Acc: 81.12%
2026-02-10 10:30:21,719 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 10:30:21,719 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 10:30:21,721 - INFO - --------------------------------------------------
2026-02-10 10:30:21,722 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 10:30:24,244 - INFO - [Train] [68/90] | Loss: 0.4096 | Train Acc: 85.94%
2026-02-10 10:30:24,811 - INFO - [Valid] [68/90] | Loss: 0.4930 | Val Acc: 80.24%
2026-02-10 10:30:24,815 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-02-10 10:30:24,816 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-02-10 10:30:24,817 - INFO - --------------------------------------------------
2026-02-10 10:30:24,818 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 10:30:27,287 - INFO - [Train] [69/90] | Loss: 0.4035 | Train Acc: 86.68%
2026-02-10 10:30:27,902 - INFO - [Valid] [69/90] | Loss: 0.4797 | Val Acc: 80.53%
2026-02-10 10:30:27,907 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:30:27,907 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:30:27,908 - INFO - --------------------------------------------------
2026-02-10 10:30:27,909 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 10:30:30,449 - INFO - [Train] [70/90] | Loss: 0.4075 | Train Acc: 86.83%
2026-02-10 10:30:31,095 - INFO - [Valid] [70/90] | Loss: 0.4774 | Val Acc: 81.71%
2026-02-10 10:30:31,099 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-02-10 10:30:31,099 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-02-10 10:30:31,101 - INFO - --------------------------------------------------
2026-02-10 10:30:31,101 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 10:30:33,625 - INFO - [Train] [71/90] | Loss: 0.4111 | Train Acc: 86.09%
2026-02-10 10:30:34,172 - INFO - [Valid] [71/90] | Loss: 0.4753 | Val Acc: 81.12%
2026-02-10 10:30:34,175 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-02-10 10:30:34,175 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-02-10 10:30:34,176 - INFO - --------------------------------------------------
2026-02-10 10:30:34,176 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 10:30:36,772 - INFO - [Train] [72/90] | Loss: 0.4017 | Train Acc: 86.38%
2026-02-10 10:30:37,325 - INFO - [Valid] [72/90] | Loss: 0.4804 | Val Acc: 82.30%
2026-02-10 10:30:37,328 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8280 | F1: 0.8125
2026-02-10 10:30:37,328 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.8187 | F1: 0.8324
2026-02-10 10:30:37,329 - INFO - --------------------------------------------------
2026-02-10 10:30:37,329 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 10:30:39,926 - INFO - [Train] [73/90] | Loss: 0.4049 | Train Acc: 86.16%
2026-02-10 10:30:40,490 - INFO - [Valid] [73/90] | Loss: 0.4750 | Val Acc: 82.30%
2026-02-10 10:30:40,493 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-02-10 10:30:40,493 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-02-10 10:30:40,494 - INFO - --------------------------------------------------
2026-02-10 10:30:40,494 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 10:30:43,105 - INFO - [Train] [74/90] | Loss: 0.3997 | Train Acc: 87.20%
2026-02-10 10:30:43,740 - INFO - [Valid] [74/90] | Loss: 0.4877 | Val Acc: 80.53%
2026-02-10 10:30:43,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:30:43,744 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:30:43,745 - INFO - --------------------------------------------------
2026-02-10 10:30:43,746 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 10:30:46,296 - INFO - [Train] [75/90] | Loss: 0.4020 | Train Acc: 86.24%
2026-02-10 10:30:46,868 - INFO - [Valid] [75/90] | Loss: 0.4831 | Val Acc: 81.42%
2026-02-10 10:30:46,872 - INFO - [Metrics for 'abnormal'] | Precision: 0.7901 | Recall: 0.8153 | F1: 0.8025
2026-02-10 10:30:46,873 - INFO - [Metrics for 'normal'] | Precision: 0.8362 | Recall: 0.8132 | F1: 0.8245
2026-02-10 10:30:46,874 - INFO - --------------------------------------------------
2026-02-10 10:30:46,875 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 10:30:49,364 - INFO - [Train] [76/90] | Loss: 0.4058 | Train Acc: 86.38%
2026-02-10 10:30:49,978 - INFO - [Valid] [76/90] | Loss: 0.4794 | Val Acc: 81.42%
2026-02-10 10:30:49,982 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-02-10 10:30:49,982 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-02-10 10:30:49,983 - INFO - --------------------------------------------------
2026-02-10 10:30:49,984 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 10:30:52,542 - INFO - [Train] [77/90] | Loss: 0.4036 | Train Acc: 86.38%
2026-02-10 10:30:53,145 - INFO - [Valid] [77/90] | Loss: 0.4752 | Val Acc: 82.60%
2026-02-10 10:30:53,149 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-02-10 10:30:53,149 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-02-10 10:30:53,150 - INFO - --------------------------------------------------
2026-02-10 10:30:53,151 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 10:30:55,618 - INFO - [Train] [78/90] | Loss: 0.3989 | Train Acc: 86.53%
2026-02-10 10:30:56,218 - INFO - [Valid] [78/90] | Loss: 0.4777 | Val Acc: 82.30%
2026-02-10 10:30:56,222 - INFO - [Metrics for 'abnormal'] | Precision: 0.8012 | Recall: 0.8217 | F1: 0.8113
2026-02-10 10:30:56,223 - INFO - [Metrics for 'normal'] | Precision: 0.8427 | Recall: 0.8242 | F1: 0.8333
2026-02-10 10:30:56,224 - INFO - --------------------------------------------------
2026-02-10 10:30:56,225 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 10:30:58,788 - INFO - [Train] [79/90] | Loss: 0.4075 | Train Acc: 86.01%
2026-02-10 10:30:59,397 - INFO - [Valid] [79/90] | Loss: 0.4708 | Val Acc: 81.42%
2026-02-10 10:30:59,400 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-02-10 10:30:59,400 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-02-10 10:30:59,407 - INFO - [Best Model Saved] (val loss: 0.4708) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:30:59,408 - INFO - --------------------------------------------------
2026-02-10 10:30:59,408 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 10:31:01,946 - INFO - [Train] [80/90] | Loss: 0.4003 | Train Acc: 86.61%
2026-02-10 10:31:02,491 - INFO - [Valid] [80/90] | Loss: 0.4680 | Val Acc: 81.71%
2026-02-10 10:31:02,495 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-02-10 10:31:02,495 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-02-10 10:31:02,501 - INFO - [Best Model Saved] (val loss: 0.4680) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:31:02,501 - INFO - --------------------------------------------------
2026-02-10 10:31:02,502 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 10:31:05,090 - INFO - [Train] [81/90] | Loss: 0.3961 | Train Acc: 86.01%
2026-02-10 10:31:05,620 - INFO - [Valid] [81/90] | Loss: 0.4654 | Val Acc: 81.71%
2026-02-10 10:31:05,622 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-02-10 10:31:05,622 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-02-10 10:31:05,630 - INFO - [Best Model Saved] (val loss: 0.4654) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:31:05,630 - INFO - --------------------------------------------------
2026-02-10 10:31:05,630 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 10:31:08,235 - INFO - [Train] [82/90] | Loss: 0.3989 | Train Acc: 86.53%
2026-02-10 10:31:08,845 - INFO - [Valid] [82/90] | Loss: 0.4745 | Val Acc: 82.01%
2026-02-10 10:31:08,849 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-02-10 10:31:08,849 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-02-10 10:31:08,851 - INFO - --------------------------------------------------
2026-02-10 10:31:08,852 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 10:31:11,436 - INFO - [Train] [83/90] | Loss: 0.3983 | Train Acc: 86.68%
2026-02-10 10:31:12,064 - INFO - [Valid] [83/90] | Loss: 0.4775 | Val Acc: 81.12%
2026-02-10 10:31:12,068 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-02-10 10:31:12,068 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-02-10 10:31:12,070 - INFO - --------------------------------------------------
2026-02-10 10:31:12,071 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 10:31:14,617 - INFO - [Train] [84/90] | Loss: 0.3963 | Train Acc: 87.05%
2026-02-10 10:31:15,211 - INFO - [Valid] [84/90] | Loss: 0.4754 | Val Acc: 82.30%
2026-02-10 10:31:15,215 - INFO - [Metrics for 'abnormal'] | Precision: 0.7939 | Recall: 0.8344 | F1: 0.8137
2026-02-10 10:31:15,215 - INFO - [Metrics for 'normal'] | Precision: 0.8506 | Recall: 0.8132 | F1: 0.8315
2026-02-10 10:31:15,216 - INFO - --------------------------------------------------
2026-02-10 10:31:15,217 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 10:31:17,787 - INFO - [Train] [85/90] | Loss: 0.3922 | Train Acc: 86.53%
2026-02-10 10:31:18,370 - INFO - [Valid] [85/90] | Loss: 0.4708 | Val Acc: 83.19%
2026-02-10 10:31:18,375 - INFO - [Metrics for 'abnormal'] | Precision: 0.8049 | Recall: 0.8408 | F1: 0.8224
2026-02-10 10:31:18,375 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.8242 | F1: 0.8403
2026-02-10 10:31:18,376 - INFO - --------------------------------------------------
2026-02-10 10:31:18,377 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 10:31:20,931 - INFO - [Train] [86/90] | Loss: 0.3944 | Train Acc: 87.43%
2026-02-10 10:31:21,533 - INFO - [Valid] [86/90] | Loss: 0.4735 | Val Acc: 83.19%
2026-02-10 10:31:21,538 - INFO - [Metrics for 'abnormal'] | Precision: 0.8049 | Recall: 0.8408 | F1: 0.8224
2026-02-10 10:31:21,538 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.8242 | F1: 0.8403
2026-02-10 10:31:21,539 - INFO - --------------------------------------------------
2026-02-10 10:31:21,540 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 10:31:24,006 - INFO - [Train] [87/90] | Loss: 0.3977 | Train Acc: 86.61%
2026-02-10 10:31:24,603 - INFO - [Valid] [87/90] | Loss: 0.4752 | Val Acc: 81.12%
2026-02-10 10:31:24,607 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-02-10 10:31:24,607 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-02-10 10:31:24,609 - INFO - --------------------------------------------------
2026-02-10 10:31:24,610 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 10:31:27,129 - INFO - [Train] [88/90] | Loss: 0.3937 | Train Acc: 87.28%
2026-02-10 10:31:27,686 - INFO - [Valid] [88/90] | Loss: 0.4743 | Val Acc: 81.71%
2026-02-10 10:31:27,689 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-02-10 10:31:27,689 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-02-10 10:31:27,690 - INFO - --------------------------------------------------
2026-02-10 10:31:27,691 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 10:31:30,153 - INFO - [Train] [89/90] | Loss: 0.3929 | Train Acc: 87.20%
2026-02-10 10:31:30,774 - INFO - [Valid] [89/90] | Loss: 0.4798 | Val Acc: 82.60%
2026-02-10 10:31:30,778 - INFO - [Metrics for 'abnormal'] | Precision: 0.7816 | Recall: 0.8662 | F1: 0.8218
2026-02-10 10:31:30,778 - INFO - [Metrics for 'normal'] | Precision: 0.8727 | Recall: 0.7912 | F1: 0.8300
2026-02-10 10:31:30,780 - INFO - --------------------------------------------------
2026-02-10 10:31:30,781 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 10:31:33,355 - INFO - [Train] [90/90] | Loss: 0.3904 | Train Acc: 87.72%
2026-02-10 10:31:33,985 - INFO - [Valid] [90/90] | Loss: 0.4772 | Val Acc: 80.53%
2026-02-10 10:31:33,989 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 10:31:33,989 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 10:31:33,991 - INFO - ==================================================
2026-02-10 10:31:33,991 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 10:31:33,991 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 10:31:33,991 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 10:31:34,200 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 10:31:34,201 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 10:31:34,202 - INFO - FPGM Pruning을 시작합니다.
2026-02-10 10:31:34,202 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 10:31:34,202 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 10:31:34,684 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 10:31:34,684 - INFO - ==================================================
2026-02-10 10:31:34,713 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/best_model.pth'
2026-02-10 10:31:34,713 - INFO - ==================================================
2026-02-10 10:31:34,713 - INFO - Test 모드를 시작합니다.
2026-02-10 10:31:34,786 - INFO - 연산량 (MACs): 0.0082 GMACs per sample
2026-02-10 10:31:34,786 - INFO - 연산량 (FLOPs): 0.0163 GFLOPs per sample
2026-02-10 10:31:34,786 - INFO - ==================================================
2026-02-10 10:31:34,786 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 10:31:35,511 - INFO - 샘플 당 평균 Forward Pass 시간: 1.59ms (std: 0.77ms), FPS: 751.32 (std: 279.75) (1개 샘플 x 100회 반복)
2026-02-10 10:31:35,511 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 104.54 MB
2026-02-10 10:31:35,511 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 10:31:36,658 - INFO - [Test] Loss: 0.3974 | Test Acc: 81.71%
2026-02-10 10:31:36,664 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-02-10 10:31:36,664 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-02-10 10:31:36,897 - INFO - ==================================================
2026-02-10 10:31:36,897 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/confusion_matrix_20260210_102640.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/confusion_matrix_20260210_102640.pdf'
2026-02-10 10:31:36,897 - INFO - ==================================================
2026-02-10 10:31:36,897 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 10:31:37,264 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/model_fp32_20260210_102640.onnx'에 저장되었습니다. (크기: 0.30 MB)
2026-02-10 10:31:37,552 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 9.38 MB
2026-02-10 10:31:37,552 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 10:31:38,292 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 5.09ms (std: 3.88ms)
2026-02-10 10:31:38,292 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 304.99 FPS (std: 159.26) (1개 샘플 x 100회 반복)
2026-02-10 10:31:38,292 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 4.69 MB
2026-02-10 10:31:38,292 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 14.05 MB
2026-02-10 10:31:39,738 - INFO - [Test (ONNX)] | Test Acc (ONNX): 82.01%
2026-02-10 10:31:39,745 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-02-10 10:31:39,746 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-02-10 10:31:39,850 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/val_acc.pdf'
2026-02-10 10:31:39,963 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/train_val_acc.pdf'
2026-02-10 10:31:40,075 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/F1_normal.pdf'
2026-02-10 10:31:40,192 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/val_loss.pdf'
2026-02-10 10:31:40,303 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/learning_rate.pdf'
2026-02-10 10:31:41,443 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260210_102640/graph_20260210_102640/compile.pdf'
