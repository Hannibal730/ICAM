2026-02-10 02:19:08,340 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/log_20260210_021908.log'에 저장됩니다.
2026-02-10 02:19:08,342 - INFO - ==================================================
2026-02-10 02:19:08,342 - INFO - config.yaml:
2026-02-10 02:19:08,342 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: mobilenet_v4_s
  use_l1_pruning: true
  pruning_params_target: 0.047585

2026-02-10 02:19:08,342 - INFO - ==================================================
2026-02-10 02:19:08,489 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 02:19:08,489 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 02:19:08,489 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 02:19:08,492 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 02:19:08,493 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 02:19:08,493 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 02:19:08,493 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 02:19:08,602 - INFO - ==================================================
2026-02-10 02:19:08,602 - INFO - 모델 파라미터 수:
2026-02-10 02:19:08,602 - INFO -   - 총 파라미터: 2,495,586 개
2026-02-10 02:19:08,602 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-02-10 02:19:08,602 - INFO - ================================================================================
2026-02-10 02:19:08,602 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 02:19:08,602 - INFO - ================================================================================
2026-02-10 02:19:08,602 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 02:19:08,603 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 02:19:08,603 - INFO - ==================================================
2026-02-10 02:19:08,603 - INFO - train 모드를 시작합니다.
2026-02-10 02:19:08,603 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 02:19:08,603 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 02:19:08,603 - INFO - --------------------------------------------------
2026-02-10 02:19:08,603 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 02:19:10,327 - INFO - [Train] [1/10] | Loss: 2.7650 | Train Acc: 67.78%
2026-02-10 02:19:10,948 - INFO - [Valid] [1/10] | Loss: 1.7061 | Val Acc: 57.82%
2026-02-10 02:19:10,952 - INFO - [Metrics for 'abnormal'] | Precision: 0.6167 | Recall: 0.2357 | F1: 0.3410
2026-02-10 02:19:10,952 - INFO - [Metrics for 'normal'] | Precision: 0.5699 | Recall: 0.8736 | F1: 0.6898
2026-02-10 02:19:10,966 - INFO - [Best Model Saved] (val loss: 1.7061) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:19:10,966 - INFO - --------------------------------------------------
2026-02-10 02:19:10,967 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 02:19:12,446 - INFO - [Train] [2/10] | Loss: 0.7308 | Train Acc: 71.80%
2026-02-10 02:19:12,842 - INFO - [Valid] [2/10] | Loss: 0.8525 | Val Acc: 73.45%
2026-02-10 02:19:12,845 - INFO - [Metrics for 'abnormal'] | Precision: 0.7519 | Recall: 0.6369 | F1: 0.6897
2026-02-10 02:19:12,845 - INFO - [Metrics for 'normal'] | Precision: 0.7233 | Recall: 0.8187 | F1: 0.7680
2026-02-10 02:19:12,861 - INFO - [Best Model Saved] (val loss: 0.8525) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:19:12,861 - INFO - --------------------------------------------------
2026-02-10 02:19:12,861 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 02:19:14,275 - INFO - [Train] [3/10] | Loss: 0.6865 | Train Acc: 70.98%
2026-02-10 02:19:14,682 - INFO - [Valid] [3/10] | Loss: 1.0400 | Val Acc: 66.67%
2026-02-10 02:19:14,685 - INFO - [Metrics for 'abnormal'] | Precision: 0.6642 | Recall: 0.5669 | F1: 0.6117
2026-02-10 02:19:14,685 - INFO - [Metrics for 'normal'] | Precision: 0.6683 | Recall: 0.7527 | F1: 0.7080
2026-02-10 02:19:14,686 - INFO - --------------------------------------------------
2026-02-10 02:19:14,686 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 02:19:16,207 - INFO - [Train] [4/10] | Loss: 0.5967 | Train Acc: 75.22%
2026-02-10 02:19:16,607 - INFO - [Valid] [4/10] | Loss: 0.6859 | Val Acc: 76.99%
2026-02-10 02:19:16,610 - INFO - [Metrics for 'abnormal'] | Precision: 0.8624 | Recall: 0.5987 | F1: 0.7068
2026-02-10 02:19:16,610 - INFO - [Metrics for 'normal'] | Precision: 0.7261 | Recall: 0.9176 | F1: 0.8107
2026-02-10 02:19:16,626 - INFO - [Best Model Saved] (val loss: 0.6859) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:19:16,626 - INFO - --------------------------------------------------
2026-02-10 02:19:16,627 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 02:19:18,240 - INFO - [Train] [5/10] | Loss: 0.6019 | Train Acc: 75.67%
2026-02-10 02:19:18,873 - INFO - [Valid] [5/10] | Loss: 0.7564 | Val Acc: 66.96%
2026-02-10 02:19:18,876 - INFO - [Metrics for 'abnormal'] | Precision: 0.6891 | Recall: 0.5223 | F1: 0.5942
2026-02-10 02:19:18,876 - INFO - [Metrics for 'normal'] | Precision: 0.6591 | Recall: 0.7967 | F1: 0.7214
2026-02-10 02:19:18,877 - INFO - --------------------------------------------------
2026-02-10 02:19:18,878 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 02:19:20,981 - INFO - [Train] [6/10] | Loss: 0.5554 | Train Acc: 79.02%
2026-02-10 02:19:21,388 - INFO - [Valid] [6/10] | Loss: 0.7610 | Val Acc: 67.55%
2026-02-10 02:19:21,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.8615 | Recall: 0.3567 | F1: 0.5045
2026-02-10 02:19:21,390 - INFO - [Metrics for 'normal'] | Precision: 0.6314 | Recall: 0.9505 | F1: 0.7588
2026-02-10 02:19:21,391 - INFO - --------------------------------------------------
2026-02-10 02:19:21,392 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 02:19:23,696 - INFO - [Train] [7/10] | Loss: 0.5442 | Train Acc: 77.16%
2026-02-10 02:19:24,349 - INFO - [Valid] [7/10] | Loss: 0.5495 | Val Acc: 78.76%
2026-02-10 02:19:24,353 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-02-10 02:19:24,353 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-02-10 02:19:24,393 - INFO - [Best Model Saved] (val loss: 0.5495) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:19:24,393 - INFO - --------------------------------------------------
2026-02-10 02:19:24,394 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 02:19:26,660 - INFO - [Train] [8/10] | Loss: 0.5040 | Train Acc: 80.21%
2026-02-10 02:19:27,452 - INFO - [Valid] [8/10] | Loss: 0.5420 | Val Acc: 78.76%
2026-02-10 02:19:27,457 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.8662 | F1: 0.7907
2026-02-10 02:19:27,458 - INFO - [Metrics for 'normal'] | Precision: 0.8618 | Recall: 0.7198 | F1: 0.7844
2026-02-10 02:19:27,499 - INFO - [Best Model Saved] (val loss: 0.5420) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:19:27,499 - INFO - --------------------------------------------------
2026-02-10 02:19:27,501 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 02:19:30,099 - INFO - [Train] [9/10] | Loss: 0.4623 | Train Acc: 82.74%
2026-02-10 02:19:31,058 - INFO - [Valid] [9/10] | Loss: 0.5215 | Val Acc: 79.65%
2026-02-10 02:19:31,063 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-02-10 02:19:31,063 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-02-10 02:19:31,103 - INFO - [Best Model Saved] (val loss: 0.5215) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:19:31,103 - INFO - --------------------------------------------------
2026-02-10 02:19:31,104 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 02:19:33,420 - INFO - [Train] [10/10] | Loss: 0.4498 | Train Acc: 84.45%
2026-02-10 02:19:34,041 - INFO - [Valid] [10/10] | Loss: 0.5224 | Val Acc: 79.94%
2026-02-10 02:19:34,046 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-02-10 02:19:34,046 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-02-10 02:19:34,049 - INFO - ================================================================================
2026-02-10 02:19:34,049 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 02:19:34,049 - INFO - ================================================================================
2026-02-10 02:19:34,095 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'을(를) 불러왔습니다.
2026-02-10 02:19:34,096 - INFO - ================================================================================
2026-02-10 02:19:34,096 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 02:19:34,097 - INFO - 원본 모델 파라미터: 2.4956M
2026-02-10 02:19:34,143 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:34,143 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:34,288 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 02:19:34,288 - INFO - ==================================================
2026-02-10 02:19:34,289 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.6554M (감소율: 73.74%)
2026-02-10 02:19:34,315 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:34,315 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:34,407 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 02:19:34,408 - INFO - ==================================================
2026-02-10 02:19:34,409 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1807M (감소율: 92.76%)
2026-02-10 02:19:34,440 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:34,440 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:34,533 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 02:19:34,533 - INFO - ==================================================
2026-02-10 02:19:34,535 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0548M (감소율: 97.80%)
2026-02-10 02:19:34,561 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:34,561 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:34,751 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 02:19:34,751 - INFO - ==================================================
2026-02-10 02:19:34,753 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0186M (감소율: 99.25%)
2026-02-10 02:19:35,210 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:35,210 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:35,409 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-02-10 02:19:35,409 - INFO - ==================================================
2026-02-10 02:19:35,411 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0343M (감소율: 98.63%)
2026-02-10 02:19:35,435 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:35,435 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:35,738 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.88171875)에 맞춰 변경되었습니다.
2026-02-10 02:19:35,739 - INFO - ==================================================
2026-02-10 02:19:35,740 - INFO -   [탐색  6] 희소도: 0.8817 -> 파라미터: 0.0441M (감소율: 98.23%)
2026-02-10 02:19:35,765 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:35,765 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:35,974 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.873984375)에 맞춰 변경되었습니다.
2026-02-10 02:19:35,975 - INFO - ==================================================
2026-02-10 02:19:35,977 - INFO -   [탐색  7] 희소도: 0.8740 -> 파라미터: 0.0497M (감소율: 98.01%)
2026-02-10 02:19:36,002 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:36,002 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:36,706 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8778515625000001)에 맞춰 변경되었습니다.
2026-02-10 02:19:36,706 - INFO - ==================================================
2026-02-10 02:19:36,707 - INFO -   [탐색  8] 희소도: 0.8779 -> 파라미터: 0.0461M (감소율: 98.15%)
2026-02-10 02:19:36,727 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:36,727 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:36,802 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.87591796875)에 맞춰 변경되었습니다.
2026-02-10 02:19:36,802 - INFO - ==================================================
2026-02-10 02:19:36,804 - INFO -   [탐색  9] 희소도: 0.8759 -> 파라미터: 0.0470M (감소율: 98.12%)
2026-02-10 02:19:36,828 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:36,828 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:36,903 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.874951171875)에 맞춰 변경되었습니다.
2026-02-10 02:19:36,903 - INFO - ==================================================
2026-02-10 02:19:36,905 - INFO -   [탐색 10] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:36,933 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:36,934 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:36,991 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8754345703125)에 맞춰 변경되었습니다.
2026-02-10 02:19:36,992 - INFO - ==================================================
2026-02-10 02:19:36,993 - INFO -   [탐색 11] 희소도: 0.8754 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:37,017 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:37,017 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:37,129 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.87519287109375)에 맞춰 변경되었습니다.
2026-02-10 02:19:37,130 - INFO - ==================================================
2026-02-10 02:19:37,131 - INFO -   [탐색 12] 희소도: 0.8752 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:37,147 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:37,147 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:37,280 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875072021484375)에 맞춰 변경되었습니다.
2026-02-10 02:19:37,280 - INFO - ==================================================
2026-02-10 02:19:37,282 - INFO -   [탐색 13] 희소도: 0.8751 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:37,304 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:37,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:37,385 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750115966796875)에 맞춰 변경되었습니다.
2026-02-10 02:19:37,386 - INFO - ==================================================
2026-02-10 02:19:37,387 - INFO -   [탐색 14] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:37,408 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:37,409 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:37,476 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749813842773437)에 맞춰 변경되었습니다.
2026-02-10 02:19:37,476 - INFO - ==================================================
2026-02-10 02:19:37,478 - INFO -   [탐색 15] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:37,502 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:37,502 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:37,589 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749964904785157)에 맞춰 변경되었습니다.
2026-02-10 02:19:37,590 - INFO - ==================================================
2026-02-10 02:19:37,591 - INFO -   [탐색 16] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:37,615 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:37,615 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:38,200 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750040435791016)에 맞춰 변경되었습니다.
2026-02-10 02:19:38,200 - INFO - ==================================================
2026-02-10 02:19:38,201 - INFO -   [탐색 17] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:38,222 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:38,223 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:38,377 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750002670288086)에 맞춰 변경되었습니다.
2026-02-10 02:19:38,378 - INFO - ==================================================
2026-02-10 02:19:38,380 - INFO -   [탐색 18] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:38,402 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:38,402 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:38,629 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749983787536622)에 맞춰 변경되었습니다.
2026-02-10 02:19:38,629 - INFO - ==================================================
2026-02-10 02:19:38,631 - INFO -   [탐색 19] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:38,654 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:38,654 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:38,834 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749993228912354)에 맞춰 변경되었습니다.
2026-02-10 02:19:38,835 - INFO - ==================================================
2026-02-10 02:19:38,837 - INFO -   [탐색 20] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:38,858 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:38,859 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:39,134 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.874999794960022)에 맞춰 변경되었습니다.
2026-02-10 02:19:39,134 - INFO - ==================================================
2026-02-10 02:19:39,135 - INFO -   [탐색 21] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:39,159 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:39,159 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:39,465 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000309944153)에 맞춰 변경되었습니다.
2026-02-10 02:19:39,465 - INFO - ==================================================
2026-02-10 02:19:39,466 - INFO -   [탐색 22] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:39,481 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:39,481 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:39,973 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999129772186)에 맞춰 변경되었습니다.
2026-02-10 02:19:39,974 - INFO - ==================================================
2026-02-10 02:19:39,975 - INFO -   [탐색 23] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:39,997 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:39,997 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,138 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999719858169)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,138 - INFO - ==================================================
2026-02-10 02:19:40,140 - INFO -   [탐색 24] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:40,165 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:40,165 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,478 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875000001490116)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,478 - INFO - ==================================================
2026-02-10 02:19:40,480 - INFO -   [탐색 25] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:40,502 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:40,503 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,573 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999867379665)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,573 - INFO - ==================================================
2026-02-10 02:19:40,575 - INFO -   [탐색 26] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:40,598 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:40,599 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999941140413)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,669 - INFO - ==================================================
2026-02-10 02:19:40,671 - INFO -   [탐색 27] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:40,694 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:40,694 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,769 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999978020786)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,769 - INFO - ==================================================
2026-02-10 02:19:40,771 - INFO -   [탐색 28] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:40,799 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:40,800 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,876 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999996460973)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,877 - INFO - ==================================================
2026-02-10 02:19:40,878 - INFO -   [탐색 29] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:40,902 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:40,903 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:40,978 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000005681067)에 맞춰 변경되었습니다.
2026-02-10 02:19:40,979 - INFO - ==================================================
2026-02-10 02:19:40,980 - INFO -   [탐색 30] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:41,004 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:41,004 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:41,614 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875000000107102)에 맞춰 변경되었습니다.
2026-02-10 02:19:41,614 - INFO - ==================================================
2026-02-10 02:19:41,618 - INFO -   [탐색 31] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:41,642 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:41,642 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:41,736 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999998765996)에 맞춰 변경되었습니다.
2026-02-10 02:19:41,737 - INFO - ==================================================
2026-02-10 02:19:41,738 - INFO -   [탐색 32] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:41,761 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:41,762 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:41,881 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999918507)에 맞춰 변경되었습니다.
2026-02-10 02:19:41,882 - INFO - ==================================================
2026-02-10 02:19:41,883 - INFO -   [탐색 33] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:41,905 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:41,905 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:42,001 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000494764)에 맞춰 변경되었습니다.
2026-02-10 02:19:42,002 - INFO - ==================================================
2026-02-10 02:19:42,004 - INFO -   [탐색 34] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:42,027 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:42,027 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:42,132 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000206636)에 맞춰 변경되었습니다.
2026-02-10 02:19:42,132 - INFO - ==================================================
2026-02-10 02:19:42,134 - INFO -   [탐색 35] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:42,157 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:42,157 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:42,301 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000062572)에 맞춰 변경되었습니다.
2026-02-10 02:19:42,301 - INFO - ==================================================
2026-02-10 02:19:42,303 - INFO -   [탐색 36] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:42,325 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:42,325 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:42,467 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.874999999999054)에 맞춰 변경되었습니다.
2026-02-10 02:19:42,467 - INFO - ==================================================
2026-02-10 02:19:42,469 - INFO -   [탐색 37] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:42,495 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:42,495 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:42,617 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000026557)에 맞춰 변경되었습니다.
2026-02-10 02:19:42,617 - INFO - ==================================================
2026-02-10 02:19:42,619 - INFO -   [탐색 38] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:42,642 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:42,642 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:43,077 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000008549)에 맞춰 변경되었습니다.
2026-02-10 02:19:43,078 - INFO - ==================================================
2026-02-10 02:19:43,080 - INFO -   [탐색 39] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:43,102 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:43,103 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:43,703 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999545)에 맞춰 변경되었습니다.
2026-02-10 02:19:43,704 - INFO - ==================================================
2026-02-10 02:19:43,705 - INFO -   [탐색 40] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:43,727 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:43,727 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:43,872 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000004047)에 맞춰 변경되었습니다.
2026-02-10 02:19:43,872 - INFO - ==================================================
2026-02-10 02:19:43,874 - INFO -   [탐색 41] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:43,898 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:43,899 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:44,000 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000001796)에 맞춰 변경되었습니다.
2026-02-10 02:19:44,000 - INFO - ==================================================
2026-02-10 02:19:44,002 - INFO -   [탐색 42] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:44,040 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:44,040 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:44,134 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000671)에 맞춰 변경되었습니다.
2026-02-10 02:19:44,134 - INFO - ==================================================
2026-02-10 02:19:44,136 - INFO -   [탐색 43] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:44,583 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:44,583 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:44,716 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000108)에 맞춰 변경되었습니다.
2026-02-10 02:19:44,716 - INFO - ==================================================
2026-02-10 02:19:44,719 - INFO -   [탐색 44] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:44,742 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:44,742 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:44,853 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999827)에 맞춰 변경되었습니다.
2026-02-10 02:19:44,853 - INFO - ==================================================
2026-02-10 02:19:44,855 - INFO -   [탐색 45] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:44,878 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:44,879 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:44,999 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999967)에 맞춰 변경되었습니다.
2026-02-10 02:19:45,000 - INFO - ==================================================
2026-02-10 02:19:45,002 - INFO -   [탐색 46] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:45,026 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:45,027 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:45,158 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000038)에 맞춰 변경되었습니다.
2026-02-10 02:19:45,159 - INFO - ==================================================
2026-02-10 02:19:45,160 - INFO -   [탐색 47] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:45,182 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:45,182 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:45,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000002)에 맞춰 변경되었습니다.
2026-02-10 02:19:45,403 - INFO - ==================================================
2026-02-10 02:19:45,405 - INFO -   [탐색 48] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:45,429 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:45,429 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:45,623 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999984)에 맞춰 변경되었습니다.
2026-02-10 02:19:45,624 - INFO - ==================================================
2026-02-10 02:19:45,625 - INFO -   [탐색 49] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:45,651 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:45,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:46,085 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999993)에 맞춰 변경되었습니다.
2026-02-10 02:19:46,085 - INFO - ==================================================
2026-02-10 02:19:46,087 - INFO -   [탐색 50] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:46,111 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:46,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:46,201 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8749999999999998)에 맞춰 변경되었습니다.
2026-02-10 02:19:46,201 - INFO - ==================================================
2026-02-10 02:19:46,202 - INFO -   [탐색 51] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:46,226 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:46,226 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:46,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:46,310 - INFO - ==================================================
2026-02-10 02:19:46,311 - INFO -   [탐색 52] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:46,335 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:46,335 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:46,430 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8750000000000001)에 맞춰 변경되었습니다.
2026-02-10 02:19:46,431 - INFO - ==================================================
2026-02-10 02:19:46,433 - INFO -   [탐색 53] 희소도: 0.8750 -> 파라미터: 0.0472M (감소율: 98.11%)
2026-02-10 02:19:46,458 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:46,458 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:47,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:47,141 - INFO - ==================================================
2026-02-10 02:19:47,144 - INFO -   [탐색 54] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:47,170 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:47,170 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:47,413 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:47,414 - INFO - ==================================================
2026-02-10 02:19:47,416 - INFO -   [탐색 55] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:47,437 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:47,438 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:47,586 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:47,586 - INFO - ==================================================
2026-02-10 02:19:47,587 - INFO -   [탐색 56] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:47,612 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:47,612 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:47,872 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:47,872 - INFO - ==================================================
2026-02-10 02:19:47,873 - INFO -   [탐색 57] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:47,898 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:47,898 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:47,992 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:47,992 - INFO - ==================================================
2026-02-10 02:19:47,994 - INFO -   [탐색 58] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:48,018 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:48,018 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:48,105 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:48,105 - INFO - ==================================================
2026-02-10 02:19:48,107 - INFO -   [탐색 59] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:48,135 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:48,135 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:48,219 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:48,219 - INFO - ==================================================
2026-02-10 02:19:48,221 - INFO -   [탐색 60] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:48,254 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:48,255 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:48,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:48,354 - INFO - ==================================================
2026-02-10 02:19:48,356 - INFO -   [탐색 61] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:48,383 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:48,384 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:48,552 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:48,552 - INFO - ==================================================
2026-02-10 02:19:48,554 - INFO -   [탐색 62] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:48,577 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:48,578 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:49,041 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:49,042 - INFO - ==================================================
2026-02-10 02:19:49,043 - INFO -   [탐색 63] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:49,068 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:49,068 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:49,154 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:49,155 - INFO - ==================================================
2026-02-10 02:19:49,156 - INFO -   [탐색 64] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:49,180 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:49,181 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:49,274 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:49,274 - INFO - ==================================================
2026-02-10 02:19:49,276 - INFO -   [탐색 65] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:49,300 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:49,301 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:50,004 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:50,005 - INFO - ==================================================
2026-02-10 02:19:50,007 - INFO -   [탐색 66] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:50,031 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:50,031 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:50,157 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:50,158 - INFO - ==================================================
2026-02-10 02:19:50,159 - INFO -   [탐색 67] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:50,182 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:50,182 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:50,319 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:50,319 - INFO - ==================================================
2026-02-10 02:19:50,321 - INFO -   [탐색 68] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:50,346 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:50,346 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:50,464 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:50,465 - INFO - ==================================================
2026-02-10 02:19:50,467 - INFO -   [탐색 69] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:50,491 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:50,491 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:50,634 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:50,635 - INFO - ==================================================
2026-02-10 02:19:50,636 - INFO -   [탐색 70] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:50,660 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:50,660 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:50,794 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:50,794 - INFO - ==================================================
2026-02-10 02:19:50,796 - INFO -   [탐색 71] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:50,819 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:50,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:51,030 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:51,030 - INFO - ==================================================
2026-02-10 02:19:51,031 - INFO -   [탐색 72] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:51,058 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:51,058 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:51,483 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:51,483 - INFO - ==================================================
2026-02-10 02:19:51,485 - INFO -   [탐색 73] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:51,509 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:51,509 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:51,900 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:51,900 - INFO - ==================================================
2026-02-10 02:19:51,902 - INFO -   [탐색 74] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:51,925 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:51,926 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:52,256 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:52,256 - INFO - ==================================================
2026-02-10 02:19:52,258 - INFO -   [탐색 75] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:52,283 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:52,283 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:52,477 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:52,477 - INFO - ==================================================
2026-02-10 02:19:52,479 - INFO -   [탐색 76] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:52,505 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:52,506 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:52,716 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:52,717 - INFO - ==================================================
2026-02-10 02:19:52,719 - INFO -   [탐색 77] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:52,741 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:52,741 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:52,861 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:52,861 - INFO - ==================================================
2026-02-10 02:19:52,863 - INFO -   [탐색 78] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:53,397 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:53,397 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:53,483 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:53,484 - INFO - ==================================================
2026-02-10 02:19:53,486 - INFO -   [탐색 79] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:53,508 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:53,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:53,616 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:53,617 - INFO - ==================================================
2026-02-10 02:19:53,618 - INFO -   [탐색 80] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:53,646 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:53,646 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:53,759 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:53,760 - INFO - ==================================================
2026-02-10 02:19:53,762 - INFO -   [탐색 81] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:53,785 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:53,785 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:53,882 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:53,883 - INFO - ==================================================
2026-02-10 02:19:53,884 - INFO -   [탐색 82] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:53,909 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:53,909 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,030 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,031 - INFO - ==================================================
2026-02-10 02:19:54,032 - INFO -   [탐색 83] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,061 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,061 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,154 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,155 - INFO - ==================================================
2026-02-10 02:19:54,156 - INFO -   [탐색 84] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,181 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,182 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,269 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,269 - INFO - ==================================================
2026-02-10 02:19:54,271 - INFO -   [탐색 85] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,294 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,294 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,388 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,389 - INFO - ==================================================
2026-02-10 02:19:54,390 - INFO -   [탐색 86] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,414 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,415 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,508 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,509 - INFO - ==================================================
2026-02-10 02:19:54,510 - INFO -   [탐색 87] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,533 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,533 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,620 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,620 - INFO - ==================================================
2026-02-10 02:19:54,622 - INFO -   [탐색 88] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,646 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,646 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,754 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,754 - INFO - ==================================================
2026-02-10 02:19:54,755 - INFO -   [탐색 89] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,778 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,779 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:54,870 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:54,870 - INFO - ==================================================
2026-02-10 02:19:54,872 - INFO -   [탐색 90] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:54,895 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:54,895 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:55,838 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:55,838 - INFO - ==================================================
2026-02-10 02:19:55,841 - INFO -   [탐색 91] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:55,867 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:55,867 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:56,019 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:56,020 - INFO - ==================================================
2026-02-10 02:19:56,023 - INFO -   [탐색 92] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:56,046 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:56,047 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:56,267 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:56,267 - INFO - ==================================================
2026-02-10 02:19:56,268 - INFO -   [탐색 93] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:56,292 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:56,292 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:56,531 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:56,532 - INFO - ==================================================
2026-02-10 02:19:56,533 - INFO -   [탐색 94] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:56,556 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:56,556 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:56,685 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:56,685 - INFO - ==================================================
2026-02-10 02:19:56,687 - INFO -   [탐색 95] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:56,710 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:56,710 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:56,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:56,822 - INFO - ==================================================
2026-02-10 02:19:56,824 - INFO -   [탐색 96] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:56,847 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:56,847 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:57,000 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:57,000 - INFO - ==================================================
2026-02-10 02:19:57,002 - INFO -   [탐색 97] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:57,029 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:57,029 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:57,314 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:57,314 - INFO - ==================================================
2026-02-10 02:19:57,316 - INFO -   [탐색 98] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:57,338 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:57,339 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:57,832 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:57,833 - INFO - ==================================================
2026-02-10 02:19:57,835 - INFO -   [탐색 99] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:57,858 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:57,858 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:58,476 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.875)에 맞춰 변경되었습니다.
2026-02-10 02:19:58,477 - INFO - ==================================================
2026-02-10 02:19:58,478 - INFO -   [탐색 100] 희소도: 0.8750 -> 파라미터: 0.0495M (감소율: 98.02%)
2026-02-10 02:19:58,478 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.8754 입니다.
2026-02-10 02:19:58,478 - INFO - ================================================================================
2026-02-10 02:19:58,481 - INFO - 계산된 Pruning 정보(희소도: 0.8754)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/pruning_info.yaml'에 저장했습니다.
2026-02-10 02:19:58,509 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 02:19:58,586 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:58,586 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:58,702 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8754345703125)에 맞춰 변경되었습니다.
2026-02-10 02:19:58,702 - INFO - ==================================================
2026-02-10 02:19:58,704 - INFO - ==================================================
2026-02-10 02:19:58,704 - INFO - 모델 파라미터 수:
2026-02-10 02:19:58,704 - INFO -   - 총 파라미터: 47,152 개
2026-02-10 02:19:58,704 - INFO -   - 학습 가능한 파라미터: 47,152 개
2026-02-10 02:19:58,758 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 02:19:58,821 - INFO - FLOPs가 0.3853 GFLOPs에서 0.0095 GFLOPs로 감소했습니다 (감소율: 97.52%).
2026-02-10 02:19:58,822 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 02:19:58,822 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 02:19:58,823 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 02:19:58,823 - INFO - ==================================================
2026-02-10 02:19:58,823 - INFO - train 모드를 시작합니다.
2026-02-10 02:19:58,823 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 02:19:58,823 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 02:19:58,823 - INFO - --------------------------------------------------
2026-02-10 02:19:58,824 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 02:20:03,552 - INFO - [Train] [11/90] | Loss: 0.7075 | Train Acc: 65.03%
2026-02-10 02:20:04,540 - INFO - [Valid] [11/90] | Loss: 0.5964 | Val Acc: 70.50%
2026-02-10 02:20:04,546 - INFO - [Metrics for 'abnormal'] | Precision: 0.7664 | Recall: 0.5223 | F1: 0.6212
2026-02-10 02:20:04,546 - INFO - [Metrics for 'normal'] | Precision: 0.6767 | Recall: 0.8626 | F1: 0.7585
2026-02-10 02:20:04,569 - INFO - [Best Model Saved] (val loss: 0.5964) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:20:04,569 - INFO - --------------------------------------------------
2026-02-10 02:20:04,570 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 02:20:08,967 - INFO - [Train] [12/90] | Loss: 0.6110 | Train Acc: 70.24%
2026-02-10 02:20:10,307 - INFO - [Valid] [12/90] | Loss: 0.6006 | Val Acc: 69.91%
2026-02-10 02:20:10,312 - INFO - [Metrics for 'abnormal'] | Precision: 0.6368 | Recall: 0.8153 | F1: 0.7151
2026-02-10 02:20:10,312 - INFO - [Metrics for 'normal'] | Precision: 0.7899 | Recall: 0.5989 | F1: 0.6813
2026-02-10 02:20:10,314 - INFO - --------------------------------------------------
2026-02-10 02:20:10,315 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 02:20:14,387 - INFO - [Train] [13/90] | Loss: 0.5771 | Train Acc: 72.62%
2026-02-10 02:20:15,667 - INFO - [Valid] [13/90] | Loss: 0.5721 | Val Acc: 74.93%
2026-02-10 02:20:15,676 - INFO - [Metrics for 'abnormal'] | Precision: 0.7143 | Recall: 0.7643 | F1: 0.7385
2026-02-10 02:20:15,676 - INFO - [Metrics for 'normal'] | Precision: 0.7836 | Recall: 0.7363 | F1: 0.7592
2026-02-10 02:20:15,699 - INFO - [Best Model Saved] (val loss: 0.5721) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:20:15,700 - INFO - --------------------------------------------------
2026-02-10 02:20:15,701 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 02:20:19,687 - INFO - [Train] [14/90] | Loss: 0.5718 | Train Acc: 72.84%
2026-02-10 02:20:21,068 - INFO - [Valid] [14/90] | Loss: 0.5713 | Val Acc: 71.68%
2026-02-10 02:20:21,077 - INFO - [Metrics for 'abnormal'] | Precision: 0.6848 | Recall: 0.7197 | F1: 0.7019
2026-02-10 02:20:21,077 - INFO - [Metrics for 'normal'] | Precision: 0.7471 | Recall: 0.7143 | F1: 0.7303
2026-02-10 02:20:21,104 - INFO - [Best Model Saved] (val loss: 0.5713) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:20:21,104 - INFO - --------------------------------------------------
2026-02-10 02:20:21,106 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 02:20:25,695 - INFO - [Train] [15/90] | Loss: 0.5567 | Train Acc: 74.26%
2026-02-10 02:20:26,913 - INFO - [Valid] [15/90] | Loss: 0.6086 | Val Acc: 69.91%
2026-02-10 02:20:26,918 - INFO - [Metrics for 'abnormal'] | Precision: 0.6471 | Recall: 0.7707 | F1: 0.7035
2026-02-10 02:20:26,918 - INFO - [Metrics for 'normal'] | Precision: 0.7632 | Recall: 0.6374 | F1: 0.6946
2026-02-10 02:20:26,920 - INFO - --------------------------------------------------
2026-02-10 02:20:26,924 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 02:20:30,475 - INFO - [Train] [16/90] | Loss: 0.5593 | Train Acc: 75.07%
2026-02-10 02:20:31,426 - INFO - [Valid] [16/90] | Loss: 0.5409 | Val Acc: 74.34%
2026-02-10 02:20:31,432 - INFO - [Metrics for 'abnormal'] | Precision: 0.7365 | Recall: 0.6943 | F1: 0.7148
2026-02-10 02:20:31,432 - INFO - [Metrics for 'normal'] | Precision: 0.7487 | Recall: 0.7857 | F1: 0.7668
2026-02-10 02:20:31,449 - INFO - [Best Model Saved] (val loss: 0.5409) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:20:31,450 - INFO - --------------------------------------------------
2026-02-10 02:20:31,451 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 02:20:34,712 - INFO - [Train] [17/90] | Loss: 0.5247 | Train Acc: 78.57%
2026-02-10 02:20:35,259 - INFO - [Valid] [17/90] | Loss: 0.5670 | Val Acc: 74.34%
2026-02-10 02:20:35,263 - INFO - [Metrics for 'abnormal'] | Precision: 0.7108 | Recall: 0.7516 | F1: 0.7307
2026-02-10 02:20:35,264 - INFO - [Metrics for 'normal'] | Precision: 0.7746 | Recall: 0.7363 | F1: 0.7549
2026-02-10 02:20:35,265 - INFO - --------------------------------------------------
2026-02-10 02:20:35,266 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 02:20:37,981 - INFO - [Train] [18/90] | Loss: 0.5356 | Train Acc: 76.93%
2026-02-10 02:20:38,517 - INFO - [Valid] [18/90] | Loss: 0.5590 | Val Acc: 78.17%
2026-02-10 02:20:38,522 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.7898 | F1: 0.7702
2026-02-10 02:20:38,522 - INFO - [Metrics for 'normal'] | Precision: 0.8103 | Recall: 0.7747 | F1: 0.7921
2026-02-10 02:20:38,523 - INFO - --------------------------------------------------
2026-02-10 02:20:38,524 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 02:20:42,466 - INFO - [Train] [19/90] | Loss: 0.5114 | Train Acc: 78.72%
2026-02-10 02:20:43,116 - INFO - [Valid] [19/90] | Loss: 0.5921 | Val Acc: 74.93%
2026-02-10 02:20:43,127 - INFO - [Metrics for 'abnormal'] | Precision: 0.7769 | Recall: 0.6433 | F1: 0.7038
2026-02-10 02:20:43,127 - INFO - [Metrics for 'normal'] | Precision: 0.7321 | Recall: 0.8407 | F1: 0.7826
2026-02-10 02:20:43,128 - INFO - --------------------------------------------------
2026-02-10 02:20:43,130 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 02:20:46,880 - INFO - [Train] [20/90] | Loss: 0.5075 | Train Acc: 80.06%
2026-02-10 02:20:47,553 - INFO - [Valid] [20/90] | Loss: 0.5629 | Val Acc: 74.93%
2026-02-10 02:20:47,557 - INFO - [Metrics for 'abnormal'] | Precision: 0.6978 | Recall: 0.8089 | F1: 0.7493
2026-02-10 02:20:47,557 - INFO - [Metrics for 'normal'] | Precision: 0.8089 | Recall: 0.6978 | F1: 0.7493
2026-02-10 02:20:47,558 - INFO - --------------------------------------------------
2026-02-10 02:20:47,559 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 02:20:49,837 - INFO - [Train] [21/90] | Loss: 0.5062 | Train Acc: 79.17%
2026-02-10 02:20:50,613 - INFO - [Valid] [21/90] | Loss: 0.5464 | Val Acc: 78.47%
2026-02-10 02:20:50,616 - INFO - [Metrics for 'abnormal'] | Precision: 0.7625 | Recall: 0.7771 | F1: 0.7697
2026-02-10 02:20:50,616 - INFO - [Metrics for 'normal'] | Precision: 0.8045 | Recall: 0.7912 | F1: 0.7978
2026-02-10 02:20:50,617 - INFO - --------------------------------------------------
2026-02-10 02:20:50,618 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 02:20:52,855 - INFO - [Train] [22/90] | Loss: 0.5094 | Train Acc: 79.61%
2026-02-10 02:20:53,695 - INFO - [Valid] [22/90] | Loss: 0.5432 | Val Acc: 76.11%
2026-02-10 02:20:53,698 - INFO - [Metrics for 'abnormal'] | Precision: 0.7184 | Recall: 0.7962 | F1: 0.7553
2026-02-10 02:20:53,698 - INFO - [Metrics for 'normal'] | Precision: 0.8061 | Recall: 0.7308 | F1: 0.7666
2026-02-10 02:20:53,699 - INFO - --------------------------------------------------
2026-02-10 02:20:53,700 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 02:20:55,923 - INFO - [Train] [23/90] | Loss: 0.4867 | Train Acc: 81.62%
2026-02-10 02:20:56,780 - INFO - [Valid] [23/90] | Loss: 0.5694 | Val Acc: 75.52%
2026-02-10 02:20:56,784 - INFO - [Metrics for 'abnormal'] | Precision: 0.6927 | Recall: 0.8471 | F1: 0.7622
2026-02-10 02:20:56,784 - INFO - [Metrics for 'normal'] | Precision: 0.8367 | Recall: 0.6758 | F1: 0.7477
2026-02-10 02:20:56,785 - INFO - --------------------------------------------------
2026-02-10 02:20:56,786 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 02:20:59,007 - INFO - [Train] [24/90] | Loss: 0.4884 | Train Acc: 80.65%
2026-02-10 02:20:59,578 - INFO - [Valid] [24/90] | Loss: 0.5558 | Val Acc: 76.11%
2026-02-10 02:20:59,582 - INFO - [Metrics for 'abnormal'] | Precision: 0.7676 | Recall: 0.6943 | F1: 0.7291
2026-02-10 02:20:59,583 - INFO - [Metrics for 'normal'] | Precision: 0.7563 | Recall: 0.8187 | F1: 0.7863
2026-02-10 02:20:59,584 - INFO - --------------------------------------------------
2026-02-10 02:20:59,585 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 02:21:02,229 - INFO - [Train] [25/90] | Loss: 0.4901 | Train Acc: 81.03%
2026-02-10 02:21:02,885 - INFO - [Valid] [25/90] | Loss: 0.5545 | Val Acc: 75.81%
2026-02-10 02:21:02,888 - INFO - [Metrics for 'abnormal'] | Precision: 0.7622 | Recall: 0.6943 | F1: 0.7267
2026-02-10 02:21:02,888 - INFO - [Metrics for 'normal'] | Precision: 0.7551 | Recall: 0.8132 | F1: 0.7831
2026-02-10 02:21:02,889 - INFO - --------------------------------------------------
2026-02-10 02:21:02,889 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 02:21:05,735 - INFO - [Train] [26/90] | Loss: 0.4827 | Train Acc: 81.25%
2026-02-10 02:21:06,722 - INFO - [Valid] [26/90] | Loss: 0.5383 | Val Acc: 78.17%
2026-02-10 02:21:06,727 - INFO - [Metrics for 'abnormal'] | Precision: 0.7902 | Recall: 0.7197 | F1: 0.7533
2026-02-10 02:21:06,728 - INFO - [Metrics for 'normal'] | Precision: 0.7755 | Recall: 0.8352 | F1: 0.8042
2026-02-10 02:21:06,746 - INFO - [Best Model Saved] (val loss: 0.5383) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:21:06,747 - INFO - --------------------------------------------------
2026-02-10 02:21:06,748 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 02:21:10,411 - INFO - [Train] [27/90] | Loss: 0.4648 | Train Acc: 82.81%
2026-02-10 02:21:11,273 - INFO - [Valid] [27/90] | Loss: 0.5773 | Val Acc: 76.40%
2026-02-10 02:21:11,278 - INFO - [Metrics for 'abnormal'] | Precision: 0.7251 | Recall: 0.7898 | F1: 0.7561
2026-02-10 02:21:11,278 - INFO - [Metrics for 'normal'] | Precision: 0.8036 | Recall: 0.7418 | F1: 0.7714
2026-02-10 02:21:11,280 - INFO - --------------------------------------------------
2026-02-10 02:21:11,281 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 02:21:15,047 - INFO - [Train] [28/90] | Loss: 0.4708 | Train Acc: 81.70%
2026-02-10 02:21:16,053 - INFO - [Valid] [28/90] | Loss: 0.5377 | Val Acc: 76.70%
2026-02-10 02:21:16,060 - INFO - [Metrics for 'abnormal'] | Precision: 0.7600 | Recall: 0.7261 | F1: 0.7427
2026-02-10 02:21:16,060 - INFO - [Metrics for 'normal'] | Precision: 0.7725 | Recall: 0.8022 | F1: 0.7871
2026-02-10 02:21:16,077 - INFO - [Best Model Saved] (val loss: 0.5377) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:21:16,078 - INFO - --------------------------------------------------
2026-02-10 02:21:16,079 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 02:21:19,637 - INFO - [Train] [29/90] | Loss: 0.4554 | Train Acc: 83.93%
2026-02-10 02:21:20,912 - INFO - [Valid] [29/90] | Loss: 0.5396 | Val Acc: 78.47%
2026-02-10 02:21:20,917 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-02-10 02:21:20,917 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-02-10 02:21:20,919 - INFO - --------------------------------------------------
2026-02-10 02:21:20,920 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 02:21:25,370 - INFO - [Train] [30/90] | Loss: 0.4639 | Train Acc: 83.18%
2026-02-10 02:21:26,690 - INFO - [Valid] [30/90] | Loss: 0.5265 | Val Acc: 78.47%
2026-02-10 02:21:26,699 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8025 | F1: 0.7754
2026-02-10 02:21:26,700 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.7692 | F1: 0.7932
2026-02-10 02:21:26,726 - INFO - [Best Model Saved] (val loss: 0.5265) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:21:26,726 - INFO - --------------------------------------------------
2026-02-10 02:21:26,728 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 02:21:31,380 - INFO - [Train] [31/90] | Loss: 0.4601 | Train Acc: 81.99%
2026-02-10 02:21:32,635 - INFO - [Valid] [31/90] | Loss: 0.5783 | Val Acc: 76.70%
2026-02-10 02:21:32,640 - INFO - [Metrics for 'abnormal'] | Precision: 0.7708 | Recall: 0.7070 | F1: 0.7375
2026-02-10 02:21:32,640 - INFO - [Metrics for 'normal'] | Precision: 0.7641 | Recall: 0.8187 | F1: 0.7905
2026-02-10 02:21:32,646 - INFO - --------------------------------------------------
2026-02-10 02:21:32,647 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 02:21:38,538 - INFO - [Train] [32/90] | Loss: 0.4564 | Train Acc: 83.56%
2026-02-10 02:21:40,017 - INFO - [Valid] [32/90] | Loss: 0.5461 | Val Acc: 77.88%
2026-02-10 02:21:40,021 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.7389 | F1: 0.7557
2026-02-10 02:21:40,021 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.8132 | F1: 0.7978
2026-02-10 02:21:40,023 - INFO - --------------------------------------------------
2026-02-10 02:21:40,027 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 02:21:46,240 - INFO - [Train] [33/90] | Loss: 0.4443 | Train Acc: 85.27%
2026-02-10 02:21:47,739 - INFO - [Valid] [33/90] | Loss: 0.5578 | Val Acc: 76.70%
2026-02-10 02:21:47,743 - INFO - [Metrics for 'abnormal'] | Precision: 0.7955 | Recall: 0.6688 | F1: 0.7266
2026-02-10 02:21:47,743 - INFO - [Metrics for 'normal'] | Precision: 0.7488 | Recall: 0.8516 | F1: 0.7969
2026-02-10 02:21:47,745 - INFO - --------------------------------------------------
2026-02-10 02:21:47,746 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 02:21:53,568 - INFO - [Train] [34/90] | Loss: 0.4539 | Train Acc: 83.71%
2026-02-10 02:21:55,081 - INFO - [Valid] [34/90] | Loss: 0.5322 | Val Acc: 77.88%
2026-02-10 02:21:55,090 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-02-10 02:21:55,090 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-02-10 02:21:55,093 - INFO - --------------------------------------------------
2026-02-10 02:21:55,094 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 02:22:00,985 - INFO - [Train] [35/90] | Loss: 0.4565 | Train Acc: 83.56%
2026-02-10 02:22:02,438 - INFO - [Valid] [35/90] | Loss: 0.5663 | Val Acc: 77.88%
2026-02-10 02:22:02,447 - INFO - [Metrics for 'abnormal'] | Precision: 0.7662 | Recall: 0.7516 | F1: 0.7588
2026-02-10 02:22:02,447 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8022 | F1: 0.7956
2026-02-10 02:22:02,449 - INFO - --------------------------------------------------
2026-02-10 02:22:02,451 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 02:22:08,359 - INFO - [Train] [36/90] | Loss: 0.4323 | Train Acc: 86.38%
2026-02-10 02:22:09,939 - INFO - [Valid] [36/90] | Loss: 0.5823 | Val Acc: 76.40%
2026-02-10 02:22:09,949 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7389 | F1: 0.7436
2026-02-10 02:22:09,949 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.7857 | F1: 0.7814
2026-02-10 02:22:09,951 - INFO - --------------------------------------------------
2026-02-10 02:22:09,952 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 02:22:16,098 - INFO - [Train] [37/90] | Loss: 0.4328 | Train Acc: 85.86%
2026-02-10 02:22:17,558 - INFO - [Valid] [37/90] | Loss: 0.5779 | Val Acc: 76.11%
2026-02-10 02:22:17,564 - INFO - [Metrics for 'abnormal'] | Precision: 0.7111 | Recall: 0.8153 | F1: 0.7596
2026-02-10 02:22:17,568 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.7143 | F1: 0.7625
2026-02-10 02:22:17,571 - INFO - --------------------------------------------------
2026-02-10 02:22:17,572 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 02:22:23,793 - INFO - [Train] [38/90] | Loss: 0.4189 | Train Acc: 86.01%
2026-02-10 02:22:25,334 - INFO - [Valid] [38/90] | Loss: 0.5690 | Val Acc: 78.47%
2026-02-10 02:22:25,339 - INFO - [Metrics for 'abnormal'] | Precision: 0.7471 | Recall: 0.8089 | F1: 0.7768
2026-02-10 02:22:25,339 - INFO - [Metrics for 'normal'] | Precision: 0.8225 | Recall: 0.7637 | F1: 0.7920
2026-02-10 02:22:25,341 - INFO - --------------------------------------------------
2026-02-10 02:22:25,342 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 02:22:30,680 - INFO - [Train] [39/90] | Loss: 0.3987 | Train Acc: 87.43%
2026-02-10 02:22:32,368 - INFO - [Valid] [39/90] | Loss: 0.5826 | Val Acc: 75.22%
2026-02-10 02:22:32,373 - INFO - [Metrics for 'abnormal'] | Precision: 0.7552 | Recall: 0.6879 | F1: 0.7200
2026-02-10 02:22:32,373 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.8077 | F1: 0.7778
2026-02-10 02:22:32,375 - INFO - --------------------------------------------------
2026-02-10 02:22:32,376 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 02:22:37,261 - INFO - [Train] [40/90] | Loss: 0.4067 | Train Acc: 87.05%
2026-02-10 02:22:39,022 - INFO - [Valid] [40/90] | Loss: 0.6201 | Val Acc: 74.34%
2026-02-10 02:22:39,033 - INFO - [Metrics for 'abnormal'] | Precision: 0.6923 | Recall: 0.8025 | F1: 0.7434
2026-02-10 02:22:39,033 - INFO - [Metrics for 'normal'] | Precision: 0.8025 | Recall: 0.6923 | F1: 0.7434
2026-02-10 02:22:39,035 - INFO - --------------------------------------------------
2026-02-10 02:22:39,037 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 02:22:44,765 - INFO - [Train] [41/90] | Loss: 0.3998 | Train Acc: 87.28%
2026-02-10 02:22:46,509 - INFO - [Valid] [41/90] | Loss: 0.6069 | Val Acc: 76.40%
2026-02-10 02:22:46,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.7655 | Recall: 0.7070 | F1: 0.7351
2026-02-10 02:22:46,523 - INFO - [Metrics for 'normal'] | Precision: 0.7629 | Recall: 0.8132 | F1: 0.7872
2026-02-10 02:22:46,525 - INFO - --------------------------------------------------
2026-02-10 02:22:46,527 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 02:22:52,562 - INFO - [Train] [42/90] | Loss: 0.4088 | Train Acc: 87.05%
2026-02-10 02:22:53,755 - INFO - [Valid] [42/90] | Loss: 0.5668 | Val Acc: 76.99%
2026-02-10 02:22:53,761 - INFO - [Metrics for 'abnormal'] | Precision: 0.7883 | Recall: 0.6879 | F1: 0.7347
2026-02-10 02:22:53,762 - INFO - [Metrics for 'normal'] | Precision: 0.7574 | Recall: 0.8407 | F1: 0.7969
2026-02-10 02:22:53,763 - INFO - --------------------------------------------------
2026-02-10 02:22:53,765 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 02:22:59,709 - INFO - [Train] [43/90] | Loss: 0.4061 | Train Acc: 86.46%
2026-02-10 02:23:01,251 - INFO - [Valid] [43/90] | Loss: 0.5789 | Val Acc: 75.52%
2026-02-10 02:23:01,256 - INFO - [Metrics for 'abnormal'] | Precision: 0.7011 | Recall: 0.8217 | F1: 0.7566
2026-02-10 02:23:01,256 - INFO - [Metrics for 'normal'] | Precision: 0.8194 | Recall: 0.6978 | F1: 0.7537
2026-02-10 02:23:01,258 - INFO - --------------------------------------------------
2026-02-10 02:23:01,259 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 02:23:07,675 - INFO - [Train] [44/90] | Loss: 0.3948 | Train Acc: 88.84%
2026-02-10 02:23:09,333 - INFO - [Valid] [44/90] | Loss: 0.5922 | Val Acc: 76.40%
2026-02-10 02:23:09,338 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.7834 | F1: 0.7546
2026-02-10 02:23:09,342 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7473 | F1: 0.7727
2026-02-10 02:23:09,346 - INFO - --------------------------------------------------
2026-02-10 02:23:09,348 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 02:23:15,647 - INFO - [Train] [45/90] | Loss: 0.4026 | Train Acc: 87.20%
2026-02-10 02:23:22,471 - INFO - [Valid] [45/90] | Loss: 0.5522 | Val Acc: 78.47%
2026-02-10 02:23:22,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.8408 | F1: 0.7834
2026-02-10 02:23:22,475 - INFO - [Metrics for 'normal'] | Precision: 0.8428 | Recall: 0.7363 | F1: 0.7859
2026-02-10 02:23:22,476 - INFO - --------------------------------------------------
2026-02-10 02:23:22,476 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 02:23:25,144 - INFO - [Train] [46/90] | Loss: 0.3796 | Train Acc: 89.29%
2026-02-10 02:23:25,688 - INFO - [Valid] [46/90] | Loss: 0.6289 | Val Acc: 72.27%
2026-02-10 02:23:25,693 - INFO - [Metrics for 'abnormal'] | Precision: 0.6760 | Recall: 0.7707 | F1: 0.7202
2026-02-10 02:23:25,693 - INFO - [Metrics for 'normal'] | Precision: 0.7750 | Recall: 0.6813 | F1: 0.7251
2026-02-10 02:23:25,694 - INFO - --------------------------------------------------
2026-02-10 02:23:25,696 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 02:23:28,186 - INFO - [Train] [47/90] | Loss: 0.3778 | Train Acc: 89.58%
2026-02-10 02:23:28,762 - INFO - [Valid] [47/90] | Loss: 0.5948 | Val Acc: 77.58%
2026-02-10 02:23:28,765 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.7771 | F1: 0.7625
2026-02-10 02:23:28,765 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7747 | F1: 0.7877
2026-02-10 02:23:28,766 - INFO - --------------------------------------------------
2026-02-10 02:23:28,766 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 02:23:31,060 - INFO - [Train] [48/90] | Loss: 0.3741 | Train Acc: 89.21%
2026-02-10 02:23:31,682 - INFO - [Valid] [48/90] | Loss: 0.6082 | Val Acc: 76.40%
2026-02-10 02:23:31,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.7834 | F1: 0.7546
2026-02-10 02:23:31,686 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7473 | F1: 0.7727
2026-02-10 02:23:31,688 - INFO - --------------------------------------------------
2026-02-10 02:23:31,689 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 02:23:33,820 - INFO - [Train] [49/90] | Loss: 0.3616 | Train Acc: 90.48%
2026-02-10 02:23:34,516 - INFO - [Valid] [49/90] | Loss: 0.6247 | Val Acc: 74.63%
2026-02-10 02:23:34,521 - INFO - [Metrics for 'abnormal'] | Precision: 0.7320 | Recall: 0.7134 | F1: 0.7226
2026-02-10 02:23:34,521 - INFO - [Metrics for 'normal'] | Precision: 0.7581 | Recall: 0.7747 | F1: 0.7663
2026-02-10 02:23:34,523 - INFO - --------------------------------------------------
2026-02-10 02:23:34,525 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 02:23:36,482 - INFO - [Train] [50/90] | Loss: 0.3747 | Train Acc: 89.73%
2026-02-10 02:23:37,188 - INFO - [Valid] [50/90] | Loss: 0.6124 | Val Acc: 76.99%
2026-02-10 02:23:37,194 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7580 | F1: 0.7532
2026-02-10 02:23:37,194 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.7802 | F1: 0.7845
2026-02-10 02:23:37,195 - INFO - --------------------------------------------------
2026-02-10 02:23:37,197 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 02:23:39,167 - INFO - [Train] [51/90] | Loss: 0.3786 | Train Acc: 88.76%
2026-02-10 02:23:39,718 - INFO - [Valid] [51/90] | Loss: 0.5570 | Val Acc: 76.70%
2026-02-10 02:23:39,722 - INFO - [Metrics for 'abnormal'] | Precision: 0.7097 | Recall: 0.8408 | F1: 0.7697
2026-02-10 02:23:39,722 - INFO - [Metrics for 'normal'] | Precision: 0.8366 | Recall: 0.7033 | F1: 0.7642
2026-02-10 02:23:39,724 - INFO - --------------------------------------------------
2026-02-10 02:23:39,725 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 02:23:41,979 - INFO - [Train] [52/90] | Loss: 0.3483 | Train Acc: 91.59%
2026-02-10 02:23:42,508 - INFO - [Valid] [52/90] | Loss: 0.5932 | Val Acc: 77.88%
2026-02-10 02:23:42,511 - INFO - [Metrics for 'abnormal'] | Precision: 0.7470 | Recall: 0.7898 | F1: 0.7678
2026-02-10 02:23:42,511 - INFO - [Metrics for 'normal'] | Precision: 0.8092 | Recall: 0.7692 | F1: 0.7887
2026-02-10 02:23:42,512 - INFO - --------------------------------------------------
2026-02-10 02:23:42,513 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 02:23:44,979 - INFO - [Train] [53/90] | Loss: 0.3594 | Train Acc: 90.40%
2026-02-10 02:23:45,483 - INFO - [Valid] [53/90] | Loss: 0.6004 | Val Acc: 79.06%
2026-02-10 02:23:45,486 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-02-10 02:23:45,486 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-02-10 02:23:45,487 - INFO - --------------------------------------------------
2026-02-10 02:23:45,488 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 02:23:47,872 - INFO - [Train] [54/90] | Loss: 0.3408 | Train Acc: 91.82%
2026-02-10 02:23:48,346 - INFO - [Valid] [54/90] | Loss: 0.6214 | Val Acc: 77.88%
2026-02-10 02:23:48,349 - INFO - [Metrics for 'abnormal'] | Precision: 0.7562 | Recall: 0.7707 | F1: 0.7634
2026-02-10 02:23:48,349 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.7857 | F1: 0.7922
2026-02-10 02:23:48,350 - INFO - --------------------------------------------------
2026-02-10 02:23:48,350 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 02:23:50,719 - INFO - [Train] [55/90] | Loss: 0.3340 | Train Acc: 92.63%
2026-02-10 02:23:51,318 - INFO - [Valid] [55/90] | Loss: 0.5945 | Val Acc: 75.22%
2026-02-10 02:23:51,321 - INFO - [Metrics for 'abnormal'] | Precision: 0.6952 | Recall: 0.8280 | F1: 0.7558
2026-02-10 02:23:51,321 - INFO - [Metrics for 'normal'] | Precision: 0.8224 | Recall: 0.6868 | F1: 0.7485
2026-02-10 02:23:51,322 - INFO - --------------------------------------------------
2026-02-10 02:23:51,323 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 02:23:53,520 - INFO - [Train] [56/90] | Loss: 0.3388 | Train Acc: 92.19%
2026-02-10 02:23:54,139 - INFO - [Valid] [56/90] | Loss: 0.5669 | Val Acc: 76.99%
2026-02-10 02:23:54,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.7261 | F1: 0.7451
2026-02-10 02:23:54,143 - INFO - [Metrics for 'normal'] | Precision: 0.7737 | Recall: 0.8077 | F1: 0.7903
2026-02-10 02:23:54,145 - INFO - --------------------------------------------------
2026-02-10 02:23:54,146 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 02:23:56,142 - INFO - [Train] [57/90] | Loss: 0.3238 | Train Acc: 93.08%
2026-02-10 02:23:56,841 - INFO - [Valid] [57/90] | Loss: 0.6180 | Val Acc: 76.11%
2026-02-10 02:23:56,845 - INFO - [Metrics for 'abnormal'] | Precision: 0.7111 | Recall: 0.8153 | F1: 0.7596
2026-02-10 02:23:56,845 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.7143 | F1: 0.7625
2026-02-10 02:23:56,846 - INFO - --------------------------------------------------
2026-02-10 02:23:56,847 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 02:23:58,818 - INFO - [Train] [58/90] | Loss: 0.3338 | Train Acc: 93.01%
2026-02-10 02:23:59,402 - INFO - [Valid] [58/90] | Loss: 0.6032 | Val Acc: 76.70%
2026-02-10 02:23:59,406 - INFO - [Metrics for 'abnormal'] | Precision: 0.7349 | Recall: 0.7771 | F1: 0.7554
2026-02-10 02:23:59,406 - INFO - [Metrics for 'normal'] | Precision: 0.7977 | Recall: 0.7582 | F1: 0.7775
2026-02-10 02:23:59,407 - INFO - --------------------------------------------------
2026-02-10 02:23:59,408 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 02:24:01,580 - INFO - [Train] [59/90] | Loss: 0.3234 | Train Acc: 93.60%
2026-02-10 02:24:02,122 - INFO - [Valid] [59/90] | Loss: 0.6111 | Val Acc: 78.76%
2026-02-10 02:24:02,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7607 | Recall: 0.7898 | F1: 0.7750
2026-02-10 02:24:02,125 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.7857 | F1: 0.7989
2026-02-10 02:24:02,125 - INFO - --------------------------------------------------
2026-02-10 02:24:02,126 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 02:24:04,440 - INFO - [Train] [60/90] | Loss: 0.3283 | Train Acc: 93.08%
2026-02-10 02:24:04,948 - INFO - [Valid] [60/90] | Loss: 0.5607 | Val Acc: 77.29%
2026-02-10 02:24:04,951 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-02-10 02:24:04,951 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-02-10 02:24:04,951 - INFO - --------------------------------------------------
2026-02-10 02:24:04,952 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 02:24:07,340 - INFO - [Train] [61/90] | Loss: 0.3229 | Train Acc: 93.23%
2026-02-10 02:24:07,984 - INFO - [Valid] [61/90] | Loss: 0.6023 | Val Acc: 76.40%
2026-02-10 02:24:07,986 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.7707 | F1: 0.7516
2026-02-10 02:24:07,986 - INFO - [Metrics for 'normal'] | Precision: 0.7931 | Recall: 0.7582 | F1: 0.7753
2026-02-10 02:24:07,987 - INFO - --------------------------------------------------
2026-02-10 02:24:07,988 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 02:24:10,243 - INFO - [Train] [62/90] | Loss: 0.3089 | Train Acc: 94.64%
2026-02-10 02:24:10,907 - INFO - [Valid] [62/90] | Loss: 0.6148 | Val Acc: 77.29%
2026-02-10 02:24:10,910 - INFO - [Metrics for 'abnormal'] | Precision: 0.7353 | Recall: 0.7962 | F1: 0.7645
2026-02-10 02:24:10,910 - INFO - [Metrics for 'normal'] | Precision: 0.8107 | Recall: 0.7527 | F1: 0.7806
2026-02-10 02:24:10,911 - INFO - --------------------------------------------------
2026-02-10 02:24:10,912 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 02:24:12,922 - INFO - [Train] [63/90] | Loss: 0.3091 | Train Acc: 93.97%
2026-02-10 02:24:13,559 - INFO - [Valid] [63/90] | Loss: 0.6130 | Val Acc: 76.99%
2026-02-10 02:24:13,564 - INFO - [Metrics for 'abnormal'] | Precision: 0.7516 | Recall: 0.7516 | F1: 0.7516
2026-02-10 02:24:13,564 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.7857 | F1: 0.7857
2026-02-10 02:24:13,565 - INFO - --------------------------------------------------
2026-02-10 02:24:13,566 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 02:24:15,551 - INFO - [Train] [64/90] | Loss: 0.3026 | Train Acc: 95.46%
2026-02-10 02:24:16,296 - INFO - [Valid] [64/90] | Loss: 0.5963 | Val Acc: 79.65%
2026-02-10 02:24:16,300 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-02-10 02:24:16,300 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-02-10 02:24:16,302 - INFO - --------------------------------------------------
2026-02-10 02:24:16,303 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 02:24:18,365 - INFO - [Train] [65/90] | Loss: 0.3229 | Train Acc: 93.08%
2026-02-10 02:24:18,904 - INFO - [Valid] [65/90] | Loss: 0.5783 | Val Acc: 79.06%
2026-02-10 02:24:18,909 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-02-10 02:24:18,909 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-02-10 02:24:18,911 - INFO - --------------------------------------------------
2026-02-10 02:24:18,912 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 02:24:21,205 - INFO - [Train] [66/90] | Loss: 0.3208 | Train Acc: 93.68%
2026-02-10 02:24:21,689 - INFO - [Valid] [66/90] | Loss: 0.5996 | Val Acc: 78.17%
2026-02-10 02:24:21,694 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.7962 | F1: 0.7716
2026-02-10 02:24:21,694 - INFO - [Metrics for 'normal'] | Precision: 0.8140 | Recall: 0.7692 | F1: 0.7910
2026-02-10 02:24:21,695 - INFO - --------------------------------------------------
2026-02-10 02:24:21,696 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 02:24:23,996 - INFO - [Train] [67/90] | Loss: 0.3086 | Train Acc: 93.97%
2026-02-10 02:24:24,538 - INFO - [Valid] [67/90] | Loss: 0.6169 | Val Acc: 78.17%
2026-02-10 02:24:24,541 - INFO - [Metrics for 'abnormal'] | Precision: 0.7712 | Recall: 0.7516 | F1: 0.7613
2026-02-10 02:24:24,541 - INFO - [Metrics for 'normal'] | Precision: 0.7903 | Recall: 0.8077 | F1: 0.7989
2026-02-10 02:24:24,542 - INFO - --------------------------------------------------
2026-02-10 02:24:24,542 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 02:24:26,884 - INFO - [Train] [68/90] | Loss: 0.2960 | Train Acc: 94.87%
2026-02-10 02:24:27,488 - INFO - [Valid] [68/90] | Loss: 0.5840 | Val Acc: 77.58%
2026-02-10 02:24:27,492 - INFO - [Metrics for 'abnormal'] | Precision: 0.7455 | Recall: 0.7834 | F1: 0.7640
2026-02-10 02:24:27,492 - INFO - [Metrics for 'normal'] | Precision: 0.8046 | Recall: 0.7692 | F1: 0.7865
2026-02-10 02:24:27,493 - INFO - --------------------------------------------------
2026-02-10 02:24:27,493 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 02:24:29,576 - INFO - [Train] [69/90] | Loss: 0.2955 | Train Acc: 95.54%
2026-02-10 02:24:30,182 - INFO - [Valid] [69/90] | Loss: 0.6420 | Val Acc: 77.29%
2026-02-10 02:24:30,186 - INFO - [Metrics for 'abnormal'] | Precision: 0.7532 | Recall: 0.7580 | F1: 0.7556
2026-02-10 02:24:30,187 - INFO - [Metrics for 'normal'] | Precision: 0.7901 | Recall: 0.7857 | F1: 0.7879
2026-02-10 02:24:30,188 - INFO - --------------------------------------------------
2026-02-10 02:24:30,189 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 02:24:32,206 - INFO - [Train] [70/90] | Loss: 0.2966 | Train Acc: 94.72%
2026-02-10 02:24:32,941 - INFO - [Valid] [70/90] | Loss: 0.6269 | Val Acc: 76.40%
2026-02-10 02:24:32,946 - INFO - [Metrics for 'abnormal'] | Precision: 0.7305 | Recall: 0.7771 | F1: 0.7531
2026-02-10 02:24:32,946 - INFO - [Metrics for 'normal'] | Precision: 0.7965 | Recall: 0.7527 | F1: 0.7740
2026-02-10 02:24:32,947 - INFO - --------------------------------------------------
2026-02-10 02:24:32,948 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 02:24:34,914 - INFO - [Train] [71/90] | Loss: 0.2847 | Train Acc: 95.68%
2026-02-10 02:24:35,477 - INFO - [Valid] [71/90] | Loss: 0.6232 | Val Acc: 74.04%
2026-02-10 02:24:35,481 - INFO - [Metrics for 'abnormal'] | Precision: 0.6994 | Recall: 0.7707 | F1: 0.7333
2026-02-10 02:24:35,481 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.7143 | F1: 0.7471
2026-02-10 02:24:35,483 - INFO - --------------------------------------------------
2026-02-10 02:24:35,484 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 02:24:37,815 - INFO - [Train] [72/90] | Loss: 0.2936 | Train Acc: 95.09%
2026-02-10 02:24:38,348 - INFO - [Valid] [72/90] | Loss: 0.6596 | Val Acc: 74.63%
2026-02-10 02:24:38,351 - INFO - [Metrics for 'abnormal'] | Precision: 0.7152 | Recall: 0.7516 | F1: 0.7329
2026-02-10 02:24:38,351 - INFO - [Metrics for 'normal'] | Precision: 0.7759 | Recall: 0.7418 | F1: 0.7584
2026-02-10 02:24:38,352 - INFO - --------------------------------------------------
2026-02-10 02:24:38,353 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 02:24:40,666 - INFO - [Train] [73/90] | Loss: 0.2883 | Train Acc: 95.91%
2026-02-10 02:24:41,188 - INFO - [Valid] [73/90] | Loss: 0.6139 | Val Acc: 76.11%
2026-02-10 02:24:41,191 - INFO - [Metrics for 'abnormal'] | Precision: 0.7317 | Recall: 0.7643 | F1: 0.7477
2026-02-10 02:24:41,191 - INFO - [Metrics for 'normal'] | Precision: 0.7886 | Recall: 0.7582 | F1: 0.7731
2026-02-10 02:24:41,192 - INFO - --------------------------------------------------
2026-02-10 02:24:41,192 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 02:24:43,481 - INFO - [Train] [74/90] | Loss: 0.2851 | Train Acc: 95.98%
2026-02-10 02:24:44,074 - INFO - [Valid] [74/90] | Loss: 0.6351 | Val Acc: 74.93%
2026-02-10 02:24:44,077 - INFO - [Metrics for 'abnormal'] | Precision: 0.7069 | Recall: 0.7834 | F1: 0.7432
2026-02-10 02:24:44,077 - INFO - [Metrics for 'normal'] | Precision: 0.7939 | Recall: 0.7198 | F1: 0.7550
2026-02-10 02:24:44,078 - INFO - --------------------------------------------------
2026-02-10 02:24:44,079 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 02:24:46,081 - INFO - [Train] [75/90] | Loss: 0.2843 | Train Acc: 96.21%
2026-02-10 02:24:46,761 - INFO - [Valid] [75/90] | Loss: 0.6287 | Val Acc: 76.70%
2026-02-10 02:24:46,764 - INFO - [Metrics for 'abnormal'] | Precision: 0.7378 | Recall: 0.7707 | F1: 0.7539
2026-02-10 02:24:46,764 - INFO - [Metrics for 'normal'] | Precision: 0.7943 | Recall: 0.7637 | F1: 0.7787
2026-02-10 02:24:46,765 - INFO - --------------------------------------------------
2026-02-10 02:24:46,766 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 02:24:48,966 - INFO - [Train] [76/90] | Loss: 0.2834 | Train Acc: 95.83%
2026-02-10 02:24:49,665 - INFO - [Valid] [76/90] | Loss: 0.6450 | Val Acc: 75.52%
2026-02-10 02:24:49,669 - INFO - [Metrics for 'abnormal'] | Precision: 0.7229 | Recall: 0.7643 | F1: 0.7430
2026-02-10 02:24:49,670 - INFO - [Metrics for 'normal'] | Precision: 0.7861 | Recall: 0.7473 | F1: 0.7662
2026-02-10 02:24:49,671 - INFO - --------------------------------------------------
2026-02-10 02:24:49,672 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 02:24:51,615 - INFO - [Train] [77/90] | Loss: 0.2860 | Train Acc: 96.13%
2026-02-10 02:24:52,190 - INFO - [Valid] [77/90] | Loss: 0.6262 | Val Acc: 76.11%
2026-02-10 02:24:52,195 - INFO - [Metrics for 'abnormal'] | Precision: 0.7262 | Recall: 0.7771 | F1: 0.7508
2026-02-10 02:24:52,195 - INFO - [Metrics for 'normal'] | Precision: 0.7953 | Recall: 0.7473 | F1: 0.7705
2026-02-10 02:24:52,196 - INFO - --------------------------------------------------
2026-02-10 02:24:52,197 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 02:24:54,420 - INFO - [Train] [78/90] | Loss: 0.2709 | Train Acc: 96.95%
2026-02-10 02:24:55,054 - INFO - [Valid] [78/90] | Loss: 0.6553 | Val Acc: 75.22%
2026-02-10 02:24:55,058 - INFO - [Metrics for 'abnormal'] | Precision: 0.7325 | Recall: 0.7325 | F1: 0.7325
2026-02-10 02:24:55,058 - INFO - [Metrics for 'normal'] | Precision: 0.7692 | Recall: 0.7692 | F1: 0.7692
2026-02-10 02:24:55,059 - INFO - --------------------------------------------------
2026-02-10 02:24:55,060 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 02:24:57,465 - INFO - [Train] [79/90] | Loss: 0.2717 | Train Acc: 96.58%
2026-02-10 02:24:57,975 - INFO - [Valid] [79/90] | Loss: 0.6427 | Val Acc: 76.40%
2026-02-10 02:24:57,978 - INFO - [Metrics for 'abnormal'] | Precision: 0.7391 | Recall: 0.7580 | F1: 0.7484
2026-02-10 02:24:57,978 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.7692 | F1: 0.7778
2026-02-10 02:24:57,979 - INFO - --------------------------------------------------
2026-02-10 02:24:57,979 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 02:25:00,324 - INFO - [Train] [80/90] | Loss: 0.2694 | Train Acc: 97.10%
2026-02-10 02:25:00,847 - INFO - [Valid] [80/90] | Loss: 0.6385 | Val Acc: 75.52%
2026-02-10 02:25:00,850 - INFO - [Metrics for 'abnormal'] | Precision: 0.7079 | Recall: 0.8025 | F1: 0.7522
2026-02-10 02:25:00,851 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.7143 | F1: 0.7580
2026-02-10 02:25:00,852 - INFO - --------------------------------------------------
2026-02-10 02:25:00,853 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 02:25:03,246 - INFO - [Train] [81/90] | Loss: 0.2821 | Train Acc: 95.91%
2026-02-10 02:25:03,835 - INFO - [Valid] [81/90] | Loss: 0.6354 | Val Acc: 76.40%
2026-02-10 02:25:03,837 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.7834 | F1: 0.7546
2026-02-10 02:25:03,838 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7473 | F1: 0.7727
2026-02-10 02:25:03,838 - INFO - --------------------------------------------------
2026-02-10 02:25:03,839 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 02:25:06,057 - INFO - [Train] [82/90] | Loss: 0.2695 | Train Acc: 97.02%
2026-02-10 02:25:06,669 - INFO - [Valid] [82/90] | Loss: 0.6110 | Val Acc: 76.40%
2026-02-10 02:25:06,673 - INFO - [Metrics for 'abnormal'] | Precision: 0.7200 | Recall: 0.8025 | F1: 0.7590
2026-02-10 02:25:06,673 - INFO - [Metrics for 'normal'] | Precision: 0.8110 | Recall: 0.7308 | F1: 0.7688
2026-02-10 02:25:06,675 - INFO - --------------------------------------------------
2026-02-10 02:25:06,676 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 02:25:08,666 - INFO - [Train] [83/90] | Loss: 0.2649 | Train Acc: 97.62%
2026-02-10 02:25:09,341 - INFO - [Valid] [83/90] | Loss: 0.6296 | Val Acc: 77.29%
2026-02-10 02:25:09,344 - INFO - [Metrics for 'abnormal'] | Precision: 0.7247 | Recall: 0.8217 | F1: 0.7701
2026-02-10 02:25:09,344 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.7308 | F1: 0.7755
2026-02-10 02:25:09,345 - INFO - --------------------------------------------------
2026-02-10 02:25:09,346 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 02:25:11,503 - INFO - [Train] [84/90] | Loss: 0.2639 | Train Acc: 96.73%
2026-02-10 02:25:12,197 - INFO - [Valid] [84/90] | Loss: 0.6412 | Val Acc: 75.22%
2026-02-10 02:25:12,200 - INFO - [Metrics for 'abnormal'] | Precision: 0.7039 | Recall: 0.8025 | F1: 0.7500
2026-02-10 02:25:12,201 - INFO - [Metrics for 'normal'] | Precision: 0.8063 | Recall: 0.7088 | F1: 0.7544
2026-02-10 02:25:12,201 - INFO - --------------------------------------------------
2026-02-10 02:25:12,202 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 02:25:14,215 - INFO - [Train] [85/90] | Loss: 0.2697 | Train Acc: 96.73%
2026-02-10 02:25:14,845 - INFO - [Valid] [85/90] | Loss: 0.6305 | Val Acc: 75.81%
2026-02-10 02:25:14,850 - INFO - [Metrics for 'abnormal'] | Precision: 0.7246 | Recall: 0.7707 | F1: 0.7469
2026-02-10 02:25:14,850 - INFO - [Metrics for 'normal'] | Precision: 0.7907 | Recall: 0.7473 | F1: 0.7684
2026-02-10 02:25:14,851 - INFO - --------------------------------------------------
2026-02-10 02:25:14,852 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 02:25:17,179 - INFO - [Train] [86/90] | Loss: 0.2640 | Train Acc: 97.17%
2026-02-10 02:25:17,676 - INFO - [Valid] [86/90] | Loss: 0.6282 | Val Acc: 76.11%
2026-02-10 02:25:17,679 - INFO - [Metrics for 'abnormal'] | Precision: 0.7317 | Recall: 0.7643 | F1: 0.7477
2026-02-10 02:25:17,679 - INFO - [Metrics for 'normal'] | Precision: 0.7886 | Recall: 0.7582 | F1: 0.7731
2026-02-10 02:25:17,680 - INFO - --------------------------------------------------
2026-02-10 02:25:17,680 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 02:25:20,028 - INFO - [Train] [87/90] | Loss: 0.2670 | Train Acc: 96.43%
2026-02-10 02:25:20,528 - INFO - [Valid] [87/90] | Loss: 0.6397 | Val Acc: 75.52%
2026-02-10 02:25:20,531 - INFO - [Metrics for 'abnormal'] | Precision: 0.7151 | Recall: 0.7834 | F1: 0.7477
2026-02-10 02:25:20,531 - INFO - [Metrics for 'normal'] | Precision: 0.7964 | Recall: 0.7308 | F1: 0.7622
2026-02-10 02:25:20,532 - INFO - --------------------------------------------------
2026-02-10 02:25:20,532 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 02:25:22,847 - INFO - [Train] [88/90] | Loss: 0.2620 | Train Acc: 97.54%
2026-02-10 02:25:23,461 - INFO - [Valid] [88/90] | Loss: 0.6474 | Val Acc: 75.52%
2026-02-10 02:25:23,464 - INFO - [Metrics for 'abnormal'] | Precision: 0.7151 | Recall: 0.7834 | F1: 0.7477
2026-02-10 02:25:23,464 - INFO - [Metrics for 'normal'] | Precision: 0.7964 | Recall: 0.7308 | F1: 0.7622
2026-02-10 02:25:23,465 - INFO - --------------------------------------------------
2026-02-10 02:25:23,466 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 02:25:25,553 - INFO - [Train] [89/90] | Loss: 0.2742 | Train Acc: 96.35%
2026-02-10 02:25:26,221 - INFO - [Valid] [89/90] | Loss: 0.6293 | Val Acc: 75.52%
2026-02-10 02:25:26,226 - INFO - [Metrics for 'abnormal'] | Precision: 0.7403 | Recall: 0.7261 | F1: 0.7331
2026-02-10 02:25:26,226 - INFO - [Metrics for 'normal'] | Precision: 0.7676 | Recall: 0.7802 | F1: 0.7738
2026-02-10 02:25:26,228 - INFO - --------------------------------------------------
2026-02-10 02:25:26,229 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 02:25:28,169 - INFO - [Train] [90/90] | Loss: 0.2614 | Train Acc: 97.47%
2026-02-10 02:25:28,928 - INFO - [Valid] [90/90] | Loss: 0.6222 | Val Acc: 74.93%
2026-02-10 02:25:28,933 - INFO - [Metrics for 'abnormal'] | Precision: 0.7169 | Recall: 0.7580 | F1: 0.7368
2026-02-10 02:25:28,933 - INFO - [Metrics for 'normal'] | Precision: 0.7803 | Recall: 0.7418 | F1: 0.7606
2026-02-10 02:25:28,936 - INFO - ==================================================
2026-02-10 02:25:28,936 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 02:25:28,937 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 02:25:28,937 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 02:25:29,031 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 02:25:29,032 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:25:29,032 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:25:29,168 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8754345703125)에 맞춰 변경되었습니다.
2026-02-10 02:25:29,168 - INFO - ==================================================
2026-02-10 02:25:29,227 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/best_model.pth'
2026-02-10 02:25:29,228 - INFO - ==================================================
2026-02-10 02:25:29,228 - INFO - Test 모드를 시작합니다.
2026-02-10 02:25:29,431 - INFO - 연산량 (MACs): 0.0048 GMACs per sample
2026-02-10 02:25:29,432 - INFO - 연산량 (FLOPs): 0.0095 GFLOPs per sample
2026-02-10 02:25:29,432 - INFO - ==================================================
2026-02-10 02:25:29,432 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 02:25:31,043 - INFO - 샘플 당 평균 Forward Pass 시간: 1.29ms (std: 0.34ms), FPS: 811.92 (std: 151.55) (1개 샘플 x 100회 반복)
2026-02-10 02:25:31,043 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 58.12 MB
2026-02-10 02:25:31,043 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 02:25:31,912 - INFO - [Test] Loss: 0.4656 | Test Acc: 78.47%
2026-02-10 02:25:31,915 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8025 | F1: 0.7754
2026-02-10 02:25:31,915 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.7692 | F1: 0.7932
2026-02-10 02:25:32,198 - INFO - ==================================================
2026-02-10 02:25:32,199 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/confusion_matrix_20260210_021908.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/confusion_matrix_20260210_021908.pdf'
2026-02-10 02:25:32,199 - INFO - ==================================================
2026-02-10 02:25:32,199 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 02:25:32,440 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/model_fp32_20260210_021908.onnx'에 저장되었습니다. (크기: 0.20 MB)
2026-02-10 02:25:32,865 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 5.81 MB
2026-02-10 02:25:32,865 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 02:25:33,407 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 2.07ms (std: 2.22ms)
2026-02-10 02:25:33,407 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 967.05 FPS (std: 552.50) (1개 샘플 x 100회 반복)
2026-02-10 02:25:33,409 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 2.44 MB
2026-02-10 02:25:33,409 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 16.31 MB
2026-02-10 02:25:34,243 - INFO - [Test (ONNX)] | Test Acc (ONNX): 78.47%
2026-02-10 02:25:34,246 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7500 | Recall: 0.8025 | F1: 0.7754
2026-02-10 02:25:34,246 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8187 | Recall: 0.7692 | F1: 0.7932
2026-02-10 02:25:34,406 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/val_acc.pdf'
2026-02-10 02:25:34,567 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/train_val_acc.pdf'
2026-02-10 02:25:34,668 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/F1_normal.pdf'
2026-02-10 02:25:34,775 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/val_loss.pdf'
2026-02-10 02:25:34,886 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/learning_rate.pdf'
2026-02-10 02:25:36,470 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260210_021908/graph_20260210_021908/compile.pdf'
