2026-02-10 08:53:51,227 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/log_20260210_085351.log'에 저장됩니다.
2026-02-10 08:53:51,230 - INFO - ==================================================
2026-02-10 08:53:51,231 - INFO - config.yaml:
2026-02-10 08:53:51,231 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: mobile_vit_xxs
  use_l1_pruning: true
  pruning_params_target: 0.047585

2026-02-10 08:53:51,231 - INFO - ==================================================
2026-02-10 08:53:51,274 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 08:53:51,275 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 08:53:51,275 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 08:53:51,282 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 08:53:51,282 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 08:53:51,283 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 08:53:51,283 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 08:53:51,461 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 08:53:51,476 - INFO - ==================================================
2026-02-10 08:53:51,476 - INFO - 모델 파라미터 수:
2026-02-10 08:53:51,476 - INFO -   - 총 파라미터: 951,666 개
2026-02-10 08:53:51,476 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-02-10 08:53:51,476 - INFO - ================================================================================
2026-02-10 08:53:51,476 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 08:53:51,476 - INFO - ================================================================================
2026-02-10 08:53:51,476 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 08:53:51,477 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 08:53:51,477 - INFO - ==================================================
2026-02-10 08:53:51,477 - INFO - train 모드를 시작합니다.
2026-02-10 08:53:51,477 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 08:53:51,477 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 08:53:51,477 - INFO - --------------------------------------------------
2026-02-10 08:53:51,478 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 08:53:58,036 - INFO - [Train] [1/10] | Loss: 0.5206 | Train Acc: 78.35%
2026-02-10 08:54:00,023 - INFO - [Valid] [1/10] | Loss: 0.5396 | Val Acc: 81.42%
2026-02-10 08:54:00,035 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 08:54:00,035 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 08:54:00,063 - INFO - [Best Model Saved] (val loss: 0.5396) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:54:00,063 - INFO - --------------------------------------------------
2026-02-10 08:54:00,066 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 08:54:05,497 - INFO - [Train] [2/10] | Loss: 0.4614 | Train Acc: 83.26%
2026-02-10 08:54:06,975 - INFO - [Valid] [2/10] | Loss: 0.5190 | Val Acc: 81.71%
2026-02-10 08:54:06,979 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-02-10 08:54:06,979 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-02-10 08:54:07,013 - INFO - [Best Model Saved] (val loss: 0.5190) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:54:07,014 - INFO - --------------------------------------------------
2026-02-10 08:54:07,016 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 08:54:13,930 - INFO - [Train] [3/10] | Loss: 0.4275 | Train Acc: 86.38%
2026-02-10 08:54:15,267 - INFO - [Valid] [3/10] | Loss: 0.5224 | Val Acc: 81.42%
2026-02-10 08:54:15,274 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-02-10 08:54:15,275 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-02-10 08:54:15,277 - INFO - --------------------------------------------------
2026-02-10 08:54:15,279 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 08:54:21,779 - INFO - [Train] [4/10] | Loss: 0.3939 | Train Acc: 87.43%
2026-02-10 08:54:23,114 - INFO - [Valid] [4/10] | Loss: 0.5297 | Val Acc: 82.01%
2026-02-10 08:54:23,123 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-02-10 08:54:23,123 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-02-10 08:54:23,124 - INFO - --------------------------------------------------
2026-02-10 08:54:23,126 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 08:54:30,354 - INFO - [Train] [5/10] | Loss: 0.3756 | Train Acc: 89.36%
2026-02-10 08:54:32,007 - INFO - [Valid] [5/10] | Loss: 0.5530 | Val Acc: 80.83%
2026-02-10 08:54:32,012 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-02-10 08:54:32,012 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-02-10 08:54:32,017 - INFO - --------------------------------------------------
2026-02-10 08:54:32,019 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 08:54:38,881 - INFO - [Train] [6/10] | Loss: 0.3501 | Train Acc: 91.67%
2026-02-10 08:54:40,409 - INFO - [Valid] [6/10] | Loss: 0.5045 | Val Acc: 80.83%
2026-02-10 08:54:40,414 - INFO - [Metrics for 'abnormal'] | Precision: 0.8026 | Recall: 0.7771 | F1: 0.7896
2026-02-10 08:54:40,414 - INFO - [Metrics for 'normal'] | Precision: 0.8128 | Recall: 0.8352 | F1: 0.8238
2026-02-10 08:54:40,457 - INFO - [Best Model Saved] (val loss: 0.5045) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:54:40,457 - INFO - --------------------------------------------------
2026-02-10 08:54:40,458 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 08:54:47,661 - INFO - [Train] [7/10] | Loss: 0.3158 | Train Acc: 93.75%
2026-02-10 08:54:49,131 - INFO - [Valid] [7/10] | Loss: 0.5090 | Val Acc: 81.12%
2026-02-10 08:54:49,137 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-02-10 08:54:49,137 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-02-10 08:54:49,138 - INFO - --------------------------------------------------
2026-02-10 08:54:49,140 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 08:54:56,056 - INFO - [Train] [8/10] | Loss: 0.2782 | Train Acc: 96.65%
2026-02-10 08:54:57,503 - INFO - [Valid] [8/10] | Loss: 0.5297 | Val Acc: 82.60%
2026-02-10 08:54:57,508 - INFO - [Metrics for 'abnormal'] | Precision: 0.7849 | Recall: 0.8599 | F1: 0.8207
2026-02-10 08:54:57,509 - INFO - [Metrics for 'normal'] | Precision: 0.8683 | Recall: 0.7967 | F1: 0.8309
2026-02-10 08:54:57,510 - INFO - --------------------------------------------------
2026-02-10 08:54:57,511 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 08:55:04,317 - INFO - [Train] [9/10] | Loss: 0.2633 | Train Acc: 97.17%
2026-02-10 08:55:06,035 - INFO - [Valid] [9/10] | Loss: 0.5016 | Val Acc: 82.89%
2026-02-10 08:55:06,041 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-02-10 08:55:06,041 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-02-10 08:55:06,078 - INFO - [Best Model Saved] (val loss: 0.5016) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:55:06,078 - INFO - --------------------------------------------------
2026-02-10 08:55:06,080 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 08:55:12,809 - INFO - [Train] [10/10] | Loss: 0.2573 | Train Acc: 97.54%
2026-02-10 08:55:14,232 - INFO - [Valid] [10/10] | Loss: 0.5022 | Val Acc: 82.60%
2026-02-10 08:55:14,237 - INFO - [Metrics for 'abnormal'] | Precision: 0.8063 | Recall: 0.8217 | F1: 0.8139
2026-02-10 08:55:14,237 - INFO - [Metrics for 'normal'] | Precision: 0.8436 | Recall: 0.8297 | F1: 0.8366
2026-02-10 08:55:14,240 - INFO - ================================================================================
2026-02-10 08:55:14,240 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 08:55:14,240 - INFO - ================================================================================
2026-02-10 08:55:14,325 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'을(를) 불러왔습니다.
2026-02-10 08:55:14,325 - INFO - ================================================================================
2026-02-10 08:55:14,325 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 08:55:14,327 - INFO - 원본 모델 파라미터: 0.9517M
2026-02-10 08:55:14,380 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:14,381 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:14,382 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:15,014 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 08:55:15,014 - INFO - ==================================================
2026-02-10 08:55:15,016 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.3049M (감소율: 67.96%)
2026-02-10 08:55:15,043 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:15,044 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:15,045 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:15,812 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:15,812 - INFO - ==================================================
2026-02-10 08:55:15,815 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1109M (감소율: 88.35%)
2026-02-10 08:55:15,846 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:15,847 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:15,847 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:16,272 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 08:55:16,272 - INFO - ==================================================
2026-02-10 08:55:16,274 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0459M (감소율: 95.18%)
2026-02-10 08:55:16,305 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:16,306 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:16,306 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:16,625 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.804375)에 맞춰 변경되었습니다.
2026-02-10 08:55:16,625 - INFO - ==================================================
2026-02-10 08:55:16,627 - INFO -   [탐색  4] 희소도: 0.8044 -> 파라미터: 0.0757M (감소율: 92.04%)
2026-02-10 08:55:16,658 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:16,658 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:16,659 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:16,997 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8353124999999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:16,998 - INFO - ==================================================
2026-02-10 08:55:17,000 - INFO -   [탐색  5] 희소도: 0.8353 -> 파라미터: 0.0610M (감소율: 93.59%)
2026-02-10 08:55:17,031 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:17,031 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:17,032 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:17,385 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8507812499999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:17,385 - INFO - ==================================================
2026-02-10 08:55:17,387 - INFO -   [탐색  6] 희소도: 0.8508 -> 파라미터: 0.0530M (감소율: 94.43%)
2026-02-10 08:55:17,421 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:17,421 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:17,422 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:18,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8585156249999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:18,355 - INFO - ==================================================
2026-02-10 08:55:18,358 - INFO -   [탐색  7] 희소도: 0.8585 -> 파라미터: 0.0509M (감소율: 94.65%)
2026-02-10 08:55:18,388 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:18,388 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:18,389 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:18,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8623828124999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:18,749 - INFO - ==================================================
2026-02-10 08:55:18,751 - INFO -   [탐색  8] 희소도: 0.8624 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:18,782 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:18,783 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:18,784 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:19,232 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 08:55:19,233 - INFO - ==================================================
2026-02-10 08:55:19,234 - INFO -   [탐색  9] 희소도: 0.8643 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:19,263 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:19,263 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:19,264 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:19,723 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8633496093749999)에 맞춰 변경되었습니다.
2026-02-10 08:55:19,723 - INFO - ==================================================
2026-02-10 08:55:19,725 - INFO -   [탐색 10] 희소도: 0.8633 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:19,755 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:19,756 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:19,756 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:20,172 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8628662109374999)에 맞춰 변경되었습니다.
2026-02-10 08:55:20,172 - INFO - ==================================================
2026-02-10 08:55:20,174 - INFO -   [탐색 11] 희소도: 0.8629 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:20,203 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:20,203 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:20,204 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:21,167 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8626245117187499)에 맞춰 변경되었습니다.
2026-02-10 08:55:21,168 - INFO - ==================================================
2026-02-10 08:55:21,171 - INFO -   [탐색 12] 희소도: 0.8626 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:21,199 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:21,199 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:21,200 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:21,676 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625036621093749)에 맞춰 변경되었습니다.
2026-02-10 08:55:21,676 - INFO - ==================================================
2026-02-10 08:55:21,678 - INFO -   [탐색 13] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:21,709 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:21,710 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:21,710 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:22,094 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624432373046874)에 맞춰 변경되었습니다.
2026-02-10 08:55:22,094 - INFO - ==================================================
2026-02-10 08:55:22,096 - INFO -   [탐색 14] 희소도: 0.8624 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:22,130 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:22,130 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:22,131 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:22,527 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624734497070312)에 맞춰 변경되었습니다.
2026-02-10 08:55:22,527 - INFO - ==================================================
2026-02-10 08:55:22,530 - INFO -   [탐색 15] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:22,561 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:22,562 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:22,562 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:22,875 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624885559082031)에 맞춰 변경되었습니다.
2026-02-10 08:55:22,875 - INFO - ==================================================
2026-02-10 08:55:22,878 - INFO -   [탐색 16] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:22,915 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:22,915 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:22,916 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:23,271 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862496109008789)에 맞춰 변경되었습니다.
2026-02-10 08:55:23,271 - INFO - ==================================================
2026-02-10 08:55:23,273 - INFO -   [탐색 17] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:23,847 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:23,847 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:23,848 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:24,205 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499885559082)에 맞춰 변경되었습니다.
2026-02-10 08:55:24,205 - INFO - ==================================================
2026-02-10 08:55:24,209 - INFO -   [탐색 18] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:24,239 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:24,239 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:24,240 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:24,710 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625017738342284)에 맞춰 변경되었습니다.
2026-02-10 08:55:24,710 - INFO - ==================================================
2026-02-10 08:55:24,712 - INFO -   [탐색 19] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:24,742 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:24,743 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:24,743 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:25,158 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625008296966552)에 맞춰 변경되었습니다.
2026-02-10 08:55:25,159 - INFO - ==================================================
2026-02-10 08:55:25,160 - INFO -   [탐색 20] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:25,192 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:25,193 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:25,193 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:25,618 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625003576278686)에 맞춰 변경되었습니다.
2026-02-10 08:55:25,619 - INFO - ==================================================
2026-02-10 08:55:25,621 - INFO -   [탐색 21] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:25,650 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:25,650 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:25,651 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:26,062 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625001215934753)에 맞춰 변경되었습니다.
2026-02-10 08:55:26,062 - INFO - ==================================================
2026-02-10 08:55:26,064 - INFO -   [탐색 22] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:26,636 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:26,636 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:26,637 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:27,054 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000035762787)에 맞춰 변경되었습니다.
2026-02-10 08:55:27,054 - INFO - ==================================================
2026-02-10 08:55:27,057 - INFO -   [탐색 23] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:27,088 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:27,089 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:27,090 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:27,469 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999445676803)에 맞춰 변경되었습니다.
2026-02-10 08:55:27,470 - INFO - ==================================================
2026-02-10 08:55:27,472 - INFO -   [탐색 24] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:27,503 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:27,504 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:27,504 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:27,897 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999740719794)에 맞춰 변경되었습니다.
2026-02-10 08:55:27,897 - INFO - ==================================================
2026-02-10 08:55:27,899 - INFO -   [탐색 25] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:27,933 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:27,933 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:27,934 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:28,304 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499988824129)에 맞춰 변경되었습니다.
2026-02-10 08:55:28,304 - INFO - ==================================================
2026-02-10 08:55:28,306 - INFO -   [탐색 26] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:28,335 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:28,336 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:28,337 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:28,852 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999962002038)에 맞춰 변경되었습니다.
2026-02-10 08:55:28,852 - INFO - ==================================================
2026-02-10 08:55:28,854 - INFO -   [탐색 27] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:29,436 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:29,436 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:29,437 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:29,875 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999998882412)에 맞춰 변경되었습니다.
2026-02-10 08:55:29,875 - INFO - ==================================================
2026-02-10 08:55:29,878 - INFO -   [탐색 28] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:29,907 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:29,907 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:29,908 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,297 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000017322599)에 맞춰 변경되었습니다.
2026-02-10 08:55:30,297 - INFO - ==================================================
2026-02-10 08:55:30,300 - INFO -   [탐색 29] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:30,329 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:30,330 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,330 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,713 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000008102506)에 맞춰 변경되었습니다.
2026-02-10 08:55:30,713 - INFO - ==================================================
2026-02-10 08:55:30,716 - INFO -   [탐색 30] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:30,746 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:30,746 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:30,747 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:31,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000003492459)에 맞춰 변경되었습니다.
2026-02-10 08:55:31,141 - INFO - ==================================================
2026-02-10 08:55:31,144 - INFO -   [탐색 31] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:31,171 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:31,172 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:31,172 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:31,475 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000001187435)에 맞춰 변경되었습니다.
2026-02-10 08:55:31,475 - INFO - ==================================================
2026-02-10 08:55:31,476 - INFO -   [탐색 32] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:32,047 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:32,048 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,048 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,475 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000034924)에 맞춰 변경되었습니다.
2026-02-10 08:55:32,475 - INFO - ==================================================
2026-02-10 08:55:32,478 - INFO -   [탐색 33] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:32,509 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:32,509 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,510 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,857 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999458668)에 맞춰 변경되었습니다.
2026-02-10 08:55:32,857 - INFO - ==================================================
2026-02-10 08:55:32,859 - INFO -   [탐색 34] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:32,890 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:32,890 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:32,891 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,234 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999746796)에 맞춰 변경되었습니다.
2026-02-10 08:55:33,235 - INFO - ==================================================
2026-02-10 08:55:33,237 - INFO -   [탐색 35] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:33,268 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:33,268 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,269 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,717 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862499999989086)에 맞춰 변경되었습니다.
2026-02-10 08:55:33,717 - INFO - ==================================================
2026-02-10 08:55:33,719 - INFO -   [탐색 36] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:33,749 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:33,749 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:33,750 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:34,082 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999962892)에 맞춰 변경되었습니다.
2026-02-10 08:55:34,083 - INFO - ==================================================
2026-02-10 08:55:34,085 - INFO -   [탐색 37] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:34,615 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:34,616 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:34,616 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:34,988 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999998908)에 맞춰 변경되었습니다.
2026-02-10 08:55:34,988 - INFO - ==================================================
2026-02-10 08:55:34,991 - INFO -   [탐색 38] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:35,020 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:35,020 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,021 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,340 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000016916)에 맞춰 변경되었습니다.
2026-02-10 08:55:35,340 - INFO - ==================================================
2026-02-10 08:55:35,342 - INFO -   [탐색 39] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:35,373 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:35,373 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,374 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,761 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000007912)에 맞춰 변경되었습니다.
2026-02-10 08:55:35,762 - INFO - ==================================================
2026-02-10 08:55:35,764 - INFO -   [탐색 40] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:35,794 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:35,794 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:35,795 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,194 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862500000000341)에 맞춰 변경되었습니다.
2026-02-10 08:55:36,194 - INFO - ==================================================
2026-02-10 08:55:36,196 - INFO -   [탐색 41] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:36,224 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:36,225 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,225 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.862500000000116)에 맞춰 변경되었습니다.
2026-02-10 08:55:36,568 - INFO - ==================================================
2026-02-10 08:55:36,570 - INFO -   [탐색 42] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:36,598 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:36,598 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:36,599 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,472 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000034)에 맞춰 변경되었습니다.
2026-02-10 08:55:37,472 - INFO - ==================================================
2026-02-10 08:55:37,475 - INFO -   [탐색 43] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:37,505 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:37,505 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,506 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999471)에 맞춰 변경되었습니다.
2026-02-10 08:55:37,863 - INFO - ==================================================
2026-02-10 08:55:37,864 - INFO -   [탐색 44] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:37,891 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:37,892 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:37,892 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,231 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999752)에 맞춰 변경되었습니다.
2026-02-10 08:55:38,232 - INFO - ==================================================
2026-02-10 08:55:38,233 - INFO -   [탐색 45] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:38,262 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:38,262 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,263 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,607 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999893)에 맞춰 변경되었습니다.
2026-02-10 08:55:38,608 - INFO - ==================================================
2026-02-10 08:55:38,609 - INFO -   [탐색 46] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:38,643 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:38,643 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,644 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:38,998 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999963)에 맞춰 변경되었습니다.
2026-02-10 08:55:38,998 - INFO - ==================================================
2026-02-10 08:55:39,001 - INFO -   [탐색 47] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:39,033 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:39,033 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:39,034 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,014 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999998)에 맞춰 변경되었습니다.
2026-02-10 08:55:40,014 - INFO - ==================================================
2026-02-10 08:55:40,018 - INFO -   [탐색 48] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:40,048 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:40,048 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,049 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,423 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000016)에 맞춰 변경되었습니다.
2026-02-10 08:55:40,423 - INFO - ==================================================
2026-02-10 08:55:40,425 - INFO -   [탐색 49] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:40,457 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:40,458 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,458 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,906 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000007)에 맞춰 변경되었습니다.
2026-02-10 08:55:40,907 - INFO - ==================================================
2026-02-10 08:55:40,908 - INFO -   [탐색 50] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:40,936 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:40,936 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:40,937 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,340 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625000000000003)에 맞춰 변경되었습니다.
2026-02-10 08:55:41,340 - INFO - ==================================================
2026-02-10 08:55:41,343 - INFO -   [탐색 51] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:41,372 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:41,373 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,373 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,763 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:41,763 - INFO - ==================================================
2026-02-10 08:55:41,765 - INFO -   [탐색 52] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:41,791 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:41,791 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:41,792 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:42,601 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8624999999999999)에 맞춰 변경되었습니다.
2026-02-10 08:55:42,601 - INFO - ==================================================
2026-02-10 08:55:42,606 - INFO -   [탐색 53] 희소도: 0.8625 -> 파라미터: 0.0496M (감소율: 94.79%)
2026-02-10 08:55:42,634 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:42,634 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:42,635 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:42,996 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:42,996 - INFO - ==================================================
2026-02-10 08:55:42,998 - INFO -   [탐색 54] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:43,029 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:43,029 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,030 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,377 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:43,377 - INFO - ==================================================
2026-02-10 08:55:43,379 - INFO -   [탐색 55] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:43,409 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:43,409 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,410 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,811 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:43,812 - INFO - ==================================================
2026-02-10 08:55:43,814 - INFO -   [탐색 56] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:43,847 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:43,847 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:43,848 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:44,199 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:44,199 - INFO - ==================================================
2026-02-10 08:55:44,201 - INFO -   [탐색 57] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:44,232 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:44,232 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:44,232 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,229 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:45,230 - INFO - ==================================================
2026-02-10 08:55:45,233 - INFO -   [탐색 58] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:45,262 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:45,262 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,263 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,683 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:45,684 - INFO - ==================================================
2026-02-10 08:55:45,686 - INFO -   [탐색 59] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:45,717 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:45,717 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:45,717 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,112 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:46,112 - INFO - ==================================================
2026-02-10 08:55:46,114 - INFO -   [탐색 60] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:46,142 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:46,142 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,143 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,510 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:46,511 - INFO - ==================================================
2026-02-10 08:55:46,512 - INFO -   [탐색 61] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:46,540 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:46,540 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,541 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,856 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:46,856 - INFO - ==================================================
2026-02-10 08:55:46,858 - INFO -   [탐색 62] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:46,887 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:46,887 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:46,888 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:47,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:47,821 - INFO - ==================================================
2026-02-10 08:55:47,824 - INFO -   [탐색 63] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:47,864 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:47,865 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:47,865 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,230 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:48,231 - INFO - ==================================================
2026-02-10 08:55:48,233 - INFO -   [탐색 64] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:48,265 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:48,265 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,266 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,695 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:48,695 - INFO - ==================================================
2026-02-10 08:55:48,696 - INFO -   [탐색 65] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:48,727 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:48,728 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:48,728 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:49,060 - INFO - ==================================================
2026-02-10 08:55:49,063 - INFO -   [탐색 66] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:49,094 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:49,095 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,096 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,493 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:49,493 - INFO - ==================================================
2026-02-10 08:55:49,495 - INFO -   [탐색 67] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:49,527 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:49,527 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:49,528 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:50,357 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:50,357 - INFO - ==================================================
2026-02-10 08:55:50,360 - INFO -   [탐색 68] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:50,391 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:50,391 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:50,392 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:50,758 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:50,758 - INFO - ==================================================
2026-02-10 08:55:50,760 - INFO -   [탐색 69] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:50,793 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:50,793 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:50,794 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,168 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:51,169 - INFO - ==================================================
2026-02-10 08:55:51,171 - INFO -   [탐색 70] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:51,203 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:51,203 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,204 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,553 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:51,553 - INFO - ==================================================
2026-02-10 08:55:51,556 - INFO -   [탐색 71] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:51,585 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:51,585 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,586 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,964 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:51,964 - INFO - ==================================================
2026-02-10 08:55:51,966 - INFO -   [탐색 72] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:51,997 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:51,997 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:51,998 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:52,908 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:52,908 - INFO - ==================================================
2026-02-10 08:55:52,912 - INFO -   [탐색 73] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:52,941 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:52,942 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:52,942 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,364 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:53,365 - INFO - ==================================================
2026-02-10 08:55:53,367 - INFO -   [탐색 74] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:53,397 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:53,397 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,398 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,774 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:53,774 - INFO - ==================================================
2026-02-10 08:55:53,777 - INFO -   [탐색 75] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:53,806 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:53,806 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:53,807 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,171 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:54,172 - INFO - ==================================================
2026-02-10 08:55:54,174 - INFO -   [탐색 76] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:54,204 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:54,204 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,205 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:54,582 - INFO - ==================================================
2026-02-10 08:55:54,585 - INFO -   [탐색 77] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:54,616 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:54,616 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:54,617 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:55,420 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:55,420 - INFO - ==================================================
2026-02-10 08:55:55,423 - INFO -   [탐색 78] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:55,452 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:55,452 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:55,453 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:55,849 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:55,849 - INFO - ==================================================
2026-02-10 08:55:55,851 - INFO -   [탐색 79] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:55,882 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:55,882 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:55,883 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,259 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:56,259 - INFO - ==================================================
2026-02-10 08:55:56,261 - INFO -   [탐색 80] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:56,290 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:56,291 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,291 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,625 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:56,625 - INFO - ==================================================
2026-02-10 08:55:56,627 - INFO -   [탐색 81] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:56,658 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:56,658 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:56,659 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,081 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:57,081 - INFO - ==================================================
2026-02-10 08:55:57,083 - INFO -   [탐색 82] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:57,114 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:57,114 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,115 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,917 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:57,918 - INFO - ==================================================
2026-02-10 08:55:57,932 - INFO -   [탐색 83] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:57,963 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:57,963 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:57,964 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:58,292 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:58,293 - INFO - ==================================================
2026-02-10 08:55:58,295 - INFO -   [탐색 84] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:58,328 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:58,328 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:58,329 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:58,742 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:58,742 - INFO - ==================================================
2026-02-10 08:55:58,744 - INFO -   [탐색 85] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:58,774 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:58,774 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:58,775 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:59,156 - INFO - ==================================================
2026-02-10 08:55:59,159 - INFO -   [탐색 86] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:59,190 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:59,190 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,191 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,643 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:55:59,643 - INFO - ==================================================
2026-02-10 08:55:59,645 - INFO -   [탐색 87] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:55:59,674 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:55:59,675 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:55:59,676 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:00,578 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:00,578 - INFO - ==================================================
2026-02-10 08:56:00,581 - INFO -   [탐색 88] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:00,607 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:00,608 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:00,608 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:00,932 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:00,932 - INFO - ==================================================
2026-02-10 08:56:00,935 - INFO -   [탐색 89] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:00,967 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:00,967 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:00,968 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:01,308 - INFO - ==================================================
2026-02-10 08:56:01,309 - INFO -   [탐색 90] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:01,340 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:01,341 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,341 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,726 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:01,727 - INFO - ==================================================
2026-02-10 08:56:01,729 - INFO -   [탐색 91] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:01,758 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:01,759 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:01,759 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,097 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:02,097 - INFO - ==================================================
2026-02-10 08:56:02,099 - INFO -   [탐색 92] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:02,129 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:02,129 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,130 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:02,555 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:02,556 - INFO - ==================================================
2026-02-10 08:56:02,558 - INFO -   [탐색 93] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:03,148 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:03,148 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,149 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,538 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:03,538 - INFO - ==================================================
2026-02-10 08:56:03,541 - INFO -   [탐색 94] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:03,571 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:03,571 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,572 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,931 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:03,931 - INFO - ==================================================
2026-02-10 08:56:03,934 - INFO -   [탐색 95] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:03,964 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:03,965 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:03,966 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,381 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:04,381 - INFO - ==================================================
2026-02-10 08:56:04,383 - INFO -   [탐색 96] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:04,412 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:04,412 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,413 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,816 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:04,817 - INFO - ==================================================
2026-02-10 08:56:04,819 - INFO -   [탐색 97] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:04,848 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:04,848 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:04,849 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:05,267 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:05,267 - INFO - ==================================================
2026-02-10 08:56:05,270 - INFO -   [탐색 98] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:05,796 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:05,796 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:05,797 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:06,060 - INFO - ==================================================
2026-02-10 08:56:06,064 - INFO -   [탐색 99] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:06,094 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:06,094 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,095 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,490 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8625)에 맞춰 변경되었습니다.
2026-02-10 08:56:06,490 - INFO - ==================================================
2026-02-10 08:56:06,492 - INFO -   [탐색 100] 희소도: 0.8625 -> 파라미터: 0.0473M (감소율: 95.03%)
2026-02-10 08:56:06,492 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.8643 입니다.
2026-02-10 08:56:06,492 - INFO - ================================================================================
2026-02-10 08:56:06,497 - INFO - 계산된 Pruning 정보(희소도: 0.8643)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/pruning_info.yaml'에 저장했습니다.
2026-02-10 08:56:06,538 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 08:56:06,626 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 08:56:06,626 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 08:56:06,626 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 08:56:07,041 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 08:56:07,041 - INFO - ==================================================
2026-02-10 08:56:07,043 - INFO - ==================================================
2026-02-10 08:56:07,043 - INFO - 모델 파라미터 수:
2026-02-10 08:56:07,043 - INFO -   - 총 파라미터: 47,330 개
2026-02-10 08:56:07,043 - INFO -   - 학습 가능한 파라미터: 47,330 개
2026-02-10 08:56:07,125 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 08:56:07,205 - INFO - FLOPs가 0.5384 GFLOPs에서 0.0262 GFLOPs로 감소했습니다 (감소율: 95.12%).
2026-02-10 08:56:07,205 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 08:56:07,205 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 08:56:07,206 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 08:56:07,207 - INFO - ==================================================
2026-02-10 08:56:07,207 - INFO - train 모드를 시작합니다.
2026-02-10 08:56:07,207 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 08:56:07,207 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 08:56:07,207 - INFO - --------------------------------------------------
2026-02-10 08:56:07,208 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 08:56:12,663 - INFO - [Train] [11/90] | Loss: 0.5750 | Train Acc: 73.88%
2026-02-10 08:56:13,986 - INFO - [Valid] [11/90] | Loss: 0.5427 | Val Acc: 76.40%
2026-02-10 08:56:13,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.6242 | F1: 0.7101
2026-02-10 08:56:13,991 - INFO - [Metrics for 'normal'] | Precision: 0.7318 | Recall: 0.8846 | F1: 0.8010
2026-02-10 08:56:14,014 - INFO - [Best Model Saved] (val loss: 0.5427) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:56:14,014 - INFO - --------------------------------------------------
2026-02-10 08:56:14,016 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 08:56:19,934 - INFO - [Train] [12/90] | Loss: 0.5091 | Train Acc: 79.02%
2026-02-10 08:56:21,111 - INFO - [Valid] [12/90] | Loss: 0.5224 | Val Acc: 79.65%
2026-02-10 08:56:21,116 - INFO - [Metrics for 'abnormal'] | Precision: 0.7821 | Recall: 0.7771 | F1: 0.7796
2026-02-10 08:56:21,116 - INFO - [Metrics for 'normal'] | Precision: 0.8087 | Recall: 0.8132 | F1: 0.8110
2026-02-10 08:56:21,136 - INFO - [Best Model Saved] (val loss: 0.5224) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:56:21,136 - INFO - --------------------------------------------------
2026-02-10 08:56:21,138 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 08:56:27,352 - INFO - [Train] [13/90] | Loss: 0.4781 | Train Acc: 82.14%
2026-02-10 08:56:28,874 - INFO - [Valid] [13/90] | Loss: 0.5251 | Val Acc: 79.06%
2026-02-10 08:56:28,879 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-02-10 08:56:28,883 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-02-10 08:56:28,885 - INFO - --------------------------------------------------
2026-02-10 08:56:28,889 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 08:56:35,875 - INFO - [Train] [14/90] | Loss: 0.4703 | Train Acc: 81.77%
2026-02-10 08:56:37,139 - INFO - [Valid] [14/90] | Loss: 0.5259 | Val Acc: 76.99%
2026-02-10 08:56:37,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.7257 | Recall: 0.8089 | F1: 0.7651
2026-02-10 08:56:37,143 - INFO - [Metrics for 'normal'] | Precision: 0.8171 | Recall: 0.7363 | F1: 0.7746
2026-02-10 08:56:37,145 - INFO - --------------------------------------------------
2026-02-10 08:56:37,147 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 08:56:43,726 - INFO - [Train] [15/90] | Loss: 0.4465 | Train Acc: 84.82%
2026-02-10 08:56:45,307 - INFO - [Valid] [15/90] | Loss: 0.5062 | Val Acc: 82.30%
2026-02-10 08:56:45,312 - INFO - [Metrics for 'abnormal'] | Precision: 0.8129 | Recall: 0.8025 | F1: 0.8077
2026-02-10 08:56:45,312 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8407 | F1: 0.8361
2026-02-10 08:56:45,333 - INFO - [Best Model Saved] (val loss: 0.5062) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:56:45,333 - INFO - --------------------------------------------------
2026-02-10 08:56:45,335 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 08:56:51,779 - INFO - [Train] [16/90] | Loss: 0.4337 | Train Acc: 85.94%
2026-02-10 08:56:53,351 - INFO - [Valid] [16/90] | Loss: 0.5066 | Val Acc: 79.65%
2026-02-10 08:56:53,356 - INFO - [Metrics for 'abnormal'] | Precision: 0.7558 | Recall: 0.8280 | F1: 0.7903
2026-02-10 08:56:53,356 - INFO - [Metrics for 'normal'] | Precision: 0.8383 | Recall: 0.7692 | F1: 0.8023
2026-02-10 08:56:53,357 - INFO - --------------------------------------------------
2026-02-10 08:56:53,363 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 08:57:00,718 - INFO - [Train] [17/90] | Loss: 0.4407 | Train Acc: 84.60%
2026-02-10 08:57:02,334 - INFO - [Valid] [17/90] | Loss: 0.5042 | Val Acc: 80.53%
2026-02-10 08:57:02,339 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-02-10 08:57:02,339 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-02-10 08:57:02,363 - INFO - [Best Model Saved] (val loss: 0.5042) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 08:57:02,364 - INFO - --------------------------------------------------
2026-02-10 08:57:02,366 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 08:57:09,190 - INFO - [Train] [18/90] | Loss: 0.4314 | Train Acc: 85.49%
2026-02-10 08:57:10,647 - INFO - [Valid] [18/90] | Loss: 0.5325 | Val Acc: 77.58%
2026-02-10 08:57:10,652 - INFO - [Metrics for 'abnormal'] | Precision: 0.7166 | Recall: 0.8535 | F1: 0.7791
2026-02-10 08:57:10,652 - INFO - [Metrics for 'normal'] | Precision: 0.8487 | Recall: 0.7088 | F1: 0.7725
2026-02-10 08:57:10,654 - INFO - --------------------------------------------------
2026-02-10 08:57:10,656 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 08:57:17,807 - INFO - [Train] [19/90] | Loss: 0.4190 | Train Acc: 86.31%
2026-02-10 08:57:18,944 - INFO - [Valid] [19/90] | Loss: 0.5331 | Val Acc: 81.71%
2026-02-10 08:57:18,950 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-02-10 08:57:18,950 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-02-10 08:57:18,951 - INFO - --------------------------------------------------
2026-02-10 08:57:18,953 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 08:57:25,943 - INFO - [Train] [20/90] | Loss: 0.4240 | Train Acc: 86.61%
2026-02-10 08:57:27,483 - INFO - [Valid] [20/90] | Loss: 0.5265 | Val Acc: 76.70%
2026-02-10 08:57:27,487 - INFO - [Metrics for 'abnormal'] | Precision: 0.7143 | Recall: 0.8280 | F1: 0.7670
2026-02-10 08:57:27,488 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.7143 | F1: 0.7670
2026-02-10 08:57:27,489 - INFO - --------------------------------------------------
2026-02-10 08:57:27,491 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 08:57:34,569 - INFO - [Train] [21/90] | Loss: 0.4172 | Train Acc: 85.94%
2026-02-10 08:57:36,045 - INFO - [Valid] [21/90] | Loss: 0.5215 | Val Acc: 80.53%
2026-02-10 08:57:36,051 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-02-10 08:57:36,051 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-02-10 08:57:36,052 - INFO - --------------------------------------------------
2026-02-10 08:57:36,054 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 08:57:42,623 - INFO - [Train] [22/90] | Loss: 0.3912 | Train Acc: 88.32%
2026-02-10 08:57:44,206 - INFO - [Valid] [22/90] | Loss: 0.5397 | Val Acc: 78.76%
2026-02-10 08:57:44,211 - INFO - [Metrics for 'abnormal'] | Precision: 0.7607 | Recall: 0.7898 | F1: 0.7750
2026-02-10 08:57:44,211 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.7857 | F1: 0.7989
2026-02-10 08:57:44,212 - INFO - --------------------------------------------------
2026-02-10 08:57:44,214 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 08:57:51,446 - INFO - [Train] [23/90] | Loss: 0.3970 | Train Acc: 87.72%
2026-02-10 08:57:53,036 - INFO - [Valid] [23/90] | Loss: 0.5253 | Val Acc: 79.94%
2026-02-10 08:57:53,041 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-02-10 08:57:53,041 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-02-10 08:57:53,043 - INFO - --------------------------------------------------
2026-02-10 08:57:53,045 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 08:58:00,352 - INFO - [Train] [24/90] | Loss: 0.3926 | Train Acc: 88.54%
2026-02-10 08:58:01,907 - INFO - [Valid] [24/90] | Loss: 0.5668 | Val Acc: 78.76%
2026-02-10 08:58:01,912 - INFO - [Metrics for 'abnormal'] | Precision: 0.7931 | Recall: 0.7325 | F1: 0.7616
2026-02-10 08:58:01,913 - INFO - [Metrics for 'normal'] | Precision: 0.7835 | Recall: 0.8352 | F1: 0.8085
2026-02-10 08:58:01,915 - INFO - --------------------------------------------------
2026-02-10 08:58:01,916 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 08:58:08,739 - INFO - [Train] [25/90] | Loss: 0.3954 | Train Acc: 87.05%
2026-02-10 08:58:10,155 - INFO - [Valid] [25/90] | Loss: 0.5511 | Val Acc: 77.29%
2026-02-10 08:58:10,165 - INFO - [Metrics for 'abnormal'] | Precision: 0.8390 | Recall: 0.6306 | F1: 0.7200
2026-02-10 08:58:10,165 - INFO - [Metrics for 'normal'] | Precision: 0.7376 | Recall: 0.8956 | F1: 0.8089
2026-02-10 08:58:10,166 - INFO - --------------------------------------------------
2026-02-10 08:58:10,168 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 08:58:17,099 - INFO - [Train] [26/90] | Loss: 0.3717 | Train Acc: 89.66%
2026-02-10 08:58:18,561 - INFO - [Valid] [26/90] | Loss: 0.5675 | Val Acc: 76.11%
2026-02-10 08:58:18,566 - INFO - [Metrics for 'abnormal'] | Precision: 0.7135 | Recall: 0.8089 | F1: 0.7582
2026-02-10 08:58:18,566 - INFO - [Metrics for 'normal'] | Precision: 0.8137 | Recall: 0.7198 | F1: 0.7638
2026-02-10 08:58:18,568 - INFO - --------------------------------------------------
2026-02-10 08:58:18,569 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 08:58:25,511 - INFO - [Train] [27/90] | Loss: 0.3949 | Train Acc: 88.62%
2026-02-10 08:58:26,952 - INFO - [Valid] [27/90] | Loss: 0.5137 | Val Acc: 79.65%
2026-02-10 08:58:26,958 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 08:58:26,958 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 08:58:26,960 - INFO - --------------------------------------------------
2026-02-10 08:58:26,961 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 08:58:33,534 - INFO - [Train] [28/90] | Loss: 0.3771 | Train Acc: 89.36%
2026-02-10 08:58:35,115 - INFO - [Valid] [28/90] | Loss: 0.5095 | Val Acc: 79.65%
2026-02-10 08:58:35,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-02-10 08:58:35,124 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-02-10 08:58:35,126 - INFO - --------------------------------------------------
2026-02-10 08:58:35,128 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 08:58:42,600 - INFO - [Train] [29/90] | Loss: 0.3649 | Train Acc: 90.33%
2026-02-10 08:58:44,228 - INFO - [Valid] [29/90] | Loss: 0.5173 | Val Acc: 78.47%
2026-02-10 08:58:44,234 - INFO - [Metrics for 'abnormal'] | Precision: 0.7386 | Recall: 0.8280 | F1: 0.7808
2026-02-10 08:58:44,234 - INFO - [Metrics for 'normal'] | Precision: 0.8344 | Recall: 0.7473 | F1: 0.7884
2026-02-10 08:58:44,236 - INFO - --------------------------------------------------
2026-02-10 08:58:44,238 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 08:58:51,590 - INFO - [Train] [30/90] | Loss: 0.3648 | Train Acc: 89.81%
2026-02-10 08:58:53,028 - INFO - [Valid] [30/90] | Loss: 0.5102 | Val Acc: 81.12%
2026-02-10 08:58:53,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.8298 | Recall: 0.7452 | F1: 0.7852
2026-02-10 08:58:53,036 - INFO - [Metrics for 'normal'] | Precision: 0.7980 | Recall: 0.8681 | F1: 0.8316
2026-02-10 08:58:53,039 - INFO - --------------------------------------------------
2026-02-10 08:58:53,041 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 08:59:00,206 - INFO - [Train] [31/90] | Loss: 0.3522 | Train Acc: 90.03%
2026-02-10 08:59:01,792 - INFO - [Valid] [31/90] | Loss: 0.5482 | Val Acc: 77.88%
2026-02-10 08:59:01,797 - INFO - [Metrics for 'abnormal'] | Precision: 0.7440 | Recall: 0.7962 | F1: 0.7692
2026-02-10 08:59:01,797 - INFO - [Metrics for 'normal'] | Precision: 0.8129 | Recall: 0.7637 | F1: 0.7875
2026-02-10 08:59:01,798 - INFO - --------------------------------------------------
2026-02-10 08:59:01,800 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 08:59:08,742 - INFO - [Train] [32/90] | Loss: 0.3408 | Train Acc: 91.67%
2026-02-10 08:59:10,420 - INFO - [Valid] [32/90] | Loss: 0.5683 | Val Acc: 76.40%
2026-02-10 08:59:10,426 - INFO - [Metrics for 'abnormal'] | Precision: 0.7452 | Recall: 0.7452 | F1: 0.7452
2026-02-10 08:59:10,426 - INFO - [Metrics for 'normal'] | Precision: 0.7802 | Recall: 0.7802 | F1: 0.7802
2026-02-10 08:59:10,428 - INFO - --------------------------------------------------
2026-02-10 08:59:10,429 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 08:59:17,414 - INFO - [Train] [33/90] | Loss: 0.3351 | Train Acc: 91.59%
2026-02-10 08:59:18,686 - INFO - [Valid] [33/90] | Loss: 0.5314 | Val Acc: 79.35%
2026-02-10 08:59:18,692 - INFO - [Metrics for 'abnormal'] | Precision: 0.8372 | Recall: 0.6879 | F1: 0.7552
2026-02-10 08:59:18,692 - INFO - [Metrics for 'normal'] | Precision: 0.7667 | Recall: 0.8846 | F1: 0.8214
2026-02-10 08:59:18,693 - INFO - --------------------------------------------------
2026-02-10 08:59:18,699 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 08:59:25,695 - INFO - [Train] [34/90] | Loss: 0.3497 | Train Acc: 90.40%
2026-02-10 08:59:27,060 - INFO - [Valid] [34/90] | Loss: 0.5510 | Val Acc: 78.17%
2026-02-10 08:59:27,066 - INFO - [Metrics for 'abnormal'] | Precision: 0.7823 | Recall: 0.7325 | F1: 0.7566
2026-02-10 08:59:27,066 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.8242 | F1: 0.8021
2026-02-10 08:59:27,068 - INFO - --------------------------------------------------
2026-02-10 08:59:27,070 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 08:59:33,828 - INFO - [Train] [35/90] | Loss: 0.3487 | Train Acc: 90.62%
2026-02-10 08:59:35,424 - INFO - [Valid] [35/90] | Loss: 0.5504 | Val Acc: 75.81%
2026-02-10 08:59:35,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.7483 | Recall: 0.7197 | F1: 0.7338
2026-02-10 08:59:35,429 - INFO - [Metrics for 'normal'] | Precision: 0.7660 | Recall: 0.7912 | F1: 0.7784
2026-02-10 08:59:35,431 - INFO - --------------------------------------------------
2026-02-10 08:59:35,436 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 08:59:42,297 - INFO - [Train] [36/90] | Loss: 0.3323 | Train Acc: 92.04%
2026-02-10 08:59:43,985 - INFO - [Valid] [36/90] | Loss: 0.5767 | Val Acc: 76.99%
2026-02-10 08:59:43,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.7325 | F1: 0.7468
2026-02-10 08:59:43,991 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8022 | F1: 0.7892
2026-02-10 08:59:43,992 - INFO - --------------------------------------------------
2026-02-10 08:59:43,994 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 08:59:50,512 - INFO - [Train] [37/90] | Loss: 0.3268 | Train Acc: 93.68%
2026-02-10 08:59:51,992 - INFO - [Valid] [37/90] | Loss: 0.5660 | Val Acc: 77.58%
2026-02-10 08:59:51,997 - INFO - [Metrics for 'abnormal'] | Precision: 0.7755 | Recall: 0.7261 | F1: 0.7500
2026-02-10 08:59:51,997 - INFO - [Metrics for 'normal'] | Precision: 0.7760 | Recall: 0.8187 | F1: 0.7968
2026-02-10 08:59:51,999 - INFO - --------------------------------------------------
2026-02-10 08:59:52,000 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 08:59:58,861 - INFO - [Train] [38/90] | Loss: 0.3274 | Train Acc: 92.41%
2026-02-10 09:00:00,231 - INFO - [Valid] [38/90] | Loss: 0.6226 | Val Acc: 76.99%
2026-02-10 09:00:00,240 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.7325 | F1: 0.7468
2026-02-10 09:00:00,241 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8022 | F1: 0.7892
2026-02-10 09:00:00,242 - INFO - --------------------------------------------------
2026-02-10 09:00:00,244 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 09:00:07,889 - INFO - [Train] [39/90] | Loss: 0.3484 | Train Acc: 91.44%
2026-02-10 09:00:08,942 - INFO - [Valid] [39/90] | Loss: 0.5811 | Val Acc: 76.99%
2026-02-10 09:00:08,954 - INFO - [Metrics for 'abnormal'] | Precision: 0.7232 | Recall: 0.8153 | F1: 0.7665
2026-02-10 09:00:08,954 - INFO - [Metrics for 'normal'] | Precision: 0.8210 | Recall: 0.7308 | F1: 0.7733
2026-02-10 09:00:08,955 - INFO - --------------------------------------------------
2026-02-10 09:00:08,957 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 09:00:16,272 - INFO - [Train] [40/90] | Loss: 0.3161 | Train Acc: 93.38%
2026-02-10 09:00:17,603 - INFO - [Valid] [40/90] | Loss: 0.5553 | Val Acc: 79.94%
2026-02-10 09:00:17,609 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-02-10 09:00:17,610 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-02-10 09:00:17,611 - INFO - --------------------------------------------------
2026-02-10 09:00:17,613 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 09:00:24,515 - INFO - [Train] [41/90] | Loss: 0.3097 | Train Acc: 93.68%
2026-02-10 09:00:26,117 - INFO - [Valid] [41/90] | Loss: 0.5903 | Val Acc: 78.17%
2026-02-10 09:00:26,122 - INFO - [Metrics for 'abnormal'] | Precision: 0.8217 | Recall: 0.6752 | F1: 0.7413
2026-02-10 09:00:26,123 - INFO - [Metrics for 'normal'] | Precision: 0.7571 | Recall: 0.8736 | F1: 0.8112
2026-02-10 09:00:26,124 - INFO - --------------------------------------------------
2026-02-10 09:00:26,126 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 09:00:33,093 - INFO - [Train] [42/90] | Loss: 0.3216 | Train Acc: 93.38%
2026-02-10 09:00:34,598 - INFO - [Valid] [42/90] | Loss: 0.5870 | Val Acc: 76.70%
2026-02-10 09:00:34,602 - INFO - [Metrics for 'abnormal'] | Precision: 0.7746 | Recall: 0.7006 | F1: 0.7358
2026-02-10 09:00:34,603 - INFO - [Metrics for 'normal'] | Precision: 0.7614 | Recall: 0.8242 | F1: 0.7916
2026-02-10 09:00:34,604 - INFO - --------------------------------------------------
2026-02-10 09:00:34,606 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 09:00:41,494 - INFO - [Train] [43/90] | Loss: 0.3194 | Train Acc: 92.78%
2026-02-10 09:00:42,837 - INFO - [Valid] [43/90] | Loss: 0.6060 | Val Acc: 79.06%
2026-02-10 09:00:42,842 - INFO - [Metrics for 'abnormal'] | Precision: 0.8071 | Recall: 0.7197 | F1: 0.7609
2026-02-10 09:00:42,842 - INFO - [Metrics for 'normal'] | Precision: 0.7789 | Recall: 0.8516 | F1: 0.8136
2026-02-10 09:00:42,844 - INFO - --------------------------------------------------
2026-02-10 09:00:42,846 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 09:00:49,969 - INFO - [Train] [44/90] | Loss: 0.3105 | Train Acc: 94.05%
2026-02-10 09:00:51,450 - INFO - [Valid] [44/90] | Loss: 0.6083 | Val Acc: 77.29%
2026-02-10 09:00:51,455 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-02-10 09:00:51,455 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-02-10 09:00:51,456 - INFO - --------------------------------------------------
2026-02-10 09:00:51,458 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 09:00:57,409 - INFO - [Train] [45/90] | Loss: 0.3152 | Train Acc: 93.60%
2026-02-10 09:00:58,619 - INFO - [Valid] [45/90] | Loss: 0.5884 | Val Acc: 77.88%
2026-02-10 09:00:58,624 - INFO - [Metrics for 'abnormal'] | Precision: 0.7562 | Recall: 0.7707 | F1: 0.7634
2026-02-10 09:00:58,624 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.7857 | F1: 0.7922
2026-02-10 09:00:58,625 - INFO - --------------------------------------------------
2026-02-10 09:00:58,627 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 09:01:05,138 - INFO - [Train] [46/90] | Loss: 0.3095 | Train Acc: 93.30%
2026-02-10 09:01:06,662 - INFO - [Valid] [46/90] | Loss: 0.5558 | Val Acc: 77.88%
2026-02-10 09:01:06,666 - INFO - [Metrics for 'abnormal'] | Precision: 0.7531 | Recall: 0.7771 | F1: 0.7649
2026-02-10 09:01:06,667 - INFO - [Metrics for 'normal'] | Precision: 0.8023 | Recall: 0.7802 | F1: 0.7911
2026-02-10 09:01:06,668 - INFO - --------------------------------------------------
2026-02-10 09:01:06,669 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 09:01:12,627 - INFO - [Train] [47/90] | Loss: 0.3053 | Train Acc: 94.72%
2026-02-10 09:01:13,746 - INFO - [Valid] [47/90] | Loss: 0.6477 | Val Acc: 75.81%
2026-02-10 09:01:13,757 - INFO - [Metrics for 'abnormal'] | Precision: 0.7219 | Recall: 0.7771 | F1: 0.7485
2026-02-10 09:01:13,758 - INFO - [Metrics for 'normal'] | Precision: 0.7941 | Recall: 0.7418 | F1: 0.7670
2026-02-10 09:01:13,759 - INFO - --------------------------------------------------
2026-02-10 09:01:13,761 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 09:01:19,582 - INFO - [Train] [48/90] | Loss: 0.2927 | Train Acc: 94.79%
2026-02-10 09:01:20,727 - INFO - [Valid] [48/90] | Loss: 0.5561 | Val Acc: 80.24%
2026-02-10 09:01:20,731 - INFO - [Metrics for 'abnormal'] | Precision: 0.7744 | Recall: 0.8089 | F1: 0.7913
2026-02-10 09:01:20,732 - INFO - [Metrics for 'normal'] | Precision: 0.8286 | Recall: 0.7967 | F1: 0.8123
2026-02-10 09:01:20,733 - INFO - --------------------------------------------------
2026-02-10 09:01:20,735 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 09:01:26,623 - INFO - [Train] [49/90] | Loss: 0.2984 | Train Acc: 94.42%
2026-02-10 09:01:27,922 - INFO - [Valid] [49/90] | Loss: 0.5887 | Val Acc: 76.70%
2026-02-10 09:01:27,928 - INFO - [Metrics for 'abnormal'] | Precision: 0.7786 | Recall: 0.6943 | F1: 0.7340
2026-02-10 09:01:27,928 - INFO - [Metrics for 'normal'] | Precision: 0.7588 | Recall: 0.8297 | F1: 0.7927
2026-02-10 09:01:27,930 - INFO - --------------------------------------------------
2026-02-10 09:01:27,935 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 09:01:33,664 - INFO - [Train] [50/90] | Loss: 0.2858 | Train Acc: 95.01%
2026-02-10 09:01:34,875 - INFO - [Valid] [50/90] | Loss: 0.6134 | Val Acc: 77.29%
2026-02-10 09:01:34,880 - INFO - [Metrics for 'abnormal'] | Precision: 0.7740 | Recall: 0.7197 | F1: 0.7459
2026-02-10 09:01:34,880 - INFO - [Metrics for 'normal'] | Precision: 0.7720 | Recall: 0.8187 | F1: 0.7947
2026-02-10 09:01:34,882 - INFO - --------------------------------------------------
2026-02-10 09:01:34,884 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 09:01:40,602 - INFO - [Train] [51/90] | Loss: 0.2882 | Train Acc: 95.54%
2026-02-10 09:01:41,736 - INFO - [Valid] [51/90] | Loss: 0.6285 | Val Acc: 75.22%
2026-02-10 09:01:41,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.7017 | Recall: 0.8089 | F1: 0.7515
2026-02-10 09:01:41,744 - INFO - [Metrics for 'normal'] | Precision: 0.8101 | Recall: 0.7033 | F1: 0.7529
2026-02-10 09:01:41,746 - INFO - --------------------------------------------------
2026-02-10 09:01:41,748 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 09:01:47,884 - INFO - [Train] [52/90] | Loss: 0.2954 | Train Acc: 94.20%
2026-02-10 09:01:49,074 - INFO - [Valid] [52/90] | Loss: 0.5854 | Val Acc: 78.47%
2026-02-10 09:01:49,079 - INFO - [Metrics for 'abnormal'] | Precision: 0.7958 | Recall: 0.7197 | F1: 0.7559
2026-02-10 09:01:49,079 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8407 | F1: 0.8074
2026-02-10 09:01:49,080 - INFO - --------------------------------------------------
2026-02-10 09:01:49,083 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 09:01:54,664 - INFO - [Train] [53/90] | Loss: 0.2915 | Train Acc: 95.68%
2026-02-10 09:01:55,919 - INFO - [Valid] [53/90] | Loss: 0.5919 | Val Acc: 79.06%
2026-02-10 09:01:55,924 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-02-10 09:01:55,925 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-02-10 09:01:55,926 - INFO - --------------------------------------------------
2026-02-10 09:01:55,928 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 09:02:01,051 - INFO - [Train] [54/90] | Loss: 0.2981 | Train Acc: 94.49%
2026-02-10 09:02:02,347 - INFO - [Valid] [54/90] | Loss: 0.5899 | Val Acc: 77.29%
2026-02-10 09:02:02,352 - INFO - [Metrics for 'abnormal'] | Precision: 0.8030 | Recall: 0.6752 | F1: 0.7336
2026-02-10 09:02:02,352 - INFO - [Metrics for 'normal'] | Precision: 0.7536 | Recall: 0.8571 | F1: 0.8021
2026-02-10 09:02:02,354 - INFO - --------------------------------------------------
2026-02-10 09:02:02,357 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 09:02:07,896 - INFO - [Train] [55/90] | Loss: 0.2841 | Train Acc: 95.54%
2026-02-10 09:02:08,899 - INFO - [Valid] [55/90] | Loss: 0.6063 | Val Acc: 78.47%
2026-02-10 09:02:08,904 - INFO - [Metrics for 'abnormal'] | Precision: 0.7561 | Recall: 0.7898 | F1: 0.7726
2026-02-10 09:02:08,904 - INFO - [Metrics for 'normal'] | Precision: 0.8114 | Recall: 0.7802 | F1: 0.7955
2026-02-10 09:02:08,906 - INFO - --------------------------------------------------
2026-02-10 09:02:08,907 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 09:02:14,295 - INFO - [Train] [56/90] | Loss: 0.2763 | Train Acc: 95.91%
2026-02-10 09:02:15,538 - INFO - [Valid] [56/90] | Loss: 0.5957 | Val Acc: 75.81%
2026-02-10 09:02:15,543 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.7643 | F1: 0.7453
2026-02-10 09:02:15,543 - INFO - [Metrics for 'normal'] | Precision: 0.7874 | Recall: 0.7527 | F1: 0.7697
2026-02-10 09:02:15,545 - INFO - --------------------------------------------------
2026-02-10 09:02:15,547 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 09:02:21,157 - INFO - [Train] [57/90] | Loss: 0.2787 | Train Acc: 95.98%
2026-02-10 09:02:22,485 - INFO - [Valid] [57/90] | Loss: 0.6055 | Val Acc: 77.58%
2026-02-10 09:02:22,493 - INFO - [Metrics for 'abnormal'] | Precision: 0.7341 | Recall: 0.8089 | F1: 0.7697
2026-02-10 09:02:22,493 - INFO - [Metrics for 'normal'] | Precision: 0.8193 | Recall: 0.7473 | F1: 0.7816
2026-02-10 09:02:22,495 - INFO - --------------------------------------------------
2026-02-10 09:02:22,496 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 09:02:27,984 - INFO - [Train] [58/90] | Loss: 0.2830 | Train Acc: 96.06%
2026-02-10 09:02:29,277 - INFO - [Valid] [58/90] | Loss: 0.6121 | Val Acc: 79.94%
2026-02-10 09:02:29,281 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-02-10 09:02:29,281 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-02-10 09:02:29,283 - INFO - --------------------------------------------------
2026-02-10 09:02:29,285 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 09:02:34,213 - INFO - [Train] [59/90] | Loss: 0.2727 | Train Acc: 96.28%
2026-02-10 09:02:35,204 - INFO - [Valid] [59/90] | Loss: 0.6112 | Val Acc: 76.99%
2026-02-10 09:02:35,210 - INFO - [Metrics for 'abnormal'] | Precision: 0.7310 | Recall: 0.7962 | F1: 0.7622
2026-02-10 09:02:35,210 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.7473 | F1: 0.7771
2026-02-10 09:02:35,212 - INFO - --------------------------------------------------
2026-02-10 09:02:35,214 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 09:02:40,511 - INFO - [Train] [60/90] | Loss: 0.2559 | Train Acc: 96.88%
2026-02-10 09:02:41,811 - INFO - [Valid] [60/90] | Loss: 0.6534 | Val Acc: 77.29%
2026-02-10 09:02:41,817 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-02-10 09:02:41,817 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-02-10 09:02:41,819 - INFO - --------------------------------------------------
2026-02-10 09:02:41,821 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 09:02:47,478 - INFO - [Train] [61/90] | Loss: 0.2795 | Train Acc: 95.61%
2026-02-10 09:02:48,848 - INFO - [Valid] [61/90] | Loss: 0.6037 | Val Acc: 77.88%
2026-02-10 09:02:48,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.7662 | Recall: 0.7516 | F1: 0.7588
2026-02-10 09:02:48,855 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8022 | F1: 0.7956
2026-02-10 09:02:48,856 - INFO - --------------------------------------------------
2026-02-10 09:02:48,858 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 09:02:54,495 - INFO - [Train] [62/90] | Loss: 0.2675 | Train Acc: 96.50%
2026-02-10 09:02:55,628 - INFO - [Valid] [62/90] | Loss: 0.6066 | Val Acc: 76.99%
2026-02-10 09:02:55,634 - INFO - [Metrics for 'abnormal'] | Precision: 0.7724 | Recall: 0.7134 | F1: 0.7417
2026-02-10 09:02:55,634 - INFO - [Metrics for 'normal'] | Precision: 0.7680 | Recall: 0.8187 | F1: 0.7926
2026-02-10 09:02:55,636 - INFO - --------------------------------------------------
2026-02-10 09:02:55,641 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 09:03:02,183 - INFO - [Train] [63/90] | Loss: 0.2750 | Train Acc: 95.91%
2026-02-10 09:03:03,736 - INFO - [Valid] [63/90] | Loss: 0.6379 | Val Acc: 78.76%
2026-02-10 09:03:03,742 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-02-10 09:03:03,742 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-02-10 09:03:03,744 - INFO - --------------------------------------------------
2026-02-10 09:03:03,746 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 09:03:10,228 - INFO - [Train] [64/90] | Loss: 0.2588 | Train Acc: 97.40%
2026-02-10 09:03:11,610 - INFO - [Valid] [64/90] | Loss: 0.6083 | Val Acc: 78.47%
2026-02-10 09:03:11,615 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.7643 | F1: 0.7668
2026-02-10 09:03:11,615 - INFO - [Metrics for 'normal'] | Precision: 0.7978 | Recall: 0.8022 | F1: 0.8000
2026-02-10 09:03:11,617 - INFO - --------------------------------------------------
2026-02-10 09:03:11,619 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 09:03:18,752 - INFO - [Train] [65/90] | Loss: 0.2681 | Train Acc: 96.50%
2026-02-10 09:03:20,301 - INFO - [Valid] [65/90] | Loss: 0.6063 | Val Acc: 77.29%
2026-02-10 09:03:20,306 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-02-10 09:03:20,306 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-02-10 09:03:20,307 - INFO - --------------------------------------------------
2026-02-10 09:03:20,309 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 09:03:27,436 - INFO - [Train] [66/90] | Loss: 0.2664 | Train Acc: 97.10%
2026-02-10 09:03:28,952 - INFO - [Valid] [66/90] | Loss: 0.6046 | Val Acc: 77.88%
2026-02-10 09:03:28,957 - INFO - [Metrics for 'abnormal'] | Precision: 0.7662 | Recall: 0.7516 | F1: 0.7588
2026-02-10 09:03:28,957 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8022 | F1: 0.7956
2026-02-10 09:03:28,958 - INFO - --------------------------------------------------
2026-02-10 09:03:28,964 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 09:03:35,436 - INFO - [Train] [67/90] | Loss: 0.2627 | Train Acc: 97.02%
2026-02-10 09:03:36,785 - INFO - [Valid] [67/90] | Loss: 0.6265 | Val Acc: 77.29%
2026-02-10 09:03:36,789 - INFO - [Metrics for 'abnormal'] | Precision: 0.7899 | Recall: 0.6943 | F1: 0.7390
2026-02-10 09:03:36,789 - INFO - [Metrics for 'normal'] | Precision: 0.7612 | Recall: 0.8407 | F1: 0.7990
2026-02-10 09:03:36,791 - INFO - --------------------------------------------------
2026-02-10 09:03:36,792 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 09:03:44,317 - INFO - [Train] [68/90] | Loss: 0.2505 | Train Acc: 97.77%
2026-02-10 09:03:45,859 - INFO - [Valid] [68/90] | Loss: 0.6143 | Val Acc: 78.76%
2026-02-10 09:03:45,864 - INFO - [Metrics for 'abnormal'] | Precision: 0.8102 | Recall: 0.7070 | F1: 0.7551
2026-02-10 09:03:45,864 - INFO - [Metrics for 'normal'] | Precision: 0.7723 | Recall: 0.8571 | F1: 0.8125
2026-02-10 09:03:45,870 - INFO - --------------------------------------------------
2026-02-10 09:03:45,871 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 09:03:52,692 - INFO - [Train] [69/90] | Loss: 0.2506 | Train Acc: 97.69%
2026-02-10 09:03:54,263 - INFO - [Valid] [69/90] | Loss: 0.6331 | Val Acc: 78.76%
2026-02-10 09:03:54,268 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-02-10 09:03:54,268 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-02-10 09:03:54,270 - INFO - --------------------------------------------------
2026-02-10 09:03:54,272 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 09:04:01,488 - INFO - [Train] [70/90] | Loss: 0.2562 | Train Acc: 97.47%
2026-02-10 09:04:03,242 - INFO - [Valid] [70/90] | Loss: 0.6292 | Val Acc: 79.06%
2026-02-10 09:04:03,248 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-02-10 09:04:03,248 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-02-10 09:04:03,249 - INFO - --------------------------------------------------
2026-02-10 09:04:03,251 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 09:04:10,436 - INFO - [Train] [71/90] | Loss: 0.2604 | Train Acc: 97.17%
2026-02-10 09:04:11,809 - INFO - [Valid] [71/90] | Loss: 0.6169 | Val Acc: 78.47%
2026-02-10 09:04:11,815 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.7643 | F1: 0.7668
2026-02-10 09:04:11,815 - INFO - [Metrics for 'normal'] | Precision: 0.7978 | Recall: 0.8022 | F1: 0.8000
2026-02-10 09:04:11,816 - INFO - --------------------------------------------------
2026-02-10 09:04:11,818 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 09:04:19,018 - INFO - [Train] [72/90] | Loss: 0.2673 | Train Acc: 96.35%
2026-02-10 09:04:20,162 - INFO - [Valid] [72/90] | Loss: 0.5966 | Val Acc: 79.06%
2026-02-10 09:04:20,166 - INFO - [Metrics for 'abnormal'] | Precision: 0.7722 | Recall: 0.7771 | F1: 0.7746
2026-02-10 09:04:20,166 - INFO - [Metrics for 'normal'] | Precision: 0.8066 | Recall: 0.8022 | F1: 0.8044
2026-02-10 09:04:20,168 - INFO - --------------------------------------------------
2026-02-10 09:04:20,169 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 09:04:27,278 - INFO - [Train] [73/90] | Loss: 0.2454 | Train Acc: 97.77%
2026-02-10 09:04:28,621 - INFO - [Valid] [73/90] | Loss: 0.6221 | Val Acc: 79.06%
2026-02-10 09:04:28,627 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-02-10 09:04:28,627 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-02-10 09:04:28,628 - INFO - --------------------------------------------------
2026-02-10 09:04:28,630 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 09:04:35,498 - INFO - [Train] [74/90] | Loss: 0.2448 | Train Acc: 97.99%
2026-02-10 09:04:37,220 - INFO - [Valid] [74/90] | Loss: 0.6590 | Val Acc: 76.40%
2026-02-10 09:04:37,225 - INFO - [Metrics for 'abnormal'] | Precision: 0.7452 | Recall: 0.7452 | F1: 0.7452
2026-02-10 09:04:37,225 - INFO - [Metrics for 'normal'] | Precision: 0.7802 | Recall: 0.7802 | F1: 0.7802
2026-02-10 09:04:37,227 - INFO - --------------------------------------------------
2026-02-10 09:04:37,229 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 09:04:44,530 - INFO - [Train] [75/90] | Loss: 0.2582 | Train Acc: 97.25%
2026-02-10 09:04:45,796 - INFO - [Valid] [75/90] | Loss: 0.6174 | Val Acc: 79.06%
2026-02-10 09:04:45,802 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.7834 | F1: 0.7760
2026-02-10 09:04:45,802 - INFO - [Metrics for 'normal'] | Precision: 0.8101 | Recall: 0.7967 | F1: 0.8033
2026-02-10 09:04:45,803 - INFO - --------------------------------------------------
2026-02-10 09:04:45,805 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 09:04:52,713 - INFO - [Train] [76/90] | Loss: 0.2396 | Train Acc: 98.07%
2026-02-10 09:04:54,285 - INFO - [Valid] [76/90] | Loss: 0.6388 | Val Acc: 78.47%
2026-02-10 09:04:54,290 - INFO - [Metrics for 'abnormal'] | Precision: 0.7360 | Recall: 0.8344 | F1: 0.7821
2026-02-10 09:04:54,291 - INFO - [Metrics for 'normal'] | Precision: 0.8385 | Recall: 0.7418 | F1: 0.7872
2026-02-10 09:04:54,293 - INFO - --------------------------------------------------
2026-02-10 09:04:54,295 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 09:05:01,349 - INFO - [Train] [77/90] | Loss: 0.2464 | Train Acc: 98.14%
2026-02-10 09:05:02,737 - INFO - [Valid] [77/90] | Loss: 0.6233 | Val Acc: 77.88%
2026-02-10 09:05:02,742 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.7452 | F1: 0.7573
2026-02-10 09:05:02,742 - INFO - [Metrics for 'normal'] | Precision: 0.7861 | Recall: 0.8077 | F1: 0.7967
2026-02-10 09:05:02,744 - INFO - --------------------------------------------------
2026-02-10 09:05:02,745 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 09:05:09,525 - INFO - [Train] [78/90] | Loss: 0.2451 | Train Acc: 97.99%
2026-02-10 09:05:11,083 - INFO - [Valid] [78/90] | Loss: 0.6469 | Val Acc: 78.17%
2026-02-10 09:05:11,088 - INFO - [Metrics for 'abnormal'] | Precision: 0.7785 | Recall: 0.7389 | F1: 0.7582
2026-02-10 09:05:11,088 - INFO - [Metrics for 'normal'] | Precision: 0.7842 | Recall: 0.8187 | F1: 0.8011
2026-02-10 09:05:11,090 - INFO - --------------------------------------------------
2026-02-10 09:05:11,092 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 09:05:17,546 - INFO - [Train] [79/90] | Loss: 0.2443 | Train Acc: 98.14%
2026-02-10 09:05:19,110 - INFO - [Valid] [79/90] | Loss: 0.6206 | Val Acc: 79.94%
2026-02-10 09:05:19,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-02-10 09:05:19,116 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-02-10 09:05:19,117 - INFO - --------------------------------------------------
2026-02-10 09:05:19,119 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 09:05:25,516 - INFO - [Train] [80/90] | Loss: 0.2438 | Train Acc: 98.21%
2026-02-10 09:05:27,226 - INFO - [Valid] [80/90] | Loss: 0.6124 | Val Acc: 78.76%
2026-02-10 09:05:27,231 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7197 | F1: 0.7584
2026-02-10 09:05:27,232 - INFO - [Metrics for 'normal'] | Precision: 0.7778 | Recall: 0.8462 | F1: 0.8105
2026-02-10 09:05:27,233 - INFO - --------------------------------------------------
2026-02-10 09:05:27,235 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 09:05:33,804 - INFO - [Train] [81/90] | Loss: 0.2518 | Train Acc: 97.54%
2026-02-10 09:05:35,190 - INFO - [Valid] [81/90] | Loss: 0.6217 | Val Acc: 79.65%
2026-02-10 09:05:35,194 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 09:05:35,195 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 09:05:35,196 - INFO - --------------------------------------------------
2026-02-10 09:05:35,197 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 09:05:42,363 - INFO - [Train] [82/90] | Loss: 0.2403 | Train Acc: 98.81%
2026-02-10 09:05:44,019 - INFO - [Valid] [82/90] | Loss: 0.6109 | Val Acc: 80.24%
2026-02-10 09:05:44,024 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-02-10 09:05:44,024 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-02-10 09:05:44,027 - INFO - --------------------------------------------------
2026-02-10 09:05:44,029 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 09:05:50,746 - INFO - [Train] [83/90] | Loss: 0.2331 | Train Acc: 98.96%
2026-02-10 09:05:52,279 - INFO - [Valid] [83/90] | Loss: 0.6097 | Val Acc: 80.53%
2026-02-10 09:05:52,284 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7707 | F1: 0.7857
2026-02-10 09:05:52,284 - INFO - [Metrics for 'normal'] | Precision: 0.8085 | Recall: 0.8352 | F1: 0.8216
2026-02-10 09:05:52,286 - INFO - --------------------------------------------------
2026-02-10 09:05:52,289 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 09:05:59,068 - INFO - [Train] [84/90] | Loss: 0.2519 | Train Acc: 97.84%
2026-02-10 09:06:00,449 - INFO - [Valid] [84/90] | Loss: 0.6118 | Val Acc: 78.47%
2026-02-10 09:06:00,454 - INFO - [Metrics for 'abnormal'] | Precision: 0.7917 | Recall: 0.7261 | F1: 0.7575
2026-02-10 09:06:00,454 - INFO - [Metrics for 'normal'] | Precision: 0.7795 | Recall: 0.8352 | F1: 0.8064
2026-02-10 09:06:00,456 - INFO - --------------------------------------------------
2026-02-10 09:06:00,458 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 09:06:07,410 - INFO - [Train] [85/90] | Loss: 0.2366 | Train Acc: 98.14%
2026-02-10 09:06:08,923 - INFO - [Valid] [85/90] | Loss: 0.6307 | Val Acc: 80.24%
2026-02-10 09:06:08,928 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-02-10 09:06:08,929 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-02-10 09:06:08,930 - INFO - --------------------------------------------------
2026-02-10 09:06:08,932 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 09:06:15,764 - INFO - [Train] [86/90] | Loss: 0.2353 | Train Acc: 98.51%
2026-02-10 09:06:17,341 - INFO - [Valid] [86/90] | Loss: 0.6290 | Val Acc: 77.88%
2026-02-10 09:06:17,346 - INFO - [Metrics for 'abnormal'] | Precision: 0.7595 | Recall: 0.7643 | F1: 0.7619
2026-02-10 09:06:17,347 - INFO - [Metrics for 'normal'] | Precision: 0.7956 | Recall: 0.7912 | F1: 0.7934
2026-02-10 09:06:17,349 - INFO - --------------------------------------------------
2026-02-10 09:06:17,354 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 09:06:24,080 - INFO - [Train] [87/90] | Loss: 0.2416 | Train Acc: 97.84%
2026-02-10 09:06:25,558 - INFO - [Valid] [87/90] | Loss: 0.6160 | Val Acc: 79.94%
2026-02-10 09:06:25,562 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-02-10 09:06:25,563 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-02-10 09:06:25,564 - INFO - --------------------------------------------------
2026-02-10 09:06:25,566 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 09:06:32,606 - INFO - [Train] [88/90] | Loss: 0.2372 | Train Acc: 98.51%
2026-02-10 09:06:34,096 - INFO - [Valid] [88/90] | Loss: 0.6287 | Val Acc: 78.76%
2026-02-10 09:06:34,101 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-02-10 09:06:34,101 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-02-10 09:06:34,102 - INFO - --------------------------------------------------
2026-02-10 09:06:34,104 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 09:06:40,781 - INFO - [Train] [89/90] | Loss: 0.2443 | Train Acc: 98.21%
2026-02-10 09:06:42,212 - INFO - [Valid] [89/90] | Loss: 0.6232 | Val Acc: 78.76%
2026-02-10 09:06:42,216 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-02-10 09:06:42,217 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-02-10 09:06:42,219 - INFO - --------------------------------------------------
2026-02-10 09:06:42,221 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 09:06:49,158 - INFO - [Train] [90/90] | Loss: 0.2409 | Train Acc: 98.74%
2026-02-10 09:06:50,676 - INFO - [Valid] [90/90] | Loss: 0.6351 | Val Acc: 79.35%
2026-02-10 09:06:50,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-02-10 09:06:50,686 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-02-10 09:06:50,689 - INFO - ==================================================
2026-02-10 09:06:50,689 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 09:06:50,689 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 09:06:50,689 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 09:06:50,731 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 09:06:50,751 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 09:06:50,752 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 09:06:50,752 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-02-10 09:06:50,753 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 09:06:51,187 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86431640625)에 맞춰 변경되었습니다.
2026-02-10 09:06:51,188 - INFO - ==================================================
2026-02-10 09:06:51,275 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/best_model.pth'
2026-02-10 09:06:51,275 - INFO - ==================================================
2026-02-10 09:06:51,275 - INFO - Test 모드를 시작합니다.
2026-02-10 09:06:51,454 - INFO - 연산량 (MACs): 0.0131 GMACs per sample
2026-02-10 09:06:51,454 - INFO - 연산량 (FLOPs): 0.0262 GFLOPs per sample
2026-02-10 09:06:51,454 - INFO - ==================================================
2026-02-10 09:06:51,454 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 09:06:53,126 - INFO - 샘플 당 평균 Forward Pass 시간: 5.49ms (std: 1.41ms), FPS: 209.05 (std: 128.38) (1개 샘플 x 100회 반복)
2026-02-10 09:06:53,126 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 38.54 MB
2026-02-10 09:06:53,126 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 09:06:55,294 - INFO - [Test] Loss: 0.4422 | Test Acc: 80.53%
2026-02-10 09:06:55,301 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-02-10 09:06:55,302 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-02-10 09:06:55,604 - INFO - ==================================================
2026-02-10 09:06:55,605 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/confusion_matrix_20260210_085351.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/confusion_matrix_20260210_085351.pdf'
2026-02-10 09:06:55,605 - INFO - ==================================================
2026-02-10 09:06:55,605 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 09:06:59,702 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/model_fp32_20260210_085351.onnx'에 저장되었습니다. (크기: 0.36 MB)
2026-02-10 09:07:00,304 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 9.75 MB
2026-02-10 09:07:00,304 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 09:07:03,371 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 24.16ms (std: 11.75ms)
2026-02-10 09:07:03,371 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 53.59 FPS (std: 36.16) (1개 샘플 x 100회 반복)
2026-02-10 09:07:03,371 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 12.00 MB
2026-02-10 09:07:03,371 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 21.71 MB
2026-02-10 09:07:13,114 - INFO - [Test (ONNX)] | Test Acc (ONNX): 80.53%
2026-02-10 09:07:13,120 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-02-10 09:07:13,127 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-02-10 09:07:13,463 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/val_acc.pdf'
2026-02-10 09:07:13,707 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/train_val_acc.pdf'
2026-02-10 09:07:13,911 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/F1_normal.pdf'
2026-02-10 09:07:14,143 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/val_loss.pdf'
2026-02-10 09:07:14,337 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/learning_rate.pdf'
2026-02-10 09:07:16,533 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260210_085351/graph_20260210_085351/compile.pdf'
