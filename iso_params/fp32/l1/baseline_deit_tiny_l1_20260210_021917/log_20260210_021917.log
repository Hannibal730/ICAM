2026-02-10 02:19:17,314 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/log_20260210_021917.log'에 저장됩니다.
2026-02-10 02:19:17,316 - INFO - ==================================================
2026-02-10 02:19:17,316 - INFO - config.yaml:
2026-02-10 02:19:17,316 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: deit_tiny
  use_l1_pruning: true
  pruning_params_target: 0.047585

2026-02-10 02:19:17,316 - INFO - ==================================================
2026-02-10 02:19:17,346 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 02:19:17,347 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 02:19:17,347 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 02:19:17,352 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 02:19:17,352 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 02:19:17,353 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 02:19:17,353 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 02:19:17,888 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 02:19:17,890 - INFO - ==================================================
2026-02-10 02:19:17,890 - INFO - 모델 파라미터 수:
2026-02-10 02:19:17,890 - INFO -   - 총 파라미터: 5,524,802 개
2026-02-10 02:19:17,890 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-02-10 02:19:17,890 - INFO - ================================================================================
2026-02-10 02:19:17,890 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-02-10 02:19:17,890 - INFO - ================================================================================
2026-02-10 02:19:17,890 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 02:19:17,890 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-02-10 02:19:17,890 - INFO - ==================================================
2026-02-10 02:19:17,890 - INFO - train 모드를 시작합니다.
2026-02-10 02:19:17,890 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 02:19:17,890 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 02:19:17,891 - INFO - --------------------------------------------------
2026-02-10 02:19:17,891 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-02-10 02:19:21,188 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-02-10 02:19:22,295 - INFO - [Valid] [1/10] | Loss: 0.6724 | Val Acc: 59.88%
2026-02-10 02:19:22,300 - INFO - [Metrics for 'abnormal'] | Precision: 0.5488 | Recall: 0.7516 | F1: 0.6344
2026-02-10 02:19:22,301 - INFO - [Metrics for 'normal'] | Precision: 0.6855 | Recall: 0.4670 | F1: 0.5556
2026-02-10 02:19:22,323 - INFO - [Best Model Saved] (val loss: 0.6724) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:19:22,323 - INFO - --------------------------------------------------
2026-02-10 02:19:22,324 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-02-10 02:19:24,904 - INFO - [Train] [2/10] | Loss: 0.6464 | Train Acc: 64.43%
2026-02-10 02:19:25,618 - INFO - [Valid] [2/10] | Loss: 0.6629 | Val Acc: 61.65%
2026-02-10 02:19:25,623 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.2548 | F1: 0.3810
2026-02-10 02:19:25,623 - INFO - [Metrics for 'normal'] | Precision: 0.5909 | Recall: 0.9286 | F1: 0.7222
2026-02-10 02:19:25,660 - INFO - [Best Model Saved] (val loss: 0.6629) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:19:25,660 - INFO - --------------------------------------------------
2026-02-10 02:19:25,661 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-02-10 02:19:28,764 - INFO - [Train] [3/10] | Loss: 0.5956 | Train Acc: 68.90%
2026-02-10 02:19:29,817 - INFO - [Valid] [3/10] | Loss: 0.5660 | Val Acc: 74.93%
2026-02-10 02:19:29,821 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.6497 | F1: 0.7059
2026-02-10 02:19:29,828 - INFO - [Metrics for 'normal'] | Precision: 0.7343 | Recall: 0.8352 | F1: 0.7815
2026-02-10 02:19:29,867 - INFO - [Best Model Saved] (val loss: 0.5660) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:19:29,867 - INFO - --------------------------------------------------
2026-02-10 02:19:29,868 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-02-10 02:19:33,136 - INFO - [Train] [4/10] | Loss: 0.5630 | Train Acc: 75.82%
2026-02-10 02:19:33,826 - INFO - [Valid] [4/10] | Loss: 0.5505 | Val Acc: 74.04%
2026-02-10 02:19:33,831 - INFO - [Metrics for 'abnormal'] | Precision: 0.7117 | Recall: 0.7389 | F1: 0.7250
2026-02-10 02:19:33,831 - INFO - [Metrics for 'normal'] | Precision: 0.7670 | Recall: 0.7418 | F1: 0.7542
2026-02-10 02:19:33,870 - INFO - [Best Model Saved] (val loss: 0.5505) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:19:33,870 - INFO - --------------------------------------------------
2026-02-10 02:19:33,871 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-02-10 02:19:36,670 - INFO - [Train] [5/10] | Loss: 0.5155 | Train Acc: 78.94%
2026-02-10 02:19:37,237 - INFO - [Valid] [5/10] | Loss: 0.5579 | Val Acc: 74.63%
2026-02-10 02:19:37,240 - INFO - [Metrics for 'abnormal'] | Precision: 0.7126 | Recall: 0.7580 | F1: 0.7346
2026-02-10 02:19:37,240 - INFO - [Metrics for 'normal'] | Precision: 0.7791 | Recall: 0.7363 | F1: 0.7571
2026-02-10 02:19:37,241 - INFO - --------------------------------------------------
2026-02-10 02:19:37,241 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-02-10 02:19:39,934 - INFO - [Train] [6/10] | Loss: 0.5177 | Train Acc: 78.50%
2026-02-10 02:19:40,416 - INFO - [Valid] [6/10] | Loss: 0.5393 | Val Acc: 74.63%
2026-02-10 02:19:40,418 - INFO - [Metrics for 'abnormal'] | Precision: 0.6940 | Recall: 0.8089 | F1: 0.7471
2026-02-10 02:19:40,418 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.6923 | F1: 0.7456
2026-02-10 02:19:40,441 - INFO - [Best Model Saved] (val loss: 0.5393) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:19:40,441 - INFO - --------------------------------------------------
2026-02-10 02:19:40,442 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-02-10 02:19:43,686 - INFO - [Train] [7/10] | Loss: 0.4901 | Train Acc: 81.32%
2026-02-10 02:19:44,579 - INFO - [Valid] [7/10] | Loss: 0.5521 | Val Acc: 76.99%
2026-02-10 02:19:44,582 - INFO - [Metrics for 'abnormal'] | Precision: 0.8264 | Recall: 0.6369 | F1: 0.7194
2026-02-10 02:19:44,582 - INFO - [Metrics for 'normal'] | Precision: 0.7385 | Recall: 0.8846 | F1: 0.8050
2026-02-10 02:19:44,583 - INFO - --------------------------------------------------
2026-02-10 02:19:44,583 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-02-10 02:19:47,784 - INFO - [Train] [8/10] | Loss: 0.4861 | Train Acc: 81.70%
2026-02-10 02:19:48,886 - INFO - [Valid] [8/10] | Loss: 0.5293 | Val Acc: 77.29%
2026-02-10 02:19:48,890 - INFO - [Metrics for 'abnormal'] | Precision: 0.8175 | Recall: 0.6561 | F1: 0.7279
2026-02-10 02:19:48,890 - INFO - [Metrics for 'normal'] | Precision: 0.7465 | Recall: 0.8736 | F1: 0.8051
2026-02-10 02:19:48,924 - INFO - [Best Model Saved] (val loss: 0.5293) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:19:48,924 - INFO - --------------------------------------------------
2026-02-10 02:19:48,925 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-02-10 02:19:52,438 - INFO - [Train] [9/10] | Loss: 0.4830 | Train Acc: 80.88%
2026-02-10 02:19:53,137 - INFO - [Valid] [9/10] | Loss: 0.5372 | Val Acc: 76.40%
2026-02-10 02:19:53,142 - INFO - [Metrics for 'abnormal'] | Precision: 0.7655 | Recall: 0.7070 | F1: 0.7351
2026-02-10 02:19:53,143 - INFO - [Metrics for 'normal'] | Precision: 0.7629 | Recall: 0.8132 | F1: 0.7872
2026-02-10 02:19:53,145 - INFO - --------------------------------------------------
2026-02-10 02:19:53,145 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-02-10 02:19:58,267 - INFO - [Train] [10/10] | Loss: 0.4752 | Train Acc: 82.29%
2026-02-10 02:19:59,452 - INFO - [Valid] [10/10] | Loss: 0.5302 | Val Acc: 76.70%
2026-02-10 02:19:59,458 - INFO - [Metrics for 'abnormal'] | Precision: 0.7378 | Recall: 0.7707 | F1: 0.7539
2026-02-10 02:19:59,458 - INFO - [Metrics for 'normal'] | Precision: 0.7943 | Recall: 0.7637 | F1: 0.7787
2026-02-10 02:19:59,460 - INFO - ================================================================================
2026-02-10 02:19:59,461 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-02-10 02:19:59,461 - INFO - ================================================================================
2026-02-10 02:19:59,496 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'을(를) 불러왔습니다.
2026-02-10 02:19:59,496 - INFO - ================================================================================
2026-02-10 02:19:59,496 - INFO - 목표 파라미터 수 (0.0476M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-02-10 02:19:59,497 - INFO - 원본 모델 파라미터: 5.5248M
2026-02-10 02:19:59,526 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:59,527 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:59,527 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:19:59,789 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-02-10 02:19:59,789 - INFO - ==================================================
2026-02-10 02:19:59,790 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.8881M (감소율: 65.83%)
2026-02-10 02:19:59,806 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:19:59,807 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:19:59,807 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:00,529 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-02-10 02:20:00,530 - INFO - ==================================================
2026-02-10 02:20:00,531 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.7436M (감소율: 86.54%)
2026-02-10 02:20:00,549 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:00,549 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:00,550 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:00,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-02-10 02:20:00,795 - INFO - ==================================================
2026-02-10 02:20:00,796 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.3258M (감소율: 94.10%)
2026-02-10 02:20:00,815 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:00,815 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:00,816 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:01,104 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-02-10 02:20:01,104 - INFO - ==================================================
2026-02-10 02:20:01,109 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.1581M (감소율: 97.14%)
2026-02-10 02:20:01,131 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:01,131 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:01,132 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:01,378 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-02-10 02:20:01,378 - INFO - ==================================================
2026-02-10 02:20:01,380 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0843M (감소율: 98.47%)
2026-02-10 02:20:01,399 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:01,399 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:01,400 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:01,651 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97453125)에 맞춰 변경되었습니다.
2026-02-10 02:20:01,651 - INFO - ==================================================
2026-02-10 02:20:01,653 - INFO -   [탐색  6] 희소도: 0.9745 -> 파라미터: 0.0500M (감소율: 99.09%)
2026-02-10 02:20:01,671 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:01,672 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:01,672 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:02,436 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9822656249999999)에 맞춰 변경되었습니다.
2026-02-10 02:20:02,436 - INFO - ==================================================
2026-02-10 02:20:02,438 - INFO -   [탐색  7] 희소도: 0.9823 -> 파라미터: 0.0388M (감소율: 99.30%)
2026-02-10 02:20:02,456 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:02,456 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:02,456 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:02,726 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 02:20:02,726 - INFO - ==================================================
2026-02-10 02:20:02,728 - INFO -   [탐색  8] 희소도: 0.9784 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:02,749 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:02,750 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:02,751 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:03,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9803320312499999)에 맞춰 변경되었습니다.
2026-02-10 02:20:03,157 - INFO - ==================================================
2026-02-10 02:20:03,158 - INFO -   [탐색  9] 희소도: 0.9803 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:03,175 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:03,175 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:03,175 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:03,434 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9793652343749999)에 맞춰 변경되었습니다.
2026-02-10 02:20:03,434 - INFO - ==================================================
2026-02-10 02:20:03,435 - INFO -   [탐색 10] 희소도: 0.9794 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:03,451 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:03,451 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:03,451 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:03,707 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9788818359374999)에 맞춰 변경되었습니다.
2026-02-10 02:20:03,707 - INFO - ==================================================
2026-02-10 02:20:03,709 - INFO -   [탐색 11] 희소도: 0.9789 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:03,724 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:03,724 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:03,724 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:04,683 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97912353515625)에 맞춰 변경되었습니다.
2026-02-10 02:20:04,684 - INFO - ==================================================
2026-02-10 02:20:04,685 - INFO -   [탐색 12] 희소도: 0.9791 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:04,703 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:04,703 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:04,704 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:04,945 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9792443847656249)에 맞춰 변경되었습니다.
2026-02-10 02:20:04,946 - INFO - ==================================================
2026-02-10 02:20:04,947 - INFO -   [탐색 13] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:04,965 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:04,965 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:04,966 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:05,194 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791839599609374)에 맞춰 변경되었습니다.
2026-02-10 02:20:05,195 - INFO - ==================================================
2026-02-10 02:20:05,196 - INFO -   [탐색 14] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:05,213 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:05,214 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:05,214 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:05,472 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791537475585936)에 맞춰 변경되었습니다.
2026-02-10 02:20:05,472 - INFO - ==================================================
2026-02-10 02:20:05,474 - INFO -   [탐색 15] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:05,489 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:05,489 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:05,490 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:05,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791688537597656)에 맞춰 변경되었습니다.
2026-02-10 02:20:05,795 - INFO - ==================================================
2026-02-10 02:20:05,797 - INFO -   [탐색 16] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:05,813 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:05,814 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:05,814 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:06,534 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791613006591796)에 맞춰 변경되었습니다.
2026-02-10 02:20:06,535 - INFO - ==================================================
2026-02-10 02:20:06,537 - INFO -   [탐색 17] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:06,553 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:06,554 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:06,554 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:06,801 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791650772094727)에 맞춰 변경되었습니다.
2026-02-10 02:20:06,801 - INFO - ==================================================
2026-02-10 02:20:06,803 - INFO -   [탐색 18] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:06,820 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:06,820 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:06,821 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:07,078 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791669654846191)에 맞춰 변경되었습니다.
2026-02-10 02:20:07,078 - INFO - ==================================================
2026-02-10 02:20:07,079 - INFO -   [탐색 19] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:07,098 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:07,098 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:07,098 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:07,463 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791660213470459)에 맞춰 변경되었습니다.
2026-02-10 02:20:07,464 - INFO - ==================================================
2026-02-10 02:20:07,465 - INFO -   [탐색 20] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:07,480 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:07,480 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:07,481 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:07,736 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791664934158325)에 맞춰 변경되었습니다.
2026-02-10 02:20:07,736 - INFO - ==================================================
2026-02-10 02:20:07,737 - INFO -   [탐색 21] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:07,753 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:07,753 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:07,754 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:08,541 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791667294502258)에 맞춰 변경되었습니다.
2026-02-10 02:20:08,541 - INFO - ==================================================
2026-02-10 02:20:08,544 - INFO -   [탐색 22] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:08,561 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:08,561 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:08,561 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:08,877 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666114330291)에 맞춰 변경되었습니다.
2026-02-10 02:20:08,878 - INFO - ==================================================
2026-02-10 02:20:08,879 - INFO -   [탐색 23] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:08,896 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:08,897 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:08,897 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:09,133 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666704416274)에 맞춰 변경되었습니다.
2026-02-10 02:20:09,133 - INFO - ==================================================
2026-02-10 02:20:09,135 - INFO -   [탐색 24] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:09,151 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:09,151 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:09,152 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:09,478 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666409373283)에 맞춰 변경되었습니다.
2026-02-10 02:20:09,478 - INFO - ==================================================
2026-02-10 02:20:09,480 - INFO -   [탐색 25] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:09,497 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:09,497 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:09,497 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:09,738 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666556894778)에 맞춰 변경되었습니다.
2026-02-10 02:20:09,739 - INFO - ==================================================
2026-02-10 02:20:09,740 - INFO -   [탐색 26] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:09,755 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:09,755 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:09,756 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:10,601 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666630655527)에 맞춰 변경되었습니다.
2026-02-10 02:20:10,601 - INFO - ==================================================
2026-02-10 02:20:10,603 - INFO -   [탐색 27] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:10,619 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:10,619 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:10,620 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:11,084 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666667535901)에 맞춰 변경되었습니다.
2026-02-10 02:20:11,085 - INFO - ==================================================
2026-02-10 02:20:11,086 - INFO -   [탐색 28] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:11,102 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:11,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:11,103 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:11,409 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666649095714)에 맞춰 변경되었습니다.
2026-02-10 02:20:11,410 - INFO - ==================================================
2026-02-10 02:20:11,411 - INFO -   [탐색 29] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:11,429 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:11,429 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:11,430 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:11,750 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666658315807)에 맞춰 변경되었습니다.
2026-02-10 02:20:11,750 - INFO - ==================================================
2026-02-10 02:20:11,752 - INFO -   [탐색 30] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:11,769 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:11,769 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:11,770 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:12,030 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666662925854)에 맞춰 변경되었습니다.
2026-02-10 02:20:12,030 - INFO - ==================================================
2026-02-10 02:20:12,033 - INFO -   [탐색 31] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:12,052 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:12,053 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:12,053 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:12,846 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666665230878)에 맞춰 변경되었습니다.
2026-02-10 02:20:12,846 - INFO - ==================================================
2026-02-10 02:20:12,848 - INFO -   [탐색 32] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:12,867 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:12,867 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:12,868 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,116 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.979166666638339)에 맞춰 변경되었습니다.
2026-02-10 02:20:13,116 - INFO - ==================================================
2026-02-10 02:20:13,118 - INFO -   [탐색 33] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:13,135 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:13,135 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,136 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,382 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666959645)에 맞춰 변경되었습니다.
2026-02-10 02:20:13,382 - INFO - ==================================================
2026-02-10 02:20:13,384 - INFO -   [탐색 34] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:13,403 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:13,403 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,403 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,642 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666671517)에 맞춰 변경되었습니다.
2026-02-10 02:20:13,642 - INFO - ==================================================
2026-02-10 02:20:13,644 - INFO -   [탐색 35] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:13,662 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:13,662 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,662 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,928 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666527453)에 맞춰 변경되었습니다.
2026-02-10 02:20:13,928 - INFO - ==================================================
2026-02-10 02:20:13,930 - INFO -   [탐색 36] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:13,946 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:13,947 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:13,947 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:14,744 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666599486)에 맞춰 변경되었습니다.
2026-02-10 02:20:14,745 - INFO - ==================================================
2026-02-10 02:20:14,747 - INFO -   [탐색 37] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:14,762 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:14,762 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:14,762 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,031 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666635501)에 맞춰 변경되었습니다.
2026-02-10 02:20:15,032 - INFO - ==================================================
2026-02-10 02:20:15,033 - INFO -   [탐색 38] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:15,049 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:15,049 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,049 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,329 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666653509)에 맞춰 변경되었습니다.
2026-02-10 02:20:15,329 - INFO - ==================================================
2026-02-10 02:20:15,330 - INFO -   [탐색 39] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:15,348 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:15,348 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,348 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,601 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666662513)에 맞춰 변경되었습니다.
2026-02-10 02:20:15,601 - INFO - ==================================================
2026-02-10 02:20:15,603 - INFO -   [탐색 40] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:15,618 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:15,618 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,619 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,923 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666667015)에 맞춰 변경되었습니다.
2026-02-10 02:20:15,923 - INFO - ==================================================
2026-02-10 02:20:15,924 - INFO -   [탐색 41] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:15,940 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:15,940 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:15,941 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:16,714 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666664764)에 맞춰 변경되었습니다.
2026-02-10 02:20:16,715 - INFO - ==================================================
2026-02-10 02:20:16,717 - INFO -   [탐색 42] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:16,733 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:16,733 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:16,734 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:17,044 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.979166666666589)에 맞춰 변경되었습니다.
2026-02-10 02:20:17,044 - INFO - ==================================================
2026-02-10 02:20:17,046 - INFO -   [탐색 43] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:17,066 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:17,066 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:17,067 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:17,486 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666452)에 맞춰 변경되었습니다.
2026-02-10 02:20:17,487 - INFO - ==================================================
2026-02-10 02:20:17,487 - INFO -   [탐색 44] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:17,504 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:17,504 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:17,504 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:17,805 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666734)에 맞춰 변경되었습니다.
2026-02-10 02:20:17,805 - INFO - ==================================================
2026-02-10 02:20:17,807 - INFO -   [탐색 45] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:17,824 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:17,824 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:17,824 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:18,158 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666593)에 맞춰 변경되었습니다.
2026-02-10 02:20:18,158 - INFO - ==================================================
2026-02-10 02:20:18,159 - INFO -   [탐색 46] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:18,180 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:18,181 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:18,181 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:18,915 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666663)에 맞춰 변경되었습니다.
2026-02-10 02:20:18,915 - INFO - ==================================================
2026-02-10 02:20:18,917 - INFO -   [탐색 47] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:18,936 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:18,936 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:18,936 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:19,200 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666698)에 맞춰 변경되었습니다.
2026-02-10 02:20:19,200 - INFO - ==================================================
2026-02-10 02:20:19,202 - INFO -   [탐색 48] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:19,217 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:19,217 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:19,218 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:19,481 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666681)에 맞춰 변경되었습니다.
2026-02-10 02:20:19,482 - INFO - ==================================================
2026-02-10 02:20:19,483 - INFO -   [탐색 49] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:19,500 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:19,500 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:19,500 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:19,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666672)에 맞춰 변경되었습니다.
2026-02-10 02:20:19,795 - INFO - ==================================================
2026-02-10 02:20:19,797 - INFO -   [탐색 50] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:19,813 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:19,813 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:19,813 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:20,038 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:20,038 - INFO - ==================================================
2026-02-10 02:20:20,040 - INFO -   [탐색 51] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:20,058 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:20,058 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:20,059 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:20,920 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666665)에 맞춰 변경되었습니다.
2026-02-10 02:20:20,921 - INFO - ==================================================
2026-02-10 02:20:20,923 - INFO -   [탐색 52] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:20,942 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:20,942 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:20,943 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:21,186 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666666)에 맞춰 변경되었습니다.
2026-02-10 02:20:21,187 - INFO - ==================================================
2026-02-10 02:20:21,188 - INFO -   [탐색 53] 희소도: 0.9792 -> 파라미터: 0.0497M (감소율: 99.10%)
2026-02-10 02:20:21,206 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:21,206 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:21,207 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:21,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:21,492 - INFO - ==================================================
2026-02-10 02:20:21,493 - INFO -   [탐색 54] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:21,509 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:21,510 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:21,510 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:21,751 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:21,751 - INFO - ==================================================
2026-02-10 02:20:21,753 - INFO -   [탐색 55] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:21,770 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:21,770 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:21,771 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:22,001 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:22,001 - INFO - ==================================================
2026-02-10 02:20:22,002 - INFO -   [탐색 56] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:22,018 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:22,019 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:22,019 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:22,852 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:22,852 - INFO - ==================================================
2026-02-10 02:20:22,854 - INFO -   [탐색 57] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:22,870 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:22,870 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:22,871 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:23,205 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:23,205 - INFO - ==================================================
2026-02-10 02:20:23,206 - INFO -   [탐색 58] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:23,222 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:23,222 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:23,223 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:23,495 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:23,495 - INFO - ==================================================
2026-02-10 02:20:23,497 - INFO -   [탐색 59] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:23,513 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:23,513 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:23,513 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:23,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:23,750 - INFO - ==================================================
2026-02-10 02:20:23,751 - INFO -   [탐색 60] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:23,770 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:23,770 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:23,770 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:24,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:24,059 - INFO - ==================================================
2026-02-10 02:20:24,061 - INFO -   [탐색 61] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:24,076 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:24,076 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:24,076 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:24,820 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:24,820 - INFO - ==================================================
2026-02-10 02:20:24,822 - INFO -   [탐색 62] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:24,840 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:24,840 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:24,840 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:25,123 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:25,123 - INFO - ==================================================
2026-02-10 02:20:25,124 - INFO -   [탐색 63] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:25,142 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:25,142 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:25,143 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:25,406 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:25,406 - INFO - ==================================================
2026-02-10 02:20:25,408 - INFO -   [탐색 64] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:25,426 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:25,426 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:25,426 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:25,919 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:25,919 - INFO - ==================================================
2026-02-10 02:20:25,921 - INFO -   [탐색 65] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:25,936 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:25,937 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:25,937 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:26,194 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:26,194 - INFO - ==================================================
2026-02-10 02:20:26,196 - INFO -   [탐색 66] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:26,214 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:26,214 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:26,215 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,040 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:27,040 - INFO - ==================================================
2026-02-10 02:20:27,042 - INFO -   [탐색 67] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:27,060 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:27,060 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,060 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,357 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:27,357 - INFO - ==================================================
2026-02-10 02:20:27,359 - INFO -   [탐색 68] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:27,373 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:27,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,374 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,686 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:27,686 - INFO - ==================================================
2026-02-10 02:20:27,688 - INFO -   [탐색 69] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:27,704 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:27,704 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,705 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,941 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:27,941 - INFO - ==================================================
2026-02-10 02:20:27,943 - INFO -   [탐색 70] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:27,961 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:27,961 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:27,961 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:28,293 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:28,293 - INFO - ==================================================
2026-02-10 02:20:28,295 - INFO -   [탐색 71] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:28,311 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:28,311 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:28,312 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:29,060 - INFO - ==================================================
2026-02-10 02:20:29,062 - INFO -   [탐색 72] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:29,078 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:29,078 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,079 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,359 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:29,360 - INFO - ==================================================
2026-02-10 02:20:29,361 - INFO -   [탐색 73] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:29,377 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:29,377 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,378 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,665 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:29,665 - INFO - ==================================================
2026-02-10 02:20:29,666 - INFO -   [탐색 74] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:29,682 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:29,682 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,683 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,936 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:29,936 - INFO - ==================================================
2026-02-10 02:20:29,937 - INFO -   [탐색 75] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:29,953 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:29,954 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:29,954 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:30,185 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:30,185 - INFO - ==================================================
2026-02-10 02:20:30,187 - INFO -   [탐색 76] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:30,206 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:30,206 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:30,207 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:30,964 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:30,964 - INFO - ==================================================
2026-02-10 02:20:30,966 - INFO -   [탐색 77] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:30,983 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:30,983 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:30,983 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:31,255 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:31,255 - INFO - ==================================================
2026-02-10 02:20:31,256 - INFO -   [탐색 78] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:31,273 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:31,273 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:31,274 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:31,501 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:31,502 - INFO - ==================================================
2026-02-10 02:20:31,503 - INFO -   [탐색 79] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:31,517 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:31,517 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:31,517 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:31,731 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:31,731 - INFO - ==================================================
2026-02-10 02:20:31,732 - INFO -   [탐색 80] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:31,747 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:31,747 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:31,747 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:32,030 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:32,030 - INFO - ==================================================
2026-02-10 02:20:32,032 - INFO -   [탐색 81] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:32,046 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:32,047 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:32,047 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:32,820 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:32,820 - INFO - ==================================================
2026-02-10 02:20:32,822 - INFO -   [탐색 82] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:32,838 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:32,839 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:32,839 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,097 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:33,097 - INFO - ==================================================
2026-02-10 02:20:33,098 - INFO -   [탐색 83] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:33,115 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:33,115 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,115 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:33,347 - INFO - ==================================================
2026-02-10 02:20:33,349 - INFO -   [탐색 84] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:33,368 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:33,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,369 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:33,628 - INFO - ==================================================
2026-02-10 02:20:33,630 - INFO -   [탐색 85] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:33,645 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:33,645 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,645 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,880 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:33,880 - INFO - ==================================================
2026-02-10 02:20:33,882 - INFO -   [탐색 86] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:33,897 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:33,897 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:33,898 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:34,605 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:34,605 - INFO - ==================================================
2026-02-10 02:20:34,607 - INFO -   [탐색 87] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:34,621 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:34,621 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:34,621 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:34,844 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:34,845 - INFO - ==================================================
2026-02-10 02:20:34,845 - INFO -   [탐색 88] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:34,854 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:34,855 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:34,855 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:35,089 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:35,089 - INFO - ==================================================
2026-02-10 02:20:35,090 - INFO -   [탐색 89] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:35,104 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:35,104 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:35,105 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:35,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:35,306 - INFO - ==================================================
2026-02-10 02:20:35,307 - INFO -   [탐색 90] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:35,325 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:35,325 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:35,326 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:35,541 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:35,541 - INFO - ==================================================
2026-02-10 02:20:35,542 - INFO -   [탐색 91] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:35,557 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:35,557 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:35,558 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:36,291 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:36,291 - INFO - ==================================================
2026-02-10 02:20:36,293 - INFO -   [탐색 92] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:36,308 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:36,309 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:36,309 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:36,542 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:36,543 - INFO - ==================================================
2026-02-10 02:20:36,544 - INFO -   [탐색 93] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:36,559 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:36,559 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:36,559 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:36,839 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:36,840 - INFO - ==================================================
2026-02-10 02:20:36,841 - INFO -   [탐색 94] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:36,856 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:36,856 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:36,856 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:37,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:37,109 - INFO - ==================================================
2026-02-10 02:20:37,111 - INFO -   [탐색 95] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:37,125 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:37,126 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:37,126 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:37,351 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:37,351 - INFO - ==================================================
2026-02-10 02:20:37,352 - INFO -   [탐색 96] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:37,368 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:37,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:37,369 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:37,945 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:37,946 - INFO - ==================================================
2026-02-10 02:20:37,947 - INFO -   [탐색 97] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:37,964 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:37,964 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:37,964 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,195 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:38,195 - INFO - ==================================================
2026-02-10 02:20:38,197 - INFO -   [탐색 98] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:38,213 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:38,214 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,214 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,419 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:38,419 - INFO - ==================================================
2026-02-10 02:20:38,420 - INFO -   [탐색 99] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:38,435 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:38,435 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,435 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,644 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9791666666666667)에 맞춰 변경되었습니다.
2026-02-10 02:20:38,644 - INFO - ==================================================
2026-02-10 02:20:38,646 - INFO -   [탐색 100] 희소도: 0.9792 -> 파라미터: 0.0390M (감소율: 99.29%)
2026-02-10 02:20:38,646 - INFO - 탐색 완료. 목표 파라미터 수(0.0476M)에 가장 근접한 최적 희소도는 0.9784 입니다.
2026-02-10 02:20:38,646 - INFO - ================================================================================
2026-02-10 02:20:38,647 - INFO - 계산된 Pruning 정보(희소도: 0.9784)를 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/pruning_info.yaml'에 저장했습니다.
2026-02-10 02:20:38,669 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-02-10 02:20:38,714 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:20:38,714 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,714 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:20:38,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 02:20:38,951 - INFO - ==================================================
2026-02-10 02:20:38,952 - INFO - ==================================================
2026-02-10 02:20:38,952 - INFO - 모델 파라미터 수:
2026-02-10 02:20:38,952 - INFO -   - 총 파라미터: 49,678 개
2026-02-10 02:20:38,952 - INFO -   - 학습 가능한 파라미터: 49,678 개
2026-02-10 02:20:38,974 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-02-10 02:20:39,017 - INFO - FLOPs가 2.1493 GFLOPs에서 0.0163 GFLOPs로 감소했습니다 (감소율: 99.24%).
2026-02-10 02:20:39,017 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-02-10 02:20:39,017 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-02-10 02:20:39,018 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-02-10 02:20:39,018 - INFO - ==================================================
2026-02-10 02:20:39,018 - INFO - train 모드를 시작합니다.
2026-02-10 02:20:39,018 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-02-10 02:20:39,018 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-02-10 02:20:39,018 - INFO - --------------------------------------------------
2026-02-10 02:20:39,019 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-02-10 02:20:42,934 - INFO - [Train] [11/90] | Loss: 0.6674 | Train Acc: 66.52%
2026-02-10 02:20:43,903 - INFO - [Valid] [11/90] | Loss: 0.6554 | Val Acc: 64.01%
2026-02-10 02:20:43,907 - INFO - [Metrics for 'abnormal'] | Precision: 0.6606 | Recall: 0.4586 | F1: 0.5414
2026-02-10 02:20:43,908 - INFO - [Metrics for 'normal'] | Precision: 0.6304 | Recall: 0.7967 | F1: 0.7039
2026-02-10 02:20:43,925 - INFO - [Best Model Saved] (val loss: 0.6554) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:20:43,925 - INFO - --------------------------------------------------
2026-02-10 02:20:43,926 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-02-10 02:20:47,959 - INFO - [Train] [12/90] | Loss: 0.6316 | Train Acc: 68.38%
2026-02-10 02:20:48,836 - INFO - [Valid] [12/90] | Loss: 0.6387 | Val Acc: 64.90%
2026-02-10 02:20:48,840 - INFO - [Metrics for 'abnormal'] | Precision: 0.5864 | Recall: 0.8217 | F1: 0.6844
2026-02-10 02:20:48,840 - INFO - [Metrics for 'normal'] | Precision: 0.7647 | Recall: 0.5000 | F1: 0.6047
2026-02-10 02:20:48,850 - INFO - [Best Model Saved] (val loss: 0.6387) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:20:48,851 - INFO - --------------------------------------------------
2026-02-10 02:20:48,851 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-02-10 02:20:51,507 - INFO - [Train] [13/90] | Loss: 0.5909 | Train Acc: 72.25%
2026-02-10 02:20:52,351 - INFO - [Valid] [13/90] | Loss: 0.5836 | Val Acc: 73.45%
2026-02-10 02:20:52,355 - INFO - [Metrics for 'abnormal'] | Precision: 0.7724 | Recall: 0.6051 | F1: 0.6786
2026-02-10 02:20:52,356 - INFO - [Metrics for 'normal'] | Precision: 0.7130 | Recall: 0.8462 | F1: 0.7739
2026-02-10 02:20:52,364 - INFO - [Best Model Saved] (val loss: 0.5836) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:20:52,364 - INFO - --------------------------------------------------
2026-02-10 02:20:52,365 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-02-10 02:20:55,106 - INFO - [Train] [14/90] | Loss: 0.5872 | Train Acc: 70.61%
2026-02-10 02:20:55,828 - INFO - [Valid] [14/90] | Loss: 0.6147 | Val Acc: 67.85%
2026-02-10 02:20:55,830 - INFO - [Metrics for 'abnormal'] | Precision: 0.7182 | Recall: 0.5032 | F1: 0.5918
2026-02-10 02:20:55,830 - INFO - [Metrics for 'normal'] | Precision: 0.6594 | Recall: 0.8297 | F1: 0.7348
2026-02-10 02:20:55,831 - INFO - --------------------------------------------------
2026-02-10 02:20:55,832 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-02-10 02:20:58,809 - INFO - [Train] [15/90] | Loss: 0.5462 | Train Acc: 76.49%
2026-02-10 02:20:59,385 - INFO - [Valid] [15/90] | Loss: 0.5709 | Val Acc: 73.45%
2026-02-10 02:20:59,388 - INFO - [Metrics for 'abnormal'] | Precision: 0.6831 | Recall: 0.7962 | F1: 0.7353
2026-02-10 02:20:59,388 - INFO - [Metrics for 'normal'] | Precision: 0.7949 | Recall: 0.6813 | F1: 0.7337
2026-02-10 02:20:59,394 - INFO - [Best Model Saved] (val loss: 0.5709) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:20:59,395 - INFO - --------------------------------------------------
2026-02-10 02:20:59,395 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-02-10 02:21:02,228 - INFO - [Train] [16/90] | Loss: 0.5077 | Train Acc: 79.99%
2026-02-10 02:21:02,914 - INFO - [Valid] [16/90] | Loss: 0.5852 | Val Acc: 70.80%
2026-02-10 02:21:02,918 - INFO - [Metrics for 'abnormal'] | Precision: 0.6330 | Recall: 0.8790 | F1: 0.7360
2026-02-10 02:21:02,919 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.5604 | F1: 0.6733
2026-02-10 02:21:02,920 - INFO - --------------------------------------------------
2026-02-10 02:21:02,921 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-02-10 02:21:06,024 - INFO - [Train] [17/90] | Loss: 0.5104 | Train Acc: 79.84%
2026-02-10 02:21:07,008 - INFO - [Valid] [17/90] | Loss: 0.5340 | Val Acc: 76.11%
2026-02-10 02:21:07,018 - INFO - [Metrics for 'abnormal'] | Precision: 0.7262 | Recall: 0.7771 | F1: 0.7508
2026-02-10 02:21:07,018 - INFO - [Metrics for 'normal'] | Precision: 0.7953 | Recall: 0.7473 | F1: 0.7705
2026-02-10 02:21:07,029 - INFO - [Best Model Saved] (val loss: 0.5340) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:07,029 - INFO - --------------------------------------------------
2026-02-10 02:21:07,030 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-02-10 02:21:11,188 - INFO - [Train] [18/90] | Loss: 0.4930 | Train Acc: 80.43%
2026-02-10 02:21:12,279 - INFO - [Valid] [18/90] | Loss: 0.5324 | Val Acc: 78.47%
2026-02-10 02:21:12,287 - INFO - [Metrics for 'abnormal'] | Precision: 0.7800 | Recall: 0.7452 | F1: 0.7622
2026-02-10 02:21:12,287 - INFO - [Metrics for 'normal'] | Precision: 0.7884 | Recall: 0.8187 | F1: 0.8032
2026-02-10 02:21:12,299 - INFO - [Best Model Saved] (val loss: 0.5324) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:12,299 - INFO - --------------------------------------------------
2026-02-10 02:21:12,300 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-02-10 02:21:16,102 - INFO - [Train] [19/90] | Loss: 0.4904 | Train Acc: 81.85%
2026-02-10 02:21:17,246 - INFO - [Valid] [19/90] | Loss: 0.5301 | Val Acc: 77.58%
2026-02-10 02:21:17,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.7682 | Recall: 0.7389 | F1: 0.7532
2026-02-10 02:21:17,251 - INFO - [Metrics for 'normal'] | Precision: 0.7819 | Recall: 0.8077 | F1: 0.7946
2026-02-10 02:21:17,263 - INFO - [Best Model Saved] (val loss: 0.5301) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:17,263 - INFO - --------------------------------------------------
2026-02-10 02:21:17,264 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-02-10 02:21:21,690 - INFO - [Train] [20/90] | Loss: 0.4902 | Train Acc: 80.43%
2026-02-10 02:21:22,872 - INFO - [Valid] [20/90] | Loss: 0.5298 | Val Acc: 78.47%
2026-02-10 02:21:22,877 - INFO - [Metrics for 'abnormal'] | Precision: 0.7763 | Recall: 0.7516 | F1: 0.7638
2026-02-10 02:21:22,877 - INFO - [Metrics for 'normal'] | Precision: 0.7914 | Recall: 0.8132 | F1: 0.8022
2026-02-10 02:21:22,894 - INFO - [Best Model Saved] (val loss: 0.5298) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:22,894 - INFO - --------------------------------------------------
2026-02-10 02:21:22,895 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-02-10 02:21:27,825 - INFO - [Train] [21/90] | Loss: 0.4837 | Train Acc: 81.92%
2026-02-10 02:21:29,198 - INFO - [Valid] [21/90] | Loss: 0.5395 | Val Acc: 77.88%
2026-02-10 02:21:29,203 - INFO - [Metrics for 'abnormal'] | Precision: 0.8015 | Recall: 0.6943 | F1: 0.7440
2026-02-10 02:21:29,203 - INFO - [Metrics for 'normal'] | Precision: 0.7635 | Recall: 0.8516 | F1: 0.8052
2026-02-10 02:21:29,204 - INFO - --------------------------------------------------
2026-02-10 02:21:29,205 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-02-10 02:21:34,564 - INFO - [Train] [22/90] | Loss: 0.4809 | Train Acc: 82.37%
2026-02-10 02:21:36,038 - INFO - [Valid] [22/90] | Loss: 0.5263 | Val Acc: 77.58%
2026-02-10 02:21:36,043 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.7006 | F1: 0.7432
2026-02-10 02:21:36,043 - INFO - [Metrics for 'normal'] | Precision: 0.7650 | Recall: 0.8407 | F1: 0.8010
2026-02-10 02:21:36,057 - INFO - [Best Model Saved] (val loss: 0.5263) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:36,061 - INFO - --------------------------------------------------
2026-02-10 02:21:36,062 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-02-10 02:21:41,970 - INFO - [Train] [23/90] | Loss: 0.4757 | Train Acc: 82.59%
2026-02-10 02:21:43,472 - INFO - [Valid] [23/90] | Loss: 0.5226 | Val Acc: 77.88%
2026-02-10 02:21:43,478 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.7452 | F1: 0.7573
2026-02-10 02:21:43,478 - INFO - [Metrics for 'normal'] | Precision: 0.7861 | Recall: 0.8077 | F1: 0.7967
2026-02-10 02:21:43,499 - INFO - [Best Model Saved] (val loss: 0.5226) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:43,499 - INFO - --------------------------------------------------
2026-02-10 02:21:43,500 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-02-10 02:21:49,609 - INFO - [Train] [24/90] | Loss: 0.4885 | Train Acc: 81.40%
2026-02-10 02:21:50,832 - INFO - [Valid] [24/90] | Loss: 0.5246 | Val Acc: 77.58%
2026-02-10 02:21:50,837 - INFO - [Metrics for 'abnormal'] | Precision: 0.7425 | Recall: 0.7898 | F1: 0.7654
2026-02-10 02:21:50,837 - INFO - [Metrics for 'normal'] | Precision: 0.8081 | Recall: 0.7637 | F1: 0.7853
2026-02-10 02:21:50,838 - INFO - --------------------------------------------------
2026-02-10 02:21:50,839 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-02-10 02:21:57,007 - INFO - [Train] [25/90] | Loss: 0.4782 | Train Acc: 81.62%
2026-02-10 02:21:58,440 - INFO - [Valid] [25/90] | Loss: 0.5180 | Val Acc: 79.35%
2026-02-10 02:21:58,449 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-02-10 02:21:58,449 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-02-10 02:21:58,468 - INFO - [Best Model Saved] (val loss: 0.5180) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:21:58,468 - INFO - --------------------------------------------------
2026-02-10 02:21:58,470 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-02-10 02:22:04,336 - INFO - [Train] [26/90] | Loss: 0.4788 | Train Acc: 81.99%
2026-02-10 02:22:05,847 - INFO - [Valid] [26/90] | Loss: 0.5147 | Val Acc: 79.94%
2026-02-10 02:22:05,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-02-10 02:22:05,855 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-02-10 02:22:05,870 - INFO - [Best Model Saved] (val loss: 0.5147) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:22:05,870 - INFO - --------------------------------------------------
2026-02-10 02:22:05,871 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-02-10 02:22:11,920 - INFO - [Train] [27/90] | Loss: 0.4772 | Train Acc: 82.89%
2026-02-10 02:22:13,411 - INFO - [Valid] [27/90] | Loss: 0.5183 | Val Acc: 79.06%
2026-02-10 02:22:13,416 - INFO - [Metrics for 'abnormal'] | Precision: 0.7590 | Recall: 0.8025 | F1: 0.7802
2026-02-10 02:22:13,416 - INFO - [Metrics for 'normal'] | Precision: 0.8208 | Recall: 0.7802 | F1: 0.8000
2026-02-10 02:22:13,417 - INFO - --------------------------------------------------
2026-02-10 02:22:13,419 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-02-10 02:22:19,460 - INFO - [Train] [28/90] | Loss: 0.4678 | Train Acc: 82.81%
2026-02-10 02:22:20,954 - INFO - [Valid] [28/90] | Loss: 0.5343 | Val Acc: 79.06%
2026-02-10 02:22:20,959 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-02-10 02:22:20,959 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-02-10 02:22:20,960 - INFO - --------------------------------------------------
2026-02-10 02:22:20,961 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-02-10 02:22:27,287 - INFO - [Train] [29/90] | Loss: 0.4716 | Train Acc: 83.04%
2026-02-10 02:22:28,663 - INFO - [Valid] [29/90] | Loss: 0.5311 | Val Acc: 78.17%
2026-02-10 02:22:28,668 - INFO - [Metrics for 'abnormal'] | Precision: 0.7943 | Recall: 0.7134 | F1: 0.7517
2026-02-10 02:22:28,668 - INFO - [Metrics for 'normal'] | Precision: 0.7727 | Recall: 0.8407 | F1: 0.8053
2026-02-10 02:22:28,671 - INFO - --------------------------------------------------
2026-02-10 02:22:28,672 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-02-10 02:22:35,207 - INFO - [Train] [30/90] | Loss: 0.4689 | Train Acc: 82.29%
2026-02-10 02:22:36,614 - INFO - [Valid] [30/90] | Loss: 0.5307 | Val Acc: 76.99%
2026-02-10 02:22:36,621 - INFO - [Metrics for 'abnormal'] | Precision: 0.7724 | Recall: 0.7134 | F1: 0.7417
2026-02-10 02:22:36,621 - INFO - [Metrics for 'normal'] | Precision: 0.7680 | Recall: 0.8187 | F1: 0.7926
2026-02-10 02:22:36,622 - INFO - --------------------------------------------------
2026-02-10 02:22:36,624 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-02-10 02:22:43,128 - INFO - [Train] [31/90] | Loss: 0.4658 | Train Acc: 82.29%
2026-02-10 02:22:44,594 - INFO - [Valid] [31/90] | Loss: 0.5696 | Val Acc: 74.34%
2026-02-10 02:22:44,598 - INFO - [Metrics for 'abnormal'] | Precision: 0.6667 | Recall: 0.8917 | F1: 0.7629
2026-02-10 02:22:44,599 - INFO - [Metrics for 'normal'] | Precision: 0.8682 | Recall: 0.6154 | F1: 0.7203
2026-02-10 02:22:44,600 - INFO - --------------------------------------------------
2026-02-10 02:22:44,601 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-02-10 02:22:50,895 - INFO - [Train] [32/90] | Loss: 0.4676 | Train Acc: 82.37%
2026-02-10 02:22:52,291 - INFO - [Valid] [32/90] | Loss: 0.5180 | Val Acc: 79.06%
2026-02-10 02:22:52,301 - INFO - [Metrics for 'abnormal'] | Precision: 0.7590 | Recall: 0.8025 | F1: 0.7802
2026-02-10 02:22:52,301 - INFO - [Metrics for 'normal'] | Precision: 0.8208 | Recall: 0.7802 | F1: 0.8000
2026-02-10 02:22:52,302 - INFO - --------------------------------------------------
2026-02-10 02:22:52,303 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-02-10 02:22:59,245 - INFO - [Train] [33/90] | Loss: 0.4629 | Train Acc: 83.04%
2026-02-10 02:23:00,768 - INFO - [Valid] [33/90] | Loss: 0.5282 | Val Acc: 78.47%
2026-02-10 02:23:00,776 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.8408 | F1: 0.7834
2026-02-10 02:23:00,776 - INFO - [Metrics for 'normal'] | Precision: 0.8428 | Recall: 0.7363 | F1: 0.7859
2026-02-10 02:23:00,778 - INFO - --------------------------------------------------
2026-02-10 02:23:00,779 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-02-10 02:23:07,597 - INFO - [Train] [34/90] | Loss: 0.4685 | Train Acc: 82.89%
2026-02-10 02:23:09,154 - INFO - [Valid] [34/90] | Loss: 0.5148 | Val Acc: 79.35%
2026-02-10 02:23:09,159 - INFO - [Metrics for 'abnormal'] | Precision: 0.7843 | Recall: 0.7643 | F1: 0.7742
2026-02-10 02:23:09,159 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.8187 | F1: 0.8098
2026-02-10 02:23:09,164 - INFO - --------------------------------------------------
2026-02-10 02:23:09,166 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-02-10 02:23:15,671 - INFO - [Train] [35/90] | Loss: 0.4591 | Train Acc: 82.74%
2026-02-10 02:23:22,469 - INFO - [Valid] [35/90] | Loss: 0.5219 | Val Acc: 79.06%
2026-02-10 02:23:22,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.7654 | Recall: 0.7898 | F1: 0.7774
2026-02-10 02:23:22,475 - INFO - [Metrics for 'normal'] | Precision: 0.8136 | Recall: 0.7912 | F1: 0.8022
2026-02-10 02:23:22,476 - INFO - --------------------------------------------------
2026-02-10 02:23:22,476 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-02-10 02:23:25,472 - INFO - [Train] [36/90] | Loss: 0.4594 | Train Acc: 82.81%
2026-02-10 02:23:26,064 - INFO - [Valid] [36/90] | Loss: 0.5211 | Val Acc: 77.88%
2026-02-10 02:23:26,069 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.8344 | F1: 0.7774
2026-02-10 02:23:26,069 - INFO - [Metrics for 'normal'] | Precision: 0.8365 | Recall: 0.7308 | F1: 0.7801
2026-02-10 02:23:26,070 - INFO - --------------------------------------------------
2026-02-10 02:23:26,072 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-02-10 02:23:28,943 - INFO - [Train] [37/90] | Loss: 0.4679 | Train Acc: 82.22%
2026-02-10 02:23:29,683 - INFO - [Valid] [37/90] | Loss: 0.5382 | Val Acc: 77.58%
2026-02-10 02:23:29,687 - INFO - [Metrics for 'abnormal'] | Precision: 0.7238 | Recall: 0.8344 | F1: 0.7751
2026-02-10 02:23:29,687 - INFO - [Metrics for 'normal'] | Precision: 0.8354 | Recall: 0.7253 | F1: 0.7765
2026-02-10 02:23:29,689 - INFO - --------------------------------------------------
2026-02-10 02:23:29,690 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-02-10 02:23:32,223 - INFO - [Train] [38/90] | Loss: 0.4682 | Train Acc: 82.81%
2026-02-10 02:23:32,926 - INFO - [Valid] [38/90] | Loss: 0.5117 | Val Acc: 78.47%
2026-02-10 02:23:32,931 - INFO - [Metrics for 'abnormal'] | Precision: 0.7917 | Recall: 0.7261 | F1: 0.7575
2026-02-10 02:23:32,931 - INFO - [Metrics for 'normal'] | Precision: 0.7795 | Recall: 0.8352 | F1: 0.8064
2026-02-10 02:23:32,947 - INFO - [Best Model Saved] (val loss: 0.5117) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:23:32,947 - INFO - --------------------------------------------------
2026-02-10 02:23:32,948 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-02-10 02:23:35,449 - INFO - [Train] [39/90] | Loss: 0.4614 | Train Acc: 83.48%
2026-02-10 02:23:36,170 - INFO - [Valid] [39/90] | Loss: 0.5043 | Val Acc: 79.35%
2026-02-10 02:23:36,172 - INFO - [Metrics for 'abnormal'] | Precision: 0.7919 | Recall: 0.7516 | F1: 0.7712
2026-02-10 02:23:36,173 - INFO - [Metrics for 'normal'] | Precision: 0.7947 | Recall: 0.8297 | F1: 0.8118
2026-02-10 02:23:36,179 - INFO - [Best Model Saved] (val loss: 0.5043) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:23:36,180 - INFO - --------------------------------------------------
2026-02-10 02:23:36,180 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-02-10 02:23:38,861 - INFO - [Train] [40/90] | Loss: 0.4527 | Train Acc: 83.56%
2026-02-10 02:23:39,394 - INFO - [Valid] [40/90] | Loss: 0.5116 | Val Acc: 79.06%
2026-02-10 02:23:39,397 - INFO - [Metrics for 'abnormal'] | Precision: 0.8116 | Recall: 0.7134 | F1: 0.7593
2026-02-10 02:23:39,398 - INFO - [Metrics for 'normal'] | Precision: 0.7761 | Recall: 0.8571 | F1: 0.8146
2026-02-10 02:23:39,399 - INFO - --------------------------------------------------
2026-02-10 02:23:39,400 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-02-10 02:23:42,024 - INFO - [Train] [41/90] | Loss: 0.4549 | Train Acc: 83.41%
2026-02-10 02:23:42,680 - INFO - [Valid] [41/90] | Loss: 0.5140 | Val Acc: 78.47%
2026-02-10 02:23:42,684 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.8408 | F1: 0.7834
2026-02-10 02:23:42,684 - INFO - [Metrics for 'normal'] | Precision: 0.8428 | Recall: 0.7363 | F1: 0.7859
2026-02-10 02:23:42,685 - INFO - --------------------------------------------------
2026-02-10 02:23:42,686 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-02-10 02:23:45,234 - INFO - [Train] [42/90] | Loss: 0.4513 | Train Acc: 83.78%
2026-02-10 02:23:45,754 - INFO - [Valid] [42/90] | Loss: 0.5019 | Val Acc: 81.12%
2026-02-10 02:23:45,758 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-02-10 02:23:45,758 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-02-10 02:23:45,767 - INFO - [Best Model Saved] (val loss: 0.5019) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:23:45,767 - INFO - --------------------------------------------------
2026-02-10 02:23:45,768 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-02-10 02:23:48,343 - INFO - [Train] [43/90] | Loss: 0.4495 | Train Acc: 83.26%
2026-02-10 02:23:48,994 - INFO - [Valid] [43/90] | Loss: 0.4940 | Val Acc: 80.83%
2026-02-10 02:23:48,998 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-02-10 02:23:48,998 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-02-10 02:23:49,008 - INFO - [Best Model Saved] (val loss: 0.4940) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:23:49,008 - INFO - --------------------------------------------------
2026-02-10 02:23:49,009 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-02-10 02:23:51,587 - INFO - [Train] [44/90] | Loss: 0.4477 | Train Acc: 83.41%
2026-02-10 02:23:52,311 - INFO - [Valid] [44/90] | Loss: 0.5181 | Val Acc: 78.76%
2026-02-10 02:23:52,315 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.8153 | F1: 0.7805
2026-02-10 02:23:52,315 - INFO - [Metrics for 'normal'] | Precision: 0.8274 | Recall: 0.7637 | F1: 0.7943
2026-02-10 02:23:52,316 - INFO - --------------------------------------------------
2026-02-10 02:23:52,317 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-02-10 02:23:54,940 - INFO - [Train] [45/90] | Loss: 0.4529 | Train Acc: 83.78%
2026-02-10 02:23:55,676 - INFO - [Valid] [45/90] | Loss: 0.4968 | Val Acc: 80.24%
2026-02-10 02:23:55,681 - INFO - [Metrics for 'abnormal'] | Precision: 0.7922 | Recall: 0.7771 | F1: 0.7846
2026-02-10 02:23:55,681 - INFO - [Metrics for 'normal'] | Precision: 0.8108 | Recall: 0.8242 | F1: 0.8174
2026-02-10 02:23:55,683 - INFO - --------------------------------------------------
2026-02-10 02:23:55,683 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-02-10 02:23:58,370 - INFO - [Train] [46/90] | Loss: 0.4527 | Train Acc: 84.45%
2026-02-10 02:23:58,873 - INFO - [Valid] [46/90] | Loss: 0.5015 | Val Acc: 79.65%
2026-02-10 02:23:58,877 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 02:23:58,877 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 02:23:58,879 - INFO - --------------------------------------------------
2026-02-10 02:23:58,880 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-02-10 02:24:01,641 - INFO - [Train] [47/90] | Loss: 0.4442 | Train Acc: 84.30%
2026-02-10 02:24:02,241 - INFO - [Valid] [47/90] | Loss: 0.5005 | Val Acc: 79.65%
2026-02-10 02:24:02,245 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.8153 | F1: 0.7877
2026-02-10 02:24:02,245 - INFO - [Metrics for 'normal'] | Precision: 0.8304 | Recall: 0.7802 | F1: 0.8045
2026-02-10 02:24:02,246 - INFO - --------------------------------------------------
2026-02-10 02:24:02,247 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-02-10 02:24:04,976 - INFO - [Train] [48/90] | Loss: 0.4512 | Train Acc: 84.23%
2026-02-10 02:24:05,680 - INFO - [Valid] [48/90] | Loss: 0.4906 | Val Acc: 80.24%
2026-02-10 02:24:05,684 - INFO - [Metrics for 'abnormal'] | Precision: 0.7922 | Recall: 0.7771 | F1: 0.7846
2026-02-10 02:24:05,684 - INFO - [Metrics for 'normal'] | Precision: 0.8108 | Recall: 0.8242 | F1: 0.8174
2026-02-10 02:24:05,696 - INFO - [Best Model Saved] (val loss: 0.4906) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:24:05,696 - INFO - --------------------------------------------------
2026-02-10 02:24:05,697 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-02-10 02:24:08,040 - INFO - [Train] [49/90] | Loss: 0.4456 | Train Acc: 84.52%
2026-02-10 02:24:08,834 - INFO - [Valid] [49/90] | Loss: 0.4944 | Val Acc: 79.35%
2026-02-10 02:24:08,839 - INFO - [Metrics for 'abnormal'] | Precision: 0.7919 | Recall: 0.7516 | F1: 0.7712
2026-02-10 02:24:08,839 - INFO - [Metrics for 'normal'] | Precision: 0.7947 | Recall: 0.8297 | F1: 0.8118
2026-02-10 02:24:08,840 - INFO - --------------------------------------------------
2026-02-10 02:24:08,841 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-02-10 02:24:11,417 - INFO - [Train] [50/90] | Loss: 0.4426 | Train Acc: 84.97%
2026-02-10 02:24:12,125 - INFO - [Valid] [50/90] | Loss: 0.5003 | Val Acc: 79.06%
2026-02-10 02:24:12,129 - INFO - [Metrics for 'abnormal'] | Precision: 0.8071 | Recall: 0.7197 | F1: 0.7609
2026-02-10 02:24:12,129 - INFO - [Metrics for 'normal'] | Precision: 0.7789 | Recall: 0.8516 | F1: 0.8136
2026-02-10 02:24:12,130 - INFO - --------------------------------------------------
2026-02-10 02:24:12,131 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-02-10 02:24:14,906 - INFO - [Train] [51/90] | Loss: 0.4371 | Train Acc: 85.12%
2026-02-10 02:24:15,513 - INFO - [Valid] [51/90] | Loss: 0.4970 | Val Acc: 79.65%
2026-02-10 02:24:15,516 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-02-10 02:24:15,516 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-02-10 02:24:15,516 - INFO - --------------------------------------------------
2026-02-10 02:24:15,517 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-02-10 02:24:18,196 - INFO - [Train] [52/90] | Loss: 0.4415 | Train Acc: 84.60%
2026-02-10 02:24:18,726 - INFO - [Valid] [52/90] | Loss: 0.4945 | Val Acc: 79.65%
2026-02-10 02:24:18,728 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-02-10 02:24:18,728 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-02-10 02:24:18,729 - INFO - --------------------------------------------------
2026-02-10 02:24:18,730 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-02-10 02:24:21,455 - INFO - [Train] [53/90] | Loss: 0.4340 | Train Acc: 85.42%
2026-02-10 02:24:21,979 - INFO - [Valid] [53/90] | Loss: 0.4964 | Val Acc: 79.65%
2026-02-10 02:24:21,983 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-02-10 02:24:21,983 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-02-10 02:24:21,984 - INFO - --------------------------------------------------
2026-02-10 02:24:21,985 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-02-10 02:24:24,604 - INFO - [Train] [54/90] | Loss: 0.4285 | Train Acc: 85.79%
2026-02-10 02:24:25,315 - INFO - [Valid] [54/90] | Loss: 0.4964 | Val Acc: 80.83%
2026-02-10 02:24:25,320 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-02-10 02:24:25,320 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-02-10 02:24:25,322 - INFO - --------------------------------------------------
2026-02-10 02:24:25,323 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-02-10 02:24:27,878 - INFO - [Train] [55/90] | Loss: 0.4441 | Train Acc: 84.00%
2026-02-10 02:24:28,612 - INFO - [Valid] [55/90] | Loss: 0.4950 | Val Acc: 78.76%
2026-02-10 02:24:28,617 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-02-10 02:24:28,617 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-02-10 02:24:28,618 - INFO - --------------------------------------------------
2026-02-10 02:24:28,619 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-02-10 02:24:31,313 - INFO - [Train] [56/90] | Loss: 0.4351 | Train Acc: 85.34%
2026-02-10 02:24:32,020 - INFO - [Valid] [56/90] | Loss: 0.4929 | Val Acc: 79.65%
2026-02-10 02:24:32,023 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-02-10 02:24:32,023 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-02-10 02:24:32,024 - INFO - --------------------------------------------------
2026-02-10 02:24:32,024 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-02-10 02:24:34,755 - INFO - [Train] [57/90] | Loss: 0.4315 | Train Acc: 84.67%
2026-02-10 02:24:35,280 - INFO - [Valid] [57/90] | Loss: 0.5047 | Val Acc: 81.12%
2026-02-10 02:24:35,283 - INFO - [Metrics for 'abnormal'] | Precision: 0.7627 | Recall: 0.8599 | F1: 0.8084
2026-02-10 02:24:35,283 - INFO - [Metrics for 'normal'] | Precision: 0.8642 | Recall: 0.7692 | F1: 0.8140
2026-02-10 02:24:35,284 - INFO - --------------------------------------------------
2026-02-10 02:24:35,285 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-02-10 02:24:37,935 - INFO - [Train] [58/90] | Loss: 0.4310 | Train Acc: 85.71%
2026-02-10 02:24:38,511 - INFO - [Valid] [58/90] | Loss: 0.4869 | Val Acc: 81.12%
2026-02-10 02:24:38,515 - INFO - [Metrics for 'abnormal'] | Precision: 0.8252 | Recall: 0.7516 | F1: 0.7867
2026-02-10 02:24:38,515 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8626 | F1: 0.8307
2026-02-10 02:24:38,525 - INFO - [Best Model Saved] (val loss: 0.4869) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:24:38,526 - INFO - --------------------------------------------------
2026-02-10 02:24:38,526 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-02-10 02:24:41,203 - INFO - [Train] [59/90] | Loss: 0.4226 | Train Acc: 86.01%
2026-02-10 02:24:41,970 - INFO - [Valid] [59/90] | Loss: 0.4930 | Val Acc: 80.24%
2026-02-10 02:24:41,974 - INFO - [Metrics for 'abnormal'] | Precision: 0.7922 | Recall: 0.7771 | F1: 0.7846
2026-02-10 02:24:41,974 - INFO - [Metrics for 'normal'] | Precision: 0.8108 | Recall: 0.8242 | F1: 0.8174
2026-02-10 02:24:41,976 - INFO - --------------------------------------------------
2026-02-10 02:24:41,976 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-02-10 02:24:44,675 - INFO - [Train] [60/90] | Loss: 0.4285 | Train Acc: 85.34%
2026-02-10 02:24:45,421 - INFO - [Valid] [60/90] | Loss: 0.4981 | Val Acc: 79.65%
2026-02-10 02:24:45,424 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 02:24:45,424 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 02:24:45,425 - INFO - --------------------------------------------------
2026-02-10 02:24:45,426 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-02-10 02:24:47,913 - INFO - [Train] [61/90] | Loss: 0.4218 | Train Acc: 86.01%
2026-02-10 02:24:48,592 - INFO - [Valid] [61/90] | Loss: 0.4930 | Val Acc: 80.53%
2026-02-10 02:24:48,595 - INFO - [Metrics for 'abnormal'] | Precision: 0.7725 | Recall: 0.8217 | F1: 0.7963
2026-02-10 02:24:48,595 - INFO - [Metrics for 'normal'] | Precision: 0.8372 | Recall: 0.7912 | F1: 0.8136
2026-02-10 02:24:48,596 - INFO - --------------------------------------------------
2026-02-10 02:24:48,596 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-02-10 02:24:51,184 - INFO - [Train] [62/90] | Loss: 0.4212 | Train Acc: 86.16%
2026-02-10 02:24:51,744 - INFO - [Valid] [62/90] | Loss: 0.5012 | Val Acc: 80.24%
2026-02-10 02:24:51,748 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-02-10 02:24:51,748 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-02-10 02:24:51,749 - INFO - --------------------------------------------------
2026-02-10 02:24:51,750 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-02-10 02:24:54,421 - INFO - [Train] [63/90] | Loss: 0.4214 | Train Acc: 86.09%
2026-02-10 02:24:54,974 - INFO - [Valid] [63/90] | Loss: 0.4938 | Val Acc: 79.35%
2026-02-10 02:24:54,977 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-02-10 02:24:54,977 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-02-10 02:24:54,978 - INFO - --------------------------------------------------
2026-02-10 02:24:54,979 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-02-10 02:24:57,674 - INFO - [Train] [64/90] | Loss: 0.4198 | Train Acc: 86.31%
2026-02-10 02:24:58,211 - INFO - [Valid] [64/90] | Loss: 0.4837 | Val Acc: 79.94%
2026-02-10 02:24:58,215 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-02-10 02:24:58,215 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-02-10 02:24:58,225 - INFO - [Best Model Saved] (val loss: 0.4837) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:24:58,225 - INFO - --------------------------------------------------
2026-02-10 02:24:58,226 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-02-10 02:25:00,817 - INFO - [Train] [65/90] | Loss: 0.4280 | Train Acc: 85.12%
2026-02-10 02:25:01,461 - INFO - [Valid] [65/90] | Loss: 0.4894 | Val Acc: 80.53%
2026-02-10 02:25:01,465 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.8280 | F1: 0.7975
2026-02-10 02:25:01,465 - INFO - [Metrics for 'normal'] | Precision: 0.8412 | Recall: 0.7857 | F1: 0.8125
2026-02-10 02:25:01,467 - INFO - --------------------------------------------------
2026-02-10 02:25:01,467 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-02-10 02:25:04,023 - INFO - [Train] [66/90] | Loss: 0.4141 | Train Acc: 87.05%
2026-02-10 02:25:04,801 - INFO - [Valid] [66/90] | Loss: 0.4867 | Val Acc: 79.06%
2026-02-10 02:25:04,806 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-02-10 02:25:04,806 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-02-10 02:25:04,807 - INFO - --------------------------------------------------
2026-02-10 02:25:04,807 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-02-10 02:25:07,474 - INFO - [Train] [67/90] | Loss: 0.4231 | Train Acc: 85.64%
2026-02-10 02:25:08,228 - INFO - [Valid] [67/90] | Loss: 0.4850 | Val Acc: 80.53%
2026-02-10 02:25:08,232 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-02-10 02:25:08,232 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-02-10 02:25:08,234 - INFO - --------------------------------------------------
2026-02-10 02:25:08,234 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-02-10 02:25:10,819 - INFO - [Train] [68/90] | Loss: 0.4161 | Train Acc: 86.31%
2026-02-10 02:25:11,384 - INFO - [Valid] [68/90] | Loss: 0.4867 | Val Acc: 79.65%
2026-02-10 02:25:11,387 - INFO - [Metrics for 'abnormal'] | Precision: 0.8056 | Recall: 0.7389 | F1: 0.7708
2026-02-10 02:25:11,387 - INFO - [Metrics for 'normal'] | Precision: 0.7897 | Recall: 0.8462 | F1: 0.8170
2026-02-10 02:25:11,388 - INFO - --------------------------------------------------
2026-02-10 02:25:11,388 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-02-10 02:25:14,157 - INFO - [Train] [69/90] | Loss: 0.4192 | Train Acc: 86.31%
2026-02-10 02:25:14,696 - INFO - [Valid] [69/90] | Loss: 0.4878 | Val Acc: 80.83%
2026-02-10 02:25:14,699 - INFO - [Metrics for 'abnormal'] | Precision: 0.7949 | Recall: 0.7898 | F1: 0.7923
2026-02-10 02:25:14,699 - INFO - [Metrics for 'normal'] | Precision: 0.8197 | Recall: 0.8242 | F1: 0.8219
2026-02-10 02:25:14,700 - INFO - --------------------------------------------------
2026-02-10 02:25:14,700 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-02-10 02:25:17,406 - INFO - [Train] [70/90] | Loss: 0.4110 | Train Acc: 86.53%
2026-02-10 02:25:17,944 - INFO - [Valid] [70/90] | Loss: 0.4913 | Val Acc: 80.83%
2026-02-10 02:25:17,949 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-02-10 02:25:17,949 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-02-10 02:25:17,951 - INFO - --------------------------------------------------
2026-02-10 02:25:17,951 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-02-10 02:25:20,580 - INFO - [Train] [71/90] | Loss: 0.4186 | Train Acc: 86.38%
2026-02-10 02:25:21,291 - INFO - [Valid] [71/90] | Loss: 0.4901 | Val Acc: 78.76%
2026-02-10 02:25:21,295 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-02-10 02:25:21,295 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-02-10 02:25:21,296 - INFO - --------------------------------------------------
2026-02-10 02:25:21,297 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-02-10 02:25:23,868 - INFO - [Train] [72/90] | Loss: 0.4149 | Train Acc: 86.16%
2026-02-10 02:25:24,595 - INFO - [Valid] [72/90] | Loss: 0.4844 | Val Acc: 80.24%
2026-02-10 02:25:24,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-02-10 02:25:24,600 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-02-10 02:25:24,601 - INFO - --------------------------------------------------
2026-02-10 02:25:24,602 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-02-10 02:25:27,285 - INFO - [Train] [73/90] | Loss: 0.4117 | Train Acc: 86.53%
2026-02-10 02:25:27,989 - INFO - [Valid] [73/90] | Loss: 0.4838 | Val Acc: 80.53%
2026-02-10 02:25:27,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-02-10 02:25:27,992 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-02-10 02:25:27,993 - INFO - --------------------------------------------------
2026-02-10 02:25:27,994 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-02-10 02:25:29,756 - INFO - [Train] [74/90] | Loss: 0.4093 | Train Acc: 86.68%
2026-02-10 02:25:30,163 - INFO - [Valid] [74/90] | Loss: 0.4990 | Val Acc: 78.47%
2026-02-10 02:25:30,165 - INFO - [Metrics for 'abnormal'] | Precision: 0.8134 | Recall: 0.6943 | F1: 0.7491
2026-02-10 02:25:30,166 - INFO - [Metrics for 'normal'] | Precision: 0.7659 | Recall: 0.8626 | F1: 0.8114
2026-02-10 02:25:30,166 - INFO - --------------------------------------------------
2026-02-10 02:25:30,167 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-02-10 02:25:31,851 - INFO - [Train] [75/90] | Loss: 0.4076 | Train Acc: 86.90%
2026-02-10 02:25:32,273 - INFO - [Valid] [75/90] | Loss: 0.4932 | Val Acc: 80.24%
2026-02-10 02:25:32,276 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-02-10 02:25:32,276 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-02-10 02:25:32,277 - INFO - --------------------------------------------------
2026-02-10 02:25:32,277 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-02-10 02:25:34,279 - INFO - [Train] [76/90] | Loss: 0.4058 | Train Acc: 86.53%
2026-02-10 02:25:34,694 - INFO - [Valid] [76/90] | Loss: 0.4909 | Val Acc: 80.53%
2026-02-10 02:25:34,697 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-02-10 02:25:34,697 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-02-10 02:25:34,698 - INFO - --------------------------------------------------
2026-02-10 02:25:34,698 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-02-10 02:25:36,274 - INFO - [Train] [77/90] | Loss: 0.4147 | Train Acc: 86.53%
2026-02-10 02:25:36,716 - INFO - [Valid] [77/90] | Loss: 0.5040 | Val Acc: 79.94%
2026-02-10 02:25:36,719 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8535 | F1: 0.7976
2026-02-10 02:25:36,719 - INFO - [Metrics for 'normal'] | Precision: 0.8562 | Recall: 0.7527 | F1: 0.8012
2026-02-10 02:25:36,720 - INFO - --------------------------------------------------
2026-02-10 02:25:36,720 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-02-10 02:25:38,252 - INFO - [Train] [78/90] | Loss: 0.4120 | Train Acc: 86.38%
2026-02-10 02:25:38,651 - INFO - [Valid] [78/90] | Loss: 0.4925 | Val Acc: 80.83%
2026-02-10 02:25:38,654 - INFO - [Metrics for 'abnormal'] | Precision: 0.8067 | Recall: 0.7707 | F1: 0.7883
2026-02-10 02:25:38,654 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.8407 | F1: 0.8248
2026-02-10 02:25:38,655 - INFO - --------------------------------------------------
2026-02-10 02:25:38,655 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-02-10 02:25:40,188 - INFO - [Train] [79/90] | Loss: 0.4122 | Train Acc: 86.24%
2026-02-10 02:25:40,596 - INFO - [Valid] [79/90] | Loss: 0.4919 | Val Acc: 80.83%
2026-02-10 02:25:40,599 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-02-10 02:25:40,599 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-02-10 02:25:40,600 - INFO - --------------------------------------------------
2026-02-10 02:25:40,600 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-02-10 02:25:42,156 - INFO - [Train] [80/90] | Loss: 0.4144 | Train Acc: 86.09%
2026-02-10 02:25:42,564 - INFO - [Valid] [80/90] | Loss: 0.4995 | Val Acc: 80.24%
2026-02-10 02:25:42,567 - INFO - [Metrics for 'abnormal'] | Precision: 0.7557 | Recall: 0.8471 | F1: 0.7988
2026-02-10 02:25:42,567 - INFO - [Metrics for 'normal'] | Precision: 0.8528 | Recall: 0.7637 | F1: 0.8058
2026-02-10 02:25:42,568 - INFO - --------------------------------------------------
2026-02-10 02:25:42,568 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-02-10 02:25:44,072 - INFO - [Train] [81/90] | Loss: 0.4070 | Train Acc: 85.86%
2026-02-10 02:25:44,481 - INFO - [Valid] [81/90] | Loss: 0.4841 | Val Acc: 80.53%
2026-02-10 02:25:44,483 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-02-10 02:25:44,483 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-02-10 02:25:44,484 - INFO - --------------------------------------------------
2026-02-10 02:25:44,485 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-02-10 02:25:45,985 - INFO - [Train] [82/90] | Loss: 0.4045 | Train Acc: 87.20%
2026-02-10 02:25:46,394 - INFO - [Valid] [82/90] | Loss: 0.4850 | Val Acc: 80.24%
2026-02-10 02:25:46,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.7812 | Recall: 0.7962 | F1: 0.7886
2026-02-10 02:25:46,396 - INFO - [Metrics for 'normal'] | Precision: 0.8212 | Recall: 0.8077 | F1: 0.8144
2026-02-10 02:25:46,397 - INFO - --------------------------------------------------
2026-02-10 02:25:46,397 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-02-10 02:25:47,929 - INFO - [Train] [83/90] | Loss: 0.4077 | Train Acc: 86.68%
2026-02-10 02:25:48,334 - INFO - [Valid] [83/90] | Loss: 0.4897 | Val Acc: 79.65%
2026-02-10 02:25:48,337 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-02-10 02:25:48,337 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-02-10 02:25:48,337 - INFO - --------------------------------------------------
2026-02-10 02:25:48,338 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-02-10 02:25:49,826 - INFO - [Train] [84/90] | Loss: 0.4073 | Train Acc: 87.05%
2026-02-10 02:25:50,231 - INFO - [Valid] [84/90] | Loss: 0.4848 | Val Acc: 81.12%
2026-02-10 02:25:50,234 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-02-10 02:25:50,234 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-02-10 02:25:50,235 - INFO - --------------------------------------------------
2026-02-10 02:25:50,235 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-02-10 02:25:51,784 - INFO - [Train] [85/90] | Loss: 0.4050 | Train Acc: 86.83%
2026-02-10 02:25:52,191 - INFO - [Valid] [85/90] | Loss: 0.4864 | Val Acc: 80.53%
2026-02-10 02:25:52,193 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-02-10 02:25:52,193 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-02-10 02:25:52,194 - INFO - --------------------------------------------------
2026-02-10 02:25:52,195 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-02-10 02:25:53,682 - INFO - [Train] [86/90] | Loss: 0.4082 | Train Acc: 86.31%
2026-02-10 02:25:54,084 - INFO - [Valid] [86/90] | Loss: 0.4893 | Val Acc: 79.35%
2026-02-10 02:25:54,086 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-02-10 02:25:54,086 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-02-10 02:25:54,087 - INFO - --------------------------------------------------
2026-02-10 02:25:54,088 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-02-10 02:25:55,597 - INFO - [Train] [87/90] | Loss: 0.4019 | Train Acc: 87.13%
2026-02-10 02:25:56,005 - INFO - [Valid] [87/90] | Loss: 0.4879 | Val Acc: 81.12%
2026-02-10 02:25:56,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-02-10 02:25:56,008 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-02-10 02:25:56,009 - INFO - --------------------------------------------------
2026-02-10 02:25:56,009 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-02-10 02:25:57,538 - INFO - [Train] [88/90] | Loss: 0.4044 | Train Acc: 87.43%
2026-02-10 02:25:57,944 - INFO - [Valid] [88/90] | Loss: 0.4881 | Val Acc: 80.24%
2026-02-10 02:25:57,947 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-02-10 02:25:57,947 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-02-10 02:25:57,948 - INFO - --------------------------------------------------
2026-02-10 02:25:57,948 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-02-10 02:25:59,432 - INFO - [Train] [89/90] | Loss: 0.3946 | Train Acc: 87.28%
2026-02-10 02:25:59,839 - INFO - [Valid] [89/90] | Loss: 0.5281 | Val Acc: 78.47%
2026-02-10 02:25:59,842 - INFO - [Metrics for 'abnormal'] | Precision: 0.7234 | Recall: 0.8662 | F1: 0.7884
2026-02-10 02:25:59,842 - INFO - [Metrics for 'normal'] | Precision: 0.8609 | Recall: 0.7143 | F1: 0.7808
2026-02-10 02:25:59,843 - INFO - --------------------------------------------------
2026-02-10 02:25:59,843 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-02-10 02:26:01,341 - INFO - [Train] [90/90] | Loss: 0.3995 | Train Acc: 86.83%
2026-02-10 02:26:01,751 - INFO - [Valid] [90/90] | Loss: 0.4909 | Val Acc: 79.94%
2026-02-10 02:26:01,753 - INFO - [Metrics for 'abnormal'] | Precision: 0.8112 | Recall: 0.7389 | F1: 0.7733
2026-02-10 02:26:01,753 - INFO - [Metrics for 'normal'] | Precision: 0.7908 | Recall: 0.8516 | F1: 0.8201
2026-02-10 02:26:01,755 - INFO - ==================================================
2026-02-10 02:26:01,755 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-02-10 02:26:01,755 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-02-10 02:26:01,755 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 02:26:01,800 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 02:26:01,800 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-02-10 02:26:01,801 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-02-10 02:26:01,801 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 02:26:01,801 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 02:26:02,045 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9783984374999999)에 맞춰 변경되었습니다.
2026-02-10 02:26:02,045 - INFO - ==================================================
2026-02-10 02:26:02,055 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/best_model.pth'
2026-02-10 02:26:02,055 - INFO - ==================================================
2026-02-10 02:26:02,055 - INFO - Test 모드를 시작합니다.
2026-02-10 02:26:02,079 - INFO - 연산량 (MACs): 0.0082 GMACs per sample
2026-02-10 02:26:02,079 - INFO - 연산량 (FLOPs): 0.0163 GFLOPs per sample
2026-02-10 02:26:02,079 - INFO - ==================================================
2026-02-10 02:26:02,079 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-02-10 02:26:02,488 - INFO - 샘플 당 평균 Forward Pass 시간: 1.55ms (std: 0.06ms), FPS: 644.89 (std: 18.96) (1개 샘플 x 100회 반복)
2026-02-10 02:26:02,488 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 104.54 MB
2026-02-10 02:26:02,488 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-02-10 02:26:03,116 - INFO - [Test] Loss: 0.4204 | Test Acc: 79.94%
2026-02-10 02:26:03,119 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-02-10 02:26:03,119 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-02-10 02:26:03,242 - INFO - ==================================================
2026-02-10 02:26:03,242 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/confusion_matrix_20260210_021917.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/confusion_matrix_20260210_021917.pdf'
2026-02-10 02:26:03,242 - INFO - ==================================================
2026-02-10 02:26:03,242 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-02-10 02:26:03,388 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/model_fp32_20260210_021917.onnx'에 저장되었습니다. (크기: 0.30 MB)
2026-02-10 02:26:03,556 - INFO - [Model Load] ONNX 모델(FP32) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 12.75 MB
2026-02-10 02:26:03,556 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 02:26:03,925 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 2.25ms (std: 0.04ms)
2026-02-10 02:26:03,925 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 445.54 FPS (std: 8.11) (1개 샘플 x 100회 반복)
2026-02-10 02:26:03,925 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 3.94 MB
2026-02-10 02:26:03,925 - INFO - [Total] (FP32) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 17.51 MB
2026-02-10 02:26:04,878 - INFO - [Test (ONNX)] | Test Acc (ONNX): 79.94%
2026-02-10 02:26:04,881 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-02-10 02:26:04,881 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-02-10 02:26:04,983 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/val_acc.pdf'
2026-02-10 02:26:05,089 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/train_val_acc.pdf'
2026-02-10 02:26:05,178 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/F1_normal.pdf'
2026-02-10 02:26:05,281 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/val_loss.pdf'
2026-02-10 02:26:05,371 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/learning_rate.pdf'
2026-02-10 02:26:06,330 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260210_021917/graph_20260210_021917/compile.pdf'
