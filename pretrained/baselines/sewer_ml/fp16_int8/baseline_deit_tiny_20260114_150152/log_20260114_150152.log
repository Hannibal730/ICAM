2026-01-14 15:01:52,923 - INFO - 로그 파일이 'log/Sewer-ML/baseline_deit_tiny_20260114_150152/log_20260114_150152.log'에 저장됩니다.
2026-01-14 15:01:52,929 - INFO - ==================================================
2026-01-14 15:01:52,929 - INFO - config.yaml:
2026-01-14 15:01:52,929 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: inference
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  use_int8_inference: true
  int8_calib_samples: 512
  int8_calibration_method: Percentile
  int8_activation_type: QUInt8
  int8_percentile: 99.99
  show_log: true
  dataset:
    name: Sewer-ML
    type: csv
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: deit_tiny
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.031371

2026-01-14 15:01:52,929 - INFO - ==================================================
2026-01-14 15:01:53,117 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 15:01:53,118 - INFO - 'Sewer-ML' 데이터 로드를 시작합니다 (Type: csv).
2026-01-14 15:01:54,565 - INFO - 데이터셋 클래스: ['Normal', 'Defect'] (총 2개)
2026-01-14 15:01:54,565 - INFO - 훈련 데이터: 1040129개, 검증 데이터: 130046개, 테스트 데이터: 130046개
2026-01-14 15:01:54,565 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 15:01:54,799 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 15:01:54,801 - INFO - ==================================================
2026-01-14 15:01:54,801 - INFO - 모델 파라미터 수:
2026-01-14 15:01:54,801 - INFO -   - 총 파라미터: 5,524,802 개
2026-01-14 15:01:54,801 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-01-14 15:01:54,801 - INFO - ==================================================
2026-01-14 15:01:54,801 - INFO - Inference 모드를 시작합니다.
2026-01-14 15:01:55,001 - INFO - [Model Load] PyTorch 모델 가중치 로드 메모리: 1309.32 MB (증가량: 0.00 MB)
2026-01-14 15:01:55,001 - INFO - './pretrained/best_model.pth' 가중치 로드 완료.
2026-01-14 15:01:55,357 - INFO - 연산량 (MACs): 1.0747 GMACs per sample
2026-01-14 15:01:55,357 - INFO - 연산량 (FLOPs): 2.1493 GFLOPs per sample
2026-01-14 15:01:55,357 - INFO - ==================================================
2026-01-14 15:01:55,357 - INFO - INT8 Static Quantization (ONNX)을 적용합니다.
2026-01-14 15:01:55,941 - INFO - Quantization 전처리를 수행합니다 (Fusion, Shape Inference)...
2026-01-14 15:01:55,941 - INFO - Performing symbolic shape inference...
2026-01-14 15:01:56,460 - INFO - Calibration 진행 (512 samples)...
2026-01-14 15:01:56,463 - INFO - Calibration Method: percentile (CalibrationMethod.Percentile)
2026-01-14 15:01:56,463 - INFO - Activation Type: QUInt8 (Extra Options: {'Percentile': 99.99})
2026-01-14 15:07:11,171 - INFO - ONNX INT8 모델 저장 완료: log/Sewer-ML/baseline_deit_tiny_20260114_150152/best_model_int8.onnx
2026-01-14 15:07:11,590 - INFO - [Model Load] ONNX 모델(INT8) 로드 메모리: 2223.29 MB (증가량: 0.00 MB)
2026-01-14 15:07:11,590 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 15:07:14,180 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 21.90ms (std: 0.78ms)
2026-01-14 15:07:14,180 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 45.70 FPS (std: 1.30) (1개 샘플 x 100회 반복)
2026-01-14 15:07:14,180 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2223.79 MB (순수 증가량: 0.50 MB)
2026-01-14 15:07:14,181 - INFO - [Total Process] ONNX 모델(INT8) 전체 메모리 사용량: 2223.79 MB (전체 증가량: 0.50 MB)
2026-01-14 15:31:42,664 - INFO - [Inference (ONNX INT8)] | Test Acc (ONNX): 87.40%
2026-01-14 15:31:43,079 - INFO - [Metrics for 'Normal' (ONNX)] | Precision: 0.9153 | Recall: 0.8391 | F1: 0.8755
2026-01-14 15:31:43,079 - INFO - [Metrics for 'Defect' (ONNX)] | Precision: 0.8352 | Recall: 0.9130 | F1: 0.8724
2026-01-14 15:31:43,672 - INFO - ==================================================
2026-01-14 15:31:43,672 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-ML/baseline_deit_tiny_20260114_150152/confusion_matrix_20260114_150152.png' and 'log/Sewer-ML/baseline_deit_tiny_20260114_150152/confusion_matrix_20260114_150152.pdf'
