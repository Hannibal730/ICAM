2026-01-14 13:18:21,971 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/log_20260114_131821.log'에 저장됩니다.
2026-01-14 13:18:21,978 - INFO - ==================================================
2026-01-14 13:18:21,978 - INFO - config.yaml:
2026-01-14 13:18:21,978 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobile_vit_xxs
  use_l1_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:18:21,979 - INFO - ==================================================
2026-01-14 13:18:22,044 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:18:22,047 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:18:22,047 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:18:22,061 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:18:22,062 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:18:22,062 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:18:22,062 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:18:22,477 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:18:22,534 - INFO - ==================================================
2026-01-14 13:18:22,535 - INFO - 모델 파라미터 수:
2026-01-14 13:18:22,536 - INFO -   - 총 파라미터: 951,666 개
2026-01-14 13:18:22,536 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-01-14 13:18:22,536 - INFO - ================================================================================
2026-01-14 13:18:22,537 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:18:22,537 - INFO - ================================================================================
2026-01-14 13:18:22,537 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:18:22,539 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:18:22,540 - INFO - ==================================================
2026-01-14 13:18:22,540 - INFO - train 모드를 시작합니다.
2026-01-14 13:18:22,541 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:18:22,541 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:18:22,542 - INFO - --------------------------------------------------
2026-01-14 13:18:22,544 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:18:33,580 - INFO - [Train] [1/10] | Loss: 0.5202 | Train Acc: 78.42%
2026-01-14 13:18:37,500 - INFO - [Valid] [1/10] | Loss: 0.5382 | Val Acc: 81.12%
2026-01-14 13:18:37,517 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 13:18:37,517 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 13:18:37,604 - INFO - [Best Model Saved] (val loss: 0.5382) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:18:37,604 - INFO - --------------------------------------------------
2026-01-14 13:18:37,608 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:18:46,902 - INFO - [Train] [2/10] | Loss: 0.4605 | Train Acc: 83.41%
2026-01-14 13:18:50,332 - INFO - [Valid] [2/10] | Loss: 0.5149 | Val Acc: 82.89%
2026-01-14 13:18:50,345 - INFO - [Metrics for 'abnormal'] | Precision: 0.8322 | Recall: 0.7898 | F1: 0.8105
2026-01-14 13:18:50,346 - INFO - [Metrics for 'normal'] | Precision: 0.8263 | Recall: 0.8626 | F1: 0.8441
2026-01-14 13:18:50,398 - INFO - [Best Model Saved] (val loss: 0.5149) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:18:50,399 - INFO - --------------------------------------------------
2026-01-14 13:18:50,402 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:18:58,815 - INFO - [Train] [3/10] | Loss: 0.4280 | Train Acc: 86.09%
2026-01-14 13:19:01,104 - INFO - [Valid] [3/10] | Loss: 0.5253 | Val Acc: 81.71%
2026-01-14 13:19:01,130 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 13:19:01,131 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 13:19:01,138 - INFO - --------------------------------------------------
2026-01-14 13:19:01,149 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:19:09,991 - INFO - [Train] [4/10] | Loss: 0.3932 | Train Acc: 88.62%
2026-01-14 13:19:11,658 - INFO - [Valid] [4/10] | Loss: 0.5204 | Val Acc: 82.30%
2026-01-14 13:19:11,669 - INFO - [Metrics for 'abnormal'] | Precision: 0.8012 | Recall: 0.8217 | F1: 0.8113
2026-01-14 13:19:11,670 - INFO - [Metrics for 'normal'] | Precision: 0.8427 | Recall: 0.8242 | F1: 0.8333
2026-01-14 13:19:11,674 - INFO - --------------------------------------------------
2026-01-14 13:19:11,677 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:19:19,169 - INFO - [Train] [5/10] | Loss: 0.3868 | Train Acc: 87.87%
2026-01-14 13:19:21,487 - INFO - [Valid] [5/10] | Loss: 0.5252 | Val Acc: 82.60%
2026-01-14 13:19:21,500 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 13:19:21,501 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 13:19:21,506 - INFO - --------------------------------------------------
2026-01-14 13:19:21,510 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:19:27,942 - INFO - [Train] [6/10] | Loss: 0.3599 | Train Acc: 90.33%
2026-01-14 13:19:29,605 - INFO - [Valid] [6/10] | Loss: 0.4773 | Val Acc: 82.01%
2026-01-14 13:19:29,617 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-01-14 13:19:29,617 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-01-14 13:19:29,667 - INFO - [Best Model Saved] (val loss: 0.4773) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:19:29,668 - INFO - --------------------------------------------------
2026-01-14 13:19:29,670 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:19:36,105 - INFO - [Train] [7/10] | Loss: 0.3135 | Train Acc: 93.68%
2026-01-14 13:19:37,956 - INFO - [Valid] [7/10] | Loss: 0.4920 | Val Acc: 83.48%
2026-01-14 13:19:37,967 - INFO - [Metrics for 'abnormal'] | Precision: 0.8024 | Recall: 0.8535 | F1: 0.8272
2026-01-14 13:19:37,968 - INFO - [Metrics for 'normal'] | Precision: 0.8663 | Recall: 0.8187 | F1: 0.8418
2026-01-14 13:19:37,971 - INFO - --------------------------------------------------
2026-01-14 13:19:37,974 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:19:44,773 - INFO - [Train] [8/10] | Loss: 0.2921 | Train Acc: 95.68%
2026-01-14 13:19:46,512 - INFO - [Valid] [8/10] | Loss: 0.5000 | Val Acc: 82.89%
2026-01-14 13:19:46,522 - INFO - [Metrics for 'abnormal'] | Precision: 0.7861 | Recall: 0.8662 | F1: 0.8242
2026-01-14 13:19:46,524 - INFO - [Metrics for 'normal'] | Precision: 0.8735 | Recall: 0.7967 | F1: 0.8333
2026-01-14 13:19:46,528 - INFO - --------------------------------------------------
2026-01-14 13:19:46,532 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:19:52,544 - INFO - [Train] [9/10] | Loss: 0.2681 | Train Acc: 97.32%
2026-01-14 13:19:54,609 - INFO - [Valid] [9/10] | Loss: 0.4843 | Val Acc: 84.37%
2026-01-14 13:19:54,620 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.8662 | F1: 0.8369
2026-01-14 13:19:54,620 - INFO - [Metrics for 'normal'] | Precision: 0.8772 | Recall: 0.8242 | F1: 0.8499
2026-01-14 13:19:54,624 - INFO - --------------------------------------------------
2026-01-14 13:19:54,627 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:20:00,936 - INFO - [Train] [10/10] | Loss: 0.2572 | Train Acc: 97.84%
2026-01-14 13:20:03,097 - INFO - [Valid] [10/10] | Loss: 0.4809 | Val Acc: 82.60%
2026-01-14 13:20:03,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-01-14 13:20:03,112 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-01-14 13:20:03,120 - INFO - ================================================================================
2026-01-14 13:20:03,121 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:20:03,121 - INFO - ================================================================================
2026-01-14 13:20:03,265 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:20:03,266 - INFO - ================================================================================
2026-01-14 13:20:03,266 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:20:03,267 - INFO - 원본 모델 파라미터: 0.9517M
2026-01-14 13:20:03,357 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:03,357 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:03,359 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,208 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:20:04,209 - INFO - ==================================================
2026-01-14 13:20:04,211 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.3049M (감소율: 67.96%)
2026-01-14 13:20:04,256 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:04,257 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,258 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,947 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:20:04,948 - INFO - ==================================================
2026-01-14 13:20:04,951 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1109M (감소율: 88.35%)
2026-01-14 13:20:05,007 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:05,008 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:05,010 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:05,976 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:20:05,976 - INFO - ==================================================
2026-01-14 13:20:05,979 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0459M (감소율: 95.18%)
2026-01-14 13:20:06,032 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:06,033 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,034 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,735 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:20:06,735 - INFO - ==================================================
2026-01-14 13:20:06,738 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0214M (감소율: 97.76%)
2026-01-14 13:20:06,776 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:06,777 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,777 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,528 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 13:20:07,529 - INFO - ==================================================
2026-01-14 13:20:07,531 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0337M (감소율: 96.46%)
2026-01-14 13:20:07,582 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:07,584 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,585 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,433 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 13:20:08,433 - INFO - ==================================================
2026-01-14 13:20:08,437 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0272M (감소율: 97.14%)
2026-01-14 13:20:08,500 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:08,501 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,503 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:20:09,348 - INFO - ==================================================
2026-01-14 13:20:09,350 - INFO -   [탐색  7] 희소도: 0.9049 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:09,405 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:09,405 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,406 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,338 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9087890624999999)에 맞춰 변경되었습니다.
2026-01-14 13:20:10,339 - INFO - ==================================================
2026-01-14 13:20:10,342 - INFO -   [탐색  8] 희소도: 0.9088 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:10,394 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:10,395 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,396 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,001 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9068554687499999)에 맞춰 변경되었습니다.
2026-01-14 13:20:11,002 - INFO - ==================================================
2026-01-14 13:20:11,004 - INFO -   [탐색  9] 희소도: 0.9069 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:11,049 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:11,050 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,051 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,750 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9058886718749999)에 맞춰 변경되었습니다.
2026-01-14 13:20:11,751 - INFO - ==================================================
2026-01-14 13:20:11,753 - INFO -   [탐색 10] 희소도: 0.9059 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:11,798 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:11,799 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,800 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9063720703124999)에 맞춰 변경되었습니다.
2026-01-14 13:20:12,404 - INFO - ==================================================
2026-01-14 13:20:12,406 - INFO -   [탐색 11] 희소도: 0.9064 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:12,450 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:12,451 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,452 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9061303710937498)에 맞춰 변경되었습니다.
2026-01-14 13:20:13,310 - INFO - ==================================================
2026-01-14 13:20:13,312 - INFO -   [탐색 12] 희소도: 0.9061 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:13,375 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:13,375 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,377 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,334 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062512207031248)에 맞춰 변경되었습니다.
2026-01-14 13:20:14,337 - INFO - ==================================================
2026-01-14 13:20:14,341 - INFO -   [탐색 13] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:14,405 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:14,406 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,407 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,052 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9061907958984373)에 맞춰 변경되었습니다.
2026-01-14 13:20:15,052 - INFO - ==================================================
2026-01-14 13:20:15,056 - INFO -   [탐색 14] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:15,114 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:15,114 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,115 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,689 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062210083007811)에 맞춰 변경되었습니다.
2026-01-14 13:20:15,689 - INFO - ==================================================
2026-01-14 13:20:15,691 - INFO -   [탐색 15] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:15,736 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:15,737 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,738 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,384 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906236114501953)에 맞춰 변경되었습니다.
2026-01-14 13:20:16,384 - INFO - ==================================================
2026-01-14 13:20:16,386 - INFO -   [탐색 16] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:16,431 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:16,432 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,433 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,071 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062436676025389)에 맞춰 변경되었습니다.
2026-01-14 13:20:17,072 - INFO - ==================================================
2026-01-14 13:20:17,074 - INFO -   [탐색 17] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:17,120 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:17,121 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,123 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,083 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062474441528319)에 맞춰 변경되었습니다.
2026-01-14 13:20:18,083 - INFO - ==================================================
2026-01-14 13:20:18,087 - INFO -   [탐색 18] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:18,174 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:18,175 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,176 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,924 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062493324279783)에 맞춰 변경되었습니다.
2026-01-14 13:20:18,925 - INFO - ==================================================
2026-01-14 13:20:18,927 - INFO -   [탐색 19] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:18,988 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:18,988 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,989 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:19,769 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062502765655516)에 맞춰 변경되었습니다.
2026-01-14 13:20:19,770 - INFO - ==================================================
2026-01-14 13:20:19,771 - INFO -   [탐색 20] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:19,815 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:19,816 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:19,817 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249804496765)에 맞춰 변경되었습니다.
2026-01-14 13:20:20,585 - INFO - ==================================================
2026-01-14 13:20:20,587 - INFO -   [탐색 21] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:20,646 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:20,646 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,648 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,441 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500405311582)에 맞춰 변경되었습니다.
2026-01-14 13:20:21,441 - INFO - ==================================================
2026-01-14 13:20:21,444 - INFO -   [탐색 22] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:21,494 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:21,495 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,496 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,487 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499225139615)에 맞춰 변경되었습니다.
2026-01-14 13:20:22,487 - INFO - ==================================================
2026-01-14 13:20:22,492 - INFO -   [탐색 23] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:22,540 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:22,541 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,542 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,285 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499815225599)에 맞춰 변경되었습니다.
2026-01-14 13:20:23,286 - INFO - ==================================================
2026-01-14 13:20:23,290 - INFO -   [탐색 24] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:23,336 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:23,336 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,338 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,926 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906250011026859)에 맞춰 변경되었습니다.
2026-01-14 13:20:23,927 - INFO - ==================================================
2026-01-14 13:20:23,928 - INFO -   [탐색 25] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:23,966 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:23,967 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,968 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,654 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499962747095)에 맞춰 변경되었습니다.
2026-01-14 13:20:24,654 - INFO - ==================================================
2026-01-14 13:20:24,656 - INFO -   [탐색 26] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:24,715 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:24,715 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,716 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,523 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500036507842)에 맞춰 변경되었습니다.
2026-01-14 13:20:25,523 - INFO - ==================================================
2026-01-14 13:20:25,526 - INFO -   [탐색 27] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:25,587 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:25,587 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,588 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:26,487 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999627469)에 맞춰 변경되었습니다.
2026-01-14 13:20:26,487 - INFO - ==================================================
2026-01-14 13:20:26,490 - INFO -   [탐색 28] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:26,535 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:26,536 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:26,537 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,248 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500018067656)에 맞춰 변경되었습니다.
2026-01-14 13:20:27,249 - INFO - ==================================================
2026-01-14 13:20:27,252 - INFO -   [탐색 29] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:27,311 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:27,311 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,313 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,976 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500008847563)에 맞춰 변경되었습니다.
2026-01-14 13:20:27,977 - INFO - ==================================================
2026-01-14 13:20:27,979 - INFO -   [탐색 30] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:28,025 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:28,025 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,027 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,722 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500004237516)에 맞춰 변경되었습니다.
2026-01-14 13:20:28,722 - INFO - ==================================================
2026-01-14 13:20:28,724 - INFO -   [탐색 31] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:28,796 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:28,797 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,799 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:29,570 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500001932492)에 맞춰 변경되었습니다.
2026-01-14 13:20:29,570 - INFO - ==================================================
2026-01-14 13:20:29,573 - INFO -   [탐색 32] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:29,627 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:29,627 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:29,628 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:31,023 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906250000077998)에 맞춰 변경되었습니다.
2026-01-14 13:20:31,024 - INFO - ==================================================
2026-01-14 13:20:31,029 - INFO -   [탐색 33] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:31,102 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:31,103 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:31,105 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:31,995 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000203725)에 맞춰 변경되었습니다.
2026-01-14 13:20:31,996 - INFO - ==================================================
2026-01-14 13:20:32,003 - INFO -   [탐색 34] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:32,132 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:32,132 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:32,137 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:33,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999915596)에 맞춰 변경되었습니다.
2026-01-14 13:20:33,213 - INFO - ==================================================
2026-01-14 13:20:33,216 - INFO -   [탐색 35] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:33,277 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:33,278 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:33,279 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,211 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000059661)에 맞춰 변경되었습니다.
2026-01-14 13:20:34,211 - INFO - ==================================================
2026-01-14 13:20:34,213 - INFO -   [탐색 36] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:34,260 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:34,260 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,261 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,946 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999987629)에 맞춰 변경되었습니다.
2026-01-14 13:20:34,946 - INFO - ==================================================
2026-01-14 13:20:34,948 - INFO -   [탐색 37] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:34,993 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:34,994 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,995 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,107 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000023646)에 맞춰 변경되었습니다.
2026-01-14 13:20:36,108 - INFO - ==================================================
2026-01-14 13:20:36,111 - INFO -   [탐색 38] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:36,160 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:36,161 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,162 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,836 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000005638)에 맞춰 변경되었습니다.
2026-01-14 13:20:36,837 - INFO - ==================================================
2026-01-14 13:20:36,840 - INFO -   [탐색 39] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:36,903 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:36,904 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,905 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:37,948 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999996634)에 맞춰 변경되었습니다.
2026-01-14 13:20:37,949 - INFO - ==================================================
2026-01-14 13:20:37,954 - INFO -   [탐색 40] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:38,026 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:38,027 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:38,028 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:39,269 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000001136)에 맞춰 변경되었습니다.
2026-01-14 13:20:39,271 - INFO - ==================================================
2026-01-14 13:20:39,274 - INFO -   [탐색 41] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:39,337 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:39,337 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:39,339 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:40,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999998885)에 맞춰 변경되었습니다.
2026-01-14 13:20:40,191 - INFO - ==================================================
2026-01-14 13:20:40,194 - INFO -   [탐색 42] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:40,253 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:40,253 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:40,254 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,014 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000011)에 맞춰 변경되었습니다.
2026-01-14 13:20:42,014 - INFO - ==================================================
2026-01-14 13:20:42,018 - INFO -   [탐색 43] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:42,065 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:42,065 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,067 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,692 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999448)에 맞춰 변경되었습니다.
2026-01-14 13:20:42,693 - INFO - ==================================================
2026-01-14 13:20:42,696 - INFO -   [탐색 44] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:42,751 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:42,752 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,753 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:43,777 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999729)에 맞춰 변경되었습니다.
2026-01-14 13:20:43,778 - INFO - ==================================================
2026-01-14 13:20:43,781 - INFO -   [탐색 45] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:43,849 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:43,850 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:43,851 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:44,587 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249999999987)에 맞춰 변경되었습니다.
2026-01-14 13:20:44,588 - INFO - ==================================================
2026-01-14 13:20:44,594 - INFO -   [탐색 46] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:44,659 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:44,659 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:44,661 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:45,574 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249999999994)에 맞춰 변경되었습니다.
2026-01-14 13:20:45,574 - INFO - ==================================================
2026-01-14 13:20:45,576 - INFO -   [탐색 47] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:45,622 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:45,623 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:45,624 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:46,489 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999976)에 맞춰 변경되었습니다.
2026-01-14 13:20:46,490 - INFO - ==================================================
2026-01-14 13:20:46,493 - INFO -   [탐색 48] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:46,907 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:46,908 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:46,910 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:47,823 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999993)에 맞춰 변경되었습니다.
2026-01-14 13:20:47,824 - INFO - ==================================================
2026-01-14 13:20:47,829 - INFO -   [탐색 49] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:47,899 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:47,899 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:47,901 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:49,449 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000002)에 맞춰 변경되었습니다.
2026-01-14 13:20:49,450 - INFO - ==================================================
2026-01-14 13:20:49,452 - INFO -   [탐색 50] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:49,518 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:49,519 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:49,521 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:50,473 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999998)에 맞춰 변경되었습니다.
2026-01-14 13:20:50,474 - INFO - ==================================================
2026-01-14 13:20:50,478 - INFO -   [탐색 51] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:50,546 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:50,547 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:50,549 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:51,496 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:20:51,497 - INFO - ==================================================
2026-01-14 13:20:51,499 - INFO -   [탐색 52] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:51,549 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:51,549 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:51,550 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:52,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000001)에 맞춰 변경되었습니다.
2026-01-14 13:20:52,669 - INFO - ==================================================
2026-01-14 13:20:52,673 - INFO -   [탐색 53] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:20:52,733 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:52,734 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:52,735 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:54,084 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:20:54,088 - INFO - ==================================================
2026-01-14 13:20:54,094 - INFO -   [탐색 54] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:54,217 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:54,217 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:54,219 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:55,138 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:20:55,138 - INFO - ==================================================
2026-01-14 13:20:55,143 - INFO -   [탐색 55] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:55,224 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:55,229 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:55,230 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:56,317 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:20:56,321 - INFO - ==================================================
2026-01-14 13:20:56,328 - INFO -   [탐색 56] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:56,426 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:56,426 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:56,427 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:57,452 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:20:57,453 - INFO - ==================================================
2026-01-14 13:20:57,456 - INFO -   [탐색 57] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:57,542 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:57,542 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:57,548 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:59,123 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:20:59,124 - INFO - ==================================================
2026-01-14 13:20:59,128 - INFO -   [탐색 58] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:20:59,201 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:59,201 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:59,202 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:00,233 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:00,233 - INFO - ==================================================
2026-01-14 13:21:00,236 - INFO -   [탐색 59] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:00,298 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:00,299 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:00,301 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:01,220 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:01,221 - INFO - ==================================================
2026-01-14 13:21:01,224 - INFO -   [탐색 60] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:01,283 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:01,284 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:01,286 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:02,164 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:02,164 - INFO - ==================================================
2026-01-14 13:21:02,167 - INFO -   [탐색 61] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:02,227 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:02,228 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:02,229 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:03,850 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:03,854 - INFO - ==================================================
2026-01-14 13:21:03,865 - INFO -   [탐색 62] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:03,991 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:03,992 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:03,993 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:06,087 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:06,088 - INFO - ==================================================
2026-01-14 13:21:06,100 - INFO -   [탐색 63] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:06,199 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:06,200 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:06,202 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:07,388 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:07,389 - INFO - ==================================================
2026-01-14 13:21:07,392 - INFO -   [탐색 64] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:07,453 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:07,454 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:07,455 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:08,488 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:08,489 - INFO - ==================================================
2026-01-14 13:21:08,492 - INFO -   [탐색 65] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:08,561 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:08,561 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:08,563 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:09,296 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:09,297 - INFO - ==================================================
2026-01-14 13:21:09,299 - INFO -   [탐색 66] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:09,345 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:09,346 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:09,347 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:10,195 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:10,196 - INFO - ==================================================
2026-01-14 13:21:10,198 - INFO -   [탐색 67] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:10,243 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:10,243 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:10,244 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:11,288 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:11,291 - INFO - ==================================================
2026-01-14 13:21:11,298 - INFO -   [탐색 68] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:11,417 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:11,417 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:11,422 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:12,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:12,445 - INFO - ==================================================
2026-01-14 13:21:12,447 - INFO -   [탐색 69] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:12,506 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:12,507 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:12,509 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:13,529 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:13,530 - INFO - ==================================================
2026-01-14 13:21:13,532 - INFO -   [탐색 70] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:13,592 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:13,592 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:13,594 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:14,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:14,583 - INFO - ==================================================
2026-01-14 13:21:14,585 - INFO -   [탐색 71] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:14,650 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:14,651 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:14,653 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:15,500 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:15,501 - INFO - ==================================================
2026-01-14 13:21:15,504 - INFO -   [탐색 72] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:15,568 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:15,569 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:15,570 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:17,276 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:17,277 - INFO - ==================================================
2026-01-14 13:21:17,282 - INFO -   [탐색 73] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:17,345 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:17,346 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:17,348 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:18,415 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:18,415 - INFO - ==================================================
2026-01-14 13:21:18,418 - INFO -   [탐색 74] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:18,515 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:18,515 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:18,517 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:19,361 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:19,362 - INFO - ==================================================
2026-01-14 13:21:19,365 - INFO -   [탐색 75] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:19,425 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:19,426 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:19,428 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:20,388 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:20,389 - INFO - ==================================================
2026-01-14 13:21:20,392 - INFO -   [탐색 76] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:20,451 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:20,452 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:20,454 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:21,390 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:21,391 - INFO - ==================================================
2026-01-14 13:21:21,393 - INFO -   [탐색 77] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:21,460 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:21,461 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:21,463 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:22,792 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:22,793 - INFO - ==================================================
2026-01-14 13:21:22,796 - INFO -   [탐색 78] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:22,856 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:22,856 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:22,858 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:24,206 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:24,206 - INFO - ==================================================
2026-01-14 13:21:24,266 - INFO -   [탐색 79] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:24,386 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:24,386 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:24,392 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:25,701 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:25,701 - INFO - ==================================================
2026-01-14 13:21:25,704 - INFO -   [탐색 80] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:25,787 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:25,788 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:25,789 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:27,744 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:27,745 - INFO - ==================================================
2026-01-14 13:21:27,751 - INFO -   [탐색 81] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:27,867 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:27,868 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:27,869 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:28,995 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:28,996 - INFO - ==================================================
2026-01-14 13:21:28,999 - INFO -   [탐색 82] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:29,055 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:29,055 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:29,057 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:30,594 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:30,595 - INFO - ==================================================
2026-01-14 13:21:30,599 - INFO -   [탐색 83] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:30,664 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:30,665 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:30,666 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:31,468 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:31,468 - INFO - ==================================================
2026-01-14 13:21:31,471 - INFO -   [탐색 84] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:31,535 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:31,536 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:31,538 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:32,447 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:32,448 - INFO - ==================================================
2026-01-14 13:21:32,451 - INFO -   [탐색 85] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:32,511 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:32,512 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:32,514 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:33,424 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:33,425 - INFO - ==================================================
2026-01-14 13:21:33,428 - INFO -   [탐색 86] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:33,524 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:33,525 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:33,527 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:34,431 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:34,432 - INFO - ==================================================
2026-01-14 13:21:34,435 - INFO -   [탐색 87] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:34,485 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:34,486 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:34,487 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:36,094 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:36,095 - INFO - ==================================================
2026-01-14 13:21:36,116 - INFO -   [탐색 88] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:36,190 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:36,190 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:36,248 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:38,373 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:38,374 - INFO - ==================================================
2026-01-14 13:21:38,377 - INFO -   [탐색 89] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:38,468 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:38,468 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:38,469 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:39,443 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:39,444 - INFO - ==================================================
2026-01-14 13:21:39,448 - INFO -   [탐색 90] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:39,507 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:39,507 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:39,508 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:40,518 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:40,519 - INFO - ==================================================
2026-01-14 13:21:40,522 - INFO -   [탐색 91] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:40,586 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:40,587 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:40,589 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:41,701 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:41,701 - INFO - ==================================================
2026-01-14 13:21:41,703 - INFO -   [탐색 92] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:41,745 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:41,746 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:41,747 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:42,497 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:42,498 - INFO - ==================================================
2026-01-14 13:21:42,501 - INFO -   [탐색 93] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:43,302 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:43,307 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:43,310 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:44,683 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:44,683 - INFO - ==================================================
2026-01-14 13:21:44,690 - INFO -   [탐색 94] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:44,883 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:44,884 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:44,891 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:46,927 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:46,928 - INFO - ==================================================
2026-01-14 13:21:46,931 - INFO -   [탐색 95] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:47,004 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:47,007 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:47,008 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:48,238 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:48,239 - INFO - ==================================================
2026-01-14 13:21:48,242 - INFO -   [탐색 96] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:48,287 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:48,288 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:48,289 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:49,038 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:49,038 - INFO - ==================================================
2026-01-14 13:21:49,040 - INFO -   [탐색 97] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:49,083 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:49,083 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:49,084 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:50,476 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:50,477 - INFO - ==================================================
2026-01-14 13:21:50,555 - INFO -   [탐색 98] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:50,729 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:50,730 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:50,731 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:51,700 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:51,700 - INFO - ==================================================
2026-01-14 13:21:51,703 - INFO -   [탐색 99] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:51,785 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:51,785 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:51,787 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:52,759 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:21:52,759 - INFO - ==================================================
2026-01-14 13:21:52,763 - INFO -   [탐색 100] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:21:52,763 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9049 입니다.
2026-01-14 13:21:52,763 - INFO - ================================================================================
2026-01-14 13:21:52,768 - INFO - 계산된 Pruning 정보(희소도: 0.9049)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:21:52,854 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:21:53,106 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:21:53,106 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:21:53,107 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:21:54,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:21:54,177 - INFO - ==================================================
2026-01-14 13:21:54,182 - INFO - ==================================================
2026-01-14 13:21:54,183 - INFO - 모델 파라미터 수:
2026-01-14 13:21:54,184 - INFO -   - 총 파라미터: 31,612 개
2026-01-14 13:21:54,184 - INFO -   - 학습 가능한 파라미터: 31,612 개
2026-01-14 13:21:54,340 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:21:54,598 - INFO - FLOPs가 0.5384 GFLOPs에서 0.0171 GFLOPs로 감소했습니다 (감소율: 96.83%).
2026-01-14 13:21:54,599 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:21:54,599 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:21:54,601 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:21:54,602 - INFO - ==================================================
2026-01-14 13:21:54,602 - INFO - train 모드를 시작합니다.
2026-01-14 13:21:54,602 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:21:54,602 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:21:54,602 - INFO - --------------------------------------------------
2026-01-14 13:21:54,605 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:22:05,338 - INFO - [Train] [11/90] | Loss: 0.6093 | Train Acc: 70.24%
2026-01-14 13:22:10,127 - INFO - [Valid] [11/90] | Loss: 0.6545 | Val Acc: 62.83%
2026-01-14 13:22:10,139 - INFO - [Metrics for 'abnormal'] | Precision: 0.5585 | Recall: 0.9427 | F1: 0.7014
2026-01-14 13:22:10,140 - INFO - [Metrics for 'normal'] | Precision: 0.8784 | Recall: 0.3571 | F1: 0.5078
2026-01-14 13:22:10,184 - INFO - [Best Model Saved] (val loss: 0.6545) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:22:10,185 - INFO - --------------------------------------------------
2026-01-14 13:22:10,188 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:22:18,987 - INFO - [Train] [12/90] | Loss: 0.5499 | Train Acc: 75.22%
2026-01-14 13:22:21,946 - INFO - [Valid] [12/90] | Loss: 0.5703 | Val Acc: 74.04%
2026-01-14 13:22:21,959 - INFO - [Metrics for 'abnormal'] | Precision: 0.6927 | Recall: 0.7898 | F1: 0.7381
2026-01-14 13:22:21,960 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.6978 | F1: 0.7427
2026-01-14 13:22:22,005 - INFO - [Best Model Saved] (val loss: 0.5703) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:22:22,006 - INFO - --------------------------------------------------
2026-01-14 13:22:22,009 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:22:31,883 - INFO - [Train] [13/90] | Loss: 0.5192 | Train Acc: 77.83%
2026-01-14 13:22:36,226 - INFO - [Valid] [13/90] | Loss: 0.5408 | Val Acc: 77.88%
2026-01-14 13:22:36,238 - INFO - [Metrics for 'abnormal'] | Precision: 0.7847 | Recall: 0.7197 | F1: 0.7508
2026-01-14 13:22:36,239 - INFO - [Metrics for 'normal'] | Precision: 0.7744 | Recall: 0.8297 | F1: 0.8011
2026-01-14 13:22:36,285 - INFO - [Best Model Saved] (val loss: 0.5408) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:22:36,286 - INFO - --------------------------------------------------
2026-01-14 13:22:36,290 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:22:45,881 - INFO - [Train] [14/90] | Loss: 0.5060 | Train Acc: 80.06%
2026-01-14 13:22:49,085 - INFO - [Valid] [14/90] | Loss: 0.5550 | Val Acc: 77.29%
2026-01-14 13:22:49,098 - INFO - [Metrics for 'abnormal'] | Precision: 0.7381 | Recall: 0.7898 | F1: 0.7631
2026-01-14 13:22:49,099 - INFO - [Metrics for 'normal'] | Precision: 0.8070 | Recall: 0.7582 | F1: 0.7819
2026-01-14 13:22:49,104 - INFO - --------------------------------------------------
2026-01-14 13:22:49,108 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:22:58,283 - INFO - [Train] [15/90] | Loss: 0.4941 | Train Acc: 79.69%
2026-01-14 13:23:01,361 - INFO - [Valid] [15/90] | Loss: 0.5398 | Val Acc: 77.58%
2026-01-14 13:23:01,373 - INFO - [Metrics for 'abnormal'] | Precision: 0.7368 | Recall: 0.8025 | F1: 0.7683
2026-01-14 13:23:01,374 - INFO - [Metrics for 'normal'] | Precision: 0.8155 | Recall: 0.7527 | F1: 0.7829
2026-01-14 13:23:01,422 - INFO - [Best Model Saved] (val loss: 0.5398) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:23:01,423 - INFO - --------------------------------------------------
2026-01-14 13:23:01,426 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:23:12,048 - INFO - [Train] [16/90] | Loss: 0.4809 | Train Acc: 82.51%
2026-01-14 13:23:14,658 - INFO - [Valid] [16/90] | Loss: 0.6076 | Val Acc: 73.45%
2026-01-14 13:23:14,671 - INFO - [Metrics for 'abnormal'] | Precision: 0.6718 | Recall: 0.8344 | F1: 0.7443
2026-01-14 13:23:14,672 - INFO - [Metrics for 'normal'] | Precision: 0.8194 | Recall: 0.6484 | F1: 0.7239
2026-01-14 13:23:14,676 - INFO - --------------------------------------------------
2026-01-14 13:23:14,680 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:23:24,811 - INFO - [Train] [17/90] | Loss: 0.4895 | Train Acc: 80.21%
2026-01-14 13:23:27,104 - INFO - [Valid] [17/90] | Loss: 0.5250 | Val Acc: 77.29%
2026-01-14 13:23:27,117 - INFO - [Metrics for 'abnormal'] | Precision: 0.7532 | Recall: 0.7580 | F1: 0.7556
2026-01-14 13:23:27,117 - INFO - [Metrics for 'normal'] | Precision: 0.7901 | Recall: 0.7857 | F1: 0.7879
2026-01-14 13:23:27,160 - INFO - [Best Model Saved] (val loss: 0.5250) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:23:27,161 - INFO - --------------------------------------------------
2026-01-14 13:23:27,165 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:23:37,685 - INFO - [Train] [18/90] | Loss: 0.4723 | Train Acc: 82.37%
2026-01-14 13:23:40,346 - INFO - [Valid] [18/90] | Loss: 0.5366 | Val Acc: 77.29%
2026-01-14 13:23:40,359 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.8153 | F1: 0.7688
2026-01-14 13:23:40,359 - INFO - [Metrics for 'normal'] | Precision: 0.8221 | Recall: 0.7363 | F1: 0.7768
2026-01-14 13:23:40,363 - INFO - --------------------------------------------------
2026-01-14 13:23:40,366 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:23:49,429 - INFO - [Train] [19/90] | Loss: 0.4582 | Train Acc: 82.74%
2026-01-14 13:23:52,129 - INFO - [Valid] [19/90] | Loss: 0.5369 | Val Acc: 77.88%
2026-01-14 13:23:52,140 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-01-14 13:23:52,141 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-01-14 13:23:52,147 - INFO - --------------------------------------------------
2026-01-14 13:23:52,151 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:24:01,991 - INFO - [Train] [20/90] | Loss: 0.4583 | Train Acc: 82.81%
2026-01-14 13:24:05,078 - INFO - [Valid] [20/90] | Loss: 0.5197 | Val Acc: 76.99%
2026-01-14 13:24:05,101 - INFO - [Metrics for 'abnormal'] | Precision: 0.7283 | Recall: 0.8025 | F1: 0.7636
2026-01-14 13:24:05,101 - INFO - [Metrics for 'normal'] | Precision: 0.8133 | Recall: 0.7418 | F1: 0.7759
2026-01-14 13:24:05,151 - INFO - [Best Model Saved] (val loss: 0.5197) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:24:05,152 - INFO - --------------------------------------------------
2026-01-14 13:24:05,156 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:24:17,023 - INFO - [Train] [21/90] | Loss: 0.4595 | Train Acc: 82.59%
2026-01-14 13:24:20,365 - INFO - [Valid] [21/90] | Loss: 0.5319 | Val Acc: 77.58%
2026-01-14 13:24:20,378 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.7771 | F1: 0.7625
2026-01-14 13:24:20,379 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7747 | F1: 0.7877
2026-01-14 13:24:20,384 - INFO - --------------------------------------------------
2026-01-14 13:24:20,387 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:24:31,398 - INFO - [Train] [22/90] | Loss: 0.4574 | Train Acc: 83.33%
2026-01-14 13:24:34,027 - INFO - [Valid] [22/90] | Loss: 0.5393 | Val Acc: 77.58%
2026-01-14 13:24:34,053 - INFO - [Metrics for 'abnormal'] | Precision: 0.7238 | Recall: 0.8344 | F1: 0.7751
2026-01-14 13:24:34,053 - INFO - [Metrics for 'normal'] | Precision: 0.8354 | Recall: 0.7253 | F1: 0.7765
2026-01-14 13:24:34,060 - INFO - --------------------------------------------------
2026-01-14 13:24:34,067 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:24:44,121 - INFO - [Train] [23/90] | Loss: 0.4476 | Train Acc: 83.71%
2026-01-14 13:24:47,031 - INFO - [Valid] [23/90] | Loss: 0.5244 | Val Acc: 74.93%
2026-01-14 13:24:47,043 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.7325 | F1: 0.7302
2026-01-14 13:24:47,044 - INFO - [Metrics for 'normal'] | Precision: 0.7680 | Recall: 0.7637 | F1: 0.7658
2026-01-14 13:24:47,048 - INFO - --------------------------------------------------
2026-01-14 13:24:47,052 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:24:57,542 - INFO - [Train] [24/90] | Loss: 0.4432 | Train Acc: 84.60%
2026-01-14 13:25:01,158 - INFO - [Valid] [24/90] | Loss: 0.5352 | Val Acc: 76.99%
2026-01-14 13:25:01,181 - INFO - [Metrics for 'abnormal'] | Precision: 0.7283 | Recall: 0.8025 | F1: 0.7636
2026-01-14 13:25:01,181 - INFO - [Metrics for 'normal'] | Precision: 0.8133 | Recall: 0.7418 | F1: 0.7759
2026-01-14 13:25:01,191 - INFO - --------------------------------------------------
2026-01-14 13:25:01,199 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:25:10,160 - INFO - [Train] [25/90] | Loss: 0.4408 | Train Acc: 84.23%
2026-01-14 13:25:13,879 - INFO - [Valid] [25/90] | Loss: 0.5155 | Val Acc: 79.94%
2026-01-14 13:25:13,891 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-01-14 13:25:13,893 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-01-14 13:25:14,205 - INFO - [Best Model Saved] (val loss: 0.5155) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:25:14,205 - INFO - --------------------------------------------------
2026-01-14 13:25:14,209 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:25:22,935 - INFO - [Train] [26/90] | Loss: 0.4319 | Train Acc: 85.34%
2026-01-14 13:25:27,142 - INFO - [Valid] [26/90] | Loss: 0.5436 | Val Acc: 79.35%
2026-01-14 13:25:27,172 - INFO - [Metrics for 'abnormal'] | Precision: 0.7806 | Recall: 0.7707 | F1: 0.7756
2026-01-14 13:25:27,176 - INFO - [Metrics for 'normal'] | Precision: 0.8043 | Recall: 0.8132 | F1: 0.8087
2026-01-14 13:25:27,184 - INFO - --------------------------------------------------
2026-01-14 13:25:27,192 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:25:37,665 - INFO - [Train] [27/90] | Loss: 0.4313 | Train Acc: 85.49%
2026-01-14 13:25:41,304 - INFO - [Valid] [27/90] | Loss: 0.5092 | Val Acc: 78.76%
2026-01-14 13:25:41,315 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-01-14 13:25:41,315 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-01-14 13:25:41,358 - INFO - [Best Model Saved] (val loss: 0.5092) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:25:41,359 - INFO - --------------------------------------------------
2026-01-14 13:25:41,361 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:25:50,974 - INFO - [Train] [28/90] | Loss: 0.4187 | Train Acc: 85.57%
2026-01-14 13:25:53,621 - INFO - [Valid] [28/90] | Loss: 0.5147 | Val Acc: 79.65%
2026-01-14 13:25:53,632 - INFO - [Metrics for 'abnormal'] | Precision: 0.7785 | Recall: 0.7834 | F1: 0.7810
2026-01-14 13:25:53,633 - INFO - [Metrics for 'normal'] | Precision: 0.8122 | Recall: 0.8077 | F1: 0.8099
2026-01-14 13:25:53,637 - INFO - --------------------------------------------------
2026-01-14 13:25:53,640 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:26:02,962 - INFO - [Train] [29/90] | Loss: 0.4120 | Train Acc: 86.46%
2026-01-14 13:26:05,912 - INFO - [Valid] [29/90] | Loss: 0.5691 | Val Acc: 75.52%
2026-01-14 13:26:05,926 - INFO - [Metrics for 'abnormal'] | Precision: 0.6814 | Recall: 0.8854 | F1: 0.7701
2026-01-14 13:26:05,927 - INFO - [Metrics for 'normal'] | Precision: 0.8667 | Recall: 0.6429 | F1: 0.7382
2026-01-14 13:26:05,932 - INFO - --------------------------------------------------
2026-01-14 13:26:05,937 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:26:15,048 - INFO - [Train] [30/90] | Loss: 0.4227 | Train Acc: 85.64%
2026-01-14 13:26:17,617 - INFO - [Valid] [30/90] | Loss: 0.5251 | Val Acc: 78.17%
2026-01-14 13:26:17,636 - INFO - [Metrics for 'abnormal'] | Precision: 0.7371 | Recall: 0.8217 | F1: 0.7771
2026-01-14 13:26:17,638 - INFO - [Metrics for 'normal'] | Precision: 0.8293 | Recall: 0.7473 | F1: 0.7861
2026-01-14 13:26:17,647 - INFO - --------------------------------------------------
2026-01-14 13:26:17,653 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:26:27,830 - INFO - [Train] [31/90] | Loss: 0.4093 | Train Acc: 86.90%
2026-01-14 13:26:29,930 - INFO - [Valid] [31/90] | Loss: 0.5760 | Val Acc: 76.70%
2026-01-14 13:26:29,941 - INFO - [Metrics for 'abnormal'] | Precision: 0.7349 | Recall: 0.7771 | F1: 0.7554
2026-01-14 13:26:29,942 - INFO - [Metrics for 'normal'] | Precision: 0.7977 | Recall: 0.7582 | F1: 0.7775
2026-01-14 13:26:29,946 - INFO - --------------------------------------------------
2026-01-14 13:26:29,949 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:26:39,806 - INFO - [Train] [32/90] | Loss: 0.4043 | Train Acc: 87.43%
2026-01-14 13:26:42,345 - INFO - [Valid] [32/90] | Loss: 0.5800 | Val Acc: 78.47%
2026-01-14 13:26:42,357 - INFO - [Metrics for 'abnormal'] | Precision: 0.7360 | Recall: 0.8344 | F1: 0.7821
2026-01-14 13:26:42,358 - INFO - [Metrics for 'normal'] | Precision: 0.8385 | Recall: 0.7418 | F1: 0.7872
2026-01-14 13:26:42,362 - INFO - --------------------------------------------------
2026-01-14 13:26:42,366 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:26:51,864 - INFO - [Train] [33/90] | Loss: 0.3931 | Train Acc: 87.80%
2026-01-14 13:26:54,747 - INFO - [Valid] [33/90] | Loss: 0.5203 | Val Acc: 79.06%
2026-01-14 13:26:54,759 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.7834 | F1: 0.7760
2026-01-14 13:26:54,759 - INFO - [Metrics for 'normal'] | Precision: 0.8101 | Recall: 0.7967 | F1: 0.8033
2026-01-14 13:26:54,763 - INFO - --------------------------------------------------
2026-01-14 13:26:54,767 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:27:04,590 - INFO - [Train] [34/90] | Loss: 0.4020 | Train Acc: 86.46%
2026-01-14 13:27:07,319 - INFO - [Valid] [34/90] | Loss: 0.5172 | Val Acc: 80.53%
2026-01-14 13:27:07,341 - INFO - [Metrics for 'abnormal'] | Precision: 0.7600 | Recall: 0.8471 | F1: 0.8012
2026-01-14 13:27:07,343 - INFO - [Metrics for 'normal'] | Precision: 0.8537 | Recall: 0.7692 | F1: 0.8092
2026-01-14 13:27:07,352 - INFO - --------------------------------------------------
2026-01-14 13:27:07,356 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:27:16,527 - INFO - [Train] [35/90] | Loss: 0.4080 | Train Acc: 86.31%
2026-01-14 13:27:19,417 - INFO - [Valid] [35/90] | Loss: 0.5717 | Val Acc: 76.70%
2026-01-14 13:27:19,450 - INFO - [Metrics for 'abnormal'] | Precision: 0.6857 | Recall: 0.9172 | F1: 0.7847
2026-01-14 13:27:19,453 - INFO - [Metrics for 'normal'] | Precision: 0.8992 | Recall: 0.6374 | F1: 0.7460
2026-01-14 13:27:19,459 - INFO - --------------------------------------------------
2026-01-14 13:27:19,467 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:27:28,775 - INFO - [Train] [36/90] | Loss: 0.3858 | Train Acc: 88.76%
2026-01-14 13:27:32,033 - INFO - [Valid] [36/90] | Loss: 0.5220 | Val Acc: 80.53%
2026-01-14 13:27:32,055 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-01-14 13:27:32,056 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-01-14 13:27:32,061 - INFO - --------------------------------------------------
2026-01-14 13:27:32,065 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:27:40,074 - INFO - [Train] [37/90] | Loss: 0.3945 | Train Acc: 88.17%
2026-01-14 13:27:44,358 - INFO - [Valid] [37/90] | Loss: 0.5309 | Val Acc: 79.35%
2026-01-14 13:27:44,375 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:27:44,376 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:27:44,381 - INFO - --------------------------------------------------
2026-01-14 13:27:44,387 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:27:54,349 - INFO - [Train] [38/90] | Loss: 0.3870 | Train Acc: 88.10%
2026-01-14 13:27:57,374 - INFO - [Valid] [38/90] | Loss: 0.5407 | Val Acc: 79.06%
2026-01-14 13:27:57,385 - INFO - [Metrics for 'abnormal'] | Precision: 0.7416 | Recall: 0.8408 | F1: 0.7881
2026-01-14 13:27:57,386 - INFO - [Metrics for 'normal'] | Precision: 0.8447 | Recall: 0.7473 | F1: 0.7930
2026-01-14 13:27:57,391 - INFO - --------------------------------------------------
2026-01-14 13:27:57,394 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:28:07,814 - INFO - [Train] [39/90] | Loss: 0.3852 | Train Acc: 87.87%
2026-01-14 13:28:10,286 - INFO - [Valid] [39/90] | Loss: 0.5641 | Val Acc: 78.76%
2026-01-14 13:28:10,299 - INFO - [Metrics for 'abnormal'] | Precision: 0.7073 | Recall: 0.9236 | F1: 0.8011
2026-01-14 13:28:10,300 - INFO - [Metrics for 'normal'] | Precision: 0.9104 | Recall: 0.6703 | F1: 0.7722
2026-01-14 13:28:10,304 - INFO - --------------------------------------------------
2026-01-14 13:28:10,308 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:28:20,186 - INFO - [Train] [40/90] | Loss: 0.3686 | Train Acc: 89.51%
2026-01-14 13:28:23,175 - INFO - [Valid] [40/90] | Loss: 0.5256 | Val Acc: 77.88%
2026-01-14 13:28:23,186 - INFO - [Metrics for 'abnormal'] | Precision: 0.7440 | Recall: 0.7962 | F1: 0.7692
2026-01-14 13:28:23,187 - INFO - [Metrics for 'normal'] | Precision: 0.8129 | Recall: 0.7637 | F1: 0.7875
2026-01-14 13:28:23,191 - INFO - --------------------------------------------------
2026-01-14 13:28:23,195 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:28:32,998 - INFO - [Train] [41/90] | Loss: 0.3747 | Train Acc: 89.96%
2026-01-14 13:28:35,366 - INFO - [Valid] [41/90] | Loss: 0.5386 | Val Acc: 77.58%
2026-01-14 13:28:35,387 - INFO - [Metrics for 'abnormal'] | Precision: 0.7425 | Recall: 0.7898 | F1: 0.7654
2026-01-14 13:28:35,388 - INFO - [Metrics for 'normal'] | Precision: 0.8081 | Recall: 0.7637 | F1: 0.7853
2026-01-14 13:28:35,393 - INFO - --------------------------------------------------
2026-01-14 13:28:35,397 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:28:45,009 - INFO - [Train] [42/90] | Loss: 0.3882 | Train Acc: 88.17%
2026-01-14 13:28:47,470 - INFO - [Valid] [42/90] | Loss: 0.5474 | Val Acc: 78.47%
2026-01-14 13:28:47,481 - INFO - [Metrics for 'abnormal'] | Precision: 0.7471 | Recall: 0.8089 | F1: 0.7768
2026-01-14 13:28:47,481 - INFO - [Metrics for 'normal'] | Precision: 0.8225 | Recall: 0.7637 | F1: 0.7920
2026-01-14 13:28:47,485 - INFO - --------------------------------------------------
2026-01-14 13:28:47,488 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:28:56,331 - INFO - [Train] [43/90] | Loss: 0.3635 | Train Acc: 90.55%
2026-01-14 13:28:59,192 - INFO - [Valid] [43/90] | Loss: 0.5306 | Val Acc: 78.76%
2026-01-14 13:28:59,203 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.7580 | F1: 0.7677
2026-01-14 13:28:59,204 - INFO - [Metrics for 'normal'] | Precision: 0.7957 | Recall: 0.8132 | F1: 0.8043
2026-01-14 13:28:59,208 - INFO - --------------------------------------------------
2026-01-14 13:28:59,212 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:29:08,675 - INFO - [Train] [44/90] | Loss: 0.3763 | Train Acc: 88.76%
2026-01-14 13:29:11,093 - INFO - [Valid] [44/90] | Loss: 0.5563 | Val Acc: 79.65%
2026-01-14 13:29:11,102 - INFO - [Metrics for 'abnormal'] | Precision: 0.7973 | Recall: 0.7516 | F1: 0.7738
2026-01-14 13:29:11,103 - INFO - [Metrics for 'normal'] | Precision: 0.7958 | Recall: 0.8352 | F1: 0.8150
2026-01-14 13:29:11,106 - INFO - --------------------------------------------------
2026-01-14 13:29:11,110 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:29:20,960 - INFO - [Train] [45/90] | Loss: 0.3798 | Train Acc: 88.76%
2026-01-14 13:29:23,482 - INFO - [Valid] [45/90] | Loss: 0.5219 | Val Acc: 78.17%
2026-01-14 13:29:23,495 - INFO - [Metrics for 'abnormal'] | Precision: 0.7456 | Recall: 0.8025 | F1: 0.7730
2026-01-14 13:29:23,495 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.7637 | F1: 0.7898
2026-01-14 13:29:23,499 - INFO - --------------------------------------------------
2026-01-14 13:29:23,503 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:29:32,858 - INFO - [Train] [46/90] | Loss: 0.3578 | Train Acc: 90.33%
2026-01-14 13:29:36,091 - INFO - [Valid] [46/90] | Loss: 0.5702 | Val Acc: 76.11%
2026-01-14 13:29:36,104 - INFO - [Metrics for 'abnormal'] | Precision: 0.7289 | Recall: 0.7707 | F1: 0.7492
2026-01-14 13:29:36,105 - INFO - [Metrics for 'normal'] | Precision: 0.7919 | Recall: 0.7527 | F1: 0.7718
2026-01-14 13:29:36,112 - INFO - --------------------------------------------------
2026-01-14 13:29:36,115 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:29:45,044 - INFO - [Train] [47/90] | Loss: 0.3761 | Train Acc: 89.06%
2026-01-14 13:29:47,545 - INFO - [Valid] [47/90] | Loss: 0.5658 | Val Acc: 76.40%
2026-01-14 13:29:47,558 - INFO - [Metrics for 'abnormal'] | Precision: 0.7225 | Recall: 0.7962 | F1: 0.7576
2026-01-14 13:29:47,558 - INFO - [Metrics for 'normal'] | Precision: 0.8072 | Recall: 0.7363 | F1: 0.7701
2026-01-14 13:29:47,562 - INFO - --------------------------------------------------
2026-01-14 13:29:47,566 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:29:57,488 - INFO - [Train] [48/90] | Loss: 0.3533 | Train Acc: 91.07%
2026-01-14 13:29:59,642 - INFO - [Valid] [48/90] | Loss: 0.5692 | Val Acc: 76.70%
2026-01-14 13:29:59,654 - INFO - [Metrics for 'abnormal'] | Precision: 0.7097 | Recall: 0.8408 | F1: 0.7697
2026-01-14 13:29:59,655 - INFO - [Metrics for 'normal'] | Precision: 0.8366 | Recall: 0.7033 | F1: 0.7642
2026-01-14 13:29:59,659 - INFO - --------------------------------------------------
2026-01-14 13:29:59,662 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:30:09,124 - INFO - [Train] [49/90] | Loss: 0.3610 | Train Acc: 90.48%
2026-01-14 13:30:12,556 - INFO - [Valid] [49/90] | Loss: 0.5678 | Val Acc: 76.70%
2026-01-14 13:30:12,568 - INFO - [Metrics for 'abnormal'] | Precision: 0.7321 | Recall: 0.7834 | F1: 0.7569
2026-01-14 13:30:12,569 - INFO - [Metrics for 'normal'] | Precision: 0.8012 | Recall: 0.7527 | F1: 0.7762
2026-01-14 13:30:12,573 - INFO - --------------------------------------------------
2026-01-14 13:30:12,577 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:30:22,314 - INFO - [Train] [50/90] | Loss: 0.3550 | Train Acc: 90.03%
2026-01-14 13:30:24,372 - INFO - [Valid] [50/90] | Loss: 0.5671 | Val Acc: 77.29%
2026-01-14 13:30:24,384 - INFO - [Metrics for 'abnormal'] | Precision: 0.7632 | Recall: 0.7389 | F1: 0.7508
2026-01-14 13:30:24,384 - INFO - [Metrics for 'normal'] | Precision: 0.7807 | Recall: 0.8022 | F1: 0.7913
2026-01-14 13:30:24,389 - INFO - --------------------------------------------------
2026-01-14 13:30:24,392 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:30:33,865 - INFO - [Train] [51/90] | Loss: 0.3399 | Train Acc: 92.19%
2026-01-14 13:30:36,443 - INFO - [Valid] [51/90] | Loss: 0.5356 | Val Acc: 78.76%
2026-01-14 13:30:36,456 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-01-14 13:30:36,457 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-01-14 13:30:36,461 - INFO - --------------------------------------------------
2026-01-14 13:30:36,465 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:30:46,991 - INFO - [Train] [52/90] | Loss: 0.3643 | Train Acc: 89.29%
2026-01-14 13:30:49,548 - INFO - [Valid] [52/90] | Loss: 0.5169 | Val Acc: 79.06%
2026-01-14 13:30:49,567 - INFO - [Metrics for 'abnormal'] | Precision: 0.7529 | Recall: 0.8153 | F1: 0.7829
2026-01-14 13:30:49,567 - INFO - [Metrics for 'normal'] | Precision: 0.8284 | Recall: 0.7692 | F1: 0.7977
2026-01-14 13:30:49,573 - INFO - --------------------------------------------------
2026-01-14 13:30:49,579 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:30:59,206 - INFO - [Train] [53/90] | Loss: 0.3536 | Train Acc: 91.07%
2026-01-14 13:31:02,803 - INFO - [Valid] [53/90] | Loss: 0.5676 | Val Acc: 77.88%
2026-01-14 13:31:02,815 - INFO - [Metrics for 'abnormal'] | Precision: 0.7440 | Recall: 0.7962 | F1: 0.7692
2026-01-14 13:31:02,816 - INFO - [Metrics for 'normal'] | Precision: 0.8129 | Recall: 0.7637 | F1: 0.7875
2026-01-14 13:31:02,820 - INFO - --------------------------------------------------
2026-01-14 13:31:02,823 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:31:13,124 - INFO - [Train] [54/90] | Loss: 0.3611 | Train Acc: 90.77%
2026-01-14 13:31:15,517 - INFO - [Valid] [54/90] | Loss: 0.5591 | Val Acc: 76.70%
2026-01-14 13:31:15,539 - INFO - [Metrics for 'abnormal'] | Precision: 0.7120 | Recall: 0.8344 | F1: 0.7683
2026-01-14 13:31:15,542 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7088 | F1: 0.7656
2026-01-14 13:31:15,552 - INFO - --------------------------------------------------
2026-01-14 13:31:15,559 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:31:24,930 - INFO - [Train] [55/90] | Loss: 0.3502 | Train Acc: 91.74%
2026-01-14 13:31:27,426 - INFO - [Valid] [55/90] | Loss: 0.5532 | Val Acc: 77.88%
2026-01-14 13:31:27,437 - INFO - [Metrics for 'abnormal'] | Precision: 0.7929 | Recall: 0.7070 | F1: 0.7475
2026-01-14 13:31:27,438 - INFO - [Metrics for 'normal'] | Precision: 0.7688 | Recall: 0.8407 | F1: 0.8031
2026-01-14 13:31:27,442 - INFO - --------------------------------------------------
2026-01-14 13:31:27,444 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:31:36,122 - INFO - [Train] [56/90] | Loss: 0.3367 | Train Acc: 92.19%
2026-01-14 13:31:38,782 - INFO - [Valid] [56/90] | Loss: 0.5445 | Val Acc: 78.47%
2026-01-14 13:31:38,796 - INFO - [Metrics for 'abnormal'] | Precision: 0.7360 | Recall: 0.8344 | F1: 0.7821
2026-01-14 13:31:38,797 - INFO - [Metrics for 'normal'] | Precision: 0.8385 | Recall: 0.7418 | F1: 0.7872
2026-01-14 13:31:38,800 - INFO - --------------------------------------------------
2026-01-14 13:31:38,803 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:31:49,149 - INFO - [Train] [57/90] | Loss: 0.3456 | Train Acc: 91.22%
2026-01-14 13:31:51,801 - INFO - [Valid] [57/90] | Loss: 0.5641 | Val Acc: 78.76%
2026-01-14 13:31:51,810 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-01-14 13:31:51,811 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-01-14 13:31:51,814 - INFO - --------------------------------------------------
2026-01-14 13:31:51,817 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:32:02,735 - INFO - [Train] [58/90] | Loss: 0.3435 | Train Acc: 92.41%
2026-01-14 13:32:05,432 - INFO - [Valid] [58/90] | Loss: 0.5469 | Val Acc: 79.94%
2026-01-14 13:32:05,445 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-01-14 13:32:05,445 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-01-14 13:32:05,449 - INFO - --------------------------------------------------
2026-01-14 13:32:05,453 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:32:16,298 - INFO - [Train] [59/90] | Loss: 0.3351 | Train Acc: 92.71%
2026-01-14 13:32:18,996 - INFO - [Valid] [59/90] | Loss: 0.5530 | Val Acc: 78.47%
2026-01-14 13:32:19,025 - INFO - [Metrics for 'abnormal'] | Precision: 0.7593 | Recall: 0.7834 | F1: 0.7712
2026-01-14 13:32:19,025 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.7857 | F1: 0.7967
2026-01-14 13:32:19,036 - INFO - --------------------------------------------------
2026-01-14 13:32:19,039 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:32:29,163 - INFO - [Train] [60/90] | Loss: 0.3339 | Train Acc: 92.19%
2026-01-14 13:32:31,839 - INFO - [Valid] [60/90] | Loss: 0.5436 | Val Acc: 78.47%
2026-01-14 13:32:31,852 - INFO - [Metrics for 'abnormal'] | Precision: 0.7763 | Recall: 0.7516 | F1: 0.7638
2026-01-14 13:32:31,852 - INFO - [Metrics for 'normal'] | Precision: 0.7914 | Recall: 0.8132 | F1: 0.8022
2026-01-14 13:32:31,857 - INFO - --------------------------------------------------
2026-01-14 13:32:31,860 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:32:41,690 - INFO - [Train] [61/90] | Loss: 0.3452 | Train Acc: 91.37%
2026-01-14 13:32:44,910 - INFO - [Valid] [61/90] | Loss: 0.5446 | Val Acc: 79.06%
2026-01-14 13:32:44,922 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 13:32:44,922 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 13:32:44,929 - INFO - --------------------------------------------------
2026-01-14 13:32:44,932 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:32:53,484 - INFO - [Train] [62/90] | Loss: 0.3295 | Train Acc: 92.71%
2026-01-14 13:32:55,824 - INFO - [Valid] [62/90] | Loss: 0.5594 | Val Acc: 80.53%
2026-01-14 13:32:55,835 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-01-14 13:32:55,835 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-01-14 13:32:55,840 - INFO - --------------------------------------------------
2026-01-14 13:32:55,844 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:33:05,077 - INFO - [Train] [63/90] | Loss: 0.3333 | Train Acc: 92.34%
2026-01-14 13:33:08,161 - INFO - [Valid] [63/90] | Loss: 0.5781 | Val Acc: 77.58%
2026-01-14 13:33:08,173 - INFO - [Metrics for 'abnormal'] | Precision: 0.7613 | Recall: 0.7516 | F1: 0.7564
2026-01-14 13:33:08,174 - INFO - [Metrics for 'normal'] | Precision: 0.7880 | Recall: 0.7967 | F1: 0.7923
2026-01-14 13:33:08,179 - INFO - --------------------------------------------------
2026-01-14 13:33:08,183 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:33:17,945 - INFO - [Train] [64/90] | Loss: 0.3194 | Train Acc: 93.60%
2026-01-14 13:33:20,273 - INFO - [Valid] [64/90] | Loss: 0.5749 | Val Acc: 78.47%
2026-01-14 13:33:20,288 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:33:20,293 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:33:20,297 - INFO - --------------------------------------------------
2026-01-14 13:33:20,303 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:33:29,555 - INFO - [Train] [65/90] | Loss: 0.3203 | Train Acc: 93.30%
2026-01-14 13:33:32,417 - INFO - [Valid] [65/90] | Loss: 0.5665 | Val Acc: 78.47%
2026-01-14 13:33:32,430 - INFO - [Metrics for 'abnormal'] | Precision: 0.7593 | Recall: 0.7834 | F1: 0.7712
2026-01-14 13:33:32,430 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.7857 | F1: 0.7967
2026-01-14 13:33:32,436 - INFO - --------------------------------------------------
2026-01-14 13:33:32,441 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:33:42,270 - INFO - [Train] [66/90] | Loss: 0.3312 | Train Acc: 92.26%
2026-01-14 13:33:45,389 - INFO - [Valid] [66/90] | Loss: 0.5550 | Val Acc: 78.76%
2026-01-14 13:33:45,401 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.7452 | F1: 0.7647
2026-01-14 13:33:45,401 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.8242 | F1: 0.8065
2026-01-14 13:33:45,406 - INFO - --------------------------------------------------
2026-01-14 13:33:45,410 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:33:52,944 - INFO - [Train] [67/90] | Loss: 0.3250 | Train Acc: 92.11%
2026-01-14 13:33:55,414 - INFO - [Valid] [67/90] | Loss: 0.5567 | Val Acc: 79.35%
2026-01-14 13:33:55,431 - INFO - [Metrics for 'abnormal'] | Precision: 0.7806 | Recall: 0.7707 | F1: 0.7756
2026-01-14 13:33:55,436 - INFO - [Metrics for 'normal'] | Precision: 0.8043 | Recall: 0.8132 | F1: 0.8087
2026-01-14 13:33:55,440 - INFO - --------------------------------------------------
2026-01-14 13:33:55,444 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:34:06,541 - INFO - [Train] [68/90] | Loss: 0.3199 | Train Acc: 93.23%
2026-01-14 13:34:08,836 - INFO - [Valid] [68/90] | Loss: 0.5634 | Val Acc: 78.76%
2026-01-14 13:34:08,855 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.7452 | F1: 0.7647
2026-01-14 13:34:08,855 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.8242 | F1: 0.8065
2026-01-14 13:34:08,859 - INFO - --------------------------------------------------
2026-01-14 13:34:08,862 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:34:16,808 - INFO - [Train] [69/90] | Loss: 0.3155 | Train Acc: 93.38%
2026-01-14 13:34:19,048 - INFO - [Valid] [69/90] | Loss: 0.5525 | Val Acc: 79.06%
2026-01-14 13:34:19,074 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-01-14 13:34:19,074 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-01-14 13:34:19,077 - INFO - --------------------------------------------------
2026-01-14 13:34:19,082 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:34:27,279 - INFO - [Train] [70/90] | Loss: 0.3308 | Train Acc: 92.04%
2026-01-14 13:34:29,452 - INFO - [Valid] [70/90] | Loss: 0.5663 | Val Acc: 79.06%
2026-01-14 13:34:29,464 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-01-14 13:34:29,465 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-01-14 13:34:29,470 - INFO - --------------------------------------------------
2026-01-14 13:34:29,473 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:34:37,289 - INFO - [Train] [71/90] | Loss: 0.3268 | Train Acc: 93.23%
2026-01-14 13:34:39,508 - INFO - [Valid] [71/90] | Loss: 0.5670 | Val Acc: 79.06%
2026-01-14 13:34:39,521 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-01-14 13:34:39,522 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-01-14 13:34:39,527 - INFO - --------------------------------------------------
2026-01-14 13:34:39,532 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:34:47,508 - INFO - [Train] [72/90] | Loss: 0.3232 | Train Acc: 92.11%
2026-01-14 13:34:49,792 - INFO - [Valid] [72/90] | Loss: 0.5590 | Val Acc: 80.24%
2026-01-14 13:34:49,803 - INFO - [Metrics for 'abnormal'] | Precision: 0.8041 | Recall: 0.7580 | F1: 0.7803
2026-01-14 13:34:49,804 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8407 | F1: 0.8204
2026-01-14 13:34:49,808 - INFO - --------------------------------------------------
2026-01-14 13:34:49,813 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:34:57,002 - INFO - [Train] [73/90] | Loss: 0.3080 | Train Acc: 93.30%
2026-01-14 13:34:58,789 - INFO - [Valid] [73/90] | Loss: 0.5721 | Val Acc: 79.35%
2026-01-14 13:34:58,798 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:34:58,798 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:34:58,802 - INFO - --------------------------------------------------
2026-01-14 13:34:58,804 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:35:06,282 - INFO - [Train] [74/90] | Loss: 0.3135 | Train Acc: 94.27%
2026-01-14 13:35:09,687 - INFO - [Valid] [74/90] | Loss: 0.5580 | Val Acc: 79.35%
2026-01-14 13:35:09,704 - INFO - [Metrics for 'abnormal'] | Precision: 0.7843 | Recall: 0.7643 | F1: 0.7742
2026-01-14 13:35:09,705 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.8187 | F1: 0.8098
2026-01-14 13:35:09,709 - INFO - --------------------------------------------------
2026-01-14 13:35:09,713 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:35:18,017 - INFO - [Train] [75/90] | Loss: 0.3272 | Train Acc: 92.78%
2026-01-14 13:35:19,652 - INFO - [Valid] [75/90] | Loss: 0.5617 | Val Acc: 79.35%
2026-01-14 13:35:19,666 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-01-14 13:35:19,666 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-01-14 13:35:19,670 - INFO - --------------------------------------------------
2026-01-14 13:35:19,674 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:35:26,735 - INFO - [Train] [76/90] | Loss: 0.3040 | Train Acc: 94.42%
2026-01-14 13:35:28,798 - INFO - [Valid] [76/90] | Loss: 0.5733 | Val Acc: 77.88%
2026-01-14 13:35:28,811 - INFO - [Metrics for 'abnormal'] | Precision: 0.7531 | Recall: 0.7771 | F1: 0.7649
2026-01-14 13:35:28,812 - INFO - [Metrics for 'normal'] | Precision: 0.8023 | Recall: 0.7802 | F1: 0.7911
2026-01-14 13:35:28,817 - INFO - --------------------------------------------------
2026-01-14 13:35:28,820 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:35:34,140 - INFO - [Train] [77/90] | Loss: 0.3084 | Train Acc: 93.97%
2026-01-14 13:35:35,680 - INFO - [Valid] [77/90] | Loss: 0.5895 | Val Acc: 78.76%
2026-01-14 13:35:35,691 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-01-14 13:35:35,691 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-01-14 13:35:35,695 - INFO - --------------------------------------------------
2026-01-14 13:35:35,697 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:35:40,948 - INFO - [Train] [78/90] | Loss: 0.3104 | Train Acc: 93.60%
2026-01-14 13:35:42,446 - INFO - [Valid] [78/90] | Loss: 0.5739 | Val Acc: 79.06%
2026-01-14 13:35:42,456 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-01-14 13:35:42,456 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-01-14 13:35:42,459 - INFO - --------------------------------------------------
2026-01-14 13:35:42,461 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:35:47,892 - INFO - [Train] [79/90] | Loss: 0.3151 | Train Acc: 93.38%
2026-01-14 13:35:49,328 - INFO - [Valid] [79/90] | Loss: 0.5570 | Val Acc: 79.35%
2026-01-14 13:35:49,338 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:35:49,339 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:35:49,344 - INFO - --------------------------------------------------
2026-01-14 13:35:49,347 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:35:54,793 - INFO - [Train] [80/90] | Loss: 0.3106 | Train Acc: 93.38%
2026-01-14 13:35:56,281 - INFO - [Valid] [80/90] | Loss: 0.5694 | Val Acc: 78.47%
2026-01-14 13:35:56,293 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:35:56,293 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:35:56,296 - INFO - --------------------------------------------------
2026-01-14 13:35:56,299 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:36:01,579 - INFO - [Train] [81/90] | Loss: 0.3116 | Train Acc: 93.82%
2026-01-14 13:36:03,066 - INFO - [Valid] [81/90] | Loss: 0.5643 | Val Acc: 77.88%
2026-01-14 13:36:03,075 - INFO - [Metrics for 'abnormal'] | Precision: 0.7562 | Recall: 0.7707 | F1: 0.7634
2026-01-14 13:36:03,075 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.7857 | F1: 0.7922
2026-01-14 13:36:03,078 - INFO - --------------------------------------------------
2026-01-14 13:36:03,081 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:36:09,304 - INFO - [Train] [82/90] | Loss: 0.3057 | Train Acc: 94.20%
2026-01-14 13:36:11,224 - INFO - [Valid] [82/90] | Loss: 0.5590 | Val Acc: 78.47%
2026-01-14 13:36:11,241 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:36:11,243 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:36:11,249 - INFO - --------------------------------------------------
2026-01-14 13:36:11,254 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:36:16,191 - INFO - [Train] [83/90] | Loss: 0.3050 | Train Acc: 93.68%
2026-01-14 13:36:17,530 - INFO - [Valid] [83/90] | Loss: 0.5880 | Val Acc: 78.17%
2026-01-14 13:36:17,539 - INFO - [Metrics for 'abnormal'] | Precision: 0.7902 | Recall: 0.7197 | F1: 0.7533
2026-01-14 13:36:17,540 - INFO - [Metrics for 'normal'] | Precision: 0.7755 | Recall: 0.8352 | F1: 0.8042
2026-01-14 13:36:17,543 - INFO - --------------------------------------------------
2026-01-14 13:36:17,545 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:36:22,393 - INFO - [Train] [84/90] | Loss: 0.3027 | Train Acc: 93.97%
2026-01-14 13:36:23,715 - INFO - [Valid] [84/90] | Loss: 0.5930 | Val Acc: 77.29%
2026-01-14 13:36:23,724 - INFO - [Metrics for 'abnormal'] | Precision: 0.7632 | Recall: 0.7389 | F1: 0.7508
2026-01-14 13:36:23,724 - INFO - [Metrics for 'normal'] | Precision: 0.7807 | Recall: 0.8022 | F1: 0.7913
2026-01-14 13:36:23,727 - INFO - --------------------------------------------------
2026-01-14 13:36:23,729 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:36:28,599 - INFO - [Train] [85/90] | Loss: 0.3048 | Train Acc: 94.27%
2026-01-14 13:36:29,917 - INFO - [Valid] [85/90] | Loss: 0.5727 | Val Acc: 78.47%
2026-01-14 13:36:29,926 - INFO - [Metrics for 'abnormal'] | Precision: 0.7593 | Recall: 0.7834 | F1: 0.7712
2026-01-14 13:36:29,926 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.7857 | F1: 0.7967
2026-01-14 13:36:29,929 - INFO - --------------------------------------------------
2026-01-14 13:36:29,931 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:36:34,294 - INFO - [Train] [86/90] | Loss: 0.3002 | Train Acc: 93.97%
2026-01-14 13:36:35,579 - INFO - [Valid] [86/90] | Loss: 0.5857 | Val Acc: 78.17%
2026-01-14 13:36:35,588 - INFO - [Metrics for 'abnormal'] | Precision: 0.7712 | Recall: 0.7516 | F1: 0.7613
2026-01-14 13:36:35,588 - INFO - [Metrics for 'normal'] | Precision: 0.7903 | Recall: 0.8077 | F1: 0.7989
2026-01-14 13:36:35,591 - INFO - --------------------------------------------------
2026-01-14 13:36:35,593 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:36:39,866 - INFO - [Train] [87/90] | Loss: 0.3088 | Train Acc: 93.01%
2026-01-14 13:36:41,143 - INFO - [Valid] [87/90] | Loss: 0.5777 | Val Acc: 79.06%
2026-01-14 13:36:41,155 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-01-14 13:36:41,156 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-01-14 13:36:41,160 - INFO - --------------------------------------------------
2026-01-14 13:36:41,163 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:36:45,509 - INFO - [Train] [88/90] | Loss: 0.3169 | Train Acc: 93.82%
2026-01-14 13:36:46,766 - INFO - [Valid] [88/90] | Loss: 0.5754 | Val Acc: 79.35%
2026-01-14 13:36:46,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.7580 | F1: 0.7727
2026-01-14 13:36:46,774 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8242 | F1: 0.8108
2026-01-14 13:36:46,777 - INFO - --------------------------------------------------
2026-01-14 13:36:46,780 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:36:51,148 - INFO - [Train] [89/90] | Loss: 0.3049 | Train Acc: 93.90%
2026-01-14 13:36:52,337 - INFO - [Valid] [89/90] | Loss: 0.5797 | Val Acc: 78.47%
2026-01-14 13:36:52,345 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7134 | F1: 0.7542
2026-01-14 13:36:52,346 - INFO - [Metrics for 'normal'] | Precision: 0.7739 | Recall: 0.8462 | F1: 0.8084
2026-01-14 13:36:52,348 - INFO - --------------------------------------------------
2026-01-14 13:36:52,350 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:36:57,036 - INFO - [Train] [90/90] | Loss: 0.3129 | Train Acc: 93.60%
2026-01-14 13:36:58,296 - INFO - [Valid] [90/90] | Loss: 0.5790 | Val Acc: 78.76%
2026-01-14 13:36:58,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-01-14 13:36:58,304 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-01-14 13:36:58,308 - INFO - ==================================================
2026-01-14 13:36:58,308 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:36:58,308 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:36:58,308 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:36:58,363 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:36:58,381 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:36:58,383 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:36:58,383 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:36:58,384 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:36:59,247 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:36:59,248 - INFO - ==================================================
2026-01-14 13:36:59,315 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/best_model.pth'
2026-01-14 13:36:59,316 - INFO - ==================================================
2026-01-14 13:36:59,316 - INFO - Test 모드를 시작합니다.
2026-01-14 13:36:59,421 - INFO - 연산량 (MACs): 0.0085 GMACs per sample
2026-01-14 13:36:59,421 - INFO - 연산량 (FLOPs): 0.0171 GFLOPs per sample
2026-01-14 13:36:59,421 - INFO - ==================================================
2026-01-14 13:36:59,422 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:37:00,708 - INFO - 샘플 당 평균 Forward Pass 시간: 7.62ms (std: 0.67ms), FPS: 132.17 (std: 10.59) (1개 샘플 x 100회 반복)
2026-01-14 13:37:00,708 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 38.17 MB
2026-01-14 13:37:00,708 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:37:02,779 - INFO - [Test] Loss: 0.4506 | Test Acc: 78.76%
2026-01-14 13:37:02,789 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-01-14 13:37:02,789 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-01-14 13:37:03,273 - INFO - ==================================================
2026-01-14 13:37:03,273 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/confusion_matrix_20260114_131821.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/confusion_matrix_20260114_131821.pdf'
2026-01-14 13:37:03,274 - INFO - ==================================================
2026-01-14 13:37:03,274 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:37:04,557 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/model_fp32_20260114_131821.onnx'에 저장되었습니다. (크기: 0.34 MB)
2026-01-14 13:37:05,038 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2489.46 MB (증가량: 8.01 MB)
2026-01-14 13:37:05,038 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:37:06,351 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 9.90ms (std: 4.58ms)
2026-01-14 13:37:06,351 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 109.98 FPS (std: 22.35) (1개 샘플 x 100회 반복)
2026-01-14 13:37:06,351 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2498.52 MB (순수 증가량: 9.06 MB)
2026-01-14 13:37:06,352 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2498.52 MB (전체 증가량: 17.07 MB)
2026-01-14 13:37:09,059 - INFO - [Test (ONNX)] | Test Acc (ONNX): 78.76%
2026-01-14 13:37:09,070 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-01-14 13:37:09,071 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-01-14 13:37:09,631 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/val_acc.pdf'
2026-01-14 13:37:10,201 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/train_val_acc.pdf'
2026-01-14 13:37:10,602 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/F1_normal.pdf'
2026-01-14 13:37:11,065 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/val_loss.pdf'
2026-01-14 13:37:11,570 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/learning_rate.pdf'
2026-01-14 13:37:15,522 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_l1_20260114_131821/graph_20260114_131821/compile.pdf'
