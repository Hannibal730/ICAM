2026-01-14 13:18:06,173 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/log_20260114_131806.log'에 저장됩니다.
2026-01-14 13:18:06,182 - INFO - ==================================================
2026-01-14 13:18:06,183 - INFO - config.yaml:
2026-01-14 13:18:06,183 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: deit_tiny
  use_l1_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:18:06,183 - INFO - ==================================================
2026-01-14 13:18:06,256 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:18:06,258 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:18:06,258 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:18:06,274 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:18:06,275 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:18:06,276 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:18:06,276 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:18:12,462 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:18:12,466 - INFO - ==================================================
2026-01-14 13:18:12,467 - INFO - 모델 파라미터 수:
2026-01-14 13:18:12,467 - INFO -   - 총 파라미터: 5,524,802 개
2026-01-14 13:18:12,468 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-01-14 13:18:12,468 - INFO - ================================================================================
2026-01-14 13:18:12,469 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:18:12,469 - INFO - ================================================================================
2026-01-14 13:18:12,469 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:18:12,471 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:18:12,472 - INFO - ==================================================
2026-01-14 13:18:12,472 - INFO - train 모드를 시작합니다.
2026-01-14 13:18:12,473 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:18:12,473 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:18:12,474 - INFO - --------------------------------------------------
2026-01-14 13:18:12,476 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:18:21,127 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-01-14 13:18:24,376 - INFO - [Valid] [1/10] | Loss: 0.6723 | Val Acc: 59.88%
2026-01-14 13:18:24,401 - INFO - [Metrics for 'abnormal'] | Precision: 0.5484 | Recall: 0.7580 | F1: 0.6364
2026-01-14 13:18:24,402 - INFO - [Metrics for 'normal'] | Precision: 0.6885 | Recall: 0.4615 | F1: 0.5526
2026-01-14 13:18:24,477 - INFO - [Best Model Saved] (val loss: 0.6723) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:18:24,478 - INFO - --------------------------------------------------
2026-01-14 13:18:24,480 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:18:32,562 - INFO - [Train] [2/10] | Loss: 0.6457 | Train Acc: 65.25%
2026-01-14 13:18:34,421 - INFO - [Valid] [2/10] | Loss: 0.6477 | Val Acc: 63.42%
2026-01-14 13:18:34,434 - INFO - [Metrics for 'abnormal'] | Precision: 0.7260 | Recall: 0.3376 | F1: 0.4609
2026-01-14 13:18:34,435 - INFO - [Metrics for 'normal'] | Precision: 0.6090 | Recall: 0.8901 | F1: 0.7232
2026-01-14 13:18:34,510 - INFO - [Best Model Saved] (val loss: 0.6477) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:18:34,510 - INFO - --------------------------------------------------
2026-01-14 13:18:34,512 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:18:43,135 - INFO - [Train] [3/10] | Loss: 0.5943 | Train Acc: 69.35%
2026-01-14 13:18:44,998 - INFO - [Valid] [3/10] | Loss: 0.5771 | Val Acc: 74.34%
2026-01-14 13:18:45,011 - INFO - [Metrics for 'abnormal'] | Precision: 0.7083 | Recall: 0.7580 | F1: 0.7323
2026-01-14 13:18:45,011 - INFO - [Metrics for 'normal'] | Precision: 0.7778 | Recall: 0.7308 | F1: 0.7535
2026-01-14 13:18:45,068 - INFO - [Best Model Saved] (val loss: 0.5771) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:18:45,069 - INFO - --------------------------------------------------
2026-01-14 13:18:45,071 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:18:52,956 - INFO - [Train] [4/10] | Loss: 0.5659 | Train Acc: 74.93%
2026-01-14 13:18:55,533 - INFO - [Valid] [4/10] | Loss: 0.5608 | Val Acc: 74.04%
2026-01-14 13:18:55,544 - INFO - [Metrics for 'abnormal'] | Precision: 0.6845 | Recall: 0.8153 | F1: 0.7442
2026-01-14 13:18:55,545 - INFO - [Metrics for 'normal'] | Precision: 0.8092 | Recall: 0.6758 | F1: 0.7365
2026-01-14 13:18:55,616 - INFO - [Best Model Saved] (val loss: 0.5608) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:18:55,616 - INFO - --------------------------------------------------
2026-01-14 13:18:55,618 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:19:02,642 - INFO - [Train] [5/10] | Loss: 0.5204 | Train Acc: 79.02%
2026-01-14 13:19:04,985 - INFO - [Valid] [5/10] | Loss: 0.6138 | Val Acc: 69.62%
2026-01-14 13:19:05,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.6174 | Recall: 0.9045 | F1: 0.7339
2026-01-14 13:19:05,015 - INFO - [Metrics for 'normal'] | Precision: 0.8624 | Recall: 0.5165 | F1: 0.6460
2026-01-14 13:19:05,021 - INFO - --------------------------------------------------
2026-01-14 13:19:05,026 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:19:11,880 - INFO - [Train] [6/10] | Loss: 0.5145 | Train Acc: 78.50%
2026-01-14 13:19:13,880 - INFO - [Valid] [6/10] | Loss: 0.5400 | Val Acc: 75.81%
2026-01-14 13:19:13,893 - INFO - [Metrics for 'abnormal'] | Precision: 0.7193 | Recall: 0.7834 | F1: 0.7500
2026-01-14 13:19:13,894 - INFO - [Metrics for 'normal'] | Precision: 0.7976 | Recall: 0.7363 | F1: 0.7657
2026-01-14 13:19:13,963 - INFO - [Best Model Saved] (val loss: 0.5400) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:19:13,963 - INFO - --------------------------------------------------
2026-01-14 13:19:13,966 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:19:21,028 - INFO - [Train] [7/10] | Loss: 0.4933 | Train Acc: 80.43%
2026-01-14 13:19:22,817 - INFO - [Valid] [7/10] | Loss: 0.5464 | Val Acc: 77.29%
2026-01-14 13:19:22,829 - INFO - [Metrics for 'abnormal'] | Precision: 0.7941 | Recall: 0.6879 | F1: 0.7372
2026-01-14 13:19:22,829 - INFO - [Metrics for 'normal'] | Precision: 0.7586 | Recall: 0.8462 | F1: 0.8000
2026-01-14 13:19:22,834 - INFO - --------------------------------------------------
2026-01-14 13:19:22,836 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:19:28,769 - INFO - [Train] [8/10] | Loss: 0.4861 | Train Acc: 81.25%
2026-01-14 13:19:30,571 - INFO - [Valid] [8/10] | Loss: 0.5383 | Val Acc: 76.11%
2026-01-14 13:19:30,582 - INFO - [Metrics for 'abnormal'] | Precision: 0.8276 | Recall: 0.6115 | F1: 0.7033
2026-01-14 13:19:30,583 - INFO - [Metrics for 'normal'] | Precision: 0.7265 | Recall: 0.8901 | F1: 0.8000
2026-01-14 13:19:30,636 - INFO - [Best Model Saved] (val loss: 0.5383) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:19:30,636 - INFO - --------------------------------------------------
2026-01-14 13:19:30,638 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:19:36,360 - INFO - [Train] [9/10] | Loss: 0.4887 | Train Acc: 80.51%
2026-01-14 13:19:38,332 - INFO - [Valid] [9/10] | Loss: 0.5392 | Val Acc: 77.58%
2026-01-14 13:19:38,345 - INFO - [Metrics for 'abnormal'] | Precision: 0.8240 | Recall: 0.6561 | F1: 0.7305
2026-01-14 13:19:38,346 - INFO - [Metrics for 'normal'] | Precision: 0.7477 | Recall: 0.8791 | F1: 0.8081
2026-01-14 13:19:38,351 - INFO - --------------------------------------------------
2026-01-14 13:19:38,353 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:19:44,457 - INFO - [Train] [10/10] | Loss: 0.4772 | Train Acc: 81.70%
2026-01-14 13:19:46,344 - INFO - [Valid] [10/10] | Loss: 0.5342 | Val Acc: 75.81%
2026-01-14 13:19:46,353 - INFO - [Metrics for 'abnormal'] | Precision: 0.7551 | Recall: 0.7070 | F1: 0.7303
2026-01-14 13:19:46,353 - INFO - [Metrics for 'normal'] | Precision: 0.7604 | Recall: 0.8022 | F1: 0.7807
2026-01-14 13:19:46,400 - INFO - [Best Model Saved] (val loss: 0.5342) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:19:46,401 - INFO - ================================================================================
2026-01-14 13:19:46,402 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:19:46,402 - INFO - ================================================================================
2026-01-14 13:19:46,451 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:19:46,451 - INFO - ================================================================================
2026-01-14 13:19:46,451 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:19:46,452 - INFO - 원본 모델 파라미터: 5.5248M
2026-01-14 13:19:46,500 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:46,501 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:46,501 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:47,040 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:19:47,041 - INFO - ==================================================
2026-01-14 13:19:47,042 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.8881M (감소율: 65.83%)
2026-01-14 13:19:47,078 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:47,078 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:47,079 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:47,612 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:47,613 - INFO - ==================================================
2026-01-14 13:19:47,615 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.7436M (감소율: 86.54%)
2026-01-14 13:19:47,653 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:47,654 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:47,655 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:48,219 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:19:48,220 - INFO - ==================================================
2026-01-14 13:19:48,221 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.3258M (감소율: 94.10%)
2026-01-14 13:19:48,677 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:48,678 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:48,680 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:49,243 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:19:49,244 - INFO - ==================================================
2026-01-14 13:19:49,246 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.1581M (감소율: 97.14%)
2026-01-14 13:19:49,284 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:49,285 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:49,286 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:50,048 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:50,049 - INFO - ==================================================
2026-01-14 13:19:50,053 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0843M (감소율: 98.47%)
2026-01-14 13:19:50,127 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:50,127 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:50,128 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:50,870 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97453125)에 맞춰 변경되었습니다.
2026-01-14 13:19:50,871 - INFO - ==================================================
2026-01-14 13:19:50,874 - INFO -   [탐색  6] 희소도: 0.9745 -> 파라미터: 0.0500M (감소율: 99.09%)
2026-01-14 13:19:50,910 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:50,911 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:50,912 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:51,516 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9822656249999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:51,517 - INFO - ==================================================
2026-01-14 13:19:51,519 - INFO -   [탐색  7] 희소도: 0.9823 -> 파라미터: 0.0388M (감소율: 99.30%)
2026-01-14 13:19:51,549 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:51,550 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:51,550 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:52,364 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9861328125)에 맞춰 변경되었습니다.
2026-01-14 13:19:52,364 - INFO - ==================================================
2026-01-14 13:19:52,366 - INFO -   [탐색  8] 희소도: 0.9861 -> 파라미터: 0.0280M (감소율: 99.49%)
2026-01-14 13:19:52,391 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:52,391 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:52,392 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:53,023 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9841992187499999)에 맞춰 변경되었습니다.
2026-01-14 13:19:53,024 - INFO - ==================================================
2026-01-14 13:19:53,026 - INFO -   [탐색  9] 희소도: 0.9842 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:19:53,056 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:53,057 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:53,058 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:53,580 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 13:19:53,581 - INFO - ==================================================
2026-01-14 13:19:53,583 - INFO -   [탐색 10] 희소도: 0.9852 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:19:53,612 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:53,612 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:53,613 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:54,084 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9846826171874999)에 맞춰 변경되었습니다.
2026-01-14 13:19:54,085 - INFO - ==================================================
2026-01-14 13:19:54,086 - INFO -   [탐색 11] 희소도: 0.9847 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:19:54,110 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:54,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:54,111 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:54,569 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9844409179687499)에 맞춰 변경되었습니다.
2026-01-14 13:19:54,569 - INFO - ==================================================
2026-01-14 13:19:54,571 - INFO -   [탐색 12] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:19:54,606 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:54,606 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:54,607 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:56,261 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843200683593749)에 맞춰 변경되었습니다.
2026-01-14 13:19:56,261 - INFO - ==================================================
2026-01-14 13:19:56,268 - INFO -   [탐색 13] 희소도: 0.9843 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:19:56,315 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:56,315 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:56,316 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:56,860 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843804931640624)에 맞춰 변경되었습니다.
2026-01-14 13:19:56,861 - INFO - ==================================================
2026-01-14 13:19:56,863 - INFO -   [탐색 14] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:19:56,907 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:56,908 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:56,908 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:57,662 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843502807617186)에 맞춰 변경되었습니다.
2026-01-14 13:19:57,663 - INFO - ==================================================
2026-01-14 13:19:57,665 - INFO -   [탐색 15] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:19:57,698 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:57,699 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:57,700 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:58,461 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843653869628906)에 맞춰 변경되었습니다.
2026-01-14 13:19:58,461 - INFO - ==================================================
2026-01-14 13:19:58,463 - INFO -   [탐색 16] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:19:58,496 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:58,497 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:58,498 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:59,058 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843729400634764)에 맞춰 변경되었습니다.
2026-01-14 13:19:59,059 - INFO - ==================================================
2026-01-14 13:19:59,060 - INFO -   [탐색 17] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:19:59,085 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:59,085 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:59,086 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:19:59,900 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843767166137694)에 맞춰 변경되었습니다.
2026-01-14 13:19:59,900 - INFO - ==================================================
2026-01-14 13:19:59,902 - INFO -   [탐색 18] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:19:59,927 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:59,927 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:59,928 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:00,517 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843748283386229)에 맞춰 변경되었습니다.
2026-01-14 13:20:00,517 - INFO - ==================================================
2026-01-14 13:20:00,519 - INFO -   [탐색 19] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:00,556 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:00,557 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:00,558 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:01,173 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843757724761961)에 맞춰 변경되었습니다.
2026-01-14 13:20:01,174 - INFO - ==================================================
2026-01-14 13:20:01,176 - INFO -   [탐색 20] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:01,205 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:01,206 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:01,207 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:01,796 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843753004074095)에 맞춰 변경되었습니다.
2026-01-14 13:20:01,796 - INFO - ==================================================
2026-01-14 13:20:01,801 - INFO -   [탐색 21] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:01,826 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:01,826 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:01,827 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:02,319 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750643730163)에 맞춰 변경되었습니다.
2026-01-14 13:20:02,319 - INFO - ==================================================
2026-01-14 13:20:02,321 - INFO -   [탐색 22] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:02,354 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:02,355 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:02,356 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:03,219 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749463558196)에 맞춰 변경되었습니다.
2026-01-14 13:20:03,220 - INFO - ==================================================
2026-01-14 13:20:03,223 - INFO -   [탐색 23] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:03,257 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:03,257 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:03,258 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:03,816 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750053644179)에 맞춰 변경되었습니다.
2026-01-14 13:20:03,817 - INFO - ==================================================
2026-01-14 13:20:03,819 - INFO -   [탐색 24] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:03,851 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:03,852 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:03,853 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,374 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749758601188)에 맞춰 변경되었습니다.
2026-01-14 13:20:04,375 - INFO - ==================================================
2026-01-14 13:20:04,376 - INFO -   [탐색 25] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:04,402 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:04,402 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,403 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,892 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749906122683)에 맞춰 변경되었습니다.
2026-01-14 13:20:04,892 - INFO - ==================================================
2026-01-14 13:20:04,894 - INFO -   [탐색 26] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:04,930 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:04,931 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,932 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:05,423 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749979883432)에 맞춰 변경되었습니다.
2026-01-14 13:20:05,423 - INFO - ==================================================
2026-01-14 13:20:05,425 - INFO -   [탐색 27] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:05,464 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:05,465 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:05,466 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,198 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750016763806)에 맞춰 변경되었습니다.
2026-01-14 13:20:06,198 - INFO - ==================================================
2026-01-14 13:20:06,199 - INFO -   [탐색 28] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:06,219 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:06,219 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,219 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,618 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749998323619)에 맞춰 변경되었습니다.
2026-01-14 13:20:06,619 - INFO - ==================================================
2026-01-14 13:20:06,620 - INFO -   [탐색 29] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:06,646 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:06,646 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,647 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,033 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750007543712)에 맞춰 변경되었습니다.
2026-01-14 13:20:07,033 - INFO - ==================================================
2026-01-14 13:20:07,035 - INFO -   [탐색 30] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:07,061 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:07,062 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,063 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,578 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750002933666)에 맞춰 변경되었습니다.
2026-01-14 13:20:07,579 - INFO - ==================================================
2026-01-14 13:20:07,581 - INFO -   [탐색 31] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:07,613 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:07,613 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,614 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,344 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000628642)에 맞춰 변경되었습니다.
2026-01-14 13:20:08,344 - INFO - ==================================================
2026-01-14 13:20:08,346 - INFO -   [탐색 32] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:08,374 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:08,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,375 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,825 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984374999947613)에 맞춰 변경되었습니다.
2026-01-14 13:20:08,825 - INFO - ==================================================
2026-01-14 13:20:08,827 - INFO -   [탐색 33] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:08,859 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:08,860 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,860 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,402 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000052386)에 맞춰 변경되었습니다.
2026-01-14 13:20:09,402 - INFO - ==================================================
2026-01-14 13:20:09,404 - INFO -   [탐색 34] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:09,438 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:09,438 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,439 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,991 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999764257)에 맞춰 변경되었습니다.
2026-01-14 13:20:09,991 - INFO - ==================================================
2026-01-14 13:20:09,993 - INFO -   [탐색 35] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:10,025 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:10,026 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,027 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,545 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999908322)에 맞춰 변경되었습니다.
2026-01-14 13:20:10,546 - INFO - ==================================================
2026-01-14 13:20:10,548 - INFO -   [탐색 36] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:10,580 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:10,581 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,581 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,342 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999980353)에 맞춰 변경되었습니다.
2026-01-14 13:20:11,343 - INFO - ==================================================
2026-01-14 13:20:11,345 - INFO -   [탐색 37] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:11,369 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:11,370 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,371 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,050 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000016369)에 맞춰 변경되었습니다.
2026-01-14 13:20:12,051 - INFO - ==================================================
2026-01-14 13:20:12,053 - INFO -   [탐색 38] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:12,087 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:12,088 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,090 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,514 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999998361)에 맞춰 변경되었습니다.
2026-01-14 13:20:12,515 - INFO - ==================================================
2026-01-14 13:20:12,517 - INFO -   [탐색 39] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:12,552 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:12,553 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,554 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000007365)에 맞춰 변경되었습니다.
2026-01-14 13:20:13,046 - INFO - ==================================================
2026-01-14 13:20:13,047 - INFO -   [탐색 40] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:13,071 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:13,071 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,072 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,513 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000002863)에 맞춰 변경되었습니다.
2026-01-14 13:20:13,513 - INFO - ==================================================
2026-01-14 13:20:13,515 - INFO -   [탐색 41] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:13,539 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:13,539 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,540 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,289 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000613)에 맞춰 변경되었습니다.
2026-01-14 13:20:14,290 - INFO - ==================================================
2026-01-14 13:20:14,292 - INFO -   [탐색 42] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:14,318 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:14,319 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,320 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,728 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999487)에 맞춰 변경되었습니다.
2026-01-14 13:20:14,728 - INFO - ==================================================
2026-01-14 13:20:14,729 - INFO -   [탐색 43] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:14,750 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:14,750 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,751 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,165 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375000000005)에 맞춰 변경되었습니다.
2026-01-14 13:20:15,166 - INFO - ==================================================
2026-01-14 13:20:15,168 - INFO -   [탐색 44] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:15,202 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:15,204 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,205 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,653 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999769)에 맞춰 변경되었습니다.
2026-01-14 13:20:15,653 - INFO - ==================================================
2026-01-14 13:20:15,654 - INFO -   [탐색 45] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:15,681 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:15,682 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,683 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,128 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999909)에 맞춰 변경되었습니다.
2026-01-14 13:20:16,129 - INFO - ==================================================
2026-01-14 13:20:16,130 - INFO -   [탐색 46] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:16,166 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:16,167 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,168 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,907 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984374999999998)에 맞춰 변경되었습니다.
2026-01-14 13:20:16,908 - INFO - ==================================================
2026-01-14 13:20:16,909 - INFO -   [탐색 47] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:16,934 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:16,934 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,935 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,355 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000016)에 맞춰 변경되었습니다.
2026-01-14 13:20:17,356 - INFO - ==================================================
2026-01-14 13:20:17,358 - INFO -   [탐색 48] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:17,386 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:17,386 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,387 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,911 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999998)에 맞춰 변경되었습니다.
2026-01-14 13:20:17,911 - INFO - ==================================================
2026-01-14 13:20:17,913 - INFO -   [탐색 49] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:17,940 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:17,940 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,941 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,386 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000007)에 맞춰 변경되었습니다.
2026-01-14 13:20:18,386 - INFO - ==================================================
2026-01-14 13:20:18,388 - INFO -   [탐색 50] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:18,421 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:18,421 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,422 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,815 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000002)에 맞춰 변경되었습니다.
2026-01-14 13:20:18,815 - INFO - ==================================================
2026-01-14 13:20:18,817 - INFO -   [탐색 51] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:18,843 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:18,844 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,845 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:19,576 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:19,576 - INFO - ==================================================
2026-01-14 13:20:19,578 - INFO -   [탐색 52] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:19,609 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:19,610 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:19,611 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,079 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000001)에 맞춰 변경되었습니다.
2026-01-14 13:20:20,080 - INFO - ==================================================
2026-01-14 13:20:20,082 - INFO -   [탐색 53] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:20:20,113 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:20,113 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,114 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,512 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:20,513 - INFO - ==================================================
2026-01-14 13:20:20,515 - INFO -   [탐색 54] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:20,540 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:20,540 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,541 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,076 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:21,076 - INFO - ==================================================
2026-01-14 13:20:21,078 - INFO -   [탐색 55] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:21,111 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:21,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,112 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,623 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:21,623 - INFO - ==================================================
2026-01-14 13:20:21,624 - INFO -   [탐색 56] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:21,645 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:21,645 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,646 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,253 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:22,253 - INFO - ==================================================
2026-01-14 13:20:22,255 - INFO -   [탐색 57] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:22,274 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:22,274 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,275 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:22,681 - INFO - ==================================================
2026-01-14 13:20:22,683 - INFO -   [탐색 58] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:22,708 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:22,708 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,709 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,057 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:23,057 - INFO - ==================================================
2026-01-14 13:20:23,059 - INFO -   [탐색 59] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:23,083 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:23,083 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,084 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,587 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:23,588 - INFO - ==================================================
2026-01-14 13:20:23,590 - INFO -   [탐색 60] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:23,617 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:23,618 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,619 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,264 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:24,264 - INFO - ==================================================
2026-01-14 13:20:24,266 - INFO -   [탐색 61] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:24,292 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:24,292 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,294 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,721 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:24,722 - INFO - ==================================================
2026-01-14 13:20:24,723 - INFO -   [탐색 62] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:24,755 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:24,756 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,757 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:25,237 - INFO - ==================================================
2026-01-14 13:20:25,238 - INFO -   [탐색 63] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:25,263 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:25,263 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,264 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:25,683 - INFO - ==================================================
2026-01-14 13:20:25,684 - INFO -   [탐색 64] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:25,709 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:25,710 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,711 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:26,189 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:26,189 - INFO - ==================================================
2026-01-14 13:20:26,191 - INFO -   [탐색 65] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:26,227 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:26,228 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:26,228 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:27,061 - INFO - ==================================================
2026-01-14 13:20:27,063 - INFO -   [탐색 66] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:27,096 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:27,097 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,097 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,624 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:27,624 - INFO - ==================================================
2026-01-14 13:20:27,626 - INFO -   [탐색 67] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:27,658 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:27,659 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,660 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,198 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:28,199 - INFO - ==================================================
2026-01-14 13:20:28,200 - INFO -   [탐색 68] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:28,232 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:28,232 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,233 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,765 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:28,765 - INFO - ==================================================
2026-01-14 13:20:28,768 - INFO -   [탐색 69] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:28,801 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:28,802 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,803 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:29,329 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:29,329 - INFO - ==================================================
2026-01-14 13:20:29,332 - INFO -   [탐색 70] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:29,368 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:29,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:29,371 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:30,272 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:30,273 - INFO - ==================================================
2026-01-14 13:20:30,275 - INFO -   [탐색 71] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:30,307 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:30,308 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:30,309 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:30,868 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:30,869 - INFO - ==================================================
2026-01-14 13:20:30,871 - INFO -   [탐색 72] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:30,900 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:30,901 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:30,902 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:31,461 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:31,462 - INFO - ==================================================
2026-01-14 13:20:31,464 - INFO -   [탐색 73] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:31,538 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:31,540 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:31,541 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:32,757 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:32,758 - INFO - ==================================================
2026-01-14 13:20:32,759 - INFO -   [탐색 74] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:32,794 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:32,794 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:32,795 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:33,357 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:33,358 - INFO - ==================================================
2026-01-14 13:20:33,360 - INFO -   [탐색 75] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:33,391 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:33,392 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:33,393 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,255 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:34,256 - INFO - ==================================================
2026-01-14 13:20:34,259 - INFO -   [탐색 76] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:34,297 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:34,297 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,298 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:34,950 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:34,950 - INFO - ==================================================
2026-01-14 13:20:34,954 - INFO -   [탐색 77] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:35,022 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:35,023 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:35,025 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:35,659 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:35,659 - INFO - ==================================================
2026-01-14 13:20:35,661 - INFO -   [탐색 78] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:35,697 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:35,698 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:35,699 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:36,238 - INFO - ==================================================
2026-01-14 13:20:36,240 - INFO -   [탐색 79] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:36,274 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:36,274 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,275 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,818 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:36,818 - INFO - ==================================================
2026-01-14 13:20:36,821 - INFO -   [탐색 80] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:36,855 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:36,855 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:36,856 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:37,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:37,750 - INFO - ==================================================
2026-01-14 13:20:37,752 - INFO -   [탐색 81] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:37,789 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:37,790 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:37,791 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:38,371 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:38,371 - INFO - ==================================================
2026-01-14 13:20:38,373 - INFO -   [탐색 82] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:38,409 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:38,410 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:38,411 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:38,976 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:38,977 - INFO - ==================================================
2026-01-14 13:20:38,978 - INFO -   [탐색 83] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:39,006 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:39,007 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:39,008 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:39,530 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:39,531 - INFO - ==================================================
2026-01-14 13:20:39,533 - INFO -   [탐색 84] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:39,566 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:39,567 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:39,568 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:40,117 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:40,118 - INFO - ==================================================
2026-01-14 13:20:40,119 - INFO -   [탐색 85] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:40,445 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:40,446 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:40,447 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:41,022 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:41,023 - INFO - ==================================================
2026-01-14 13:20:41,025 - INFO -   [탐색 86] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:41,072 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:41,073 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:41,074 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:41,604 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:41,605 - INFO - ==================================================
2026-01-14 13:20:41,607 - INFO -   [탐색 87] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:41,644 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:41,644 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:41,646 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,251 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:42,251 - INFO - ==================================================
2026-01-14 13:20:42,253 - INFO -   [탐색 88] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:42,289 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:42,290 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,290 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,898 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:42,898 - INFO - ==================================================
2026-01-14 13:20:42,900 - INFO -   [탐색 89] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:42,932 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:42,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:42,933 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:43,836 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:43,837 - INFO - ==================================================
2026-01-14 13:20:43,839 - INFO -   [탐색 90] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:43,863 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:43,863 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:43,864 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:44,395 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:44,396 - INFO - ==================================================
2026-01-14 13:20:44,399 - INFO -   [탐색 91] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:44,458 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:44,458 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:44,459 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:45,336 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:45,337 - INFO - ==================================================
2026-01-14 13:20:45,340 - INFO -   [탐색 92] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:45,372 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:45,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:45,375 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:46,181 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:46,182 - INFO - ==================================================
2026-01-14 13:20:46,183 - INFO -   [탐색 93] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:46,216 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:46,216 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:46,217 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:46,817 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:46,818 - INFO - ==================================================
2026-01-14 13:20:46,820 - INFO -   [탐색 94] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:46,853 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:46,854 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:46,855 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:47,695 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:47,696 - INFO - ==================================================
2026-01-14 13:20:47,698 - INFO -   [탐색 95] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:47,751 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:47,771 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:47,772 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:48,390 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:48,391 - INFO - ==================================================
2026-01-14 13:20:48,393 - INFO -   [탐색 96] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:48,447 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:48,448 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:48,450 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:49,095 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:49,096 - INFO - ==================================================
2026-01-14 13:20:49,098 - INFO -   [탐색 97] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:49,134 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:49,134 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:49,135 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:49,766 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:49,766 - INFO - ==================================================
2026-01-14 13:20:49,768 - INFO -   [탐색 98] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:49,805 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:49,806 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:49,807 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:50,429 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:50,430 - INFO - ==================================================
2026-01-14 13:20:50,432 - INFO -   [탐색 99] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:50,468 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:50,468 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:50,470 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:51,524 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:20:51,529 - INFO - ==================================================
2026-01-14 13:20:51,533 - INFO -   [탐색 100] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:20:51,533 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9852 입니다.
2026-01-14 13:20:51,534 - INFO - ================================================================================
2026-01-14 13:20:51,536 - INFO - 계산된 Pruning 정보(희소도: 0.9852)를 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:20:51,578 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:20:51,695 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:51,698 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:51,702 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:20:52,484 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 13:20:52,484 - INFO - ==================================================
2026-01-14 13:20:52,486 - INFO - ==================================================
2026-01-14 13:20:52,487 - INFO - 모델 파라미터 수:
2026-01-14 13:20:52,487 - INFO -   - 총 파라미터: 28,092 개
2026-01-14 13:20:52,487 - INFO -   - 학습 가능한 파라미터: 28,092 개
2026-01-14 13:20:52,532 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:20:52,639 - INFO - FLOPs가 2.1493 GFLOPs에서 0.0081 GFLOPs로 감소했습니다 (감소율: 99.62%).
2026-01-14 13:20:52,639 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:20:52,639 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:20:52,641 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:20:52,641 - INFO - ==================================================
2026-01-14 13:20:52,641 - INFO - train 모드를 시작합니다.
2026-01-14 13:20:52,641 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:20:52,641 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:20:52,641 - INFO - --------------------------------------------------
2026-01-14 13:20:52,643 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:21:00,915 - INFO - [Train] [11/90] | Loss: 0.6845 | Train Acc: 60.34%
2026-01-14 13:21:03,019 - INFO - [Valid] [11/90] | Loss: 0.6803 | Val Acc: 59.00%
2026-01-14 13:21:03,038 - INFO - [Metrics for 'abnormal'] | Precision: 0.5372 | Recall: 0.8280 | F1: 0.6516
2026-01-14 13:21:03,039 - INFO - [Metrics for 'normal'] | Precision: 0.7216 | Recall: 0.3846 | F1: 0.5018
2026-01-14 13:21:03,072 - INFO - [Best Model Saved] (val loss: 0.6803) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:21:03,073 - INFO - --------------------------------------------------
2026-01-14 13:21:03,075 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:21:10,831 - INFO - [Train] [12/90] | Loss: 0.6603 | Train Acc: 65.62%
2026-01-14 13:21:13,019 - INFO - [Valid] [12/90] | Loss: 0.6766 | Val Acc: 58.70%
2026-01-14 13:21:13,031 - INFO - [Metrics for 'abnormal'] | Precision: 0.5359 | Recall: 0.8089 | F1: 0.6447
2026-01-14 13:21:13,032 - INFO - [Metrics for 'normal'] | Precision: 0.7059 | Recall: 0.3956 | F1: 0.5070
2026-01-14 13:21:13,060 - INFO - [Best Model Saved] (val loss: 0.6766) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:21:13,061 - INFO - --------------------------------------------------
2026-01-14 13:21:13,064 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:21:20,720 - INFO - [Train] [13/90] | Loss: 0.6496 | Train Acc: 65.92%
2026-01-14 13:21:22,828 - INFO - [Valid] [13/90] | Loss: 0.6774 | Val Acc: 58.70%
2026-01-14 13:21:22,841 - INFO - [Metrics for 'abnormal'] | Precision: 0.5359 | Recall: 0.8089 | F1: 0.6447
2026-01-14 13:21:22,841 - INFO - [Metrics for 'normal'] | Precision: 0.7059 | Recall: 0.3956 | F1: 0.5070
2026-01-14 13:21:22,846 - INFO - --------------------------------------------------
2026-01-14 13:21:22,849 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:21:30,916 - INFO - [Train] [14/90] | Loss: 0.6439 | Train Acc: 66.37%
2026-01-14 13:21:32,830 - INFO - [Valid] [14/90] | Loss: 0.6790 | Val Acc: 58.41%
2026-01-14 13:21:32,841 - INFO - [Metrics for 'abnormal'] | Precision: 0.5336 | Recall: 0.8089 | F1: 0.6430
2026-01-14 13:21:32,841 - INFO - [Metrics for 'normal'] | Precision: 0.7030 | Recall: 0.3901 | F1: 0.5018
2026-01-14 13:21:32,846 - INFO - --------------------------------------------------
2026-01-14 13:21:32,848 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:21:40,643 - INFO - [Train] [15/90] | Loss: 0.6434 | Train Acc: 66.29%
2026-01-14 13:21:42,416 - INFO - [Valid] [15/90] | Loss: 0.6803 | Val Acc: 58.41%
2026-01-14 13:21:42,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.5336 | Recall: 0.8089 | F1: 0.6430
2026-01-14 13:21:42,430 - INFO - [Metrics for 'normal'] | Precision: 0.7030 | Recall: 0.3901 | F1: 0.5018
2026-01-14 13:21:42,435 - INFO - --------------------------------------------------
2026-01-14 13:21:42,437 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:21:49,798 - INFO - [Train] [16/90] | Loss: 0.6485 | Train Acc: 65.40%
2026-01-14 13:21:51,697 - INFO - [Valid] [16/90] | Loss: 0.6787 | Val Acc: 58.41%
2026-01-14 13:21:51,708 - INFO - [Metrics for 'abnormal'] | Precision: 0.5336 | Recall: 0.8089 | F1: 0.6430
2026-01-14 13:21:51,708 - INFO - [Metrics for 'normal'] | Precision: 0.7030 | Recall: 0.3901 | F1: 0.5018
2026-01-14 13:21:51,712 - INFO - --------------------------------------------------
2026-01-14 13:21:51,714 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:22:01,614 - INFO - [Train] [17/90] | Loss: 0.6483 | Train Acc: 65.33%
2026-01-14 13:22:03,858 - INFO - [Valid] [17/90] | Loss: 0.6792 | Val Acc: 58.41%
2026-01-14 13:22:03,868 - INFO - [Metrics for 'abnormal'] | Precision: 0.5336 | Recall: 0.8089 | F1: 0.6430
2026-01-14 13:22:03,869 - INFO - [Metrics for 'normal'] | Precision: 0.7030 | Recall: 0.3901 | F1: 0.5018
2026-01-14 13:22:03,873 - INFO - --------------------------------------------------
2026-01-14 13:22:03,875 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:22:12,949 - INFO - [Train] [18/90] | Loss: 0.6472 | Train Acc: 65.40%
2026-01-14 13:22:15,320 - INFO - [Valid] [18/90] | Loss: 0.6722 | Val Acc: 59.29%
2026-01-14 13:22:15,334 - INFO - [Metrics for 'abnormal'] | Precision: 0.5391 | Recall: 0.8344 | F1: 0.6550
2026-01-14 13:22:15,335 - INFO - [Metrics for 'normal'] | Precision: 0.7292 | Recall: 0.3846 | F1: 0.5036
2026-01-14 13:22:15,378 - INFO - [Best Model Saved] (val loss: 0.6722) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:22:15,379 - INFO - --------------------------------------------------
2026-01-14 13:22:15,381 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:22:25,266 - INFO - [Train] [19/90] | Loss: 0.6426 | Train Acc: 66.00%
2026-01-14 13:22:27,399 - INFO - [Valid] [19/90] | Loss: 0.6718 | Val Acc: 59.29%
2026-01-14 13:22:27,410 - INFO - [Metrics for 'abnormal'] | Precision: 0.5391 | Recall: 0.8344 | F1: 0.6550
2026-01-14 13:22:27,411 - INFO - [Metrics for 'normal'] | Precision: 0.7292 | Recall: 0.3846 | F1: 0.5036
2026-01-14 13:22:27,435 - INFO - [Best Model Saved] (val loss: 0.6718) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:22:27,435 - INFO - --------------------------------------------------
2026-01-14 13:22:27,438 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:22:37,450 - INFO - [Train] [20/90] | Loss: 0.6626 | Train Acc: 63.91%
2026-01-14 13:22:39,729 - INFO - [Valid] [20/90] | Loss: 0.6573 | Val Acc: 64.31%
2026-01-14 13:22:39,740 - INFO - [Metrics for 'abnormal'] | Precision: 0.5989 | Recall: 0.6943 | F1: 0.6431
2026-01-14 13:22:39,740 - INFO - [Metrics for 'normal'] | Precision: 0.6943 | Recall: 0.5989 | F1: 0.6431
2026-01-14 13:22:39,766 - INFO - [Best Model Saved] (val loss: 0.6573) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:22:39,766 - INFO - --------------------------------------------------
2026-01-14 13:22:39,768 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:22:50,181 - INFO - [Train] [21/90] | Loss: 0.6659 | Train Acc: 63.10%
2026-01-14 13:22:53,671 - INFO - [Valid] [21/90] | Loss: 0.6551 | Val Acc: 64.60%
2026-01-14 13:22:53,685 - INFO - [Metrics for 'abnormal'] | Precision: 0.6000 | Recall: 0.7070 | F1: 0.6491
2026-01-14 13:22:53,685 - INFO - [Metrics for 'normal'] | Precision: 0.7013 | Recall: 0.5934 | F1: 0.6429
2026-01-14 13:22:53,717 - INFO - [Best Model Saved] (val loss: 0.6551) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:22:53,718 - INFO - --------------------------------------------------
2026-01-14 13:22:53,720 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:23:02,872 - INFO - [Train] [22/90] | Loss: 0.6614 | Train Acc: 63.76%
2026-01-14 13:23:05,626 - INFO - [Valid] [22/90] | Loss: 0.6551 | Val Acc: 64.60%
2026-01-14 13:23:05,649 - INFO - [Metrics for 'abnormal'] | Precision: 0.6000 | Recall: 0.7070 | F1: 0.6491
2026-01-14 13:23:05,652 - INFO - [Metrics for 'normal'] | Precision: 0.7013 | Recall: 0.5934 | F1: 0.6429
2026-01-14 13:23:05,706 - INFO - [Best Model Saved] (val loss: 0.6551) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:23:05,707 - INFO - --------------------------------------------------
2026-01-14 13:23:05,709 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:23:14,806 - INFO - [Train] [23/90] | Loss: 0.6581 | Train Acc: 64.51%
2026-01-14 13:23:18,058 - INFO - [Valid] [23/90] | Loss: 0.6551 | Val Acc: 64.60%
2026-01-14 13:23:18,070 - INFO - [Metrics for 'abnormal'] | Precision: 0.6000 | Recall: 0.7070 | F1: 0.6491
2026-01-14 13:23:18,071 - INFO - [Metrics for 'normal'] | Precision: 0.7013 | Recall: 0.5934 | F1: 0.6429
2026-01-14 13:23:18,076 - INFO - --------------------------------------------------
2026-01-14 13:23:18,078 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:23:27,876 - INFO - [Train] [24/90] | Loss: 0.6633 | Train Acc: 63.39%
2026-01-14 13:23:30,752 - INFO - [Valid] [24/90] | Loss: 0.6554 | Val Acc: 64.60%
2026-01-14 13:23:30,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.6000 | Recall: 0.7070 | F1: 0.6491
2026-01-14 13:23:30,781 - INFO - [Metrics for 'normal'] | Precision: 0.7013 | Recall: 0.5934 | F1: 0.6429
2026-01-14 13:23:30,789 - INFO - --------------------------------------------------
2026-01-14 13:23:30,792 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:23:39,177 - INFO - [Train] [25/90] | Loss: 0.6578 | Train Acc: 64.58%
2026-01-14 13:23:42,128 - INFO - [Valid] [25/90] | Loss: 0.6540 | Val Acc: 64.90%
2026-01-14 13:23:42,141 - INFO - [Metrics for 'abnormal'] | Precision: 0.6022 | Recall: 0.7134 | F1: 0.6531
2026-01-14 13:23:42,142 - INFO - [Metrics for 'normal'] | Precision: 0.7059 | Recall: 0.5934 | F1: 0.6448
2026-01-14 13:23:42,171 - INFO - [Best Model Saved] (val loss: 0.6540) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:23:42,172 - INFO - --------------------------------------------------
2026-01-14 13:23:42,174 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:23:51,907 - INFO - [Train] [26/90] | Loss: 0.6580 | Train Acc: 64.51%
2026-01-14 13:23:54,578 - INFO - [Valid] [26/90] | Loss: 0.6554 | Val Acc: 64.60%
2026-01-14 13:23:54,590 - INFO - [Metrics for 'abnormal'] | Precision: 0.6000 | Recall: 0.7070 | F1: 0.6491
2026-01-14 13:23:54,591 - INFO - [Metrics for 'normal'] | Precision: 0.7013 | Recall: 0.5934 | F1: 0.6429
2026-01-14 13:23:54,596 - INFO - --------------------------------------------------
2026-01-14 13:23:54,599 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:24:02,856 - INFO - [Train] [27/90] | Loss: 0.6655 | Train Acc: 62.87%
2026-01-14 13:24:05,778 - INFO - [Valid] [27/90] | Loss: 0.6564 | Val Acc: 64.60%
2026-01-14 13:24:05,790 - INFO - [Metrics for 'abnormal'] | Precision: 0.6069 | Recall: 0.6688 | F1: 0.6364
2026-01-14 13:24:05,791 - INFO - [Metrics for 'normal'] | Precision: 0.6867 | Recall: 0.6264 | F1: 0.6552
2026-01-14 13:24:05,795 - INFO - --------------------------------------------------
2026-01-14 13:24:05,798 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:24:16,785 - INFO - [Train] [28/90] | Loss: 0.6629 | Train Acc: 63.62%
2026-01-14 13:24:20,556 - INFO - [Valid] [28/90] | Loss: 0.6551 | Val Acc: 65.19%
2026-01-14 13:24:20,566 - INFO - [Metrics for 'abnormal'] | Precision: 0.6242 | Recall: 0.6242 | F1: 0.6242
2026-01-14 13:24:20,566 - INFO - [Metrics for 'normal'] | Precision: 0.6758 | Recall: 0.6758 | F1: 0.6758
2026-01-14 13:24:20,570 - INFO - --------------------------------------------------
2026-01-14 13:24:20,572 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:24:29,622 - INFO - [Train] [29/90] | Loss: 0.6658 | Train Acc: 63.10%
2026-01-14 13:24:31,504 - INFO - [Valid] [29/90] | Loss: 0.6563 | Val Acc: 64.90%
2026-01-14 13:24:31,518 - INFO - [Metrics for 'abnormal'] | Precision: 0.6203 | Recall: 0.6242 | F1: 0.6222
2026-01-14 13:24:31,519 - INFO - [Metrics for 'normal'] | Precision: 0.6740 | Recall: 0.6703 | F1: 0.6722
2026-01-14 13:24:31,524 - INFO - --------------------------------------------------
2026-01-14 13:24:31,527 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:24:40,885 - INFO - [Train] [30/90] | Loss: 0.6665 | Train Acc: 62.80%
2026-01-14 13:24:43,514 - INFO - [Valid] [30/90] | Loss: 0.6589 | Val Acc: 64.31%
2026-01-14 13:24:43,525 - INFO - [Metrics for 'abnormal'] | Precision: 0.6125 | Recall: 0.6242 | F1: 0.6183
2026-01-14 13:24:43,525 - INFO - [Metrics for 'normal'] | Precision: 0.6704 | Recall: 0.6593 | F1: 0.6648
2026-01-14 13:24:43,530 - INFO - --------------------------------------------------
2026-01-14 13:24:43,532 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:24:54,306 - INFO - [Train] [31/90] | Loss: 0.6609 | Train Acc: 64.06%
2026-01-14 13:24:56,392 - INFO - [Valid] [31/90] | Loss: 0.6561 | Val Acc: 64.90%
2026-01-14 13:24:56,403 - INFO - [Metrics for 'abnormal'] | Precision: 0.6203 | Recall: 0.6242 | F1: 0.6222
2026-01-14 13:24:56,403 - INFO - [Metrics for 'normal'] | Precision: 0.6740 | Recall: 0.6703 | F1: 0.6722
2026-01-14 13:24:56,408 - INFO - --------------------------------------------------
2026-01-14 13:24:56,410 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:25:06,208 - INFO - [Train] [32/90] | Loss: 0.6601 | Train Acc: 64.21%
2026-01-14 13:25:08,334 - INFO - [Valid] [32/90] | Loss: 0.6592 | Val Acc: 64.01%
2026-01-14 13:25:08,360 - INFO - [Metrics for 'abnormal'] | Precision: 0.5989 | Recall: 0.6752 | F1: 0.6347
2026-01-14 13:25:08,360 - INFO - [Metrics for 'normal'] | Precision: 0.6852 | Recall: 0.6099 | F1: 0.6453
2026-01-14 13:25:08,371 - INFO - --------------------------------------------------
2026-01-14 13:25:08,373 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:25:17,681 - INFO - [Train] [33/90] | Loss: 0.6555 | Train Acc: 65.10%
2026-01-14 13:25:19,622 - INFO - [Valid] [33/90] | Loss: 0.6591 | Val Acc: 64.01%
2026-01-14 13:25:19,635 - INFO - [Metrics for 'abnormal'] | Precision: 0.5989 | Recall: 0.6752 | F1: 0.6347
2026-01-14 13:25:19,636 - INFO - [Metrics for 'normal'] | Precision: 0.6852 | Recall: 0.6099 | F1: 0.6453
2026-01-14 13:25:19,640 - INFO - --------------------------------------------------
2026-01-14 13:25:19,643 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:25:29,372 - INFO - [Train] [34/90] | Loss: 0.6638 | Train Acc: 63.47%
2026-01-14 13:25:31,494 - INFO - [Valid] [34/90] | Loss: 0.6535 | Val Acc: 65.19%
2026-01-14 13:25:31,505 - INFO - [Metrics for 'abnormal'] | Precision: 0.6077 | Recall: 0.7006 | F1: 0.6509
2026-01-14 13:25:31,506 - INFO - [Metrics for 'normal'] | Precision: 0.7025 | Recall: 0.6099 | F1: 0.6529
2026-01-14 13:25:31,534 - INFO - [Best Model Saved] (val loss: 0.6535) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:25:31,535 - INFO - --------------------------------------------------
2026-01-14 13:25:31,537 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:25:41,004 - INFO - [Train] [35/90] | Loss: 0.6605 | Train Acc: 64.06%
2026-01-14 13:25:43,546 - INFO - [Valid] [35/90] | Loss: 0.6571 | Val Acc: 64.31%
2026-01-14 13:25:43,558 - INFO - [Metrics for 'abnormal'] | Precision: 0.5947 | Recall: 0.7197 | F1: 0.6513
2026-01-14 13:25:43,559 - INFO - [Metrics for 'normal'] | Precision: 0.7047 | Recall: 0.5769 | F1: 0.6344
2026-01-14 13:25:43,563 - INFO - --------------------------------------------------
2026-01-14 13:25:43,565 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:25:53,041 - INFO - [Train] [36/90] | Loss: 0.6553 | Train Acc: 65.03%
2026-01-14 13:25:55,894 - INFO - [Valid] [36/90] | Loss: 0.6526 | Val Acc: 65.19%
2026-01-14 13:25:55,927 - INFO - [Metrics for 'abnormal'] | Precision: 0.6010 | Recall: 0.7389 | F1: 0.6629
2026-01-14 13:25:55,927 - INFO - [Metrics for 'normal'] | Precision: 0.7192 | Recall: 0.5769 | F1: 0.6402
2026-01-14 13:25:55,959 - INFO - [Best Model Saved] (val loss: 0.6526) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:25:55,960 - INFO - --------------------------------------------------
2026-01-14 13:25:55,963 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:26:06,250 - INFO - [Train] [37/90] | Loss: 0.6530 | Train Acc: 65.03%
2026-01-14 13:26:09,779 - INFO - [Valid] [37/90] | Loss: 0.6745 | Val Acc: 59.00%
2026-01-14 13:26:09,807 - INFO - [Metrics for 'abnormal'] | Precision: 0.5321 | Recall: 0.9490 | F1: 0.6819
2026-01-14 13:26:09,810 - INFO - [Metrics for 'normal'] | Precision: 0.8644 | Recall: 0.2802 | F1: 0.4232
2026-01-14 13:26:09,817 - INFO - --------------------------------------------------
2026-01-14 13:26:09,823 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:26:17,826 - INFO - [Train] [38/90] | Loss: 0.6562 | Train Acc: 62.57%
2026-01-14 13:26:20,886 - INFO - [Valid] [38/90] | Loss: 0.6707 | Val Acc: 58.11%
2026-01-14 13:26:20,899 - INFO - [Metrics for 'abnormal'] | Precision: 0.5265 | Recall: 0.9490 | F1: 0.6773
2026-01-14 13:26:20,903 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.2637 | F1: 0.4034
2026-01-14 13:26:20,913 - INFO - --------------------------------------------------
2026-01-14 13:26:20,922 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:26:29,485 - INFO - [Train] [39/90] | Loss: 0.6481 | Train Acc: 63.10%
2026-01-14 13:26:31,892 - INFO - [Valid] [39/90] | Loss: 0.6647 | Val Acc: 58.41%
2026-01-14 13:26:31,904 - INFO - [Metrics for 'abnormal'] | Precision: 0.5284 | Recall: 0.9490 | F1: 0.6788
2026-01-14 13:26:31,904 - INFO - [Metrics for 'normal'] | Precision: 0.8596 | Recall: 0.2692 | F1: 0.4100
2026-01-14 13:26:31,909 - INFO - --------------------------------------------------
2026-01-14 13:26:31,911 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:26:40,807 - INFO - [Train] [40/90] | Loss: 0.6409 | Train Acc: 63.76%
2026-01-14 13:26:43,376 - INFO - [Valid] [40/90] | Loss: 0.6554 | Val Acc: 60.18%
2026-01-14 13:26:43,387 - INFO - [Metrics for 'abnormal'] | Precision: 0.5404 | Recall: 0.9363 | F1: 0.6853
2026-01-14 13:26:43,388 - INFO - [Metrics for 'normal'] | Precision: 0.8507 | Recall: 0.3132 | F1: 0.4578
2026-01-14 13:26:43,394 - INFO - --------------------------------------------------
2026-01-14 13:26:43,397 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:26:52,158 - INFO - [Train] [41/90] | Loss: 0.6312 | Train Acc: 65.40%
2026-01-14 13:26:54,619 - INFO - [Valid] [41/90] | Loss: 0.6574 | Val Acc: 60.18%
2026-01-14 13:26:54,628 - INFO - [Metrics for 'abnormal'] | Precision: 0.5417 | Recall: 0.9108 | F1: 0.6793
2026-01-14 13:26:54,629 - INFO - [Metrics for 'normal'] | Precision: 0.8133 | Recall: 0.3352 | F1: 0.4747
2026-01-14 13:26:54,632 - INFO - --------------------------------------------------
2026-01-14 13:26:54,634 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:27:03,542 - INFO - [Train] [42/90] | Loss: 0.6308 | Train Acc: 66.07%
2026-01-14 13:27:06,554 - INFO - [Valid] [42/90] | Loss: 0.6659 | Val Acc: 60.18%
2026-01-14 13:27:06,568 - INFO - [Metrics for 'abnormal'] | Precision: 0.5447 | Recall: 0.8535 | F1: 0.6650
2026-01-14 13:27:06,568 - INFO - [Metrics for 'normal'] | Precision: 0.7527 | Recall: 0.3846 | F1: 0.5091
2026-01-14 13:27:06,573 - INFO - --------------------------------------------------
2026-01-14 13:27:06,576 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:27:14,993 - INFO - [Train] [43/90] | Loss: 0.6304 | Train Acc: 67.19%
2026-01-14 13:27:17,286 - INFO - [Valid] [43/90] | Loss: 0.6672 | Val Acc: 60.18%
2026-01-14 13:27:17,297 - INFO - [Metrics for 'abnormal'] | Precision: 0.5447 | Recall: 0.8535 | F1: 0.6650
2026-01-14 13:27:17,298 - INFO - [Metrics for 'normal'] | Precision: 0.7527 | Recall: 0.3846 | F1: 0.5091
2026-01-14 13:27:17,303 - INFO - --------------------------------------------------
2026-01-14 13:27:17,305 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:27:26,406 - INFO - [Train] [44/90] | Loss: 0.6345 | Train Acc: 66.74%
2026-01-14 13:27:28,750 - INFO - [Valid] [44/90] | Loss: 0.6694 | Val Acc: 59.88%
2026-01-14 13:27:28,762 - INFO - [Metrics for 'abnormal'] | Precision: 0.5429 | Recall: 0.8471 | F1: 0.6617
2026-01-14 13:27:28,763 - INFO - [Metrics for 'normal'] | Precision: 0.7447 | Recall: 0.3846 | F1: 0.5072
2026-01-14 13:27:28,768 - INFO - --------------------------------------------------
2026-01-14 13:27:28,769 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:27:37,469 - INFO - [Train] [45/90] | Loss: 0.6401 | Train Acc: 63.69%
2026-01-14 13:27:40,060 - INFO - [Valid] [45/90] | Loss: 0.6838 | Val Acc: 53.10%
2026-01-14 13:27:40,076 - INFO - [Metrics for 'abnormal'] | Precision: 0.4968 | Recall: 0.9873 | F1: 0.6610
2026-01-14 13:27:40,076 - INFO - [Metrics for 'normal'] | Precision: 0.9259 | Recall: 0.1374 | F1: 0.2392
2026-01-14 13:27:40,084 - INFO - --------------------------------------------------
2026-01-14 13:27:40,085 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:27:49,881 - INFO - [Train] [46/90] | Loss: 0.6693 | Train Acc: 59.23%
2026-01-14 13:27:52,926 - INFO - [Valid] [46/90] | Loss: 0.7088 | Val Acc: 46.31%
2026-01-14 13:27:52,938 - INFO - [Metrics for 'abnormal'] | Precision: 0.4631 | Recall: 1.0000 | F1: 0.6331
2026-01-14 13:27:52,939 - INFO - [Metrics for 'normal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:27:52,943 - INFO - --------------------------------------------------
2026-01-14 13:27:52,946 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:28:02,608 - INFO - [Train] [47/90] | Loss: 0.6989 | Train Acc: 48.74%
2026-01-14 13:28:06,987 - INFO - [Valid] [47/90] | Loss: 0.6966 | Val Acc: 46.31%
2026-01-14 13:28:07,012 - INFO - [Metrics for 'abnormal'] | Precision: 0.4631 | Recall: 1.0000 | F1: 0.6331
2026-01-14 13:28:07,016 - INFO - [Metrics for 'normal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:28:07,024 - INFO - --------------------------------------------------
2026-01-14 13:28:07,029 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:28:16,301 - INFO - [Train] [48/90] | Loss: 0.6944 | Train Acc: 48.44%
2026-01-14 13:28:19,184 - INFO - [Valid] [48/90] | Loss: 0.6937 | Val Acc: 46.31%
2026-01-14 13:28:19,196 - INFO - [Metrics for 'abnormal'] | Precision: 0.4631 | Recall: 1.0000 | F1: 0.6331
2026-01-14 13:28:19,197 - INFO - [Metrics for 'normal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:28:19,202 - INFO - --------------------------------------------------
2026-01-14 13:28:19,205 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:28:27,917 - INFO - [Train] [49/90] | Loss: 0.6933 | Train Acc: 49.85%
2026-01-14 13:28:30,891 - INFO - [Valid] [49/90] | Loss: 0.6928 | Val Acc: 53.69%
2026-01-14 13:28:30,909 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:28:30,913 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:28:30,921 - INFO - --------------------------------------------------
2026-01-14 13:28:30,931 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:28:38,594 - INFO - [Train] [50/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 13:28:40,896 - INFO - [Valid] [50/90] | Loss: 0.6925 | Val Acc: 53.69%
2026-01-14 13:28:40,910 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:28:40,910 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:28:40,915 - INFO - --------------------------------------------------
2026-01-14 13:28:40,917 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:28:49,175 - INFO - [Train] [51/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:28:53,546 - INFO - [Valid] [51/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:28:53,576 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:28:53,577 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:28:53,582 - INFO - --------------------------------------------------
2026-01-14 13:28:53,585 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:29:03,253 - INFO - [Train] [52/90] | Loss: 0.6930 | Train Acc: 51.19%
2026-01-14 13:29:06,181 - INFO - [Valid] [52/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:29:06,207 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:29:06,208 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:29:06,216 - INFO - --------------------------------------------------
2026-01-14 13:29:06,221 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:29:15,242 - INFO - [Train] [53/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:29:18,423 - INFO - [Valid] [53/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:29:18,435 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:29:18,436 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:29:18,440 - INFO - --------------------------------------------------
2026-01-14 13:29:18,442 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:29:26,321 - INFO - [Train] [54/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:29:29,597 - INFO - [Valid] [54/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:29:29,611 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:29:29,611 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:29:29,615 - INFO - --------------------------------------------------
2026-01-14 13:29:29,618 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:29:38,103 - INFO - [Train] [55/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:29:41,769 - INFO - [Valid] [55/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:29:41,782 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:29:41,782 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:29:41,786 - INFO - --------------------------------------------------
2026-01-14 13:29:41,789 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:29:51,812 - INFO - [Train] [56/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:29:54,860 - INFO - [Valid] [56/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:29:54,871 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:29:54,872 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:29:54,876 - INFO - --------------------------------------------------
2026-01-14 13:29:54,878 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:30:02,972 - INFO - [Train] [57/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:30:05,747 - INFO - [Valid] [57/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:30:05,759 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:30:05,760 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:30:05,765 - INFO - --------------------------------------------------
2026-01-14 13:30:05,768 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:30:15,377 - INFO - [Train] [58/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:30:18,422 - INFO - [Valid] [58/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:30:18,448 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:30:18,449 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:30:18,460 - INFO - --------------------------------------------------
2026-01-14 13:30:18,465 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:30:27,066 - INFO - [Train] [59/90] | Loss: 0.6931 | Train Acc: 51.19%
2026-01-14 13:30:31,196 - INFO - [Valid] [59/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:30:31,208 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:30:31,209 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:30:31,213 - INFO - --------------------------------------------------
2026-01-14 13:30:31,215 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:30:39,597 - INFO - [Train] [60/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:30:42,617 - INFO - [Valid] [60/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:30:42,630 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:30:42,631 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:30:42,636 - INFO - --------------------------------------------------
2026-01-14 13:30:42,638 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:30:52,269 - INFO - [Train] [61/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:30:55,073 - INFO - [Valid] [61/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:30:55,100 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:30:55,101 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:30:55,109 - INFO - --------------------------------------------------
2026-01-14 13:30:55,111 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:31:03,709 - INFO - [Train] [62/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:31:06,818 - INFO - [Valid] [62/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:31:06,862 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:31:06,863 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:31:06,882 - INFO - --------------------------------------------------
2026-01-14 13:31:06,884 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:31:15,121 - INFO - [Train] [63/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:31:18,246 - INFO - [Valid] [63/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:31:18,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:31:18,260 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:31:18,265 - INFO - --------------------------------------------------
2026-01-14 13:31:18,268 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:31:27,286 - INFO - [Train] [64/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 13:31:29,372 - INFO - [Valid] [64/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:31:29,392 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:31:29,392 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:31:29,398 - INFO - --------------------------------------------------
2026-01-14 13:31:29,400 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:31:39,002 - INFO - [Train] [65/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:31:40,960 - INFO - [Valid] [65/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:31:40,973 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:31:40,974 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:31:40,978 - INFO - --------------------------------------------------
2026-01-14 13:31:40,981 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:31:49,790 - INFO - [Train] [66/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 13:31:51,870 - INFO - [Valid] [66/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:31:51,883 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:31:51,884 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:31:51,889 - INFO - --------------------------------------------------
2026-01-14 13:31:51,891 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:32:03,584 - INFO - [Train] [67/90] | Loss: 0.6931 | Train Acc: 51.19%
2026-01-14 13:32:05,933 - INFO - [Valid] [67/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:32:05,948 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:32:05,949 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:32:05,953 - INFO - --------------------------------------------------
2026-01-14 13:32:05,956 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:32:16,116 - INFO - [Train] [68/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:32:18,114 - INFO - [Valid] [68/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:32:18,131 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:32:18,132 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:32:18,140 - INFO - --------------------------------------------------
2026-01-14 13:32:18,143 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:32:27,276 - INFO - [Train] [69/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:32:29,193 - INFO - [Valid] [69/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:32:29,205 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:32:29,205 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:32:29,208 - INFO - --------------------------------------------------
2026-01-14 13:32:29,210 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:32:39,108 - INFO - [Train] [70/90] | Loss: 0.6929 | Train Acc: 51.19%
2026-01-14 13:32:41,984 - INFO - [Valid] [70/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:32:42,039 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:32:42,039 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:32:42,043 - INFO - --------------------------------------------------
2026-01-14 13:32:42,045 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:32:51,288 - INFO - [Train] [71/90] | Loss: 0.6930 | Train Acc: 51.12%
2026-01-14 13:32:54,187 - INFO - [Valid] [71/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:32:54,213 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:32:54,219 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:32:54,235 - INFO - --------------------------------------------------
2026-01-14 13:32:54,239 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:33:03,307 - INFO - [Train] [72/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:33:05,969 - INFO - [Valid] [72/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:33:05,980 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:33:05,980 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:33:05,984 - INFO - --------------------------------------------------
2026-01-14 13:33:05,986 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:33:17,117 - INFO - [Train] [73/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:33:19,758 - INFO - [Valid] [73/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:33:19,771 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:33:19,772 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:33:19,776 - INFO - --------------------------------------------------
2026-01-14 13:33:19,779 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:33:29,429 - INFO - [Train] [74/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:33:32,829 - INFO - [Valid] [74/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:33:32,843 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:33:32,843 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:33:32,848 - INFO - --------------------------------------------------
2026-01-14 13:33:32,851 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:33:41,852 - INFO - [Train] [75/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:33:44,331 - INFO - [Valid] [75/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:33:44,342 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:33:44,342 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:33:44,346 - INFO - --------------------------------------------------
2026-01-14 13:33:44,348 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:33:52,022 - INFO - [Train] [76/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:33:54,327 - INFO - [Valid] [76/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:33:54,352 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:33:54,355 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:33:54,364 - INFO - --------------------------------------------------
2026-01-14 13:33:54,367 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:34:04,889 - INFO - [Train] [77/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:34:07,764 - INFO - [Valid] [77/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:34:07,772 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:34:07,772 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:34:07,776 - INFO - --------------------------------------------------
2026-01-14 13:34:07,778 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:34:15,287 - INFO - [Train] [78/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:34:17,069 - INFO - [Valid] [78/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:34:17,081 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:34:17,082 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:34:17,086 - INFO - --------------------------------------------------
2026-01-14 13:34:17,088 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:34:24,553 - INFO - [Train] [79/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:34:26,674 - INFO - [Valid] [79/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:34:26,691 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:34:26,691 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:34:26,696 - INFO - --------------------------------------------------
2026-01-14 13:34:26,698 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:34:34,805 - INFO - [Train] [80/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:34:37,089 - INFO - [Valid] [80/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:34:37,100 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:34:37,100 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:34:37,105 - INFO - --------------------------------------------------
2026-01-14 13:34:37,108 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:34:44,605 - INFO - [Train] [81/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:34:46,769 - INFO - [Valid] [81/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:34:46,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:34:46,781 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:34:46,785 - INFO - --------------------------------------------------
2026-01-14 13:34:46,787 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:34:53,926 - INFO - [Train] [82/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:34:56,017 - INFO - [Valid] [82/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:34:56,029 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:34:56,030 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:34:56,035 - INFO - --------------------------------------------------
2026-01-14 13:34:56,037 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:35:02,008 - INFO - [Train] [83/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:35:04,286 - INFO - [Valid] [83/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:04,298 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:04,299 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:04,303 - INFO - --------------------------------------------------
2026-01-14 13:35:04,306 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:35:12,865 - INFO - [Train] [84/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:35:14,703 - INFO - [Valid] [84/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:14,714 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:14,715 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:14,718 - INFO - --------------------------------------------------
2026-01-14 13:35:14,722 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:35:20,435 - INFO - [Train] [85/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:35:22,163 - INFO - [Valid] [85/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:22,171 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:22,171 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:22,175 - INFO - --------------------------------------------------
2026-01-14 13:35:22,176 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:35:29,592 - INFO - [Train] [86/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:35:31,102 - INFO - [Valid] [86/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:31,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:31,112 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:31,115 - INFO - --------------------------------------------------
2026-01-14 13:35:31,117 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:35:36,093 - INFO - [Train] [87/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:35:37,545 - INFO - [Valid] [87/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:37,556 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:37,556 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:37,560 - INFO - --------------------------------------------------
2026-01-14 13:35:37,562 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:35:42,397 - INFO - [Train] [88/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:35:43,766 - INFO - [Valid] [88/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:43,775 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:43,775 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:43,779 - INFO - --------------------------------------------------
2026-01-14 13:35:43,780 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:35:48,612 - INFO - [Train] [89/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:35:50,086 - INFO - [Valid] [89/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:35:50,098 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:50,098 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:50,102 - INFO - --------------------------------------------------
2026-01-14 13:35:50,104 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:35:55,096 - INFO - [Train] [90/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:35:56,455 - INFO - [Valid] [90/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:35:56,467 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:35:56,467 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:35:56,473 - INFO - ==================================================
2026-01-14 13:35:56,473 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:35:56,473 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:35:56,473 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:35:59,025 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:35:59,027 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:35:59,029 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:35:59,029 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:35:59,030 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:35:59,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 13:35:59,585 - INFO - ==================================================
2026-01-14 13:35:59,643 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/best_model.pth'
2026-01-14 13:35:59,644 - INFO - ==================================================
2026-01-14 13:35:59,644 - INFO - Test 모드를 시작합니다.
2026-01-14 13:35:59,879 - INFO - 연산량 (MACs): 0.0040 GMACs per sample
2026-01-14 13:35:59,879 - INFO - 연산량 (FLOPs): 0.0081 GFLOPs per sample
2026-01-14 13:35:59,879 - INFO - ==================================================
2026-01-14 13:35:59,880 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:36:00,979 - INFO - 샘플 당 평균 Forward Pass 시간: 5.06ms (std: 0.74ms), FPS: 201.28 (std: 25.46) (1개 샘플 x 100회 반복)
2026-01-14 13:36:00,979 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 104.15 MB
2026-01-14 13:36:00,979 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:36:03,259 - INFO - [Test] Loss: 0.6441 | Test Acc: 65.19%
2026-01-14 13:36:03,273 - INFO - [Metrics for 'abnormal'] | Precision: 0.6010 | Recall: 0.7389 | F1: 0.6629
2026-01-14 13:36:03,273 - INFO - [Metrics for 'normal'] | Precision: 0.7192 | Recall: 0.5769 | F1: 0.6402
2026-01-14 13:36:03,860 - INFO - ==================================================
2026-01-14 13:36:03,860 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/confusion_matrix_20260114_131806.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/confusion_matrix_20260114_131806.pdf'
2026-01-14 13:36:03,860 - INFO - ==================================================
2026-01-14 13:36:03,860 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:36:05,903 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/model_fp32_20260114_131806.onnx'에 저장되었습니다. (크기: 0.24 MB)
2026-01-14 13:36:06,339 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2290.25 MB (증가량: 6.46 MB)
2026-01-14 13:36:06,340 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:36:08,157 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 13.20ms (std: 11.02ms)
2026-01-14 13:36:08,158 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 97.15 FPS (std: 35.37) (1개 샘플 x 100회 반복)
2026-01-14 13:36:08,159 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2292.81 MB (순수 증가량: 2.56 MB)
2026-01-14 13:36:08,159 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2292.81 MB (전체 증가량: 9.02 MB)
2026-01-14 13:36:12,253 - INFO - [Test (ONNX)] | Test Acc (ONNX): 65.19%
2026-01-14 13:36:12,265 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.6010 | Recall: 0.7389 | F1: 0.6629
2026-01-14 13:36:12,265 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.7192 | Recall: 0.5769 | F1: 0.6402
2026-01-14 13:36:12,819 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/val_acc.pdf'
2026-01-14 13:36:13,258 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/train_val_acc.pdf'
2026-01-14 13:36:13,636 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/F1_normal.pdf'
2026-01-14 13:36:14,094 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/val_loss.pdf'
2026-01-14 13:36:14,566 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/learning_rate.pdf'
2026-01-14 13:36:19,329 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_l1_20260114_131806/graph_20260114_131806/compile.pdf'
