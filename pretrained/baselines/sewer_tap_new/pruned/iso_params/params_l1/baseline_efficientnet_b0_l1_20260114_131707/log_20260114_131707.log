2026-01-14 13:17:07,498 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/log_20260114_131707.log'에 저장됩니다.
2026-01-14 13:17:07,504 - INFO - ==================================================
2026-01-14 13:17:07,505 - INFO - config.yaml:
2026-01-14 13:17:07,505 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: efficientnet_b0
  use_l1_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:17:07,505 - INFO - ==================================================
2026-01-14 13:17:07,709 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:17:07,709 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:17:07,709 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:17:07,717 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:17:07,717 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:17:07,718 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:17:07,718 - INFO - Baseline 모델 'efficientnet_b0'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:17:07,975 - INFO - ==================================================
2026-01-14 13:17:07,975 - INFO - 모델 파라미터 수:
2026-01-14 13:17:07,975 - INFO -   - 총 파라미터: 4,010,110 개
2026-01-14 13:17:07,975 - INFO -   - 학습 가능한 파라미터: 4,010,110 개
2026-01-14 13:17:07,975 - INFO - ================================================================================
2026-01-14 13:17:07,975 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:17:07,975 - INFO - ================================================================================
2026-01-14 13:17:07,975 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:17:07,977 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:17:07,977 - INFO - ==================================================
2026-01-14 13:17:07,977 - INFO - train 모드를 시작합니다.
2026-01-14 13:17:07,977 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:17:07,977 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:17:07,977 - INFO - --------------------------------------------------
2026-01-14 13:17:07,979 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:17:13,416 - INFO - [Train] [1/10] | Loss: 0.5853 | Train Acc: 73.66%
2026-01-14 13:17:15,473 - INFO - [Valid] [1/10] | Loss: 0.6242 | Val Acc: 71.68%
2026-01-14 13:17:15,485 - INFO - [Metrics for 'abnormal'] | Precision: 0.8427 | Recall: 0.4777 | F1: 0.6098
2026-01-14 13:17:15,485 - INFO - [Metrics for 'normal'] | Precision: 0.6720 | Recall: 0.9231 | F1: 0.7778
2026-01-14 13:17:15,531 - INFO - [Best Model Saved] (val loss: 0.6242) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:17:15,531 - INFO - --------------------------------------------------
2026-01-14 13:17:15,532 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:17:19,865 - INFO - [Train] [2/10] | Loss: 0.5375 | Train Acc: 80.21%
2026-01-14 13:17:21,137 - INFO - [Valid] [2/10] | Loss: 0.5086 | Val Acc: 79.94%
2026-01-14 13:17:21,145 - INFO - [Metrics for 'abnormal'] | Precision: 0.8397 | Recall: 0.7006 | F1: 0.7639
2026-01-14 13:17:21,145 - INFO - [Metrics for 'normal'] | Precision: 0.7740 | Recall: 0.8846 | F1: 0.8256
2026-01-14 13:17:21,189 - INFO - [Best Model Saved] (val loss: 0.5086) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:17:21,189 - INFO - --------------------------------------------------
2026-01-14 13:17:21,191 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:17:25,610 - INFO - [Train] [3/10] | Loss: 0.5054 | Train Acc: 80.13%
2026-01-14 13:17:27,007 - INFO - [Valid] [3/10] | Loss: 0.5069 | Val Acc: 82.01%
2026-01-14 13:17:27,018 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.7898 | F1: 0.8026
2026-01-14 13:17:27,018 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.8462 | F1: 0.8347
2026-01-14 13:17:27,086 - INFO - [Best Model Saved] (val loss: 0.5069) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:17:27,087 - INFO - --------------------------------------------------
2026-01-14 13:17:27,088 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:17:31,580 - INFO - [Train] [4/10] | Loss: 0.4629 | Train Acc: 84.00%
2026-01-14 13:17:33,012 - INFO - [Valid] [4/10] | Loss: 0.4941 | Val Acc: 83.19%
2026-01-14 13:17:33,021 - INFO - [Metrics for 'abnormal'] | Precision: 0.7874 | Recall: 0.8726 | F1: 0.8278
2026-01-14 13:17:33,021 - INFO - [Metrics for 'normal'] | Precision: 0.8788 | Recall: 0.7967 | F1: 0.8357
2026-01-14 13:17:33,069 - INFO - [Best Model Saved] (val loss: 0.4941) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:17:33,070 - INFO - --------------------------------------------------
2026-01-14 13:17:33,071 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:17:37,587 - INFO - [Train] [5/10] | Loss: 0.4448 | Train Acc: 84.00%
2026-01-14 13:17:39,080 - INFO - [Valid] [5/10] | Loss: 0.5026 | Val Acc: 82.89%
2026-01-14 13:17:39,088 - INFO - [Metrics for 'abnormal'] | Precision: 0.8037 | Recall: 0.8344 | F1: 0.8187
2026-01-14 13:17:39,089 - INFO - [Metrics for 'normal'] | Precision: 0.8523 | Recall: 0.8242 | F1: 0.8380
2026-01-14 13:17:39,092 - INFO - --------------------------------------------------
2026-01-14 13:17:39,094 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:17:44,270 - INFO - [Train] [6/10] | Loss: 0.4344 | Train Acc: 85.71%
2026-01-14 13:17:45,611 - INFO - [Valid] [6/10] | Loss: 0.5642 | Val Acc: 76.70%
2026-01-14 13:17:45,619 - INFO - [Metrics for 'abnormal'] | Precision: 0.8250 | Recall: 0.6306 | F1: 0.7148
2026-01-14 13:17:45,619 - INFO - [Metrics for 'normal'] | Precision: 0.7352 | Recall: 0.8846 | F1: 0.8030
2026-01-14 13:17:45,622 - INFO - --------------------------------------------------
2026-01-14 13:17:45,624 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:17:50,806 - INFO - [Train] [7/10] | Loss: 0.4125 | Train Acc: 87.13%
2026-01-14 13:17:52,488 - INFO - [Valid] [7/10] | Loss: 0.4591 | Val Acc: 81.42%
2026-01-14 13:17:52,499 - INFO - [Metrics for 'abnormal'] | Precision: 0.8507 | Recall: 0.7261 | F1: 0.7835
2026-01-14 13:17:52,500 - INFO - [Metrics for 'normal'] | Precision: 0.7902 | Recall: 0.8901 | F1: 0.8372
2026-01-14 13:17:52,565 - INFO - [Best Model Saved] (val loss: 0.4591) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:17:52,565 - INFO - --------------------------------------------------
2026-01-14 13:17:52,567 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:17:58,265 - INFO - [Train] [8/10] | Loss: 0.3831 | Train Acc: 89.73%
2026-01-14 13:17:59,829 - INFO - [Valid] [8/10] | Loss: 0.4577 | Val Acc: 84.37%
2026-01-14 13:17:59,838 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.8662 | F1: 0.8369
2026-01-14 13:17:59,838 - INFO - [Metrics for 'normal'] | Precision: 0.8772 | Recall: 0.8242 | F1: 0.8499
2026-01-14 13:17:59,890 - INFO - [Best Model Saved] (val loss: 0.4577) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:17:59,890 - INFO - --------------------------------------------------
2026-01-14 13:17:59,892 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:18:06,275 - INFO - [Train] [9/10] | Loss: 0.3392 | Train Acc: 91.07%
2026-01-14 13:18:08,339 - INFO - [Valid] [9/10] | Loss: 0.4704 | Val Acc: 83.19%
2026-01-14 13:18:08,357 - INFO - [Metrics for 'abnormal'] | Precision: 0.8086 | Recall: 0.8344 | F1: 0.8213
2026-01-14 13:18:08,363 - INFO - [Metrics for 'normal'] | Precision: 0.8531 | Recall: 0.8297 | F1: 0.8412
2026-01-14 13:18:08,367 - INFO - --------------------------------------------------
2026-01-14 13:18:08,371 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:18:15,648 - INFO - [Train] [10/10] | Loss: 0.3192 | Train Acc: 93.01%
2026-01-14 13:18:17,546 - INFO - [Valid] [10/10] | Loss: 0.4711 | Val Acc: 83.48%
2026-01-14 13:18:17,570 - INFO - [Metrics for 'abnormal'] | Precision: 0.8531 | Recall: 0.7771 | F1: 0.8133
2026-01-14 13:18:17,571 - INFO - [Metrics for 'normal'] | Precision: 0.8214 | Recall: 0.8846 | F1: 0.8519
2026-01-14 13:18:17,578 - INFO - ================================================================================
2026-01-14 13:18:17,580 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:18:17,581 - INFO - ================================================================================
2026-01-14 13:18:17,696 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:18:17,697 - INFO - ================================================================================
2026-01-14 13:18:17,697 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:18:17,699 - INFO - 원본 모델 파라미터: 4.0101M
2026-01-14 13:18:17,798 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:17,799 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:18,330 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:18:18,331 - INFO - ==================================================
2026-01-14 13:18:18,332 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.0721M (감소율: 73.26%)
2026-01-14 13:18:18,373 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:18,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:18,831 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:18:18,832 - INFO - ==================================================
2026-01-14 13:18:18,835 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.3065M (감소율: 92.36%)
2026-01-14 13:18:18,887 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:18,887 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:19,286 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:18:19,287 - INFO - ==================================================
2026-01-14 13:18:19,289 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0963M (감소율: 97.60%)
2026-01-14 13:18:19,335 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:19,335 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:19,713 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:18:19,714 - INFO - ==================================================
2026-01-14 13:18:19,716 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0360M (감소율: 99.10%)
2026-01-14 13:18:19,761 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:19,762 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:20,544 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 13:18:20,544 - INFO - ==================================================
2026-01-14 13:18:20,548 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0183M (감소율: 99.54%)
2026-01-14 13:18:20,592 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:20,592 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:20,932 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.94359375)에 맞춰 변경되었습니다.
2026-01-14 13:18:20,932 - INFO - ==================================================
2026-01-14 13:18:20,934 - INFO -   [탐색  6] 희소도: 0.9436 -> 파라미터: 0.0247M (감소율: 99.38%)
2026-01-14 13:18:20,979 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:20,979 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:21,341 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9358593749999999)에 맞춰 변경되었습니다.
2026-01-14 13:18:21,341 - INFO - ==================================================
2026-01-14 13:18:21,344 - INFO -   [탐색  7] 희소도: 0.9359 -> 파라미터: 0.0306M (감소율: 99.24%)
2026-01-14 13:18:21,398 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:21,399 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:21,740 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9319921874999999)에 맞춰 변경되었습니다.
2026-01-14 13:18:21,740 - INFO - ==================================================
2026-01-14 13:18:21,744 - INFO -   [탐색  8] 희소도: 0.9320 -> 파라미터: 0.0332M (감소율: 99.17%)
2026-01-14 13:18:21,802 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:21,803 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:22,196 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9339257812499999)에 맞춰 변경되었습니다.
2026-01-14 13:18:22,197 - INFO - ==================================================
2026-01-14 13:18:22,200 - INFO -   [탐색  9] 희소도: 0.9339 -> 파라미터: 0.0317M (감소율: 99.21%)
2026-01-14 13:18:22,289 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:22,290 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:22,677 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9348925781249999)에 맞춰 변경되었습니다.
2026-01-14 13:18:22,677 - INFO - ==================================================
2026-01-14 13:18:22,679 - INFO -   [탐색 10] 희소도: 0.9349 -> 파라미터: 0.0311M (감소율: 99.22%)
2026-01-14 13:18:22,728 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:22,729 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:23,130 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 13:18:23,131 - INFO - ==================================================
2026-01-14 13:18:23,134 - INFO -   [탐색 11] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:23,213 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:23,213 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:23,907 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9341674804687499)에 맞춰 변경되었습니다.
2026-01-14 13:18:23,910 - INFO - ==================================================
2026-01-14 13:18:23,913 - INFO -   [탐색 12] 희소도: 0.9342 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:24,385 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:24,386 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:24,747 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9342883300781248)에 맞춰 변경되었습니다.
2026-01-14 13:18:24,748 - INFO - ==================================================
2026-01-14 13:18:24,754 - INFO -   [탐색 13] 희소도: 0.9343 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:24,817 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:24,818 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:25,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343487548828124)에 맞춰 변경되었습니다.
2026-01-14 13:18:25,238 - INFO - ==================================================
2026-01-14 13:18:25,240 - INFO -   [탐색 14] 희소도: 0.9343 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:25,303 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:25,303 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:25,727 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343789672851561)에 맞춰 변경되었습니다.
2026-01-14 13:18:25,728 - INFO - ==================================================
2026-01-14 13:18:25,730 - INFO -   [탐색 15] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:25,793 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:25,794 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:26,166 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343638610839843)에 맞춰 변경되었습니다.
2026-01-14 13:18:26,167 - INFO - ==================================================
2026-01-14 13:18:26,169 - INFO -   [탐색 16] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:26,209 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:26,210 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:26,616 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343714141845703)에 맞춰 변경되었습니다.
2026-01-14 13:18:26,616 - INFO - ==================================================
2026-01-14 13:18:26,619 - INFO -   [탐색 17] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:26,677 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:26,678 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:27,082 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343751907348632)에 맞춰 변경되었습니다.
2026-01-14 13:18:27,083 - INFO - ==================================================
2026-01-14 13:18:27,086 - INFO -   [탐색 18] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:27,135 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:27,136 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:27,554 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343733024597167)에 맞춰 변경되었습니다.
2026-01-14 13:18:27,554 - INFO - ==================================================
2026-01-14 13:18:27,557 - INFO -   [탐색 19] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:27,602 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:27,602 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:28,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93437424659729)에 맞춰 변경되었습니다.
2026-01-14 13:18:28,444 - INFO - ==================================================
2026-01-14 13:18:28,448 - INFO -   [탐색 20] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:28,504 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:28,505 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:28,861 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343747186660766)에 맞춰 변경되었습니다.
2026-01-14 13:18:28,866 - INFO - ==================================================
2026-01-14 13:18:28,870 - INFO -   [탐색 21] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:28,924 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:28,925 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:29,362 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749547004698)에 맞춰 변경되었습니다.
2026-01-14 13:18:29,362 - INFO - ==================================================
2026-01-14 13:18:29,365 - INFO -   [탐색 22] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:29,613 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:29,613 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:30,020 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750727176665)에 맞춰 변경되었습니다.
2026-01-14 13:18:30,024 - INFO - ==================================================
2026-01-14 13:18:30,026 - INFO -   [탐색 23] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:30,094 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:30,095 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:30,624 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750137090682)에 맞춰 변경되었습니다.
2026-01-14 13:18:30,625 - INFO - ==================================================
2026-01-14 13:18:30,635 - INFO -   [탐색 24] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:30,706 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:30,707 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:31,256 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934374984204769)에 맞춰 변경되었습니다.
2026-01-14 13:18:31,256 - INFO - ==================================================
2026-01-14 13:18:31,259 - INFO -   [탐색 25] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:31,338 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:31,339 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:31,858 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749989569186)에 맞춰 변경되었습니다.
2026-01-14 13:18:31,859 - INFO - ==================================================
2026-01-14 13:18:31,861 - INFO -   [탐색 26] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:31,905 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:31,905 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:32,260 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750063329934)에 맞춰 변경되었습니다.
2026-01-14 13:18:32,261 - INFO - ==================================================
2026-01-14 13:18:32,263 - INFO -   [탐색 27] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:32,308 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:32,308 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:33,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375002644956)에 맞춰 변경되었습니다.
2026-01-14 13:18:33,348 - INFO - ==================================================
2026-01-14 13:18:33,351 - INFO -   [탐색 28] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:33,388 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:33,388 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:33,872 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750008009373)에 맞춰 변경되었습니다.
2026-01-14 13:18:33,872 - INFO - ==================================================
2026-01-14 13:18:33,874 - INFO -   [탐색 29] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:33,929 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:33,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:34,318 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749998789279)에 맞춰 변경되었습니다.
2026-01-14 13:18:34,319 - INFO - ==================================================
2026-01-14 13:18:34,321 - INFO -   [탐색 30] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:34,373 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:34,376 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:34,627 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750003399326)에 맞춰 변경되었습니다.
2026-01-14 13:18:34,627 - INFO - ==================================================
2026-01-14 13:18:34,629 - INFO -   [탐색 31] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:34,697 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:34,698 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:35,030 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750001094302)에 맞춰 변경되었습니다.
2026-01-14 13:18:35,034 - INFO - ==================================================
2026-01-14 13:18:35,036 - INFO -   [탐색 32] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:35,143 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:35,144 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:35,819 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999941791)에 맞춰 변경되었습니다.
2026-01-14 13:18:35,820 - INFO - ==================================================
2026-01-14 13:18:35,822 - INFO -   [탐색 33] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:35,914 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:35,915 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:36,557 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000518046)에 맞춰 변경되었습니다.
2026-01-14 13:18:36,558 - INFO - ==================================================
2026-01-14 13:18:36,560 - INFO -   [탐색 34] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:36,702 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:36,703 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:37,086 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000229918)에 맞춰 변경되었습니다.
2026-01-14 13:18:37,087 - INFO - ==================================================
2026-01-14 13:18:37,089 - INFO -   [탐색 35] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:37,137 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:37,138 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:38,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000085854)에 맞춰 변경되었습니다.
2026-01-14 13:18:38,238 - INFO - ==================================================
2026-01-14 13:18:38,243 - INFO -   [탐색 36] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:38,301 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:38,302 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:38,935 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000013822)에 맞춰 변경되었습니다.
2026-01-14 13:18:38,936 - INFO - ==================================================
2026-01-14 13:18:38,939 - INFO -   [탐색 37] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:39,220 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:39,220 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:39,672 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999977806)에 맞춰 변경되었습니다.
2026-01-14 13:18:39,672 - INFO - ==================================================
2026-01-14 13:18:39,675 - INFO -   [탐색 38] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:39,743 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:39,743 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:40,151 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999995814)에 맞춰 변경되었습니다.
2026-01-14 13:18:40,152 - INFO - ==================================================
2026-01-14 13:18:40,154 - INFO -   [탐색 39] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:40,204 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:40,205 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:40,593 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000004818)에 맞춰 변경되었습니다.
2026-01-14 13:18:40,594 - INFO - ==================================================
2026-01-14 13:18:40,596 - INFO -   [탐색 40] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:40,664 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:40,665 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:41,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000316)에 맞춰 변경되었습니다.
2026-01-14 13:18:41,110 - INFO - ==================================================
2026-01-14 13:18:41,112 - INFO -   [탐색 41] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:41,216 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:41,217 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:41,743 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999998066)에 맞춰 변경되었습니다.
2026-01-14 13:18:41,744 - INFO - ==================================================
2026-01-14 13:18:41,747 - INFO -   [탐색 42] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:41,799 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:41,800 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:42,186 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999191)에 맞춰 변경되었습니다.
2026-01-14 13:18:42,186 - INFO - ==================================================
2026-01-14 13:18:42,189 - INFO -   [탐색 43] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:42,238 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:42,239 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:43,276 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999753)에 맞춰 변경되었습니다.
2026-01-14 13:18:43,276 - INFO - ==================================================
2026-01-14 13:18:43,281 - INFO -   [탐색 44] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:43,367 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:43,368 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:43,867 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000035)에 맞춰 변경되었습니다.
2026-01-14 13:18:43,868 - INFO - ==================================================
2026-01-14 13:18:43,871 - INFO -   [탐색 45] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:43,938 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:43,938 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:44,566 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999894)에 맞춰 변경되었습니다.
2026-01-14 13:18:44,567 - INFO - ==================================================
2026-01-14 13:18:44,570 - INFO -   [탐색 46] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:44,631 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:44,632 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:45,542 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999964)에 맞춰 변경되었습니다.
2026-01-14 13:18:45,542 - INFO - ==================================================
2026-01-14 13:18:45,545 - INFO -   [탐색 47] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:45,619 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:45,620 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:45,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:45,952 - INFO - ==================================================
2026-01-14 13:18:45,955 - INFO -   [탐색 48] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:46,002 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:46,003 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:46,435 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000017)에 맞춰 변경되었습니다.
2026-01-14 13:18:46,436 - INFO - ==================================================
2026-01-14 13:18:46,438 - INFO -   [탐색 49] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:46,491 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:46,492 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:46,869 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000008)에 맞춰 변경되었습니다.
2026-01-14 13:18:46,870 - INFO - ==================================================
2026-01-14 13:18:46,873 - INFO -   [탐색 50] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:46,923 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:46,924 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:47,209 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000004)에 맞춰 변경되었습니다.
2026-01-14 13:18:47,210 - INFO - ==================================================
2026-01-14 13:18:47,212 - INFO -   [탐색 51] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:47,602 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:47,603 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:48,089 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000002)에 맞춰 변경되었습니다.
2026-01-14 13:18:48,090 - INFO - ==================================================
2026-01-14 13:18:48,094 - INFO -   [탐색 52] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:48,159 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:48,159 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:48,501 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000001)에 맞춰 변경되었습니다.
2026-01-14 13:18:48,503 - INFO - ==================================================
2026-01-14 13:18:48,506 - INFO -   [탐색 53] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:18:48,565 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:48,566 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:49,054 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:49,054 - INFO - ==================================================
2026-01-14 13:18:49,057 - INFO -   [탐색 54] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:49,122 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:49,123 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:49,498 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:49,499 - INFO - ==================================================
2026-01-14 13:18:49,501 - INFO -   [탐색 55] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:49,559 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:49,560 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:49,991 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:49,991 - INFO - ==================================================
2026-01-14 13:18:49,994 - INFO -   [탐색 56] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:50,042 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:50,043 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:50,507 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:50,508 - INFO - ==================================================
2026-01-14 13:18:50,511 - INFO -   [탐색 57] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:50,576 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:50,576 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:51,196 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:51,197 - INFO - ==================================================
2026-01-14 13:18:51,199 - INFO -   [탐색 58] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:51,267 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:51,267 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:52,041 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:52,042 - INFO - ==================================================
2026-01-14 13:18:52,046 - INFO -   [탐색 59] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:52,097 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:52,098 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:52,603 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:52,603 - INFO - ==================================================
2026-01-14 13:18:52,606 - INFO -   [탐색 60] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:52,658 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:52,659 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:53,132 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:53,133 - INFO - ==================================================
2026-01-14 13:18:53,136 - INFO -   [탐색 61] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:53,202 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:53,203 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:53,637 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:53,638 - INFO - ==================================================
2026-01-14 13:18:53,641 - INFO -   [탐색 62] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:53,713 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:53,714 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:54,483 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:54,483 - INFO - ==================================================
2026-01-14 13:18:54,486 - INFO -   [탐색 63] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:54,546 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:54,547 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:55,273 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:55,273 - INFO - ==================================================
2026-01-14 13:18:55,276 - INFO -   [탐색 64] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:55,334 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:55,335 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:56,123 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:56,123 - INFO - ==================================================
2026-01-14 13:18:56,127 - INFO -   [탐색 65] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:56,199 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:56,200 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:56,788 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:56,790 - INFO - ==================================================
2026-01-14 13:18:56,792 - INFO -   [탐색 66] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:56,852 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:56,853 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:57,882 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:57,883 - INFO - ==================================================
2026-01-14 13:18:57,889 - INFO -   [탐색 67] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:57,954 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:57,954 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:58,610 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:58,611 - INFO - ==================================================
2026-01-14 13:18:58,614 - INFO -   [탐색 68] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:58,675 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:58,676 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:59,283 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:59,288 - INFO - ==================================================
2026-01-14 13:18:59,294 - INFO -   [탐색 69] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:18:59,395 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:18:59,397 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:18:59,936 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:18:59,937 - INFO - ==================================================
2026-01-14 13:18:59,940 - INFO -   [탐색 70] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:00,005 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:00,006 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:00,436 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:00,440 - INFO - ==================================================
2026-01-14 13:19:00,442 - INFO -   [탐색 71] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:00,499 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:00,500 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:00,888 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:00,889 - INFO - ==================================================
2026-01-14 13:19:00,891 - INFO -   [탐색 72] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:00,946 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:00,949 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:01,325 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:01,326 - INFO - ==================================================
2026-01-14 13:19:01,328 - INFO -   [탐색 73] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:01,374 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:01,375 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:01,643 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:01,643 - INFO - ==================================================
2026-01-14 13:19:01,645 - INFO -   [탐색 74] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:02,007 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:02,008 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:02,516 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:02,517 - INFO - ==================================================
2026-01-14 13:19:02,520 - INFO -   [탐색 75] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:02,560 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:02,560 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:02,891 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:02,892 - INFO - ==================================================
2026-01-14 13:19:02,894 - INFO -   [탐색 76] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:02,959 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:02,960 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:03,303 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:03,304 - INFO - ==================================================
2026-01-14 13:19:03,307 - INFO -   [탐색 77] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:03,373 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:03,373 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:03,804 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:03,805 - INFO - ==================================================
2026-01-14 13:19:03,807 - INFO -   [탐색 78] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:03,866 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:03,867 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:04,266 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:04,268 - INFO - ==================================================
2026-01-14 13:19:04,271 - INFO -   [탐색 79] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:04,334 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:04,334 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:04,856 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:04,856 - INFO - ==================================================
2026-01-14 13:19:04,858 - INFO -   [탐색 80] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:04,914 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:04,914 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:05,232 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:05,232 - INFO - ==================================================
2026-01-14 13:19:05,235 - INFO -   [탐색 81] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:05,297 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:05,297 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:06,066 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:06,067 - INFO - ==================================================
2026-01-14 13:19:06,071 - INFO -   [탐색 82] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:06,138 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:06,138 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:06,735 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:06,736 - INFO - ==================================================
2026-01-14 13:19:06,738 - INFO -   [탐색 83] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:06,781 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:06,781 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:07,099 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:07,100 - INFO - ==================================================
2026-01-14 13:19:07,102 - INFO -   [탐색 84] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:07,156 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:07,156 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:07,600 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:07,600 - INFO - ==================================================
2026-01-14 13:19:07,603 - INFO -   [탐색 85] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:07,651 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:07,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:08,182 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:08,182 - INFO - ==================================================
2026-01-14 13:19:08,185 - INFO -   [탐색 86] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:08,243 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:08,243 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:09,032 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:09,033 - INFO - ==================================================
2026-01-14 13:19:09,035 - INFO -   [탐색 87] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:09,093 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:09,093 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:09,545 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:09,546 - INFO - ==================================================
2026-01-14 13:19:09,549 - INFO -   [탐색 88] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:09,611 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:09,612 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:10,189 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:10,190 - INFO - ==================================================
2026-01-14 13:19:10,193 - INFO -   [탐색 89] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:10,257 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:10,258 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:11,072 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:11,072 - INFO - ==================================================
2026-01-14 13:19:11,077 - INFO -   [탐색 90] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:11,140 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:11,141 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:11,712 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:11,713 - INFO - ==================================================
2026-01-14 13:19:11,715 - INFO -   [탐색 91] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:11,777 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:11,778 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:12,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:12,142 - INFO - ==================================================
2026-01-14 13:19:12,144 - INFO -   [탐색 92] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:12,188 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:12,188 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:12,531 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:12,531 - INFO - ==================================================
2026-01-14 13:19:12,535 - INFO -   [탐색 93] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:12,613 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:12,614 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:12,963 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:12,964 - INFO - ==================================================
2026-01-14 13:19:12,966 - INFO -   [탐색 94] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:13,021 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:13,022 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:13,443 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:13,443 - INFO - ==================================================
2026-01-14 13:19:13,446 - INFO -   [탐색 95] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:13,508 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:13,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:14,036 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:14,037 - INFO - ==================================================
2026-01-14 13:19:14,039 - INFO -   [탐색 96] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:14,101 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:14,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:14,516 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:14,517 - INFO - ==================================================
2026-01-14 13:19:14,520 - INFO -   [탐색 97] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:14,902 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:14,903 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:15,329 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:15,329 - INFO - ==================================================
2026-01-14 13:19:15,332 - INFO -   [탐색 98] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:15,377 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:15,377 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:15,765 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:15,766 - INFO - ==================================================
2026-01-14 13:19:15,768 - INFO -   [탐색 99] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:15,814 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:15,815 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:16,259 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:19:16,260 - INFO - ==================================================
2026-01-14 13:19:16,262 - INFO -   [탐색 100] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:19:16,262 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9344 입니다.
2026-01-14 13:19:16,263 - INFO - ================================================================================
2026-01-14 13:19:16,267 - INFO - 계산된 Pruning 정보(희소도: 0.9344)를 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:19:16,326 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:19:16,470 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:16,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:16,994 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 13:19:16,994 - INFO - ==================================================
2026-01-14 13:19:16,998 - INFO - ==================================================
2026-01-14 13:19:16,999 - INFO - 모델 파라미터 수:
2026-01-14 13:19:16,999 - INFO -   - 총 파라미터: 31,288 개
2026-01-14 13:19:16,999 - INFO -   - 학습 가능한 파라미터: 31,288 개
2026-01-14 13:19:17,127 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:19:17,347 - INFO - FLOPs가 0.8277 GFLOPs에서 0.0120 GFLOPs로 감소했습니다 (감소율: 98.55%).
2026-01-14 13:19:17,348 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:19:17,348 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:19:17,349 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:19:17,350 - INFO - ==================================================
2026-01-14 13:19:17,350 - INFO - train 모드를 시작합니다.
2026-01-14 13:19:17,350 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:19:17,350 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:19:17,350 - INFO - --------------------------------------------------
2026-01-14 13:19:17,352 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:19:23,818 - INFO - [Train] [11/90] | Loss: 0.5865 | Train Acc: 73.14%
2026-01-14 13:19:25,939 - INFO - [Valid] [11/90] | Loss: 0.5356 | Val Acc: 74.93%
2026-01-14 13:19:25,953 - INFO - [Metrics for 'abnormal'] | Precision: 0.7338 | Recall: 0.7197 | F1: 0.7267
2026-01-14 13:19:25,954 - INFO - [Metrics for 'normal'] | Precision: 0.7622 | Recall: 0.7747 | F1: 0.7684
2026-01-14 13:19:26,003 - INFO - [Best Model Saved] (val loss: 0.5356) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:19:26,004 - INFO - --------------------------------------------------
2026-01-14 13:19:26,007 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:19:31,891 - INFO - [Train] [12/90] | Loss: 0.5307 | Train Acc: 78.57%
2026-01-14 13:19:33,911 - INFO - [Valid] [12/90] | Loss: 0.5222 | Val Acc: 77.88%
2026-01-14 13:19:33,920 - INFO - [Metrics for 'abnormal'] | Precision: 0.8106 | Recall: 0.6815 | F1: 0.7405
2026-01-14 13:19:33,921 - INFO - [Metrics for 'normal'] | Precision: 0.7585 | Recall: 0.8626 | F1: 0.8072
2026-01-14 13:19:33,961 - INFO - [Best Model Saved] (val loss: 0.5222) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:19:33,962 - INFO - --------------------------------------------------
2026-01-14 13:19:33,964 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:19:40,031 - INFO - [Train] [13/90] | Loss: 0.4963 | Train Acc: 79.91%
2026-01-14 13:19:42,368 - INFO - [Valid] [13/90] | Loss: 0.5434 | Val Acc: 76.70%
2026-01-14 13:19:42,404 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.6497 | F1: 0.7208
2026-01-14 13:19:42,406 - INFO - [Metrics for 'normal'] | Precision: 0.7418 | Recall: 0.8681 | F1: 0.8000
2026-01-14 13:19:42,411 - INFO - --------------------------------------------------
2026-01-14 13:19:42,413 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:19:48,398 - INFO - [Train] [14/90] | Loss: 0.4882 | Train Acc: 81.32%
2026-01-14 13:19:50,624 - INFO - [Valid] [14/90] | Loss: 0.5440 | Val Acc: 76.99%
2026-01-14 13:19:50,636 - INFO - [Metrics for 'abnormal'] | Precision: 0.7310 | Recall: 0.7962 | F1: 0.7622
2026-01-14 13:19:50,636 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.7473 | F1: 0.7771
2026-01-14 13:19:50,640 - INFO - --------------------------------------------------
2026-01-14 13:19:50,644 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:19:56,527 - INFO - [Train] [15/90] | Loss: 0.4958 | Train Acc: 81.03%
2026-01-14 13:19:58,446 - INFO - [Valid] [15/90] | Loss: 0.5285 | Val Acc: 78.47%
2026-01-14 13:19:58,457 - INFO - [Metrics for 'abnormal'] | Precision: 0.7593 | Recall: 0.7834 | F1: 0.7712
2026-01-14 13:19:58,457 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.7857 | F1: 0.7967
2026-01-14 13:19:58,461 - INFO - --------------------------------------------------
2026-01-14 13:19:58,463 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:20:03,809 - INFO - [Train] [16/90] | Loss: 0.4730 | Train Acc: 82.89%
2026-01-14 13:20:05,257 - INFO - [Valid] [16/90] | Loss: 0.5452 | Val Acc: 79.94%
2026-01-14 13:20:05,266 - INFO - [Metrics for 'abnormal'] | Precision: 0.8201 | Recall: 0.7261 | F1: 0.7703
2026-01-14 13:20:05,267 - INFO - [Metrics for 'normal'] | Precision: 0.7850 | Recall: 0.8626 | F1: 0.8220
2026-01-14 13:20:05,270 - INFO - --------------------------------------------------
2026-01-14 13:20:05,272 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:20:09,995 - INFO - [Train] [17/90] | Loss: 0.4745 | Train Acc: 82.07%
2026-01-14 13:20:11,455 - INFO - [Valid] [17/90] | Loss: 0.5704 | Val Acc: 77.88%
2026-01-14 13:20:11,464 - INFO - [Metrics for 'abnormal'] | Precision: 0.8417 | Recall: 0.6433 | F1: 0.7292
2026-01-14 13:20:11,464 - INFO - [Metrics for 'normal'] | Precision: 0.7443 | Recall: 0.8956 | F1: 0.8130
2026-01-14 13:20:11,468 - INFO - --------------------------------------------------
2026-01-14 13:20:11,471 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:20:16,357 - INFO - [Train] [18/90] | Loss: 0.4751 | Train Acc: 82.37%
2026-01-14 13:20:17,878 - INFO - [Valid] [18/90] | Loss: 0.5714 | Val Acc: 77.88%
2026-01-14 13:20:17,886 - INFO - [Metrics for 'abnormal'] | Precision: 0.7181 | Recall: 0.8599 | F1: 0.7826
2026-01-14 13:20:17,887 - INFO - [Metrics for 'normal'] | Precision: 0.8543 | Recall: 0.7088 | F1: 0.7748
2026-01-14 13:20:17,890 - INFO - --------------------------------------------------
2026-01-14 13:20:17,892 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:20:22,700 - INFO - [Train] [19/90] | Loss: 0.4692 | Train Acc: 82.51%
2026-01-14 13:20:24,102 - INFO - [Valid] [19/90] | Loss: 0.5164 | Val Acc: 79.94%
2026-01-14 13:20:24,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 13:20:24,111 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 13:20:24,154 - INFO - [Best Model Saved] (val loss: 0.5164) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:20:24,155 - INFO - --------------------------------------------------
2026-01-14 13:20:24,157 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:20:29,428 - INFO - [Train] [20/90] | Loss: 0.4632 | Train Acc: 83.33%
2026-01-14 13:20:31,367 - INFO - [Valid] [20/90] | Loss: 0.5411 | Val Acc: 79.06%
2026-01-14 13:20:31,380 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-01-14 13:20:31,380 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-01-14 13:20:31,384 - INFO - --------------------------------------------------
2026-01-14 13:20:31,388 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:20:37,819 - INFO - [Train] [21/90] | Loss: 0.4617 | Train Acc: 82.14%
2026-01-14 13:20:40,381 - INFO - [Valid] [21/90] | Loss: 0.5011 | Val Acc: 79.94%
2026-01-14 13:20:40,393 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8471 | F1: 0.7964
2026-01-14 13:20:40,393 - INFO - [Metrics for 'normal'] | Precision: 0.8519 | Recall: 0.7582 | F1: 0.8023
2026-01-14 13:20:40,441 - INFO - [Best Model Saved] (val loss: 0.5011) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:20:40,441 - INFO - --------------------------------------------------
2026-01-14 13:20:40,444 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:20:46,494 - INFO - [Train] [22/90] | Loss: 0.4498 | Train Acc: 83.85%
2026-01-14 13:20:48,472 - INFO - [Valid] [22/90] | Loss: 0.5406 | Val Acc: 78.76%
2026-01-14 13:20:48,485 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-01-14 13:20:48,486 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-01-14 13:20:48,491 - INFO - --------------------------------------------------
2026-01-14 13:20:48,494 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:20:55,293 - INFO - [Train] [23/90] | Loss: 0.4362 | Train Acc: 84.75%
2026-01-14 13:20:57,423 - INFO - [Valid] [23/90] | Loss: 0.4975 | Val Acc: 80.53%
2026-01-14 13:20:57,434 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 13:20:57,435 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 13:20:57,482 - INFO - [Best Model Saved] (val loss: 0.4975) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:20:57,483 - INFO - --------------------------------------------------
2026-01-14 13:20:57,485 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:21:05,318 - INFO - [Train] [24/90] | Loss: 0.4374 | Train Acc: 85.12%
2026-01-14 13:21:07,763 - INFO - [Valid] [24/90] | Loss: 0.5539 | Val Acc: 79.06%
2026-01-14 13:21:07,779 - INFO - [Metrics for 'abnormal'] | Precision: 0.8525 | Recall: 0.6624 | F1: 0.7455
2026-01-14 13:21:07,780 - INFO - [Metrics for 'normal'] | Precision: 0.7558 | Recall: 0.9011 | F1: 0.8221
2026-01-14 13:21:07,786 - INFO - --------------------------------------------------
2026-01-14 13:21:07,789 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:21:14,223 - INFO - [Train] [25/90] | Loss: 0.4346 | Train Acc: 85.57%
2026-01-14 13:21:17,251 - INFO - [Valid] [25/90] | Loss: 0.5108 | Val Acc: 79.94%
2026-01-14 13:21:17,279 - INFO - [Metrics for 'abnormal'] | Precision: 0.8201 | Recall: 0.7261 | F1: 0.7703
2026-01-14 13:21:17,280 - INFO - [Metrics for 'normal'] | Precision: 0.7850 | Recall: 0.8626 | F1: 0.8220
2026-01-14 13:21:17,284 - INFO - --------------------------------------------------
2026-01-14 13:21:17,295 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:21:24,354 - INFO - [Train] [26/90] | Loss: 0.4258 | Train Acc: 86.68%
2026-01-14 13:21:26,757 - INFO - [Valid] [26/90] | Loss: 0.5782 | Val Acc: 79.06%
2026-01-14 13:21:26,766 - INFO - [Metrics for 'abnormal'] | Precision: 0.7363 | Recall: 0.8535 | F1: 0.7906
2026-01-14 13:21:26,766 - INFO - [Metrics for 'normal'] | Precision: 0.8535 | Recall: 0.7363 | F1: 0.7906
2026-01-14 13:21:26,770 - INFO - --------------------------------------------------
2026-01-14 13:21:26,775 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:21:33,482 - INFO - [Train] [27/90] | Loss: 0.4201 | Train Acc: 86.09%
2026-01-14 13:21:35,862 - INFO - [Valid] [27/90] | Loss: 0.5653 | Val Acc: 80.24%
2026-01-14 13:21:35,871 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:21:35,872 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:21:35,876 - INFO - --------------------------------------------------
2026-01-14 13:21:35,878 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:21:42,812 - INFO - [Train] [28/90] | Loss: 0.4180 | Train Acc: 86.24%
2026-01-14 13:21:45,058 - INFO - [Valid] [28/90] | Loss: 0.5530 | Val Acc: 79.94%
2026-01-14 13:21:45,072 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8471 | F1: 0.7964
2026-01-14 13:21:45,073 - INFO - [Metrics for 'normal'] | Precision: 0.8519 | Recall: 0.7582 | F1: 0.8023
2026-01-14 13:21:45,077 - INFO - --------------------------------------------------
2026-01-14 13:21:45,080 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:21:52,180 - INFO - [Train] [29/90] | Loss: 0.4085 | Train Acc: 86.61%
2026-01-14 13:21:54,501 - INFO - [Valid] [29/90] | Loss: 0.5503 | Val Acc: 80.24%
2026-01-14 13:21:54,513 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 13:21:54,513 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 13:21:54,517 - INFO - --------------------------------------------------
2026-01-14 13:21:54,520 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:22:03,414 - INFO - [Train] [30/90] | Loss: 0.4008 | Train Acc: 87.72%
2026-01-14 13:22:05,968 - INFO - [Valid] [30/90] | Loss: 0.5398 | Val Acc: 80.83%
2026-01-14 13:22:06,041 - INFO - [Metrics for 'abnormal'] | Precision: 0.8194 | Recall: 0.7516 | F1: 0.7841
2026-01-14 13:22:06,042 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8571 | F1: 0.8276
2026-01-14 13:22:06,047 - INFO - --------------------------------------------------
2026-01-14 13:22:06,050 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:22:14,978 - INFO - [Train] [31/90] | Loss: 0.4146 | Train Acc: 86.90%
2026-01-14 13:22:17,472 - INFO - [Valid] [31/90] | Loss: 0.5482 | Val Acc: 79.94%
2026-01-14 13:22:17,485 - INFO - [Metrics for 'abnormal'] | Precision: 0.7543 | Recall: 0.8408 | F1: 0.7952
2026-01-14 13:22:17,486 - INFO - [Metrics for 'normal'] | Precision: 0.8476 | Recall: 0.7637 | F1: 0.8035
2026-01-14 13:22:17,490 - INFO - --------------------------------------------------
2026-01-14 13:22:17,493 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:22:26,411 - INFO - [Train] [32/90] | Loss: 0.4230 | Train Acc: 86.24%
2026-01-14 13:22:28,461 - INFO - [Valid] [32/90] | Loss: 0.5261 | Val Acc: 81.12%
2026-01-14 13:22:28,474 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:22:28,475 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:22:28,480 - INFO - --------------------------------------------------
2026-01-14 13:22:28,483 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:22:37,359 - INFO - [Train] [33/90] | Loss: 0.4154 | Train Acc: 86.83%
2026-01-14 13:22:39,772 - INFO - [Valid] [33/90] | Loss: 0.5179 | Val Acc: 80.83%
2026-01-14 13:22:39,784 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 13:22:39,785 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 13:22:39,790 - INFO - --------------------------------------------------
2026-01-14 13:22:39,793 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:22:48,998 - INFO - [Train] [34/90] | Loss: 0.3889 | Train Acc: 88.62%
2026-01-14 13:22:51,162 - INFO - [Valid] [34/90] | Loss: 0.5026 | Val Acc: 81.42%
2026-01-14 13:22:51,175 - INFO - [Metrics for 'abnormal'] | Precision: 0.7901 | Recall: 0.8153 | F1: 0.8025
2026-01-14 13:22:51,176 - INFO - [Metrics for 'normal'] | Precision: 0.8362 | Recall: 0.8132 | F1: 0.8245
2026-01-14 13:22:51,180 - INFO - --------------------------------------------------
2026-01-14 13:22:51,183 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:23:00,908 - INFO - [Train] [35/90] | Loss: 0.4073 | Train Acc: 86.24%
2026-01-14 13:23:02,904 - INFO - [Valid] [35/90] | Loss: 0.5067 | Val Acc: 79.94%
2026-01-14 13:23:02,916 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-01-14 13:23:02,917 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-01-14 13:23:02,921 - INFO - --------------------------------------------------
2026-01-14 13:23:02,924 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:23:12,461 - INFO - [Train] [36/90] | Loss: 0.4066 | Train Acc: 87.72%
2026-01-14 13:23:14,733 - INFO - [Valid] [36/90] | Loss: 0.5332 | Val Acc: 79.35%
2026-01-14 13:23:14,741 - INFO - [Metrics for 'abnormal'] | Precision: 0.7669 | Recall: 0.7962 | F1: 0.7812
2026-01-14 13:23:14,741 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.7912 | F1: 0.8045
2026-01-14 13:23:14,745 - INFO - --------------------------------------------------
2026-01-14 13:23:14,746 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:23:24,176 - INFO - [Train] [37/90] | Loss: 0.3987 | Train Acc: 87.50%
2026-01-14 13:23:27,064 - INFO - [Valid] [37/90] | Loss: 0.5500 | Val Acc: 80.24%
2026-01-14 13:23:27,074 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 13:23:27,074 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 13:23:27,078 - INFO - --------------------------------------------------
2026-01-14 13:23:27,080 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:23:35,715 - INFO - [Train] [38/90] | Loss: 0.3894 | Train Acc: 87.65%
2026-01-14 13:23:38,219 - INFO - [Valid] [38/90] | Loss: 0.5438 | Val Acc: 79.35%
2026-01-14 13:23:38,238 - INFO - [Metrics for 'abnormal'] | Precision: 0.7636 | Recall: 0.8025 | F1: 0.7826
2026-01-14 13:23:38,240 - INFO - [Metrics for 'normal'] | Precision: 0.8218 | Recall: 0.7857 | F1: 0.8034
2026-01-14 13:23:38,244 - INFO - --------------------------------------------------
2026-01-14 13:23:38,247 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:23:47,059 - INFO - [Train] [39/90] | Loss: 0.3829 | Train Acc: 88.84%
2026-01-14 13:23:49,508 - INFO - [Valid] [39/90] | Loss: 0.5634 | Val Acc: 79.94%
2026-01-14 13:23:49,601 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-01-14 13:23:49,601 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-01-14 13:23:49,606 - INFO - --------------------------------------------------
2026-01-14 13:23:49,609 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:24:00,102 - INFO - [Train] [40/90] | Loss: 0.3674 | Train Acc: 89.58%
2026-01-14 13:24:02,508 - INFO - [Valid] [40/90] | Loss: 0.5831 | Val Acc: 79.35%
2026-01-14 13:24:02,532 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-01-14 13:24:02,533 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-01-14 13:24:02,538 - INFO - --------------------------------------------------
2026-01-14 13:24:02,550 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:24:11,267 - INFO - [Train] [41/90] | Loss: 0.3742 | Train Acc: 89.14%
2026-01-14 13:24:14,374 - INFO - [Valid] [41/90] | Loss: 0.5665 | Val Acc: 79.35%
2026-01-14 13:24:14,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-01-14 13:24:14,397 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-01-14 13:24:14,401 - INFO - --------------------------------------------------
2026-01-14 13:24:14,405 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:24:22,503 - INFO - [Train] [42/90] | Loss: 0.3717 | Train Acc: 88.99%
2026-01-14 13:24:24,982 - INFO - [Valid] [42/90] | Loss: 0.5490 | Val Acc: 80.53%
2026-01-14 13:24:25,005 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 13:24:25,006 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 13:24:25,009 - INFO - --------------------------------------------------
2026-01-14 13:24:25,012 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:24:33,551 - INFO - [Train] [43/90] | Loss: 0.3598 | Train Acc: 91.37%
2026-01-14 13:24:36,017 - INFO - [Valid] [43/90] | Loss: 0.5877 | Val Acc: 81.12%
2026-01-14 13:24:36,031 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 13:24:36,032 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 13:24:36,037 - INFO - --------------------------------------------------
2026-01-14 13:24:36,041 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:24:43,815 - INFO - [Train] [44/90] | Loss: 0.3723 | Train Acc: 89.29%
2026-01-14 13:24:46,355 - INFO - [Valid] [44/90] | Loss: 0.5650 | Val Acc: 78.17%
2026-01-14 13:24:46,367 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-01-14 13:24:46,367 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-01-14 13:24:46,372 - INFO - --------------------------------------------------
2026-01-14 13:24:46,375 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:24:54,739 - INFO - [Train] [45/90] | Loss: 0.3550 | Train Acc: 90.03%
2026-01-14 13:24:56,957 - INFO - [Valid] [45/90] | Loss: 0.5461 | Val Acc: 79.94%
2026-01-14 13:24:56,970 - INFO - [Metrics for 'abnormal'] | Precision: 0.7908 | Recall: 0.7707 | F1: 0.7806
2026-01-14 13:24:56,971 - INFO - [Metrics for 'normal'] | Precision: 0.8065 | Recall: 0.8242 | F1: 0.8152
2026-01-14 13:24:56,975 - INFO - --------------------------------------------------
2026-01-14 13:24:56,979 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:25:07,080 - INFO - [Train] [46/90] | Loss: 0.3503 | Train Acc: 91.22%
2026-01-14 13:25:09,275 - INFO - [Valid] [46/90] | Loss: 0.5611 | Val Acc: 79.35%
2026-01-14 13:25:09,290 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:25:09,290 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:25:09,299 - INFO - --------------------------------------------------
2026-01-14 13:25:09,303 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:25:18,766 - INFO - [Train] [47/90] | Loss: 0.3471 | Train Acc: 90.92%
2026-01-14 13:25:20,939 - INFO - [Valid] [47/90] | Loss: 0.5551 | Val Acc: 79.94%
2026-01-14 13:25:20,960 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-01-14 13:25:20,960 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-01-14 13:25:20,964 - INFO - --------------------------------------------------
2026-01-14 13:25:20,967 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:25:29,441 - INFO - [Train] [48/90] | Loss: 0.3476 | Train Acc: 91.29%
2026-01-14 13:25:31,832 - INFO - [Valid] [48/90] | Loss: 0.5567 | Val Acc: 78.17%
2026-01-14 13:25:31,846 - INFO - [Metrics for 'abnormal'] | Precision: 0.7610 | Recall: 0.7707 | F1: 0.7658
2026-01-14 13:25:31,847 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7912 | F1: 0.7956
2026-01-14 13:25:31,851 - INFO - --------------------------------------------------
2026-01-14 13:25:31,854 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:25:40,534 - INFO - [Train] [49/90] | Loss: 0.3281 | Train Acc: 91.74%
2026-01-14 13:25:42,812 - INFO - [Valid] [49/90] | Loss: 0.5809 | Val Acc: 78.17%
2026-01-14 13:25:42,823 - INFO - [Metrics for 'abnormal'] | Precision: 0.7712 | Recall: 0.7516 | F1: 0.7613
2026-01-14 13:25:42,823 - INFO - [Metrics for 'normal'] | Precision: 0.7903 | Recall: 0.8077 | F1: 0.7989
2026-01-14 13:25:42,827 - INFO - --------------------------------------------------
2026-01-14 13:25:42,830 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:25:52,017 - INFO - [Train] [50/90] | Loss: 0.3500 | Train Acc: 90.92%
2026-01-14 13:25:54,149 - INFO - [Valid] [50/90] | Loss: 0.5742 | Val Acc: 79.94%
2026-01-14 13:25:54,158 - INFO - [Metrics for 'abnormal'] | Precision: 0.8069 | Recall: 0.7452 | F1: 0.7748
2026-01-14 13:25:54,158 - INFO - [Metrics for 'normal'] | Precision: 0.7938 | Recall: 0.8462 | F1: 0.8191
2026-01-14 13:25:54,162 - INFO - --------------------------------------------------
2026-01-14 13:25:54,164 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:26:03,616 - INFO - [Train] [51/90] | Loss: 0.3389 | Train Acc: 92.04%
2026-01-14 13:26:05,825 - INFO - [Valid] [51/90] | Loss: 0.5708 | Val Acc: 79.35%
2026-01-14 13:26:05,834 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:26:05,834 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:26:05,838 - INFO - --------------------------------------------------
2026-01-14 13:26:05,841 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:26:14,186 - INFO - [Train] [52/90] | Loss: 0.3443 | Train Acc: 91.82%
2026-01-14 13:26:17,127 - INFO - [Valid] [52/90] | Loss: 0.5829 | Val Acc: 79.06%
2026-01-14 13:26:17,140 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-01-14 13:26:17,140 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-01-14 13:26:17,146 - INFO - --------------------------------------------------
2026-01-14 13:26:17,149 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:26:25,200 - INFO - [Train] [53/90] | Loss: 0.3266 | Train Acc: 91.96%
2026-01-14 13:26:27,695 - INFO - [Valid] [53/90] | Loss: 0.5759 | Val Acc: 79.35%
2026-01-14 13:26:27,706 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-01-14 13:26:27,706 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-01-14 13:26:27,711 - INFO - --------------------------------------------------
2026-01-14 13:26:27,713 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:26:35,836 - INFO - [Train] [54/90] | Loss: 0.3220 | Train Acc: 92.34%
2026-01-14 13:26:39,429 - INFO - [Valid] [54/90] | Loss: 0.6045 | Val Acc: 79.94%
2026-01-14 13:26:39,440 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 13:26:39,440 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 13:26:39,444 - INFO - --------------------------------------------------
2026-01-14 13:26:39,447 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:26:47,798 - INFO - [Train] [55/90] | Loss: 0.3356 | Train Acc: 91.82%
2026-01-14 13:26:51,333 - INFO - [Valid] [55/90] | Loss: 0.5968 | Val Acc: 77.88%
2026-01-14 13:26:51,343 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.7389 | F1: 0.7557
2026-01-14 13:26:51,344 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.8132 | F1: 0.7978
2026-01-14 13:26:51,347 - INFO - --------------------------------------------------
2026-01-14 13:26:51,350 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:26:59,685 - INFO - [Train] [56/90] | Loss: 0.3204 | Train Acc: 93.45%
2026-01-14 13:27:02,733 - INFO - [Valid] [56/90] | Loss: 0.5976 | Val Acc: 79.06%
2026-01-14 13:27:02,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-01-14 13:27:02,745 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-01-14 13:27:02,748 - INFO - --------------------------------------------------
2026-01-14 13:27:02,750 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:27:10,563 - INFO - [Train] [57/90] | Loss: 0.3278 | Train Acc: 92.78%
2026-01-14 13:27:13,554 - INFO - [Valid] [57/90] | Loss: 0.5706 | Val Acc: 78.17%
2026-01-14 13:27:13,569 - INFO - [Metrics for 'abnormal'] | Precision: 0.7610 | Recall: 0.7707 | F1: 0.7658
2026-01-14 13:27:13,570 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7912 | F1: 0.7956
2026-01-14 13:27:13,573 - INFO - --------------------------------------------------
2026-01-14 13:27:13,576 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:27:22,447 - INFO - [Train] [58/90] | Loss: 0.3073 | Train Acc: 94.27%
2026-01-14 13:27:25,987 - INFO - [Valid] [58/90] | Loss: 0.6239 | Val Acc: 78.47%
2026-01-14 13:27:25,999 - INFO - [Metrics for 'abnormal'] | Precision: 0.7800 | Recall: 0.7452 | F1: 0.7622
2026-01-14 13:27:25,999 - INFO - [Metrics for 'normal'] | Precision: 0.7884 | Recall: 0.8187 | F1: 0.8032
2026-01-14 13:27:26,003 - INFO - --------------------------------------------------
2026-01-14 13:27:26,005 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:27:35,056 - INFO - [Train] [59/90] | Loss: 0.3118 | Train Acc: 94.35%
2026-01-14 13:27:37,686 - INFO - [Valid] [59/90] | Loss: 0.5991 | Val Acc: 78.17%
2026-01-14 13:27:37,699 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-01-14 13:27:37,700 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-01-14 13:27:37,704 - INFO - --------------------------------------------------
2026-01-14 13:27:37,707 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:27:46,565 - INFO - [Train] [60/90] | Loss: 0.3223 | Train Acc: 92.86%
2026-01-14 13:27:48,903 - INFO - [Valid] [60/90] | Loss: 0.5611 | Val Acc: 79.06%
2026-01-14 13:27:48,916 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 13:27:48,917 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 13:27:48,922 - INFO - --------------------------------------------------
2026-01-14 13:27:48,925 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:27:57,357 - INFO - [Train] [61/90] | Loss: 0.3001 | Train Acc: 94.05%
2026-01-14 13:28:00,441 - INFO - [Valid] [61/90] | Loss: 0.6325 | Val Acc: 77.29%
2026-01-14 13:28:00,452 - INFO - [Metrics for 'abnormal'] | Precision: 0.7564 | Recall: 0.7516 | F1: 0.7540
2026-01-14 13:28:00,453 - INFO - [Metrics for 'normal'] | Precision: 0.7869 | Recall: 0.7912 | F1: 0.7890
2026-01-14 13:28:00,457 - INFO - --------------------------------------------------
2026-01-14 13:28:00,460 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:28:09,287 - INFO - [Train] [62/90] | Loss: 0.3154 | Train Acc: 93.68%
2026-01-14 13:28:11,410 - INFO - [Valid] [62/90] | Loss: 0.5726 | Val Acc: 79.35%
2026-01-14 13:28:11,422 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:28:11,423 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:28:11,457 - INFO - --------------------------------------------------
2026-01-14 13:28:11,460 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:28:21,621 - INFO - [Train] [63/90] | Loss: 0.2957 | Train Acc: 94.57%
2026-01-14 13:28:23,784 - INFO - [Valid] [63/90] | Loss: 0.6347 | Val Acc: 77.29%
2026-01-14 13:28:23,796 - INFO - [Metrics for 'abnormal'] | Precision: 0.7564 | Recall: 0.7516 | F1: 0.7540
2026-01-14 13:28:23,797 - INFO - [Metrics for 'normal'] | Precision: 0.7869 | Recall: 0.7912 | F1: 0.7890
2026-01-14 13:28:23,801 - INFO - --------------------------------------------------
2026-01-14 13:28:23,804 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:28:33,285 - INFO - [Train] [64/90] | Loss: 0.2915 | Train Acc: 94.35%
2026-01-14 13:28:35,799 - INFO - [Valid] [64/90] | Loss: 0.6262 | Val Acc: 79.06%
2026-01-14 13:28:35,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-01-14 13:28:35,810 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-01-14 13:28:35,813 - INFO - --------------------------------------------------
2026-01-14 13:28:35,816 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:28:45,864 - INFO - [Train] [65/90] | Loss: 0.2943 | Train Acc: 94.57%
2026-01-14 13:28:48,486 - INFO - [Valid] [65/90] | Loss: 0.6218 | Val Acc: 78.47%
2026-01-14 13:28:48,497 - INFO - [Metrics for 'abnormal'] | Precision: 0.7763 | Recall: 0.7516 | F1: 0.7638
2026-01-14 13:28:48,498 - INFO - [Metrics for 'normal'] | Precision: 0.7914 | Recall: 0.8132 | F1: 0.8022
2026-01-14 13:28:48,503 - INFO - --------------------------------------------------
2026-01-14 13:28:48,506 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:28:57,577 - INFO - [Train] [66/90] | Loss: 0.3100 | Train Acc: 93.82%
2026-01-14 13:29:00,491 - INFO - [Valid] [66/90] | Loss: 0.6382 | Val Acc: 78.76%
2026-01-14 13:29:00,501 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-01-14 13:29:00,502 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-01-14 13:29:00,505 - INFO - --------------------------------------------------
2026-01-14 13:29:00,508 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:29:10,102 - INFO - [Train] [67/90] | Loss: 0.2757 | Train Acc: 95.83%
2026-01-14 13:29:12,560 - INFO - [Valid] [67/90] | Loss: 0.6305 | Val Acc: 79.65%
2026-01-14 13:29:12,572 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-01-14 13:29:12,572 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-01-14 13:29:12,576 - INFO - --------------------------------------------------
2026-01-14 13:29:12,578 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:29:21,703 - INFO - [Train] [68/90] | Loss: 0.2905 | Train Acc: 95.54%
2026-01-14 13:29:24,615 - INFO - [Valid] [68/90] | Loss: 0.6338 | Val Acc: 78.76%
2026-01-14 13:29:24,637 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.8153 | F1: 0.7805
2026-01-14 13:29:24,640 - INFO - [Metrics for 'normal'] | Precision: 0.8274 | Recall: 0.7637 | F1: 0.7943
2026-01-14 13:29:24,649 - INFO - --------------------------------------------------
2026-01-14 13:29:24,653 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:29:33,169 - INFO - [Train] [69/90] | Loss: 0.2924 | Train Acc: 94.87%
2026-01-14 13:29:36,102 - INFO - [Valid] [69/90] | Loss: 0.6001 | Val Acc: 79.65%
2026-01-14 13:29:36,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-01-14 13:29:36,111 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-01-14 13:29:36,115 - INFO - --------------------------------------------------
2026-01-14 13:29:36,117 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:29:44,621 - INFO - [Train] [70/90] | Loss: 0.2769 | Train Acc: 96.13%
2026-01-14 13:29:47,665 - INFO - [Valid] [70/90] | Loss: 0.6256 | Val Acc: 76.70%
2026-01-14 13:29:47,674 - INFO - [Metrics for 'abnormal'] | Precision: 0.7468 | Recall: 0.7516 | F1: 0.7492
2026-01-14 13:29:47,674 - INFO - [Metrics for 'normal'] | Precision: 0.7845 | Recall: 0.7802 | F1: 0.7824
2026-01-14 13:29:47,677 - INFO - --------------------------------------------------
2026-01-14 13:29:47,679 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:29:57,187 - INFO - [Train] [71/90] | Loss: 0.2768 | Train Acc: 95.98%
2026-01-14 13:29:59,871 - INFO - [Valid] [71/90] | Loss: 0.6403 | Val Acc: 77.88%
2026-01-14 13:29:59,883 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-01-14 13:29:59,884 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-01-14 13:29:59,889 - INFO - --------------------------------------------------
2026-01-14 13:29:59,892 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:30:09,164 - INFO - [Train] [72/90] | Loss: 0.2655 | Train Acc: 97.10%
2026-01-14 13:30:12,169 - INFO - [Valid] [72/90] | Loss: 0.6531 | Val Acc: 77.88%
2026-01-14 13:30:12,181 - INFO - [Metrics for 'abnormal'] | Precision: 0.7770 | Recall: 0.7325 | F1: 0.7541
2026-01-14 13:30:12,183 - INFO - [Metrics for 'normal'] | Precision: 0.7801 | Recall: 0.8187 | F1: 0.7989
2026-01-14 13:30:12,193 - INFO - --------------------------------------------------
2026-01-14 13:30:12,196 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:30:21,691 - INFO - [Train] [73/90] | Loss: 0.2765 | Train Acc: 96.50%
2026-01-14 13:30:24,628 - INFO - [Valid] [73/90] | Loss: 0.6361 | Val Acc: 78.76%
2026-01-14 13:30:24,681 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-01-14 13:30:24,681 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-01-14 13:30:24,685 - INFO - --------------------------------------------------
2026-01-14 13:30:24,687 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:30:34,177 - INFO - [Train] [74/90] | Loss: 0.2915 | Train Acc: 95.31%
2026-01-14 13:30:36,861 - INFO - [Valid] [74/90] | Loss: 0.6113 | Val Acc: 77.29%
2026-01-14 13:30:36,896 - INFO - [Metrics for 'abnormal'] | Precision: 0.7632 | Recall: 0.7389 | F1: 0.7508
2026-01-14 13:30:36,898 - INFO - [Metrics for 'normal'] | Precision: 0.7807 | Recall: 0.8022 | F1: 0.7913
2026-01-14 13:30:36,903 - INFO - --------------------------------------------------
2026-01-14 13:30:36,909 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:30:46,067 - INFO - [Train] [75/90] | Loss: 0.2827 | Train Acc: 96.13%
2026-01-14 13:30:48,304 - INFO - [Valid] [75/90] | Loss: 0.6268 | Val Acc: 78.47%
2026-01-14 13:30:48,316 - INFO - [Metrics for 'abnormal'] | Precision: 0.7838 | Recall: 0.7389 | F1: 0.7607
2026-01-14 13:30:48,316 - INFO - [Metrics for 'normal'] | Precision: 0.7853 | Recall: 0.8242 | F1: 0.8043
2026-01-14 13:30:48,320 - INFO - --------------------------------------------------
2026-01-14 13:30:48,323 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:30:57,026 - INFO - [Train] [76/90] | Loss: 0.2790 | Train Acc: 95.83%
2026-01-14 13:30:59,051 - INFO - [Valid] [76/90] | Loss: 0.6410 | Val Acc: 77.88%
2026-01-14 13:30:59,064 - INFO - [Metrics for 'abnormal'] | Precision: 0.7595 | Recall: 0.7643 | F1: 0.7619
2026-01-14 13:30:59,065 - INFO - [Metrics for 'normal'] | Precision: 0.7956 | Recall: 0.7912 | F1: 0.7934
2026-01-14 13:30:59,069 - INFO - --------------------------------------------------
2026-01-14 13:30:59,073 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:31:07,459 - INFO - [Train] [77/90] | Loss: 0.2742 | Train Acc: 96.50%
2026-01-14 13:31:09,732 - INFO - [Valid] [77/90] | Loss: 0.6245 | Val Acc: 78.76%
2026-01-14 13:31:09,742 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.7452 | F1: 0.7647
2026-01-14 13:31:09,742 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.8242 | F1: 0.8065
2026-01-14 13:31:09,747 - INFO - --------------------------------------------------
2026-01-14 13:31:09,750 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:31:18,478 - INFO - [Train] [78/90] | Loss: 0.2778 | Train Acc: 95.91%
2026-01-14 13:31:21,069 - INFO - [Valid] [78/90] | Loss: 0.6337 | Val Acc: 77.29%
2026-01-14 13:31:21,078 - INFO - [Metrics for 'abnormal'] | Precision: 0.7667 | Recall: 0.7325 | F1: 0.7492
2026-01-14 13:31:21,079 - INFO - [Metrics for 'normal'] | Precision: 0.7778 | Recall: 0.8077 | F1: 0.7925
2026-01-14 13:31:21,082 - INFO - --------------------------------------------------
2026-01-14 13:31:21,085 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:31:29,677 - INFO - [Train] [79/90] | Loss: 0.2805 | Train Acc: 95.61%
2026-01-14 13:31:33,593 - INFO - [Valid] [79/90] | Loss: 0.6217 | Val Acc: 77.58%
2026-01-14 13:31:33,605 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.7643 | F1: 0.7595
2026-01-14 13:31:33,606 - INFO - [Metrics for 'normal'] | Precision: 0.7944 | Recall: 0.7857 | F1: 0.7901
2026-01-14 13:31:33,611 - INFO - --------------------------------------------------
2026-01-14 13:31:33,613 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:31:41,814 - INFO - [Train] [80/90] | Loss: 0.2677 | Train Acc: 96.73%
2026-01-14 13:31:45,342 - INFO - [Valid] [80/90] | Loss: 0.6194 | Val Acc: 76.70%
2026-01-14 13:31:45,365 - INFO - [Metrics for 'abnormal'] | Precision: 0.7438 | Recall: 0.7580 | F1: 0.7508
2026-01-14 13:31:45,369 - INFO - [Metrics for 'normal'] | Precision: 0.7877 | Recall: 0.7747 | F1: 0.7812
2026-01-14 13:31:45,373 - INFO - --------------------------------------------------
2026-01-14 13:31:45,379 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:31:54,350 - INFO - [Train] [81/90] | Loss: 0.2654 | Train Acc: 96.28%
2026-01-14 13:31:56,659 - INFO - [Valid] [81/90] | Loss: 0.6350 | Val Acc: 77.29%
2026-01-14 13:31:56,721 - INFO - [Metrics for 'abnormal'] | Precision: 0.7469 | Recall: 0.7707 | F1: 0.7586
2026-01-14 13:31:56,722 - INFO - [Metrics for 'normal'] | Precision: 0.7966 | Recall: 0.7747 | F1: 0.7855
2026-01-14 13:31:56,725 - INFO - --------------------------------------------------
2026-01-14 13:31:56,728 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:32:05,141 - INFO - [Train] [82/90] | Loss: 0.2693 | Train Acc: 96.88%
2026-01-14 13:32:07,656 - INFO - [Valid] [82/90] | Loss: 0.6506 | Val Acc: 77.29%
2026-01-14 13:32:07,676 - INFO - [Metrics for 'abnormal'] | Precision: 0.7564 | Recall: 0.7516 | F1: 0.7540
2026-01-14 13:32:07,676 - INFO - [Metrics for 'normal'] | Precision: 0.7869 | Recall: 0.7912 | F1: 0.7890
2026-01-14 13:32:07,681 - INFO - --------------------------------------------------
2026-01-14 13:32:07,684 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:32:16,588 - INFO - [Train] [83/90] | Loss: 0.2648 | Train Acc: 97.02%
2026-01-14 13:32:19,983 - INFO - [Valid] [83/90] | Loss: 0.6393 | Val Acc: 79.06%
2026-01-14 13:32:19,994 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-01-14 13:32:19,994 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-01-14 13:32:19,999 - INFO - --------------------------------------------------
2026-01-14 13:32:20,002 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:32:29,321 - INFO - [Train] [84/90] | Loss: 0.2652 | Train Acc: 96.95%
2026-01-14 13:32:32,472 - INFO - [Valid] [84/90] | Loss: 0.6189 | Val Acc: 77.88%
2026-01-14 13:32:32,484 - INFO - [Metrics for 'abnormal'] | Precision: 0.7562 | Recall: 0.7707 | F1: 0.7634
2026-01-14 13:32:32,485 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.7857 | F1: 0.7922
2026-01-14 13:32:32,489 - INFO - --------------------------------------------------
2026-01-14 13:32:32,491 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:32:41,669 - INFO - [Train] [85/90] | Loss: 0.2676 | Train Acc: 96.43%
2026-01-14 13:32:43,891 - INFO - [Valid] [85/90] | Loss: 0.6328 | Val Acc: 78.17%
2026-01-14 13:32:43,905 - INFO - [Metrics for 'abnormal'] | Precision: 0.7546 | Recall: 0.7834 | F1: 0.7688
2026-01-14 13:32:43,906 - INFO - [Metrics for 'normal'] | Precision: 0.8068 | Recall: 0.7802 | F1: 0.7933
2026-01-14 13:32:43,909 - INFO - --------------------------------------------------
2026-01-14 13:32:43,912 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:32:54,076 - INFO - [Train] [86/90] | Loss: 0.2612 | Train Acc: 96.73%
2026-01-14 13:32:56,626 - INFO - [Valid] [86/90] | Loss: 0.6395 | Val Acc: 78.17%
2026-01-14 13:32:56,648 - INFO - [Metrics for 'abnormal'] | Precision: 0.7748 | Recall: 0.7452 | F1: 0.7597
2026-01-14 13:32:56,648 - INFO - [Metrics for 'normal'] | Precision: 0.7872 | Recall: 0.8132 | F1: 0.8000
2026-01-14 13:32:56,651 - INFO - --------------------------------------------------
2026-01-14 13:32:56,655 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:33:06,237 - INFO - [Train] [87/90] | Loss: 0.2627 | Train Acc: 97.32%
2026-01-14 13:33:09,104 - INFO - [Valid] [87/90] | Loss: 0.6354 | Val Acc: 77.58%
2026-01-14 13:33:09,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.7613 | Recall: 0.7516 | F1: 0.7564
2026-01-14 13:33:09,116 - INFO - [Metrics for 'normal'] | Precision: 0.7880 | Recall: 0.7967 | F1: 0.7923
2026-01-14 13:33:09,120 - INFO - --------------------------------------------------
2026-01-14 13:33:09,124 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:33:19,515 - INFO - [Train] [88/90] | Loss: 0.2544 | Train Acc: 97.47%
2026-01-14 13:33:23,009 - INFO - [Valid] [88/90] | Loss: 0.6303 | Val Acc: 78.47%
2026-01-14 13:33:23,027 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.7643 | F1: 0.7668
2026-01-14 13:33:23,028 - INFO - [Metrics for 'normal'] | Precision: 0.7978 | Recall: 0.8022 | F1: 0.8000
2026-01-14 13:33:23,034 - INFO - --------------------------------------------------
2026-01-14 13:33:23,037 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:33:31,689 - INFO - [Train] [89/90] | Loss: 0.2564 | Train Acc: 97.10%
2026-01-14 13:33:34,190 - INFO - [Valid] [89/90] | Loss: 0.6312 | Val Acc: 77.29%
2026-01-14 13:33:34,202 - INFO - [Metrics for 'abnormal'] | Precision: 0.7439 | Recall: 0.7771 | F1: 0.7601
2026-01-14 13:33:34,203 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7692 | F1: 0.7843
2026-01-14 13:33:34,208 - INFO - --------------------------------------------------
2026-01-14 13:33:34,211 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:33:42,766 - INFO - [Train] [90/90] | Loss: 0.2636 | Train Acc: 96.95%
2026-01-14 13:33:45,665 - INFO - [Valid] [90/90] | Loss: 0.6255 | Val Acc: 78.76%
2026-01-14 13:33:45,675 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-01-14 13:33:45,676 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-01-14 13:33:45,680 - INFO - ==================================================
2026-01-14 13:33:45,681 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:33:45,682 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:33:45,682 - INFO - Baseline 모델 'efficientnet_b0'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:33:45,864 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:33:45,869 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:33:45,870 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:33:46,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 13:33:46,348 - INFO - ==================================================
2026-01-14 13:33:46,460 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/best_model.pth'
2026-01-14 13:33:46,460 - INFO - ==================================================
2026-01-14 13:33:46,461 - INFO - Test 모드를 시작합니다.
2026-01-14 13:33:47,264 - INFO - 연산량 (MACs): 0.0060 GMACs per sample
2026-01-14 13:33:47,264 - INFO - 연산량 (FLOPs): 0.0120 GFLOPs per sample
2026-01-14 13:33:47,264 - INFO - ==================================================
2026-01-14 13:33:47,264 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:33:49,876 - INFO - 샘플 당 평균 Forward Pass 시간: 11.11ms (std: 11.72ms), FPS: 109.39 (std: 31.22) (1개 샘플 x 100회 반복)
2026-01-14 13:33:49,880 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 80.42 MB
2026-01-14 13:33:49,880 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:33:53,187 - INFO - [Test] Loss: 0.4359 | Test Acc: 80.53%
2026-01-14 13:33:53,201 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 13:33:53,201 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 13:33:53,778 - INFO - ==================================================
2026-01-14 13:33:53,779 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/confusion_matrix_20260114_131707.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/confusion_matrix_20260114_131707.pdf'
2026-01-14 13:33:53,779 - INFO - ==================================================
2026-01-14 13:33:53,780 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:33:59,669 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/model_fp32_20260114_131707.onnx'에 저장되었습니다. (크기: 0.18 MB)
2026-01-14 13:34:00,344 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2461.22 MB (증가량: 5.95 MB)
2026-01-14 13:34:00,344 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:34:02,330 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 15.38ms (std: 10.53ms)
2026-01-14 13:34:02,330 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 87.25 FPS (std: 42.75) (1개 샘플 x 100회 반복)
2026-01-14 13:34:02,330 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2463.77 MB (순수 증가량: 2.54 MB)
2026-01-14 13:34:02,331 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2463.77 MB (전체 증가량: 8.49 MB)
2026-01-14 13:34:06,373 - INFO - [Test (ONNX)] | Test Acc (ONNX): 80.53%
2026-01-14 13:34:06,382 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 13:34:06,382 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 13:34:07,108 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/val_acc.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/val_acc.pdf'
2026-01-14 13:34:07,734 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/train_val_acc.pdf'
2026-01-14 13:34:08,203 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/F1_normal.pdf'
2026-01-14 13:34:08,699 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/val_loss.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/val_loss.pdf'
2026-01-14 13:34:09,087 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/learning_rate.pdf'
2026-01-14 13:34:14,694 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/compile.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_l1_20260114_131707/graph_20260114_131707/compile.pdf'
