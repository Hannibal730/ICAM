2026-01-14 13:17:48,565 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/log_20260114_131748.log'에 저장됩니다.
2026-01-14 13:17:48,573 - INFO - ==================================================
2026-01-14 13:17:48,574 - INFO - config.yaml:
2026-01-14 13:17:48,574 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: xie2019
  use_l1_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:17:48,575 - INFO - ==================================================
2026-01-14 13:17:48,647 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:17:48,648 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:17:48,648 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:17:48,662 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:17:48,663 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:17:48,663 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:17:48,664 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:17:49,008 - INFO - ==================================================
2026-01-14 13:17:49,009 - INFO - 모델 파라미터 수:
2026-01-14 13:17:49,009 - INFO -   - 총 파라미터: 9,160,194 개
2026-01-14 13:17:49,009 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-01-14 13:17:49,009 - INFO - ================================================================================
2026-01-14 13:17:49,009 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:17:49,009 - INFO - ================================================================================
2026-01-14 13:17:49,009 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:17:49,010 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:17:49,010 - INFO - ==================================================
2026-01-14 13:17:49,010 - INFO - train 모드를 시작합니다.
2026-01-14 13:17:49,010 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:17:49,010 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:17:49,010 - INFO - --------------------------------------------------
2026-01-14 13:17:49,010 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:17:55,855 - INFO - [Train] [1/10] | Loss: 0.5863 | Train Acc: 74.40%
2026-01-14 13:17:59,154 - INFO - [Valid] [1/10] | Loss: 0.5862 | Val Acc: 75.22%
2026-01-14 13:17:59,184 - INFO - [Metrics for 'abnormal'] | Precision: 0.8288 | Recall: 0.5860 | F1: 0.6866
2026-01-14 13:17:59,186 - INFO - [Metrics for 'normal'] | Precision: 0.7149 | Recall: 0.8956 | F1: 0.7951
2026-01-14 13:17:59,270 - INFO - [Best Model Saved] (val loss: 0.5862) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:17:59,270 - INFO - --------------------------------------------------
2026-01-14 13:17:59,271 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:18:05,231 - INFO - [Train] [2/10] | Loss: 0.5662 | Train Acc: 78.27%
2026-01-14 13:18:06,940 - INFO - [Valid] [2/10] | Loss: 0.6528 | Val Acc: 67.55%
2026-01-14 13:18:06,952 - INFO - [Metrics for 'abnormal'] | Precision: 0.6083 | Recall: 0.8408 | F1: 0.7059
2026-01-14 13:18:06,961 - INFO - [Metrics for 'normal'] | Precision: 0.7951 | Recall: 0.5330 | F1: 0.6382
2026-01-14 13:18:06,967 - INFO - --------------------------------------------------
2026-01-14 13:18:06,967 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:18:14,123 - INFO - [Train] [3/10] | Loss: 0.5329 | Train Acc: 79.76%
2026-01-14 13:18:16,545 - INFO - [Valid] [3/10] | Loss: 0.5335 | Val Acc: 76.99%
2026-01-14 13:18:16,556 - INFO - [Metrics for 'abnormal'] | Precision: 0.7365 | Recall: 0.7834 | F1: 0.7593
2026-01-14 13:18:16,557 - INFO - [Metrics for 'normal'] | Precision: 0.8023 | Recall: 0.7582 | F1: 0.7797
2026-01-14 13:18:16,643 - INFO - [Best Model Saved] (val loss: 0.5335) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:18:16,644 - INFO - --------------------------------------------------
2026-01-14 13:18:16,645 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:18:22,644 - INFO - [Train] [4/10] | Loss: 0.5064 | Train Acc: 81.25%
2026-01-14 13:18:24,753 - INFO - [Valid] [4/10] | Loss: 0.5505 | Val Acc: 75.81%
2026-01-14 13:18:24,771 - INFO - [Metrics for 'abnormal'] | Precision: 0.8205 | Recall: 0.6115 | F1: 0.7007
2026-01-14 13:18:24,772 - INFO - [Metrics for 'normal'] | Precision: 0.7252 | Recall: 0.8846 | F1: 0.7970
2026-01-14 13:18:24,778 - INFO - --------------------------------------------------
2026-01-14 13:18:24,779 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:18:31,862 - INFO - [Train] [5/10] | Loss: 0.4993 | Train Acc: 80.28%
2026-01-14 13:18:33,679 - INFO - [Valid] [5/10] | Loss: 0.5276 | Val Acc: 78.76%
2026-01-14 13:18:33,694 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.8153 | F1: 0.7805
2026-01-14 13:18:33,695 - INFO - [Metrics for 'normal'] | Precision: 0.8274 | Recall: 0.7637 | F1: 0.7943
2026-01-14 13:18:33,786 - INFO - [Best Model Saved] (val loss: 0.5276) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:18:33,786 - INFO - --------------------------------------------------
2026-01-14 13:18:33,787 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:18:41,357 - INFO - [Train] [6/10] | Loss: 0.4809 | Train Acc: 83.26%
2026-01-14 13:18:43,606 - INFO - [Valid] [6/10] | Loss: 0.5105 | Val Acc: 79.35%
2026-01-14 13:18:43,625 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:18:43,625 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:18:43,767 - INFO - [Best Model Saved] (val loss: 0.5105) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:18:43,768 - INFO - --------------------------------------------------
2026-01-14 13:18:43,768 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:18:50,899 - INFO - [Train] [7/10] | Loss: 0.4653 | Train Acc: 83.78%
2026-01-14 13:18:53,259 - INFO - [Valid] [7/10] | Loss: 0.5104 | Val Acc: 79.35%
2026-01-14 13:18:53,286 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-01-14 13:18:53,286 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-01-14 13:18:53,477 - INFO - [Best Model Saved] (val loss: 0.5104) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:18:53,477 - INFO - --------------------------------------------------
2026-01-14 13:18:53,480 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:19:00,418 - INFO - [Train] [8/10] | Loss: 0.4546 | Train Acc: 84.30%
2026-01-14 13:19:03,011 - INFO - [Valid] [8/10] | Loss: 0.4955 | Val Acc: 82.01%
2026-01-14 13:19:03,024 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 13:19:03,025 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 13:19:03,123 - INFO - [Best Model Saved] (val loss: 0.4955) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:19:03,124 - INFO - --------------------------------------------------
2026-01-14 13:19:03,124 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:19:10,665 - INFO - [Train] [9/10] | Loss: 0.4442 | Train Acc: 84.82%
2026-01-14 13:19:12,160 - INFO - [Valid] [9/10] | Loss: 0.5006 | Val Acc: 81.12%
2026-01-14 13:19:12,170 - INFO - [Metrics for 'abnormal'] | Precision: 0.8079 | Recall: 0.7771 | F1: 0.7922
2026-01-14 13:19:12,170 - INFO - [Metrics for 'normal'] | Precision: 0.8138 | Recall: 0.8407 | F1: 0.8270
2026-01-14 13:19:12,174 - INFO - --------------------------------------------------
2026-01-14 13:19:12,174 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:19:19,326 - INFO - [Train] [10/10] | Loss: 0.4463 | Train Acc: 84.45%
2026-01-14 13:19:21,275 - INFO - [Valid] [10/10] | Loss: 0.4945 | Val Acc: 81.71%
2026-01-14 13:19:21,315 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 13:19:21,315 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 13:19:21,410 - INFO - [Best Model Saved] (val loss: 0.4945) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:19:21,413 - INFO - ================================================================================
2026-01-14 13:19:21,413 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:19:21,413 - INFO - ================================================================================
2026-01-14 13:19:21,460 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:19:21,460 - INFO - ================================================================================
2026-01-14 13:19:21,461 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:19:21,461 - INFO - 원본 모델 파라미터: 9.1602M
2026-01-14 13:19:21,469 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:21,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:22,254 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:19:22,255 - INFO - ==================================================
2026-01-14 13:19:22,256 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 2.3194M (감소율: 74.68%)
2026-01-14 13:19:22,262 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:22,262 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:22,947 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:22,948 - INFO - ==================================================
2026-01-14 13:19:22,948 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.5934M (감소율: 93.52%)
2026-01-14 13:19:22,953 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:22,953 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:23,618 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:19:23,618 - INFO - ==================================================
2026-01-14 13:19:23,618 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.1643M (감소율: 98.21%)
2026-01-14 13:19:23,622 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:23,622 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:24,256 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:19:24,256 - INFO - ==================================================
2026-01-14 13:19:24,257 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-01-14 13:19:24,263 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:24,265 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:25,366 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:25,368 - INFO - ==================================================
2026-01-14 13:19:25,369 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0151M (감소율: 99.84%)
2026-01-14 13:19:25,374 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:25,375 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:26,375 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.94359375)에 맞춰 변경되었습니다.
2026-01-14 13:19:26,376 - INFO - ==================================================
2026-01-14 13:19:26,377 - INFO -   [탐색  6] 희소도: 0.9436 -> 파라미터: 0.0290M (감소율: 99.68%)
2026-01-14 13:19:26,382 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:26,382 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:27,026 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9358593749999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:27,026 - INFO - ==================================================
2026-01-14 13:19:27,027 - INFO -   [탐색  7] 희소도: 0.9359 -> 파라미터: 0.0379M (감소율: 99.59%)
2026-01-14 13:19:27,031 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:27,032 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:27,625 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9397265625)에 맞춰 변경되었습니다.
2026-01-14 13:19:27,625 - INFO - ==================================================
2026-01-14 13:19:27,628 - INFO -   [탐색  8] 희소도: 0.9397 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:27,631 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:27,632 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:28,247 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93779296875)에 맞춰 변경되었습니다.
2026-01-14 13:19:28,248 - INFO - ==================================================
2026-01-14 13:19:28,248 - INFO -   [탐색  9] 희소도: 0.9378 -> 파라미터: 0.0321M (감소율: 99.65%)
2026-01-14 13:19:28,253 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:28,254 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:28,937 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 13:19:28,937 - INFO - ==================================================
2026-01-14 13:19:28,938 - INFO -   [탐색 10] 희소도: 0.9388 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:28,942 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:28,942 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:29,733 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9392431640625)에 맞춰 변경되었습니다.
2026-01-14 13:19:29,733 - INFO - ==================================================
2026-01-14 13:19:29,734 - INFO -   [탐색 11] 희소도: 0.9392 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:29,738 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:29,738 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:30,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93948486328125)에 맞춰 변경되었습니다.
2026-01-14 13:19:30,569 - INFO - ==================================================
2026-01-14 13:19:30,569 - INFO -   [탐색 12] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:30,574 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:30,574 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:31,410 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939364013671875)에 맞춰 변경되었습니다.
2026-01-14 13:19:31,411 - INFO - ==================================================
2026-01-14 13:19:31,412 - INFO -   [탐색 13] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:31,417 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:31,419 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:32,153 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394244384765625)에 맞춰 변경되었습니다.
2026-01-14 13:19:32,155 - INFO - ==================================================
2026-01-14 13:19:32,155 - INFO -   [탐색 14] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:32,162 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:32,164 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:32,880 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394546508789063)에 맞춰 변경되었습니다.
2026-01-14 13:19:32,881 - INFO - ==================================================
2026-01-14 13:19:32,881 - INFO -   [탐색 15] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:32,887 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:32,888 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:33,643 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394395446777344)에 맞춰 변경되었습니다.
2026-01-14 13:19:33,644 - INFO - ==================================================
2026-01-14 13:19:33,644 - INFO -   [탐색 16] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:33,649 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:33,650 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:34,351 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394470977783204)에 맞춰 변경되었습니다.
2026-01-14 13:19:34,351 - INFO - ==================================================
2026-01-14 13:19:34,352 - INFO -   [탐색 17] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:34,356 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:34,357 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:35,187 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394508743286134)에 맞춰 변경되었습니다.
2026-01-14 13:19:35,187 - INFO - ==================================================
2026-01-14 13:19:35,188 - INFO -   [탐색 18] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:35,193 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:35,193 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:35,775 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394527626037599)에 맞춰 변경되었습니다.
2026-01-14 13:19:35,775 - INFO - ==================================================
2026-01-14 13:19:35,776 - INFO -   [탐색 19] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:35,779 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:35,780 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:36,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394537067413331)에 맞춰 변경되었습니다.
2026-01-14 13:19:36,308 - INFO - ==================================================
2026-01-14 13:19:36,308 - INFO -   [탐색 20] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:36,312 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:36,313 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:37,117 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394532346725465)에 맞춰 변경되었습니다.
2026-01-14 13:19:37,118 - INFO - ==================================================
2026-01-14 13:19:37,119 - INFO -   [탐색 21] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:37,124 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:37,124 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:37,763 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394529986381532)에 맞춰 변경되었습니다.
2026-01-14 13:19:37,763 - INFO - ==================================================
2026-01-14 13:19:37,764 - INFO -   [탐색 22] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:37,768 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:37,769 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:38,458 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531166553499)에 맞춰 변경되었습니다.
2026-01-14 13:19:38,459 - INFO - ==================================================
2026-01-14 13:19:38,459 - INFO -   [탐색 23] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:38,466 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:38,467 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:39,201 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531756639481)에 맞춰 변경되었습니다.
2026-01-14 13:19:39,202 - INFO - ==================================================
2026-01-14 13:19:39,202 - INFO -   [탐색 24] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:39,207 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:39,208 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:39,859 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453146159649)에 맞춰 변경되었습니다.
2026-01-14 13:19:39,860 - INFO - ==================================================
2026-01-14 13:19:39,861 - INFO -   [탐색 25] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:39,867 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:39,867 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:40,518 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531314074994)에 맞춰 변경되었습니다.
2026-01-14 13:19:40,518 - INFO - ==================================================
2026-01-14 13:19:40,518 - INFO -   [탐색 26] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:40,523 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:40,524 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:41,445 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531240314247)에 맞춰 변경되었습니다.
2026-01-14 13:19:41,446 - INFO - ==================================================
2026-01-14 13:19:41,446 - INFO -   [탐색 27] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:41,452 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:41,452 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:42,143 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453127719462)에 맞춰 변경되었습니다.
2026-01-14 13:19:42,143 - INFO - ==================================================
2026-01-14 13:19:42,144 - INFO -   [탐색 28] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:42,147 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:42,148 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:42,876 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531258754433)에 맞춰 변경되었습니다.
2026-01-14 13:19:42,876 - INFO - ==================================================
2026-01-14 13:19:42,877 - INFO -   [탐색 29] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:42,881 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:42,881 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:43,529 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249534339)에 맞춰 변경되었습니다.
2026-01-14 13:19:43,530 - INFO - ==================================================
2026-01-14 13:19:43,531 - INFO -   [탐색 30] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:43,534 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:43,535 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:44,410 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531254144386)에 맞춰 변경되었습니다.
2026-01-14 13:19:44,410 - INFO - ==================================================
2026-01-14 13:19:44,411 - INFO -   [탐색 31] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:44,415 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:44,416 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:45,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531251839362)에 맞춰 변경되었습니다.
2026-01-14 13:19:45,110 - INFO - ==================================================
2026-01-14 13:19:45,110 - INFO -   [탐색 32] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:45,114 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:45,114 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:45,817 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250686851)에 맞춰 변경되었습니다.
2026-01-14 13:19:45,817 - INFO - ==================================================
2026-01-14 13:19:45,818 - INFO -   [탐색 33] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:45,822 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:45,822 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:46,456 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250110595)에 맞춰 변경되었습니다.
2026-01-14 13:19:46,457 - INFO - ==================================================
2026-01-14 13:19:46,457 - INFO -   [탐색 34] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:46,462 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:46,463 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:47,465 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249822466)에 맞춰 변경되었습니다.
2026-01-14 13:19:47,465 - INFO - ==================================================
2026-01-14 13:19:47,466 - INFO -   [탐색 35] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:47,469 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:47,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:48,248 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249966531)에 맞춰 변경되었습니다.
2026-01-14 13:19:48,251 - INFO - ==================================================
2026-01-14 13:19:48,251 - INFO -   [탐색 36] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:48,258 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:48,260 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:48,846 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250038562)에 맞춰 변경되었습니다.
2026-01-14 13:19:48,846 - INFO - ==================================================
2026-01-14 13:19:48,847 - INFO -   [탐색 37] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:48,852 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:48,853 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:49,461 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250002547)에 맞춰 변경되었습니다.
2026-01-14 13:19:49,461 - INFO - ==================================================
2026-01-14 13:19:49,462 - INFO -   [탐색 38] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:49,467 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:49,467 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:50,373 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249984539)에 맞춰 변경되었습니다.
2026-01-14 13:19:50,374 - INFO - ==================================================
2026-01-14 13:19:50,374 - INFO -   [탐색 39] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:50,380 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:50,381 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:50,997 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249993543)에 맞춰 변경되었습니다.
2026-01-14 13:19:50,998 - INFO - ==================================================
2026-01-14 13:19:50,998 - INFO -   [탐색 40] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:51,002 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:51,003 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:51,666 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249998045)에 맞춰 변경되었습니다.
2026-01-14 13:19:51,667 - INFO - ==================================================
2026-01-14 13:19:51,668 - INFO -   [탐색 41] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:51,675 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:51,675 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:52,191 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000295)에 맞춰 변경되었습니다.
2026-01-14 13:19:52,192 - INFO - ==================================================
2026-01-14 13:19:52,192 - INFO -   [탐색 42] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:52,196 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:52,197 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:52,924 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453124999917)에 맞춰 변경되었습니다.
2026-01-14 13:19:52,924 - INFO - ==================================================
2026-01-14 13:19:52,924 - INFO -   [탐색 43] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:52,929 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:52,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:53,493 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999732)에 맞춰 변경되었습니다.
2026-01-14 13:19:53,494 - INFO - ==================================================
2026-01-14 13:19:53,494 - INFO -   [탐색 44] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:53,497 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:53,498 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:53,990 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000013)에 맞춰 변경되었습니다.
2026-01-14 13:19:53,991 - INFO - ==================================================
2026-01-14 13:19:53,991 - INFO -   [탐색 45] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:53,995 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:53,995 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:54,573 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999873)에 맞춰 변경되었습니다.
2026-01-14 13:19:54,574 - INFO - ==================================================
2026-01-14 13:19:54,575 - INFO -   [탐색 46] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:54,580 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:54,580 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:55,602 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999943)에 맞춰 변경되었습니다.
2026-01-14 13:19:55,602 - INFO - ==================================================
2026-01-14 13:19:55,603 - INFO -   [탐색 47] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:55,607 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:55,607 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:56,178 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999978)에 맞춰 변경되었습니다.
2026-01-14 13:19:56,180 - INFO - ==================================================
2026-01-14 13:19:56,181 - INFO -   [탐색 48] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:56,186 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:56,187 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:56,816 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999996)에 맞춰 변경되었습니다.
2026-01-14 13:19:56,817 - INFO - ==================================================
2026-01-14 13:19:56,817 - INFO -   [탐색 49] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:56,821 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:56,822 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:57,560 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000004)에 맞춰 변경되었습니다.
2026-01-14 13:19:57,560 - INFO - ==================================================
2026-01-14 13:19:57,561 - INFO -   [탐색 50] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:57,566 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:57,567 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:58,560 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:19:58,560 - INFO - ==================================================
2026-01-14 13:19:58,561 - INFO -   [탐색 51] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:19:58,565 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:58,566 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:59,310 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000002)에 맞춰 변경되었습니다.
2026-01-14 13:19:59,311 - INFO - ==================================================
2026-01-14 13:19:59,311 - INFO -   [탐색 52] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:19:59,315 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:59,316 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:00,075 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000001)에 맞춰 변경되었습니다.
2026-01-14 13:20:00,076 - INFO - ==================================================
2026-01-14 13:20:00,076 - INFO -   [탐색 53] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:20:00,079 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:00,080 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:00,657 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:00,658 - INFO - ==================================================
2026-01-14 13:20:00,658 - INFO -   [탐색 54] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:00,661 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:00,662 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:01,316 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:01,317 - INFO - ==================================================
2026-01-14 13:20:01,318 - INFO -   [탐색 55] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:01,323 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:01,323 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:02,039 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:02,040 - INFO - ==================================================
2026-01-14 13:20:02,042 - INFO -   [탐색 56] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:02,047 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:02,048 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:02,630 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:02,630 - INFO - ==================================================
2026-01-14 13:20:02,631 - INFO -   [탐색 57] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:02,635 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:02,636 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:03,222 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:03,222 - INFO - ==================================================
2026-01-14 13:20:03,222 - INFO -   [탐색 58] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:03,227 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:03,227 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,012 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:04,013 - INFO - ==================================================
2026-01-14 13:20:04,014 - INFO -   [탐색 59] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:04,018 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:04,019 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:04,596 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:04,597 - INFO - ==================================================
2026-01-14 13:20:04,597 - INFO -   [탐색 60] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:04,601 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:04,602 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:05,178 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:05,178 - INFO - ==================================================
2026-01-14 13:20:05,178 - INFO -   [탐색 61] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:05,183 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:05,183 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:05,764 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:05,764 - INFO - ==================================================
2026-01-14 13:20:05,765 - INFO -   [탐색 62] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:05,769 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:05,770 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,263 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:06,264 - INFO - ==================================================
2026-01-14 13:20:06,264 - INFO -   [탐색 63] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:06,267 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:06,267 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:06,678 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:06,679 - INFO - ==================================================
2026-01-14 13:20:06,679 - INFO -   [탐색 64] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:06,681 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:06,682 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,132 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:07,132 - INFO - ==================================================
2026-01-14 13:20:07,133 - INFO -   [탐색 65] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:07,137 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:07,137 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:07,629 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:07,630 - INFO - ==================================================
2026-01-14 13:20:07,631 - INFO -   [탐색 66] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:07,635 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:07,635 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:08,307 - INFO - ==================================================
2026-01-14 13:20:08,307 - INFO -   [탐색 67] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:08,310 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:08,311 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:08,803 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:08,803 - INFO - ==================================================
2026-01-14 13:20:08,804 - INFO -   [탐색 68] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:08,808 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:08,809 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,386 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:09,387 - INFO - ==================================================
2026-01-14 13:20:09,387 - INFO -   [탐색 69] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:09,392 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:09,393 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:09,974 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:09,974 - INFO - ==================================================
2026-01-14 13:20:09,975 - INFO -   [탐색 70] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:09,979 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:09,979 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,462 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:10,462 - INFO - ==================================================
2026-01-14 13:20:10,463 - INFO -   [탐색 71] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:10,466 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:10,466 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:10,967 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:10,968 - INFO - ==================================================
2026-01-14 13:20:10,968 - INFO -   [탐색 72] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:10,972 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:10,973 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:11,469 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:11,470 - INFO - ==================================================
2026-01-14 13:20:11,471 - INFO -   [탐색 73] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:11,475 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:11,476 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:12,178 - INFO - ==================================================
2026-01-14 13:20:12,178 - INFO -   [탐색 74] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:12,182 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:12,182 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:12,715 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:12,715 - INFO - ==================================================
2026-01-14 13:20:12,715 - INFO -   [탐색 75] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:12,719 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:12,719 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,179 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:13,180 - INFO - ==================================================
2026-01-14 13:20:13,180 - INFO -   [탐색 76] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:13,183 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:13,184 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:13,643 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:13,643 - INFO - ==================================================
2026-01-14 13:20:13,644 - INFO -   [탐색 77] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:13,648 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:13,649 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,233 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:14,234 - INFO - ==================================================
2026-01-14 13:20:14,235 - INFO -   [탐색 78] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:14,239 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:14,239 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:14,702 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:14,702 - INFO - ==================================================
2026-01-14 13:20:14,702 - INFO -   [탐색 79] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:14,705 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:14,706 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:15,423 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:15,423 - INFO - ==================================================
2026-01-14 13:20:15,424 - INFO -   [탐색 80] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:15,428 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:15,429 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,019 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:16,019 - INFO - ==================================================
2026-01-14 13:20:16,020 - INFO -   [탐색 81] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:16,024 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:16,025 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:16,609 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:16,609 - INFO - ==================================================
2026-01-14 13:20:16,610 - INFO -   [탐색 82] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:16,615 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:16,616 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,235 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:17,236 - INFO - ==================================================
2026-01-14 13:20:17,237 - INFO -   [탐색 83] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:17,242 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:17,242 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:17,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:17,821 - INFO - ==================================================
2026-01-14 13:20:17,822 - INFO -   [탐색 84] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:17,827 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:17,827 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:18,492 - INFO - ==================================================
2026-01-14 13:20:18,493 - INFO -   [탐색 85] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:18,496 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:18,496 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:18,963 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:18,964 - INFO - ==================================================
2026-01-14 13:20:18,964 - INFO -   [탐색 86] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:18,968 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:18,968 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:19,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:19,444 - INFO - ==================================================
2026-01-14 13:20:19,445 - INFO -   [탐색 87] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:19,448 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:19,449 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:19,927 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:19,927 - INFO - ==================================================
2026-01-14 13:20:19,928 - INFO -   [탐색 88] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:19,931 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:19,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:20,782 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:20,783 - INFO - ==================================================
2026-01-14 13:20:20,783 - INFO -   [탐색 89] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:20,790 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:20,791 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:21,483 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:21,484 - INFO - ==================================================
2026-01-14 13:20:21,484 - INFO -   [탐색 90] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:21,489 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:21,489 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:22,156 - INFO - ==================================================
2026-01-14 13:20:22,157 - INFO -   [탐색 91] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:22,161 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:22,161 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:22,751 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:22,751 - INFO - ==================================================
2026-01-14 13:20:22,752 - INFO -   [탐색 92] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:22,756 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:22,756 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:23,536 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:23,537 - INFO - ==================================================
2026-01-14 13:20:23,537 - INFO -   [탐색 93] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:23,542 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:23,543 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,127 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:24,127 - INFO - ==================================================
2026-01-14 13:20:24,128 - INFO -   [탐색 94] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:24,132 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:24,133 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:24,707 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:24,707 - INFO - ==================================================
2026-01-14 13:20:24,708 - INFO -   [탐색 95] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:24,713 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:24,713 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:25,297 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:25,298 - INFO - ==================================================
2026-01-14 13:20:25,299 - INFO -   [탐색 96] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:25,304 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:25,305 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:26,087 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:26,088 - INFO - ==================================================
2026-01-14 13:20:26,088 - INFO -   [탐색 97] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:26,093 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:26,094 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:26,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:26,669 - INFO - ==================================================
2026-01-14 13:20:26,670 - INFO -   [탐색 98] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:26,675 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:26,675 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,257 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:27,257 - INFO - ==================================================
2026-01-14 13:20:27,258 - INFO -   [탐색 99] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:27,262 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:27,263 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:27,856 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:20:27,856 - INFO - ==================================================
2026-01-14 13:20:27,856 - INFO -   [탐색 100] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:20:27,857 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9388 입니다.
2026-01-14 13:20:27,857 - INFO - ================================================================================
2026-01-14 13:20:27,858 - INFO - 계산된 Pruning 정보(희소도: 0.9388)를 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:20:27,865 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:20:27,875 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:20:27,876 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:20:28,663 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 13:20:28,663 - INFO - ==================================================
2026-01-14 13:20:28,664 - INFO - ==================================================
2026-01-14 13:20:28,664 - INFO - 모델 파라미터 수:
2026-01-14 13:20:28,664 - INFO -   - 총 파라미터: 31,591 개
2026-01-14 13:20:28,665 - INFO -   - 학습 가능한 파라미터: 31,591 개
2026-01-14 13:20:28,674 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:20:28,683 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1107 GFLOPs로 감소했습니다 (감소율: 96.14%).
2026-01-14 13:20:28,684 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:20:28,684 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:20:28,685 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:20:28,685 - INFO - ==================================================
2026-01-14 13:20:28,685 - INFO - train 모드를 시작합니다.
2026-01-14 13:20:28,686 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:20:28,686 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:20:28,686 - INFO - --------------------------------------------------
2026-01-14 13:20:28,687 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:20:34,769 - INFO - [Train] [11/90] | Loss: 0.5749 | Train Acc: 79.24%
2026-01-14 13:20:36,681 - INFO - [Valid] [11/90] | Loss: 0.5548 | Val Acc: 74.34%
2026-01-14 13:20:36,693 - INFO - [Metrics for 'abnormal'] | Precision: 0.6882 | Recall: 0.8153 | F1: 0.7464
2026-01-14 13:20:36,693 - INFO - [Metrics for 'normal'] | Precision: 0.8105 | Recall: 0.6813 | F1: 0.7403
2026-01-14 13:20:36,701 - INFO - [Best Model Saved] (val loss: 0.5548) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:20:36,701 - INFO - --------------------------------------------------
2026-01-14 13:20:36,701 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:20:42,731 - INFO - [Train] [12/90] | Loss: 0.5185 | Train Acc: 81.18%
2026-01-14 13:20:44,601 - INFO - [Valid] [12/90] | Loss: 0.5352 | Val Acc: 74.93%
2026-01-14 13:20:44,613 - INFO - [Metrics for 'abnormal'] | Precision: 0.7045 | Recall: 0.7898 | F1: 0.7447
2026-01-14 13:20:44,614 - INFO - [Metrics for 'normal'] | Precision: 0.7975 | Recall: 0.7143 | F1: 0.7536
2026-01-14 13:20:44,621 - INFO - [Best Model Saved] (val loss: 0.5352) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:20:44,622 - INFO - --------------------------------------------------
2026-01-14 13:20:44,622 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:20:50,828 - INFO - [Train] [13/90] | Loss: 0.4985 | Train Acc: 82.07%
2026-01-14 13:20:52,961 - INFO - [Valid] [13/90] | Loss: 0.5244 | Val Acc: 78.47%
2026-01-14 13:20:52,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.7958 | Recall: 0.7197 | F1: 0.7559
2026-01-14 13:20:52,986 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8407 | F1: 0.8074
2026-01-14 13:20:53,003 - INFO - [Best Model Saved] (val loss: 0.5244) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:20:53,004 - INFO - --------------------------------------------------
2026-01-14 13:20:53,004 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:21:00,160 - INFO - [Train] [14/90] | Loss: 0.4972 | Train Acc: 81.40%
2026-01-14 13:21:01,981 - INFO - [Valid] [14/90] | Loss: 0.5087 | Val Acc: 77.29%
2026-01-14 13:21:01,993 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.8153 | F1: 0.7688
2026-01-14 13:21:01,993 - INFO - [Metrics for 'normal'] | Precision: 0.8221 | Recall: 0.7363 | F1: 0.7768
2026-01-14 13:21:02,004 - INFO - [Best Model Saved] (val loss: 0.5087) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:21:02,004 - INFO - --------------------------------------------------
2026-01-14 13:21:02,005 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:21:09,333 - INFO - [Train] [15/90] | Loss: 0.4871 | Train Acc: 82.37%
2026-01-14 13:21:11,481 - INFO - [Valid] [15/90] | Loss: 0.5255 | Val Acc: 78.47%
2026-01-14 13:21:11,505 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.7643 | F1: 0.7668
2026-01-14 13:21:11,508 - INFO - [Metrics for 'normal'] | Precision: 0.7978 | Recall: 0.8022 | F1: 0.8000
2026-01-14 13:21:11,514 - INFO - --------------------------------------------------
2026-01-14 13:21:11,517 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:21:19,833 - INFO - [Train] [16/90] | Loss: 0.4811 | Train Acc: 81.70%
2026-01-14 13:21:21,980 - INFO - [Valid] [16/90] | Loss: 0.5134 | Val Acc: 76.40%
2026-01-14 13:21:21,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7104 | Recall: 0.8280 | F1: 0.7647
2026-01-14 13:21:21,991 - INFO - [Metrics for 'normal'] | Precision: 0.8269 | Recall: 0.7088 | F1: 0.7633
2026-01-14 13:21:21,995 - INFO - --------------------------------------------------
2026-01-14 13:21:21,995 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:21:29,857 - INFO - [Train] [17/90] | Loss: 0.4830 | Train Acc: 82.44%
2026-01-14 13:21:31,670 - INFO - [Valid] [17/90] | Loss: 0.5214 | Val Acc: 78.76%
2026-01-14 13:21:31,684 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-01-14 13:21:31,685 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-01-14 13:21:31,688 - INFO - --------------------------------------------------
2026-01-14 13:21:31,689 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:21:39,514 - INFO - [Train] [18/90] | Loss: 0.4748 | Train Acc: 83.33%
2026-01-14 13:21:41,575 - INFO - [Valid] [18/90] | Loss: 0.5030 | Val Acc: 77.58%
2026-01-14 13:21:41,586 - INFO - [Metrics for 'abnormal'] | Precision: 0.7341 | Recall: 0.8089 | F1: 0.7697
2026-01-14 13:21:41,586 - INFO - [Metrics for 'normal'] | Precision: 0.8193 | Recall: 0.7473 | F1: 0.7816
2026-01-14 13:21:41,594 - INFO - [Best Model Saved] (val loss: 0.5030) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:21:41,595 - INFO - --------------------------------------------------
2026-01-14 13:21:41,595 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:21:49,144 - INFO - [Train] [19/90] | Loss: 0.4696 | Train Acc: 82.89%
2026-01-14 13:21:50,999 - INFO - [Valid] [19/90] | Loss: 0.4944 | Val Acc: 79.94%
2026-01-14 13:21:51,012 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 13:21:51,013 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 13:21:51,022 - INFO - [Best Model Saved] (val loss: 0.4944) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:21:51,022 - INFO - --------------------------------------------------
2026-01-14 13:21:51,023 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:21:59,276 - INFO - [Train] [20/90] | Loss: 0.4708 | Train Acc: 83.85%
2026-01-14 13:22:02,324 - INFO - [Valid] [20/90] | Loss: 0.5023 | Val Acc: 80.53%
2026-01-14 13:22:02,335 - INFO - [Metrics for 'abnormal'] | Precision: 0.8054 | Recall: 0.7643 | F1: 0.7843
2026-01-14 13:22:02,336 - INFO - [Metrics for 'normal'] | Precision: 0.8053 | Recall: 0.8407 | F1: 0.8226
2026-01-14 13:22:02,341 - INFO - --------------------------------------------------
2026-01-14 13:22:02,342 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:22:12,320 - INFO - [Train] [21/90] | Loss: 0.4599 | Train Acc: 83.48%
2026-01-14 13:22:14,781 - INFO - [Valid] [21/90] | Loss: 0.5137 | Val Acc: 79.94%
2026-01-14 13:22:14,805 - INFO - [Metrics for 'abnormal'] | Precision: 0.8248 | Recall: 0.7197 | F1: 0.7687
2026-01-14 13:22:14,806 - INFO - [Metrics for 'normal'] | Precision: 0.7822 | Recall: 0.8681 | F1: 0.8229
2026-01-14 13:22:14,813 - INFO - --------------------------------------------------
2026-01-14 13:22:14,817 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:22:24,746 - INFO - [Train] [22/90] | Loss: 0.4637 | Train Acc: 84.08%
2026-01-14 13:22:26,969 - INFO - [Valid] [22/90] | Loss: 0.4896 | Val Acc: 79.65%
2026-01-14 13:22:26,994 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-01-14 13:22:26,995 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-01-14 13:22:27,013 - INFO - [Best Model Saved] (val loss: 0.4896) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:22:27,013 - INFO - --------------------------------------------------
2026-01-14 13:22:27,014 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:22:36,975 - INFO - [Train] [23/90] | Loss: 0.4524 | Train Acc: 83.48%
2026-01-14 13:22:39,229 - INFO - [Valid] [23/90] | Loss: 0.4863 | Val Acc: 81.71%
2026-01-14 13:22:39,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.8146 | Recall: 0.7834 | F1: 0.7987
2026-01-14 13:22:39,243 - INFO - [Metrics for 'normal'] | Precision: 0.8191 | Recall: 0.8462 | F1: 0.8324
2026-01-14 13:22:39,254 - INFO - [Best Model Saved] (val loss: 0.4863) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:22:39,255 - INFO - --------------------------------------------------
2026-01-14 13:22:39,255 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:22:47,500 - INFO - [Train] [24/90] | Loss: 0.4514 | Train Acc: 84.45%
2026-01-14 13:22:49,946 - INFO - [Valid] [24/90] | Loss: 0.4898 | Val Acc: 81.12%
2026-01-14 13:22:49,957 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:22:49,958 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:22:49,962 - INFO - --------------------------------------------------
2026-01-14 13:22:49,963 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:22:58,051 - INFO - [Train] [25/90] | Loss: 0.4590 | Train Acc: 84.67%
2026-01-14 13:23:01,298 - INFO - [Valid] [25/90] | Loss: 0.4813 | Val Acc: 81.12%
2026-01-14 13:23:01,311 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 13:23:01,312 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 13:23:01,323 - INFO - [Best Model Saved] (val loss: 0.4813) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:23:01,324 - INFO - --------------------------------------------------
2026-01-14 13:23:01,324 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:23:10,317 - INFO - [Train] [26/90] | Loss: 0.4506 | Train Acc: 84.75%
2026-01-14 13:23:13,228 - INFO - [Valid] [26/90] | Loss: 0.5074 | Val Acc: 78.76%
2026-01-14 13:23:13,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-01-14 13:23:13,252 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-01-14 13:23:13,259 - INFO - --------------------------------------------------
2026-01-14 13:23:13,263 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:23:22,791 - INFO - [Train] [27/90] | Loss: 0.4502 | Train Acc: 84.75%
2026-01-14 13:23:24,991 - INFO - [Valid] [27/90] | Loss: 0.5116 | Val Acc: 80.24%
2026-01-14 13:23:25,016 - INFO - [Metrics for 'abnormal'] | Precision: 0.8462 | Recall: 0.7006 | F1: 0.7666
2026-01-14 13:23:25,016 - INFO - [Metrics for 'normal'] | Precision: 0.7751 | Recall: 0.8901 | F1: 0.8286
2026-01-14 13:23:25,020 - INFO - --------------------------------------------------
2026-01-14 13:23:25,020 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:23:33,734 - INFO - [Train] [28/90] | Loss: 0.4482 | Train Acc: 84.75%
2026-01-14 13:23:36,245 - INFO - [Valid] [28/90] | Loss: 0.4889 | Val Acc: 80.83%
2026-01-14 13:23:36,257 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 13:23:36,258 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 13:23:36,263 - INFO - --------------------------------------------------
2026-01-14 13:23:36,264 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:23:44,389 - INFO - [Train] [29/90] | Loss: 0.4490 | Train Acc: 84.75%
2026-01-14 13:23:46,991 - INFO - [Valid] [29/90] | Loss: 0.4806 | Val Acc: 82.30%
2026-01-14 13:23:47,004 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-01-14 13:23:47,005 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-01-14 13:23:47,015 - INFO - [Best Model Saved] (val loss: 0.4806) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:23:47,016 - INFO - --------------------------------------------------
2026-01-14 13:23:47,017 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:23:55,679 - INFO - [Train] [30/90] | Loss: 0.4431 | Train Acc: 86.24%
2026-01-14 13:23:58,848 - INFO - [Valid] [30/90] | Loss: 0.4981 | Val Acc: 81.71%
2026-01-14 13:23:58,893 - INFO - [Metrics for 'abnormal'] | Precision: 0.8417 | Recall: 0.7452 | F1: 0.7905
2026-01-14 13:23:58,893 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8791 | F1: 0.8377
2026-01-14 13:23:58,901 - INFO - --------------------------------------------------
2026-01-14 13:23:58,901 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:24:07,418 - INFO - [Train] [31/90] | Loss: 0.4395 | Train Acc: 85.04%
2026-01-14 13:24:10,333 - INFO - [Valid] [31/90] | Loss: 0.4793 | Val Acc: 82.30%
2026-01-14 13:24:10,346 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-01-14 13:24:10,346 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-01-14 13:24:10,353 - INFO - [Best Model Saved] (val loss: 0.4793) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:24:10,353 - INFO - --------------------------------------------------
2026-01-14 13:24:10,354 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:24:18,871 - INFO - [Train] [32/90] | Loss: 0.4309 | Train Acc: 85.34%
2026-01-14 13:24:21,630 - INFO - [Valid] [32/90] | Loss: 0.4889 | Val Acc: 80.24%
2026-01-14 13:24:21,657 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-01-14 13:24:21,658 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-01-14 13:24:21,666 - INFO - --------------------------------------------------
2026-01-14 13:24:21,669 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:24:31,509 - INFO - [Train] [33/90] | Loss: 0.4283 | Train Acc: 86.61%
2026-01-14 13:24:33,834 - INFO - [Valid] [33/90] | Loss: 0.4868 | Val Acc: 80.83%
2026-01-14 13:24:33,855 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 13:24:33,856 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 13:24:33,863 - INFO - --------------------------------------------------
2026-01-14 13:24:33,864 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:24:43,953 - INFO - [Train] [34/90] | Loss: 0.4284 | Train Acc: 86.68%
2026-01-14 13:24:46,640 - INFO - [Valid] [34/90] | Loss: 0.4869 | Val Acc: 81.71%
2026-01-14 13:24:46,650 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 13:24:46,651 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 13:24:46,655 - INFO - --------------------------------------------------
2026-01-14 13:24:46,656 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:24:55,873 - INFO - [Train] [35/90] | Loss: 0.4230 | Train Acc: 86.68%
2026-01-14 13:24:57,803 - INFO - [Valid] [35/90] | Loss: 0.4836 | Val Acc: 80.53%
2026-01-14 13:24:57,845 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-01-14 13:24:57,845 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-01-14 13:24:57,857 - INFO - --------------------------------------------------
2026-01-14 13:24:57,857 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:25:07,627 - INFO - [Train] [36/90] | Loss: 0.4136 | Train Acc: 87.28%
2026-01-14 13:25:09,699 - INFO - [Valid] [36/90] | Loss: 0.4742 | Val Acc: 82.01%
2026-01-14 13:25:09,714 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8535 | F1: 0.8146
2026-01-14 13:25:09,715 - INFO - [Metrics for 'normal'] | Precision: 0.8623 | Recall: 0.7912 | F1: 0.8252
2026-01-14 13:25:09,727 - INFO - [Best Model Saved] (val loss: 0.4742) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:25:09,728 - INFO - --------------------------------------------------
2026-01-14 13:25:09,728 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:25:19,436 - INFO - [Train] [37/90] | Loss: 0.4280 | Train Acc: 86.76%
2026-01-14 13:25:21,852 - INFO - [Valid] [37/90] | Loss: 0.4834 | Val Acc: 81.71%
2026-01-14 13:25:21,863 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 13:25:21,863 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 13:25:21,866 - INFO - --------------------------------------------------
2026-01-14 13:25:21,867 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:25:31,228 - INFO - [Train] [38/90] | Loss: 0.4277 | Train Acc: 87.05%
2026-01-14 13:25:33,988 - INFO - [Valid] [38/90] | Loss: 0.4672 | Val Acc: 82.89%
2026-01-14 13:25:34,001 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.8025 | F1: 0.8129
2026-01-14 13:25:34,002 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8516 | F1: 0.8424
2026-01-14 13:25:34,017 - INFO - [Best Model Saved] (val loss: 0.4672) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:25:34,017 - INFO - --------------------------------------------------
2026-01-14 13:25:34,018 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:25:43,591 - INFO - [Train] [39/90] | Loss: 0.4172 | Train Acc: 87.28%
2026-01-14 13:25:46,240 - INFO - [Valid] [39/90] | Loss: 0.4927 | Val Acc: 79.94%
2026-01-14 13:25:46,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.7908 | Recall: 0.7707 | F1: 0.7806
2026-01-14 13:25:46,259 - INFO - [Metrics for 'normal'] | Precision: 0.8065 | Recall: 0.8242 | F1: 0.8152
2026-01-14 13:25:46,273 - INFO - --------------------------------------------------
2026-01-14 13:25:46,277 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:25:54,466 - INFO - [Train] [40/90] | Loss: 0.4250 | Train Acc: 86.68%
2026-01-14 13:25:57,297 - INFO - [Valid] [40/90] | Loss: 0.4690 | Val Acc: 82.60%
2026-01-14 13:25:57,312 - INFO - [Metrics for 'abnormal'] | Precision: 0.8551 | Recall: 0.7516 | F1: 0.8000
2026-01-14 13:25:57,313 - INFO - [Metrics for 'normal'] | Precision: 0.8060 | Recall: 0.8901 | F1: 0.8460
2026-01-14 13:25:57,319 - INFO - --------------------------------------------------
2026-01-14 13:25:57,320 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:26:07,098 - INFO - [Train] [41/90] | Loss: 0.4128 | Train Acc: 88.91%
2026-01-14 13:26:09,609 - INFO - [Valid] [41/90] | Loss: 0.4675 | Val Acc: 82.89%
2026-01-14 13:26:09,631 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 13:26:09,631 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 13:26:09,636 - INFO - --------------------------------------------------
2026-01-14 13:26:09,637 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:26:18,614 - INFO - [Train] [42/90] | Loss: 0.4077 | Train Acc: 88.24%
2026-01-14 13:26:21,099 - INFO - [Valid] [42/90] | Loss: 0.4652 | Val Acc: 81.71%
2026-01-14 13:26:21,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 13:26:21,111 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 13:26:21,119 - INFO - [Best Model Saved] (val loss: 0.4652) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:26:21,120 - INFO - --------------------------------------------------
2026-01-14 13:26:21,121 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:26:29,285 - INFO - [Train] [43/90] | Loss: 0.4020 | Train Acc: 87.95%
2026-01-14 13:26:31,724 - INFO - [Valid] [43/90] | Loss: 0.4821 | Val Acc: 81.12%
2026-01-14 13:26:31,734 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 13:26:31,734 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 13:26:31,740 - INFO - --------------------------------------------------
2026-01-14 13:26:31,741 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:26:41,395 - INFO - [Train] [44/90] | Loss: 0.4003 | Train Acc: 87.95%
2026-01-14 13:26:43,529 - INFO - [Valid] [44/90] | Loss: 0.4796 | Val Acc: 80.24%
2026-01-14 13:26:43,544 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 13:26:43,553 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 13:26:43,572 - INFO - --------------------------------------------------
2026-01-14 13:26:43,572 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:26:53,319 - INFO - [Train] [45/90] | Loss: 0.4054 | Train Acc: 89.43%
2026-01-14 13:26:55,796 - INFO - [Valid] [45/90] | Loss: 0.4739 | Val Acc: 82.60%
2026-01-14 13:26:55,843 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 13:26:55,844 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 13:26:55,849 - INFO - --------------------------------------------------
2026-01-14 13:26:55,849 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:27:04,853 - INFO - [Train] [46/90] | Loss: 0.4004 | Train Acc: 88.62%
2026-01-14 13:27:07,458 - INFO - [Valid] [46/90] | Loss: 0.4750 | Val Acc: 81.42%
2026-01-14 13:27:07,471 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 13:27:07,472 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 13:27:07,477 - INFO - --------------------------------------------------
2026-01-14 13:27:07,478 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:27:15,959 - INFO - [Train] [47/90] | Loss: 0.4018 | Train Acc: 88.24%
2026-01-14 13:27:18,383 - INFO - [Valid] [47/90] | Loss: 0.4758 | Val Acc: 82.60%
2026-01-14 13:27:18,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.8356 | Recall: 0.7771 | F1: 0.8053
2026-01-14 13:27:18,397 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8681 | F1: 0.8427
2026-01-14 13:27:18,402 - INFO - --------------------------------------------------
2026-01-14 13:27:18,403 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:27:26,640 - INFO - [Train] [48/90] | Loss: 0.4051 | Train Acc: 87.95%
2026-01-14 13:27:29,229 - INFO - [Valid] [48/90] | Loss: 0.4852 | Val Acc: 81.71%
2026-01-14 13:27:29,309 - INFO - [Metrics for 'abnormal'] | Precision: 0.7811 | Recall: 0.8408 | F1: 0.8098
2026-01-14 13:27:29,309 - INFO - [Metrics for 'normal'] | Precision: 0.8529 | Recall: 0.7967 | F1: 0.8239
2026-01-14 13:27:29,316 - INFO - --------------------------------------------------
2026-01-14 13:27:29,316 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:27:37,361 - INFO - [Train] [49/90] | Loss: 0.4059 | Train Acc: 88.10%
2026-01-14 13:27:40,081 - INFO - [Valid] [49/90] | Loss: 0.4715 | Val Acc: 82.60%
2026-01-14 13:27:40,108 - INFO - [Metrics for 'abnormal'] | Precision: 0.8451 | Recall: 0.7643 | F1: 0.8027
2026-01-14 13:27:40,109 - INFO - [Metrics for 'normal'] | Precision: 0.8122 | Recall: 0.8791 | F1: 0.8443
2026-01-14 13:27:40,119 - INFO - --------------------------------------------------
2026-01-14 13:27:40,119 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:27:49,679 - INFO - [Train] [50/90] | Loss: 0.3930 | Train Acc: 89.81%
2026-01-14 13:27:52,900 - INFO - [Valid] [50/90] | Loss: 0.4857 | Val Acc: 82.30%
2026-01-14 13:27:52,915 - INFO - [Metrics for 'abnormal'] | Precision: 0.7836 | Recall: 0.8535 | F1: 0.8171
2026-01-14 13:27:52,916 - INFO - [Metrics for 'normal'] | Precision: 0.8631 | Recall: 0.7967 | F1: 0.8286
2026-01-14 13:27:52,921 - INFO - --------------------------------------------------
2026-01-14 13:27:52,922 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:28:02,044 - INFO - [Train] [51/90] | Loss: 0.4006 | Train Acc: 88.84%
2026-01-14 13:28:04,694 - INFO - [Valid] [51/90] | Loss: 0.4718 | Val Acc: 81.12%
2026-01-14 13:28:04,705 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:28:04,705 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:28:04,709 - INFO - --------------------------------------------------
2026-01-14 13:28:04,710 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:28:13,687 - INFO - [Train] [52/90] | Loss: 0.3944 | Train Acc: 89.06%
2026-01-14 13:28:16,896 - INFO - [Valid] [52/90] | Loss: 0.5036 | Val Acc: 80.83%
2026-01-14 13:28:16,950 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 13:28:16,950 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 13:28:16,967 - INFO - --------------------------------------------------
2026-01-14 13:28:16,968 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:28:25,323 - INFO - [Train] [53/90] | Loss: 0.3874 | Train Acc: 89.88%
2026-01-14 13:28:27,612 - INFO - [Valid] [53/90] | Loss: 0.4692 | Val Acc: 82.60%
2026-01-14 13:28:27,624 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8280 | F1: 0.8150
2026-01-14 13:28:27,625 - INFO - [Metrics for 'normal'] | Precision: 0.8475 | Recall: 0.8242 | F1: 0.8357
2026-01-14 13:28:27,629 - INFO - --------------------------------------------------
2026-01-14 13:28:27,630 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:28:36,899 - INFO - [Train] [54/90] | Loss: 0.3822 | Train Acc: 89.73%
2026-01-14 13:28:39,834 - INFO - [Valid] [54/90] | Loss: 0.4865 | Val Acc: 82.30%
2026-01-14 13:28:39,849 - INFO - [Metrics for 'abnormal'] | Precision: 0.7870 | Recall: 0.8471 | F1: 0.8160
2026-01-14 13:28:39,849 - INFO - [Metrics for 'normal'] | Precision: 0.8588 | Recall: 0.8022 | F1: 0.8295
2026-01-14 13:28:39,854 - INFO - --------------------------------------------------
2026-01-14 13:28:39,855 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:28:47,701 - INFO - [Train] [55/90] | Loss: 0.3832 | Train Acc: 90.03%
2026-01-14 13:28:49,955 - INFO - [Valid] [55/90] | Loss: 0.4791 | Val Acc: 82.60%
2026-01-14 13:28:49,967 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-01-14 13:28:49,968 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-01-14 13:28:49,973 - INFO - --------------------------------------------------
2026-01-14 13:28:49,974 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:28:58,529 - INFO - [Train] [56/90] | Loss: 0.3767 | Train Acc: 90.70%
2026-01-14 13:29:00,996 - INFO - [Valid] [56/90] | Loss: 0.4894 | Val Acc: 82.01%
2026-01-14 13:29:01,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.8038 | Recall: 0.8089 | F1: 0.8063
2026-01-14 13:29:01,008 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8297 | F1: 0.8320
2026-01-14 13:29:01,013 - INFO - --------------------------------------------------
2026-01-14 13:29:01,014 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:29:09,407 - INFO - [Train] [57/90] | Loss: 0.3802 | Train Acc: 89.58%
2026-01-14 13:29:11,957 - INFO - [Valid] [57/90] | Loss: 0.4718 | Val Acc: 82.89%
2026-01-14 13:29:11,979 - INFO - [Metrics for 'abnormal'] | Precision: 0.8037 | Recall: 0.8344 | F1: 0.8187
2026-01-14 13:29:11,979 - INFO - [Metrics for 'normal'] | Precision: 0.8523 | Recall: 0.8242 | F1: 0.8380
2026-01-14 13:29:11,984 - INFO - --------------------------------------------------
2026-01-14 13:29:11,985 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:29:21,302 - INFO - [Train] [58/90] | Loss: 0.3754 | Train Acc: 90.62%
2026-01-14 13:29:24,056 - INFO - [Valid] [58/90] | Loss: 0.4779 | Val Acc: 82.30%
2026-01-14 13:29:24,072 - INFO - [Metrics for 'abnormal'] | Precision: 0.8089 | Recall: 0.8089 | F1: 0.8089
2026-01-14 13:29:24,072 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8352 | F1: 0.8352
2026-01-14 13:29:24,076 - INFO - --------------------------------------------------
2026-01-14 13:29:24,077 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:29:32,489 - INFO - [Train] [59/90] | Loss: 0.3796 | Train Acc: 90.55%
2026-01-14 13:29:35,556 - INFO - [Valid] [59/90] | Loss: 0.4773 | Val Acc: 82.89%
2026-01-14 13:29:35,576 - INFO - [Metrics for 'abnormal'] | Precision: 0.8153 | Recall: 0.8153 | F1: 0.8153
2026-01-14 13:29:35,578 - INFO - [Metrics for 'normal'] | Precision: 0.8407 | Recall: 0.8407 | F1: 0.8407
2026-01-14 13:29:35,591 - INFO - --------------------------------------------------
2026-01-14 13:29:35,593 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:29:43,810 - INFO - [Train] [60/90] | Loss: 0.3724 | Train Acc: 90.48%
2026-01-14 13:29:46,655 - INFO - [Valid] [60/90] | Loss: 0.4855 | Val Acc: 82.30%
2026-01-14 13:29:46,669 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-01-14 13:29:46,670 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-01-14 13:29:46,676 - INFO - --------------------------------------------------
2026-01-14 13:29:46,677 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:29:55,712 - INFO - [Train] [61/90] | Loss: 0.3674 | Train Acc: 90.85%
2026-01-14 13:29:58,559 - INFO - [Valid] [61/90] | Loss: 0.4839 | Val Acc: 81.42%
2026-01-14 13:29:58,580 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 13:29:58,580 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 13:29:58,584 - INFO - --------------------------------------------------
2026-01-14 13:29:58,585 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:30:07,114 - INFO - [Train] [62/90] | Loss: 0.3756 | Train Acc: 90.70%
2026-01-14 13:30:10,229 - INFO - [Valid] [62/90] | Loss: 0.4835 | Val Acc: 82.01%
2026-01-14 13:30:10,605 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 13:30:10,605 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 13:30:10,614 - INFO - --------------------------------------------------
2026-01-14 13:30:10,615 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:30:20,352 - INFO - [Train] [63/90] | Loss: 0.3593 | Train Acc: 91.15%
2026-01-14 13:30:23,408 - INFO - [Valid] [63/90] | Loss: 0.4806 | Val Acc: 82.01%
2026-01-14 13:30:23,420 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 13:30:23,421 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 13:30:23,425 - INFO - --------------------------------------------------
2026-01-14 13:30:23,429 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:30:31,677 - INFO - [Train] [64/90] | Loss: 0.3639 | Train Acc: 91.29%
2026-01-14 13:30:34,291 - INFO - [Valid] [64/90] | Loss: 0.4810 | Val Acc: 81.71%
2026-01-14 13:30:34,313 - INFO - [Metrics for 'abnormal'] | Precision: 0.8276 | Recall: 0.7643 | F1: 0.7947
2026-01-14 13:30:34,318 - INFO - [Metrics for 'normal'] | Precision: 0.8093 | Recall: 0.8626 | F1: 0.8351
2026-01-14 13:30:34,325 - INFO - --------------------------------------------------
2026-01-14 13:30:34,326 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:30:43,514 - INFO - [Train] [65/90] | Loss: 0.3609 | Train Acc: 91.52%
2026-01-14 13:30:46,239 - INFO - [Valid] [65/90] | Loss: 0.4805 | Val Acc: 81.71%
2026-01-14 13:30:46,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 13:30:46,252 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 13:30:46,256 - INFO - --------------------------------------------------
2026-01-14 13:30:46,259 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:30:54,236 - INFO - [Train] [66/90] | Loss: 0.3532 | Train Acc: 92.04%
2026-01-14 13:30:56,652 - INFO - [Valid] [66/90] | Loss: 0.4829 | Val Acc: 82.89%
2026-01-14 13:30:56,666 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 13:30:56,666 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 13:30:56,671 - INFO - --------------------------------------------------
2026-01-14 13:30:56,672 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:31:04,849 - INFO - [Train] [67/90] | Loss: 0.3686 | Train Acc: 90.55%
2026-01-14 13:31:08,223 - INFO - [Valid] [67/90] | Loss: 0.4808 | Val Acc: 82.89%
2026-01-14 13:31:08,245 - INFO - [Metrics for 'abnormal'] | Precision: 0.8153 | Recall: 0.8153 | F1: 0.8153
2026-01-14 13:31:08,249 - INFO - [Metrics for 'normal'] | Precision: 0.8407 | Recall: 0.8407 | F1: 0.8407
2026-01-14 13:31:08,301 - INFO - --------------------------------------------------
2026-01-14 13:31:08,308 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:31:17,168 - INFO - [Train] [68/90] | Loss: 0.3662 | Train Acc: 91.67%
2026-01-14 13:31:19,972 - INFO - [Valid] [68/90] | Loss: 0.4779 | Val Acc: 81.71%
2026-01-14 13:31:19,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 13:31:19,985 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 13:31:19,989 - INFO - --------------------------------------------------
2026-01-14 13:31:19,989 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:31:28,798 - INFO - [Train] [69/90] | Loss: 0.3553 | Train Acc: 92.56%
2026-01-14 13:31:31,759 - INFO - [Valid] [69/90] | Loss: 0.4922 | Val Acc: 81.12%
2026-01-14 13:31:31,780 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 13:31:31,783 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 13:31:31,790 - INFO - --------------------------------------------------
2026-01-14 13:31:31,790 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:31:40,490 - INFO - [Train] [70/90] | Loss: 0.3571 | Train Acc: 92.86%
2026-01-14 13:31:43,038 - INFO - [Valid] [70/90] | Loss: 0.4932 | Val Acc: 81.12%
2026-01-14 13:31:43,047 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:31:43,048 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:31:43,053 - INFO - --------------------------------------------------
2026-01-14 13:31:43,053 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:31:52,069 - INFO - [Train] [71/90] | Loss: 0.3606 | Train Acc: 91.59%
2026-01-14 13:31:55,201 - INFO - [Valid] [71/90] | Loss: 0.4822 | Val Acc: 81.71%
2026-01-14 13:31:55,213 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-01-14 13:31:55,213 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-01-14 13:31:55,217 - INFO - --------------------------------------------------
2026-01-14 13:31:55,217 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:32:04,048 - INFO - [Train] [72/90] | Loss: 0.3576 | Train Acc: 91.59%
2026-01-14 13:32:05,992 - INFO - [Valid] [72/90] | Loss: 0.4921 | Val Acc: 82.01%
2026-01-14 13:32:06,028 - INFO - [Metrics for 'abnormal'] | Precision: 0.8077 | Recall: 0.8025 | F1: 0.8051
2026-01-14 13:32:06,029 - INFO - [Metrics for 'normal'] | Precision: 0.8306 | Recall: 0.8352 | F1: 0.8329
2026-01-14 13:32:06,039 - INFO - --------------------------------------------------
2026-01-14 13:32:06,043 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:32:16,213 - INFO - [Train] [73/90] | Loss: 0.3520 | Train Acc: 91.89%
2026-01-14 13:32:18,570 - INFO - [Valid] [73/90] | Loss: 0.4775 | Val Acc: 82.30%
2026-01-14 13:32:18,582 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 13:32:18,583 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 13:32:18,587 - INFO - --------------------------------------------------
2026-01-14 13:32:18,588 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:32:27,957 - INFO - [Train] [74/90] | Loss: 0.3517 | Train Acc: 92.71%
2026-01-14 13:32:30,561 - INFO - [Valid] [74/90] | Loss: 0.4892 | Val Acc: 81.42%
2026-01-14 13:32:30,586 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-01-14 13:32:30,587 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-01-14 13:32:30,593 - INFO - --------------------------------------------------
2026-01-14 13:32:30,594 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:32:39,681 - INFO - [Train] [75/90] | Loss: 0.3585 | Train Acc: 91.37%
2026-01-14 13:32:41,963 - INFO - [Valid] [75/90] | Loss: 0.4831 | Val Acc: 81.42%
2026-01-14 13:32:41,987 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-01-14 13:32:41,992 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-01-14 13:32:41,996 - INFO - --------------------------------------------------
2026-01-14 13:32:42,001 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:32:50,970 - INFO - [Train] [76/90] | Loss: 0.3503 | Train Acc: 91.82%
2026-01-14 13:32:53,589 - INFO - [Valid] [76/90] | Loss: 0.4990 | Val Acc: 80.83%
2026-01-14 13:32:53,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 13:32:53,601 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 13:32:53,605 - INFO - --------------------------------------------------
2026-01-14 13:32:53,606 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:33:03,239 - INFO - [Train] [77/90] | Loss: 0.3580 | Train Acc: 92.34%
2026-01-14 13:33:05,421 - INFO - [Valid] [77/90] | Loss: 0.4899 | Val Acc: 81.71%
2026-01-14 13:33:05,445 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:33:05,445 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:33:05,450 - INFO - --------------------------------------------------
2026-01-14 13:33:05,451 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:33:14,454 - INFO - [Train] [78/90] | Loss: 0.3585 | Train Acc: 91.74%
2026-01-14 13:33:16,928 - INFO - [Valid] [78/90] | Loss: 0.4947 | Val Acc: 81.12%
2026-01-14 13:33:16,943 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 13:33:16,945 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 13:33:16,961 - INFO - --------------------------------------------------
2026-01-14 13:33:16,963 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:33:25,182 - INFO - [Train] [79/90] | Loss: 0.3452 | Train Acc: 92.71%
2026-01-14 13:33:27,770 - INFO - [Valid] [79/90] | Loss: 0.4850 | Val Acc: 81.42%
2026-01-14 13:33:27,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 13:33:27,782 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 13:33:27,786 - INFO - --------------------------------------------------
2026-01-14 13:33:27,787 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:33:34,965 - INFO - [Train] [80/90] | Loss: 0.3465 | Train Acc: 93.08%
2026-01-14 13:33:38,649 - INFO - [Valid] [80/90] | Loss: 0.4912 | Val Acc: 82.01%
2026-01-14 13:33:38,673 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-01-14 13:33:38,678 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-01-14 13:33:38,682 - INFO - --------------------------------------------------
2026-01-14 13:33:38,686 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:33:46,717 - INFO - [Train] [81/90] | Loss: 0.3436 | Train Acc: 92.56%
2026-01-14 13:33:49,456 - INFO - [Valid] [81/90] | Loss: 0.4867 | Val Acc: 81.71%
2026-01-14 13:33:49,510 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-01-14 13:33:49,510 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-01-14 13:33:49,520 - INFO - --------------------------------------------------
2026-01-14 13:33:49,520 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:33:56,677 - INFO - [Train] [82/90] | Loss: 0.3491 | Train Acc: 92.34%
2026-01-14 13:33:59,872 - INFO - [Valid] [82/90] | Loss: 0.4985 | Val Acc: 81.42%
2026-01-14 13:33:59,886 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-01-14 13:33:59,887 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-01-14 13:33:59,892 - INFO - --------------------------------------------------
2026-01-14 13:33:59,893 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:34:10,211 - INFO - [Train] [83/90] | Loss: 0.3429 | Train Acc: 92.56%
2026-01-14 13:34:12,523 - INFO - [Valid] [83/90] | Loss: 0.4944 | Val Acc: 80.83%
2026-01-14 13:34:12,546 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 13:34:12,549 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 13:34:12,557 - INFO - --------------------------------------------------
2026-01-14 13:34:12,561 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:34:19,285 - INFO - [Train] [84/90] | Loss: 0.3477 | Train Acc: 92.63%
2026-01-14 13:34:21,756 - INFO - [Valid] [84/90] | Loss: 0.4923 | Val Acc: 81.42%
2026-01-14 13:34:21,787 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-01-14 13:34:21,788 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-01-14 13:34:21,794 - INFO - --------------------------------------------------
2026-01-14 13:34:21,795 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:34:29,085 - INFO - [Train] [85/90] | Loss: 0.3436 | Train Acc: 93.23%
2026-01-14 13:34:31,862 - INFO - [Valid] [85/90] | Loss: 0.5020 | Val Acc: 80.53%
2026-01-14 13:34:31,871 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 13:34:31,872 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 13:34:31,876 - INFO - --------------------------------------------------
2026-01-14 13:34:31,877 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:34:38,522 - INFO - [Train] [86/90] | Loss: 0.3422 | Train Acc: 92.56%
2026-01-14 13:34:41,042 - INFO - [Valid] [86/90] | Loss: 0.4955 | Val Acc: 80.83%
2026-01-14 13:34:41,072 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 13:34:41,072 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 13:34:41,099 - INFO - --------------------------------------------------
2026-01-14 13:34:41,099 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:34:47,949 - INFO - [Train] [87/90] | Loss: 0.3435 | Train Acc: 93.45%
2026-01-14 13:34:50,716 - INFO - [Valid] [87/90] | Loss: 0.4936 | Val Acc: 81.71%
2026-01-14 13:34:50,751 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 13:34:50,751 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 13:34:50,762 - INFO - --------------------------------------------------
2026-01-14 13:34:50,762 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:34:57,451 - INFO - [Train] [88/90] | Loss: 0.3420 | Train Acc: 92.71%
2026-01-14 13:34:59,153 - INFO - [Valid] [88/90] | Loss: 0.4857 | Val Acc: 82.30%
2026-01-14 13:34:59,163 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 13:34:59,163 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 13:34:59,167 - INFO - --------------------------------------------------
2026-01-14 13:34:59,167 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:35:05,697 - INFO - [Train] [89/90] | Loss: 0.3391 | Train Acc: 92.93%
2026-01-14 13:35:07,643 - INFO - [Valid] [89/90] | Loss: 0.4947 | Val Acc: 81.42%
2026-01-14 13:35:07,655 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 13:35:07,656 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 13:35:07,659 - INFO - --------------------------------------------------
2026-01-14 13:35:07,660 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:35:15,721 - INFO - [Train] [90/90] | Loss: 0.3459 | Train Acc: 92.86%
2026-01-14 13:35:17,515 - INFO - [Valid] [90/90] | Loss: 0.4790 | Val Acc: 82.30%
2026-01-14 13:35:17,527 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 13:35:17,528 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 13:35:17,535 - INFO - ==================================================
2026-01-14 13:35:17,536 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:35:17,536 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:35:17,536 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:35:17,623 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:35:17,624 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:35:17,625 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:35:18,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 13:35:18,191 - INFO - ==================================================
2026-01-14 13:35:18,197 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/best_model.pth'
2026-01-14 13:35:18,197 - INFO - ==================================================
2026-01-14 13:35:18,198 - INFO - Test 모드를 시작합니다.
2026-01-14 13:35:18,527 - INFO - 연산량 (MACs): 0.0554 GMACs per sample
2026-01-14 13:35:18,528 - INFO - 연산량 (FLOPs): 0.1107 GFLOPs per sample
2026-01-14 13:35:18,528 - INFO - ==================================================
2026-01-14 13:35:18,530 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:35:19,054 - INFO - 샘플 당 평균 Forward Pass 시간: 0.31ms (std: 0.15ms), FPS: 4507.22 (std: 3077.39) (1개 샘플 x 100회 반복)
2026-01-14 13:35:19,055 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 158.92 MB
2026-01-14 13:35:19,055 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:35:21,768 - INFO - [Test] Loss: 0.3894 | Test Acc: 81.71%
2026-01-14 13:35:21,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 13:35:21,781 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 13:35:22,360 - INFO - ==================================================
2026-01-14 13:35:22,360 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/confusion_matrix_20260114_131748.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/confusion_matrix_20260114_131748.pdf'
2026-01-14 13:35:22,360 - INFO - ==================================================
2026-01-14 13:35:22,361 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:35:23,098 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/model_fp32_20260114_131748.onnx'에 저장되었습니다. (크기: 0.12 MB)
2026-01-14 13:35:23,540 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2338.67 MB (증가량: 6.50 MB)
2026-01-14 13:35:23,541 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:35:24,568 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 5.00ms (std: 8.62ms)
2026-01-14 13:35:24,568 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 388.60 FPS (std: 254.58) (1개 샘플 x 100회 반복)
2026-01-14 13:35:24,568 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2340.17 MB (순수 증가량: 1.50 MB)
2026-01-14 13:35:24,568 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2340.17 MB (전체 증가량: 8.00 MB)
2026-01-14 13:35:28,126 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.71%
2026-01-14 13:35:28,136 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 13:35:28,137 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 13:35:28,797 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/val_acc.pdf'
2026-01-14 13:35:29,205 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/train_val_acc.pdf'
2026-01-14 13:35:29,520 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/F1_normal.pdf'
2026-01-14 13:35:29,967 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/val_loss.pdf'
2026-01-14 13:35:30,420 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/learning_rate.pdf'
2026-01-14 13:35:35,699 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_131748/graph_20260114_131748/compile.pdf'
