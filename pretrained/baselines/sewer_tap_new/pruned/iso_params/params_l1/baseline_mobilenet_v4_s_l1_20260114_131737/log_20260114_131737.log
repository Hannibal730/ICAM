2026-01-14 13:17:37,431 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/log_20260114_131737.log'에 저장됩니다.
2026-01-14 13:17:37,437 - INFO - ==================================================
2026-01-14 13:17:37,437 - INFO - config.yaml:
2026-01-14 13:17:37,438 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobilenet_v4_s
  use_l1_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:17:37,438 - INFO - ==================================================
2026-01-14 13:17:37,500 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:17:37,501 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:17:37,501 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:17:37,511 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:17:37,512 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:17:37,513 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:17:37,513 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:17:37,760 - INFO - ==================================================
2026-01-14 13:17:37,761 - INFO - 모델 파라미터 수:
2026-01-14 13:17:37,761 - INFO -   - 총 파라미터: 2,495,586 개
2026-01-14 13:17:37,761 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-01-14 13:17:37,761 - INFO - ================================================================================
2026-01-14 13:17:37,761 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:17:37,761 - INFO - ================================================================================
2026-01-14 13:17:37,761 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:17:37,762 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:17:37,762 - INFO - ==================================================
2026-01-14 13:17:37,762 - INFO - train 모드를 시작합니다.
2026-01-14 13:17:37,763 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:17:37,763 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:17:37,763 - INFO - --------------------------------------------------
2026-01-14 13:17:37,764 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:17:44,534 - INFO - [Train] [1/10] | Loss: 2.7142 | Train Acc: 65.62%
2026-01-14 13:17:47,004 - INFO - [Valid] [1/10] | Loss: 1.0126 | Val Acc: 63.13%
2026-01-14 13:17:47,024 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.2739 | F1: 0.4076
2026-01-14 13:17:47,024 - INFO - [Metrics for 'normal'] | Precision: 0.6000 | Recall: 0.9396 | F1: 0.7323
2026-01-14 13:17:47,082 - INFO - [Best Model Saved] (val loss: 1.0126) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:17:47,082 - INFO - --------------------------------------------------
2026-01-14 13:17:47,085 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:17:52,563 - INFO - [Train] [2/10] | Loss: 0.7030 | Train Acc: 72.40%
2026-01-14 13:17:54,680 - INFO - [Valid] [2/10] | Loss: 1.3041 | Val Acc: 56.34%
2026-01-14 13:17:54,693 - INFO - [Metrics for 'abnormal'] | Precision: 0.5266 | Recall: 0.5669 | F1: 0.5460
2026-01-14 13:17:54,694 - INFO - [Metrics for 'normal'] | Precision: 0.6000 | Recall: 0.5604 | F1: 0.5795
2026-01-14 13:17:54,699 - INFO - --------------------------------------------------
2026-01-14 13:17:54,703 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:18:00,380 - INFO - [Train] [3/10] | Loss: 0.6384 | Train Acc: 74.93%
2026-01-14 13:18:03,270 - INFO - [Valid] [3/10] | Loss: 1.5432 | Val Acc: 46.02%
2026-01-14 13:18:03,285 - INFO - [Metrics for 'abnormal'] | Precision: 0.4330 | Recall: 0.5350 | F1: 0.4786
2026-01-14 13:18:03,286 - INFO - [Metrics for 'normal'] | Precision: 0.4966 | Recall: 0.3956 | F1: 0.4404
2026-01-14 13:18:03,291 - INFO - --------------------------------------------------
2026-01-14 13:18:03,295 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:18:10,069 - INFO - [Train] [4/10] | Loss: 0.6166 | Train Acc: 74.11%
2026-01-14 13:18:12,371 - INFO - [Valid] [4/10] | Loss: 0.6813 | Val Acc: 68.44%
2026-01-14 13:18:12,381 - INFO - [Metrics for 'abnormal'] | Precision: 0.6359 | Recall: 0.7452 | F1: 0.6862
2026-01-14 13:18:12,381 - INFO - [Metrics for 'normal'] | Precision: 0.7419 | Recall: 0.6319 | F1: 0.6825
2026-01-14 13:18:12,433 - INFO - [Best Model Saved] (val loss: 0.6813) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:18:12,434 - INFO - --------------------------------------------------
2026-01-14 13:18:12,435 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:18:19,464 - INFO - [Train] [5/10] | Loss: 0.5977 | Train Acc: 75.60%
2026-01-14 13:18:21,289 - INFO - [Valid] [5/10] | Loss: 0.8661 | Val Acc: 72.27%
2026-01-14 13:18:21,300 - INFO - [Metrics for 'abnormal'] | Precision: 0.7944 | Recall: 0.5414 | F1: 0.6439
2026-01-14 13:18:21,300 - INFO - [Metrics for 'normal'] | Precision: 0.6897 | Recall: 0.8791 | F1: 0.7729
2026-01-14 13:18:21,304 - INFO - --------------------------------------------------
2026-01-14 13:18:21,306 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:18:28,684 - INFO - [Train] [6/10] | Loss: 0.5553 | Train Acc: 77.16%
2026-01-14 13:18:31,108 - INFO - [Valid] [6/10] | Loss: 0.7397 | Val Acc: 69.62%
2026-01-14 13:18:31,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.6144 | Recall: 0.9236 | F1: 0.7379
2026-01-14 13:18:31,124 - INFO - [Metrics for 'normal'] | Precision: 0.8835 | Recall: 0.5000 | F1: 0.6386
2026-01-14 13:18:31,129 - INFO - --------------------------------------------------
2026-01-14 13:18:31,133 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:18:37,503 - INFO - [Train] [7/10] | Loss: 0.5214 | Train Acc: 79.76%
2026-01-14 13:18:40,220 - INFO - [Valid] [7/10] | Loss: 0.5609 | Val Acc: 76.70%
2026-01-14 13:18:40,237 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.7452 | F1: 0.7476
2026-01-14 13:18:40,238 - INFO - [Metrics for 'normal'] | Precision: 0.7814 | Recall: 0.7857 | F1: 0.7836
2026-01-14 13:18:40,311 - INFO - [Best Model Saved] (val loss: 0.5609) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:18:40,312 - INFO - --------------------------------------------------
2026-01-14 13:18:40,314 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:18:47,445 - INFO - [Train] [8/10] | Loss: 0.5112 | Train Acc: 80.88%
2026-01-14 13:18:50,390 - INFO - [Valid] [8/10] | Loss: 0.5585 | Val Acc: 76.40%
2026-01-14 13:18:50,400 - INFO - [Metrics for 'abnormal'] | Precision: 0.7037 | Recall: 0.8471 | F1: 0.7688
2026-01-14 13:18:50,400 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.6923 | F1: 0.7590
2026-01-14 13:18:50,457 - INFO - [Best Model Saved] (val loss: 0.5585) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:18:50,457 - INFO - --------------------------------------------------
2026-01-14 13:18:50,460 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:18:58,133 - INFO - [Train] [9/10] | Loss: 0.4561 | Train Acc: 82.14%
2026-01-14 13:19:00,585 - INFO - [Valid] [9/10] | Loss: 0.5304 | Val Acc: 76.40%
2026-01-14 13:19:00,596 - INFO - [Metrics for 'abnormal'] | Precision: 0.7421 | Recall: 0.7516 | F1: 0.7468
2026-01-14 13:19:00,596 - INFO - [Metrics for 'normal'] | Precision: 0.7833 | Recall: 0.7747 | F1: 0.7790
2026-01-14 13:19:00,690 - INFO - [Best Model Saved] (val loss: 0.5304) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:19:00,690 - INFO - --------------------------------------------------
2026-01-14 13:19:00,692 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:19:08,541 - INFO - [Train] [10/10] | Loss: 0.4536 | Train Acc: 83.71%
2026-01-14 13:19:10,463 - INFO - [Valid] [10/10] | Loss: 0.5619 | Val Acc: 79.35%
2026-01-14 13:19:10,506 - INFO - [Metrics for 'abnormal'] | Precision: 0.8042 | Recall: 0.7325 | F1: 0.7667
2026-01-14 13:19:10,506 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.8462 | F1: 0.8148
2026-01-14 13:19:10,518 - INFO - ================================================================================
2026-01-14 13:19:10,521 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:19:10,522 - INFO - ================================================================================
2026-01-14 13:19:10,649 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:19:10,650 - INFO - ================================================================================
2026-01-14 13:19:10,650 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:19:10,652 - INFO - 원본 모델 파라미터: 2.4956M
2026-01-14 13:19:10,757 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:10,758 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:11,136 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:19:11,136 - INFO - ==================================================
2026-01-14 13:19:11,138 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.6554M (감소율: 73.74%)
2026-01-14 13:19:11,189 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:11,190 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:11,421 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:19:11,422 - INFO - ==================================================
2026-01-14 13:19:11,424 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1807M (감소율: 92.76%)
2026-01-14 13:19:11,463 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:11,463 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:11,769 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:19:11,769 - INFO - ==================================================
2026-01-14 13:19:11,772 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0548M (감소율: 97.80%)
2026-01-14 13:19:11,819 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:11,820 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:11,972 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:19:11,973 - INFO - ==================================================
2026-01-14 13:19:11,975 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0186M (감소율: 99.25%)
2026-01-14 13:19:12,016 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:12,016 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:12,206 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 13:19:12,206 - INFO - ==================================================
2026-01-14 13:19:12,208 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0343M (감소율: 98.63%)
2026-01-14 13:19:12,251 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:12,251 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:12,439 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 13:19:12,440 - INFO - ==================================================
2026-01-14 13:19:12,441 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0259M (감소율: 98.96%)
2026-01-14 13:19:12,537 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:12,538 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:12,691 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:19:12,692 - INFO - ==================================================
2026-01-14 13:19:12,694 - INFO -   [탐색  7] 희소도: 0.9049 -> 파라미터: 0.0304M (감소율: 98.78%)
2026-01-14 13:19:12,735 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:12,736 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:13,402 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9010546875000001)에 맞춰 변경되었습니다.
2026-01-14 13:19:13,402 - INFO - ==================================================
2026-01-14 13:19:13,405 - INFO -   [탐색  8] 희소도: 0.9011 -> 파라미터: 0.0317M (감소율: 98.73%)
2026-01-14 13:19:13,464 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:13,465 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:13,824 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9029882812500001)에 맞춰 변경되었습니다.
2026-01-14 13:19:13,827 - INFO - ==================================================
2026-01-14 13:19:13,828 - INFO -   [탐색  9] 희소도: 0.9030 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:13,899 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:13,900 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:14,181 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9020214843750001)에 맞춰 변경되었습니다.
2026-01-14 13:19:14,183 - INFO - ==================================================
2026-01-14 13:19:14,185 - INFO -   [탐색 10] 희소도: 0.9020 -> 파라미터: 0.0316M (감소율: 98.73%)
2026-01-14 13:19:14,244 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:14,245 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:14,443 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 13:19:14,443 - INFO - ==================================================
2026-01-14 13:19:14,445 - INFO -   [탐색 11] 희소도: 0.9025 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:14,497 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:14,498 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:14,708 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90226318359375)에 맞춰 변경되었습니다.
2026-01-14 13:19:14,708 - INFO - ==================================================
2026-01-14 13:19:14,711 - INFO -   [탐색 12] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:14,757 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:14,757 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:15,113 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902384033203125)에 맞춰 변경되었습니다.
2026-01-14 13:19:15,113 - INFO - ==================================================
2026-01-14 13:19:15,118 - INFO -   [탐색 13] 희소도: 0.9024 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:15,196 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:15,197 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:15,400 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023236083984375)에 맞춰 변경되었습니다.
2026-01-14 13:19:15,402 - INFO - ==================================================
2026-01-14 13:19:15,404 - INFO -   [탐색 14] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:15,450 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:15,451 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:15,655 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023538208007813)에 맞춰 변경되었습니다.
2026-01-14 13:19:15,656 - INFO - ==================================================
2026-01-14 13:19:15,659 - INFO -   [탐색 15] 희소도: 0.9024 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:15,705 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:15,706 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:15,912 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023387145996093)에 맞춰 변경되었습니다.
2026-01-14 13:19:15,912 - INFO - ==================================================
2026-01-14 13:19:15,914 - INFO -   [탐색 16] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:15,955 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:15,956 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:16,154 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023462677001953)에 맞춰 변경되었습니다.
2026-01-14 13:19:16,154 - INFO - ==================================================
2026-01-14 13:19:16,156 - INFO -   [탐색 17] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:16,196 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:16,197 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:16,409 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023424911499023)에 맞춰 변경되었습니다.
2026-01-14 13:19:16,410 - INFO - ==================================================
2026-01-14 13:19:16,412 - INFO -   [탐색 18] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:16,461 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:16,462 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:17,038 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023443794250487)에 맞춰 변경되었습니다.
2026-01-14 13:19:17,039 - INFO - ==================================================
2026-01-14 13:19:17,043 - INFO -   [탐색 19] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:17,101 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:17,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:17,374 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023434352874755)에 맞춰 변경되었습니다.
2026-01-14 13:19:17,374 - INFO - ==================================================
2026-01-14 13:19:17,377 - INFO -   [탐색 20] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:17,419 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:17,419 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:17,727 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023439073562621)에 맞춰 변경되었습니다.
2026-01-14 13:19:17,728 - INFO - ==================================================
2026-01-14 13:19:17,733 - INFO -   [탐색 21] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:17,852 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:17,852 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:18,122 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023436713218689)에 맞춰 변경되었습니다.
2026-01-14 13:19:18,123 - INFO - ==================================================
2026-01-14 13:19:18,125 - INFO -   [탐색 22] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:18,244 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:18,244 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:18,677 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437893390656)에 맞춰 변경되었습니다.
2026-01-14 13:19:18,678 - INFO - ==================================================
2026-01-14 13:19:18,681 - INFO -   [탐색 23] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:18,745 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:18,748 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:19,174 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437303304672)에 맞춰 변경되었습니다.
2026-01-14 13:19:19,175 - INFO - ==================================================
2026-01-14 13:19:19,177 - INFO -   [탐색 24] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:19,226 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:19,227 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:19,417 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437598347663)에 맞춰 변경되었습니다.
2026-01-14 13:19:19,418 - INFO - ==================================================
2026-01-14 13:19:19,421 - INFO -   [탐색 25] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:19,470 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:19,471 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:19,871 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437450826168)에 맞춰 변경되었습니다.
2026-01-14 13:19:19,871 - INFO - ==================================================
2026-01-14 13:19:19,873 - INFO -   [탐색 26] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:19,987 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:19,987 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:20,324 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437524586916)에 맞춰 변경되었습니다.
2026-01-14 13:19:20,325 - INFO - ==================================================
2026-01-14 13:19:20,328 - INFO -   [탐색 27] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:20,488 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:20,489 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:20,878 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437487706543)에 맞춰 변경되었습니다.
2026-01-14 13:19:20,879 - INFO - ==================================================
2026-01-14 13:19:20,881 - INFO -   [탐색 28] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:20,933 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:20,934 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:21,150 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343750614673)에 맞춰 변경되었습니다.
2026-01-14 13:19:21,151 - INFO - ==================================================
2026-01-14 13:19:21,153 - INFO -   [탐색 29] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:21,204 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:21,205 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:21,945 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437496926636)에 맞춰 변경되었습니다.
2026-01-14 13:19:21,945 - INFO - ==================================================
2026-01-14 13:19:21,949 - INFO -   [탐색 30] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:22,009 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:22,010 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:22,253 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437501536683)에 맞춰 변경되었습니다.
2026-01-14 13:19:22,254 - INFO - ==================================================
2026-01-14 13:19:22,256 - INFO -   [탐색 31] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:22,309 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:22,310 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:22,513 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499231659)에 맞춰 변경되었습니다.
2026-01-14 13:19:22,514 - INFO - ==================================================
2026-01-14 13:19:22,516 - INFO -   [탐색 32] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:22,574 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:22,574 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:22,844 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343750038417)에 맞춰 변경되었습니다.
2026-01-14 13:19:22,845 - INFO - ==================================================
2026-01-14 13:19:22,847 - INFO -   [탐색 33] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:22,917 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:22,918 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:23,202 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499807915)에 맞춰 변경되었습니다.
2026-01-14 13:19:23,202 - INFO - ==================================================
2026-01-14 13:19:23,205 - INFO -   [탐색 34] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:23,257 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:23,257 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:23,597 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500096043)에 맞춰 변경되었습니다.
2026-01-14 13:19:23,600 - INFO - ==================================================
2026-01-14 13:19:23,602 - INFO -   [탐색 35] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:23,650 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:23,650 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:23,865 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499951978)에 맞춰 변경되었습니다.
2026-01-14 13:19:23,866 - INFO - ==================================================
2026-01-14 13:19:23,868 - INFO -   [탐색 36] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:23,922 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:23,923 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:24,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500024011)에 맞춰 변경되었습니다.
2026-01-14 13:19:24,178 - INFO - ==================================================
2026-01-14 13:19:24,182 - INFO -   [탐색 37] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:24,233 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:24,234 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:24,493 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499987994)에 맞춰 변경되었습니다.
2026-01-14 13:19:24,494 - INFO - ==================================================
2026-01-14 13:19:24,496 - INFO -   [탐색 38] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:24,548 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:24,549 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:24,847 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500006002)에 맞춰 변경되었습니다.
2026-01-14 13:19:24,847 - INFO - ==================================================
2026-01-14 13:19:24,850 - INFO -   [탐색 39] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:24,908 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:24,909 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:25,216 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499996998)에 맞춰 변경되었습니다.
2026-01-14 13:19:25,217 - INFO - ==================================================
2026-01-14 13:19:25,219 - INFO -   [탐색 40] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:25,258 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:25,259 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:25,509 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375000015)에 맞춰 변경되었습니다.
2026-01-14 13:19:25,509 - INFO - ==================================================
2026-01-14 13:19:25,511 - INFO -   [탐색 41] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:25,554 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:25,555 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:26,170 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343749999925)에 맞춰 변경되었습니다.
2026-01-14 13:19:26,170 - INFO - ==================================================
2026-01-14 13:19:26,174 - INFO -   [탐색 42] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:26,223 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:26,224 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:26,524 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000375)에 맞춰 변경되었습니다.
2026-01-14 13:19:26,525 - INFO - ==================================================
2026-01-14 13:19:26,528 - INFO -   [탐색 43] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:26,597 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:26,597 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:26,865 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999812)에 맞춰 변경되었습니다.
2026-01-14 13:19:26,866 - INFO - ==================================================
2026-01-14 13:19:26,868 - INFO -   [탐색 44] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:26,907 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:26,908 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:27,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000093)에 맞춰 변경되었습니다.
2026-01-14 13:19:27,141 - INFO - ==================================================
2026-01-14 13:19:27,144 - INFO -   [탐색 45] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:27,192 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:27,193 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:27,576 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999953)에 맞춰 변경되었습니다.
2026-01-14 13:19:27,577 - INFO - ==================================================
2026-01-14 13:19:27,580 - INFO -   [탐색 46] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:27,634 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:27,635 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:28,006 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000023)에 맞춰 변경되었습니다.
2026-01-14 13:19:28,007 - INFO - ==================================================
2026-01-14 13:19:28,009 - INFO -   [탐색 47] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:28,061 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:28,061 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:28,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999989)에 맞춰 변경되었습니다.
2026-01-14 13:19:28,307 - INFO - ==================================================
2026-01-14 13:19:28,311 - INFO -   [탐색 48] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:28,367 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:28,367 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:28,580 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000007)에 맞춰 변경되었습니다.
2026-01-14 13:19:28,580 - INFO - ==================================================
2026-01-14 13:19:28,583 - INFO -   [탐색 49] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:28,636 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:28,636 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:28,877 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999998)에 맞춰 변경되었습니다.
2026-01-14 13:19:28,877 - INFO - ==================================================
2026-01-14 13:19:28,880 - INFO -   [탐색 50] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:28,929 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:28,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:29,078 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000002)에 맞춰 변경되었습니다.
2026-01-14 13:19:29,078 - INFO - ==================================================
2026-01-14 13:19:29,080 - INFO -   [탐색 51] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:29,120 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:29,120 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:29,305 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:29,306 - INFO - ==================================================
2026-01-14 13:19:29,308 - INFO -   [탐색 52] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:29,357 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:29,358 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:29,580 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000001)에 맞춰 변경되었습니다.
2026-01-14 13:19:29,581 - INFO - ==================================================
2026-01-14 13:19:29,583 - INFO -   [탐색 53] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:19:29,633 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:29,633 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:29,848 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:29,849 - INFO - ==================================================
2026-01-14 13:19:29,851 - INFO -   [탐색 54] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:29,913 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:29,914 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:30,075 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:30,076 - INFO - ==================================================
2026-01-14 13:19:30,078 - INFO -   [탐색 55] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:30,519 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:30,520 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:30,700 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:30,700 - INFO - ==================================================
2026-01-14 13:19:30,703 - INFO -   [탐색 56] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:30,769 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:30,769 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:31,081 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:31,082 - INFO - ==================================================
2026-01-14 13:19:31,084 - INFO -   [탐색 57] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:31,140 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:31,141 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:31,357 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:31,358 - INFO - ==================================================
2026-01-14 13:19:31,360 - INFO -   [탐색 58] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:31,401 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:31,401 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:31,698 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:31,699 - INFO - ==================================================
2026-01-14 13:19:31,702 - INFO -   [탐색 59] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:31,754 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:31,755 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:32,144 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:32,145 - INFO - ==================================================
2026-01-14 13:19:32,148 - INFO -   [탐색 60] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:32,201 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:32,202 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:32,520 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:32,523 - INFO - ==================================================
2026-01-14 13:19:32,525 - INFO -   [탐색 61] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:32,569 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:32,570 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:32,796 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:32,797 - INFO - ==================================================
2026-01-14 13:19:32,799 - INFO -   [탐색 62] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:32,842 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:32,843 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:33,057 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:33,057 - INFO - ==================================================
2026-01-14 13:19:33,059 - INFO -   [탐색 63] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:33,108 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:33,109 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:33,363 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:33,364 - INFO - ==================================================
2026-01-14 13:19:33,366 - INFO -   [탐색 64] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:33,409 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:33,410 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:33,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:33,670 - INFO - ==================================================
2026-01-14 13:19:33,672 - INFO -   [탐색 65] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:33,723 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:33,724 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:34,019 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:34,020 - INFO - ==================================================
2026-01-14 13:19:34,027 - INFO -   [탐색 66] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:34,113 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:34,114 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:34,324 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:34,325 - INFO - ==================================================
2026-01-14 13:19:34,328 - INFO -   [탐색 67] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:34,369 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:34,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:34,764 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:34,766 - INFO - ==================================================
2026-01-14 13:19:34,770 - INFO -   [탐색 68] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:34,848 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:34,848 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:35,965 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:35,966 - INFO - ==================================================
2026-01-14 13:19:35,970 - INFO -   [탐색 69] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:36,030 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:36,030 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:36,280 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:36,281 - INFO - ==================================================
2026-01-14 13:19:36,283 - INFO -   [탐색 70] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:36,336 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:36,337 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:36,570 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:36,571 - INFO - ==================================================
2026-01-14 13:19:36,574 - INFO -   [탐색 71] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:36,629 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:36,629 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:36,814 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:36,814 - INFO - ==================================================
2026-01-14 13:19:36,817 - INFO -   [탐색 72] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:36,875 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:36,876 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:37,117 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:37,118 - INFO - ==================================================
2026-01-14 13:19:37,120 - INFO -   [탐색 73] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:37,188 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:37,188 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:37,500 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:37,501 - INFO - ==================================================
2026-01-14 13:19:37,505 - INFO -   [탐색 74] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:37,559 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:37,559 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:37,800 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:37,801 - INFO - ==================================================
2026-01-14 13:19:37,803 - INFO -   [탐색 75] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:37,840 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:37,841 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:38,021 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:38,022 - INFO - ==================================================
2026-01-14 13:19:38,024 - INFO -   [탐색 76] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:38,094 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:38,096 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:38,259 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:38,260 - INFO - ==================================================
2026-01-14 13:19:38,262 - INFO -   [탐색 77] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:38,320 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:38,320 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:38,679 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:38,680 - INFO - ==================================================
2026-01-14 13:19:38,681 - INFO -   [탐색 78] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:38,725 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:38,726 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:39,095 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:39,096 - INFO - ==================================================
2026-01-14 13:19:39,099 - INFO -   [탐색 79] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:39,149 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:39,150 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:39,413 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:39,413 - INFO - ==================================================
2026-01-14 13:19:39,415 - INFO -   [탐색 80] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:39,490 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:39,490 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:39,746 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:39,746 - INFO - ==================================================
2026-01-14 13:19:39,748 - INFO -   [탐색 81] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:40,205 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:40,206 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:40,435 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:40,436 - INFO - ==================================================
2026-01-14 13:19:40,440 - INFO -   [탐색 82] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:40,491 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:40,493 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:40,720 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:40,721 - INFO - ==================================================
2026-01-14 13:19:40,724 - INFO -   [탐색 83] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:40,780 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:40,781 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:41,012 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:41,012 - INFO - ==================================================
2026-01-14 13:19:41,014 - INFO -   [탐색 84] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:41,053 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:41,054 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:41,241 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:41,242 - INFO - ==================================================
2026-01-14 13:19:41,244 - INFO -   [탐색 85] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:41,284 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:41,285 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:41,471 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:41,471 - INFO - ==================================================
2026-01-14 13:19:41,473 - INFO -   [탐색 86] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:41,512 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:41,513 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:41,753 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:41,754 - INFO - ==================================================
2026-01-14 13:19:41,757 - INFO -   [탐색 87] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:41,818 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:41,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:42,056 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:42,056 - INFO - ==================================================
2026-01-14 13:19:42,058 - INFO -   [탐색 88] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:42,104 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:42,105 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:42,368 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:42,369 - INFO - ==================================================
2026-01-14 13:19:42,371 - INFO -   [탐색 89] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:42,426 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:42,427 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:42,639 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:42,640 - INFO - ==================================================
2026-01-14 13:19:42,642 - INFO -   [탐색 90] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:42,693 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:42,694 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:42,874 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:42,875 - INFO - ==================================================
2026-01-14 13:19:42,878 - INFO -   [탐색 91] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:42,917 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:42,918 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:43,504 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:43,505 - INFO - ==================================================
2026-01-14 13:19:43,511 - INFO -   [탐색 92] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:43,564 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:43,564 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:44,119 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:44,120 - INFO - ==================================================
2026-01-14 13:19:44,123 - INFO -   [탐색 93] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:44,178 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:44,178 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:44,526 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:44,527 - INFO - ==================================================
2026-01-14 13:19:44,529 - INFO -   [탐색 94] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:44,583 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:44,583 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:44,829 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:44,829 - INFO - ==================================================
2026-01-14 13:19:44,831 - INFO -   [탐색 95] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:44,886 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:44,887 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:45,188 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:45,188 - INFO - ==================================================
2026-01-14 13:19:45,191 - INFO -   [탐색 96] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:45,248 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:45,248 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:45,442 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:45,443 - INFO - ==================================================
2026-01-14 13:19:45,445 - INFO -   [탐색 97] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:45,491 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:45,492 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:45,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:45,647 - INFO - ==================================================
2026-01-14 13:19:45,649 - INFO -   [탐색 98] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:45,707 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:45,708 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:45,944 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:45,945 - INFO - ==================================================
2026-01-14 13:19:45,947 - INFO -   [탐색 99] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:45,986 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:45,986 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:46,176 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:19:46,177 - INFO - ==================================================
2026-01-14 13:19:46,179 - INFO -   [탐색 100] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:19:46,179 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9025 입니다.
2026-01-14 13:19:46,180 - INFO - ================================================================================
2026-01-14 13:19:46,184 - INFO - 계산된 Pruning 정보(희소도: 0.9025)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:19:46,231 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:19:46,346 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:19:46,347 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:19:46,598 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 13:19:46,598 - INFO - ==================================================
2026-01-14 13:19:46,600 - INFO - ==================================================
2026-01-14 13:19:46,601 - INFO - 모델 파라미터 수:
2026-01-14 13:19:46,601 - INFO -   - 총 파라미터: 31,233 개
2026-01-14 13:19:46,601 - INFO -   - 학습 가능한 파라미터: 31,233 개
2026-01-14 13:19:46,689 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:19:46,814 - INFO - FLOPs가 0.3853 GFLOPs에서 0.0077 GFLOPs로 감소했습니다 (감소율: 97.99%).
2026-01-14 13:19:46,814 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:19:46,815 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:19:46,817 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:19:46,818 - INFO - ==================================================
2026-01-14 13:19:46,818 - INFO - train 모드를 시작합니다.
2026-01-14 13:19:46,819 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:19:46,819 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:19:46,819 - INFO - --------------------------------------------------
2026-01-14 13:19:46,822 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:19:52,515 - INFO - [Train] [11/90] | Loss: 0.8146 | Train Acc: 61.76%
2026-01-14 13:19:54,107 - INFO - [Valid] [11/90] | Loss: 0.6949 | Val Acc: 67.85%
2026-01-14 13:19:54,121 - INFO - [Metrics for 'abnormal'] | Precision: 0.6714 | Recall: 0.5987 | F1: 0.6330
2026-01-14 13:19:54,122 - INFO - [Metrics for 'normal'] | Precision: 0.6834 | Recall: 0.7473 | F1: 0.7139
2026-01-14 13:19:54,164 - INFO - [Best Model Saved] (val loss: 0.6949) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:19:54,165 - INFO - --------------------------------------------------
2026-01-14 13:19:54,167 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:20:00,247 - INFO - [Train] [12/90] | Loss: 0.6047 | Train Acc: 68.30%
2026-01-14 13:20:01,908 - INFO - [Valid] [12/90] | Loss: 0.6145 | Val Acc: 66.96%
2026-01-14 13:20:01,922 - INFO - [Metrics for 'abnormal'] | Precision: 0.6452 | Recall: 0.6369 | F1: 0.6410
2026-01-14 13:20:01,922 - INFO - [Metrics for 'normal'] | Precision: 0.6902 | Recall: 0.6978 | F1: 0.6940
2026-01-14 13:20:01,965 - INFO - [Best Model Saved] (val loss: 0.6145) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:20:01,965 - INFO - --------------------------------------------------
2026-01-14 13:20:01,968 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:20:07,009 - INFO - [Train] [13/90] | Loss: 0.5805 | Train Acc: 71.88%
2026-01-14 13:20:08,635 - INFO - [Valid] [13/90] | Loss: 0.6213 | Val Acc: 69.91%
2026-01-14 13:20:08,647 - INFO - [Metrics for 'abnormal'] | Precision: 0.7311 | Recall: 0.5541 | F1: 0.6304
2026-01-14 13:20:08,648 - INFO - [Metrics for 'normal'] | Precision: 0.6818 | Recall: 0.8242 | F1: 0.7463
2026-01-14 13:20:08,652 - INFO - --------------------------------------------------
2026-01-14 13:20:08,654 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:20:13,627 - INFO - [Train] [14/90] | Loss: 0.5632 | Train Acc: 74.03%
2026-01-14 13:20:15,033 - INFO - [Valid] [14/90] | Loss: 0.6180 | Val Acc: 71.09%
2026-01-14 13:20:15,041 - INFO - [Metrics for 'abnormal'] | Precision: 0.6468 | Recall: 0.8280 | F1: 0.7263
2026-01-14 13:20:15,041 - INFO - [Metrics for 'normal'] | Precision: 0.8043 | Recall: 0.6099 | F1: 0.6937
2026-01-14 13:20:15,044 - INFO - --------------------------------------------------
2026-01-14 13:20:15,045 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:20:19,973 - INFO - [Train] [15/90] | Loss: 0.5589 | Train Acc: 74.33%
2026-01-14 13:20:21,601 - INFO - [Valid] [15/90] | Loss: 0.5620 | Val Acc: 72.86%
2026-01-14 13:20:21,609 - INFO - [Metrics for 'abnormal'] | Precision: 0.7124 | Recall: 0.6943 | F1: 0.7032
2026-01-14 13:20:21,609 - INFO - [Metrics for 'normal'] | Precision: 0.7419 | Recall: 0.7582 | F1: 0.7500
2026-01-14 13:20:21,635 - INFO - [Best Model Saved] (val loss: 0.5620) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:20:21,635 - INFO - --------------------------------------------------
2026-01-14 13:20:21,637 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:20:26,657 - INFO - [Train] [16/90] | Loss: 0.5308 | Train Acc: 76.49%
2026-01-14 13:20:28,280 - INFO - [Valid] [16/90] | Loss: 0.5572 | Val Acc: 72.86%
2026-01-14 13:20:28,292 - INFO - [Metrics for 'abnormal'] | Precision: 0.7097 | Recall: 0.7006 | F1: 0.7051
2026-01-14 13:20:28,293 - INFO - [Metrics for 'normal'] | Precision: 0.7446 | Recall: 0.7527 | F1: 0.7486
2026-01-14 13:20:28,332 - INFO - [Best Model Saved] (val loss: 0.5572) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:20:28,332 - INFO - --------------------------------------------------
2026-01-14 13:20:28,335 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:20:34,565 - INFO - [Train] [17/90] | Loss: 0.5222 | Train Acc: 78.65%
2026-01-14 13:20:36,389 - INFO - [Valid] [17/90] | Loss: 0.5505 | Val Acc: 76.11%
2026-01-14 13:20:36,403 - INFO - [Metrics for 'abnormal'] | Precision: 0.7209 | Recall: 0.7898 | F1: 0.7538
2026-01-14 13:20:36,404 - INFO - [Metrics for 'normal'] | Precision: 0.8024 | Recall: 0.7363 | F1: 0.7679
2026-01-14 13:20:36,444 - INFO - [Best Model Saved] (val loss: 0.5505) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:20:36,444 - INFO - --------------------------------------------------
2026-01-14 13:20:36,446 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:20:42,281 - INFO - [Train] [18/90] | Loss: 0.5158 | Train Acc: 78.72%
2026-01-14 13:20:44,093 - INFO - [Valid] [18/90] | Loss: 0.5778 | Val Acc: 74.93%
2026-01-14 13:20:44,102 - INFO - [Metrics for 'abnormal'] | Precision: 0.7093 | Recall: 0.7771 | F1: 0.7416
2026-01-14 13:20:44,102 - INFO - [Metrics for 'normal'] | Precision: 0.7904 | Recall: 0.7253 | F1: 0.7564
2026-01-14 13:20:44,105 - INFO - --------------------------------------------------
2026-01-14 13:20:44,107 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:20:50,578 - INFO - [Train] [19/90] | Loss: 0.5062 | Train Acc: 79.32%
2026-01-14 13:20:52,509 - INFO - [Valid] [19/90] | Loss: 0.5823 | Val Acc: 72.27%
2026-01-14 13:20:52,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.7114 | Recall: 0.6752 | F1: 0.6928
2026-01-14 13:20:52,523 - INFO - [Metrics for 'normal'] | Precision: 0.7316 | Recall: 0.7637 | F1: 0.7473
2026-01-14 13:20:52,528 - INFO - --------------------------------------------------
2026-01-14 13:20:52,531 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:21:00,728 - INFO - [Train] [20/90] | Loss: 0.4923 | Train Acc: 81.62%
2026-01-14 13:21:02,578 - INFO - [Valid] [20/90] | Loss: 0.5600 | Val Acc: 77.58%
2026-01-14 13:21:02,587 - INFO - [Metrics for 'abnormal'] | Precision: 0.7872 | Recall: 0.7070 | F1: 0.7450
2026-01-14 13:21:02,587 - INFO - [Metrics for 'normal'] | Precision: 0.7677 | Recall: 0.8352 | F1: 0.8000
2026-01-14 13:21:02,591 - INFO - --------------------------------------------------
2026-01-14 13:21:02,592 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:21:09,256 - INFO - [Train] [21/90] | Loss: 0.4922 | Train Acc: 80.51%
2026-01-14 13:21:11,209 - INFO - [Valid] [21/90] | Loss: 0.5553 | Val Acc: 76.70%
2026-01-14 13:21:11,229 - INFO - [Metrics for 'abnormal'] | Precision: 0.7407 | Recall: 0.7643 | F1: 0.7524
2026-01-14 13:21:11,230 - INFO - [Metrics for 'normal'] | Precision: 0.7910 | Recall: 0.7692 | F1: 0.7799
2026-01-14 13:21:11,236 - INFO - --------------------------------------------------
2026-01-14 13:21:11,238 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:21:19,426 - INFO - [Train] [22/90] | Loss: 0.4750 | Train Acc: 83.41%
2026-01-14 13:21:21,326 - INFO - [Valid] [22/90] | Loss: 0.5535 | Val Acc: 75.81%
2026-01-14 13:21:21,356 - INFO - [Metrics for 'abnormal'] | Precision: 0.7622 | Recall: 0.6943 | F1: 0.7267
2026-01-14 13:21:21,357 - INFO - [Metrics for 'normal'] | Precision: 0.7551 | Recall: 0.8132 | F1: 0.7831
2026-01-14 13:21:21,364 - INFO - --------------------------------------------------
2026-01-14 13:21:21,371 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:21:29,154 - INFO - [Train] [23/90] | Loss: 0.4762 | Train Acc: 82.07%
2026-01-14 13:21:31,447 - INFO - [Valid] [23/90] | Loss: 0.5282 | Val Acc: 77.29%
2026-01-14 13:21:31,460 - INFO - [Metrics for 'abnormal'] | Precision: 0.7597 | Recall: 0.7452 | F1: 0.7524
2026-01-14 13:21:31,461 - INFO - [Metrics for 'normal'] | Precision: 0.7838 | Recall: 0.7967 | F1: 0.7902
2026-01-14 13:21:31,508 - INFO - [Best Model Saved] (val loss: 0.5282) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:21:31,508 - INFO - --------------------------------------------------
2026-01-14 13:21:31,511 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:21:39,496 - INFO - [Train] [24/90] | Loss: 0.4798 | Train Acc: 81.70%
2026-01-14 13:21:41,664 - INFO - [Valid] [24/90] | Loss: 0.5573 | Val Acc: 77.58%
2026-01-14 13:21:41,678 - INFO - [Metrics for 'abnormal'] | Precision: 0.7314 | Recall: 0.8153 | F1: 0.7711
2026-01-14 13:21:41,679 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.7418 | F1: 0.7803
2026-01-14 13:21:41,684 - INFO - --------------------------------------------------
2026-01-14 13:21:41,686 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:21:50,401 - INFO - [Train] [25/90] | Loss: 0.4676 | Train Acc: 82.51%
2026-01-14 13:21:52,423 - INFO - [Valid] [25/90] | Loss: 0.5409 | Val Acc: 77.29%
2026-01-14 13:21:52,450 - INFO - [Metrics for 'abnormal'] | Precision: 0.7667 | Recall: 0.7325 | F1: 0.7492
2026-01-14 13:21:52,450 - INFO - [Metrics for 'normal'] | Precision: 0.7778 | Recall: 0.8077 | F1: 0.7925
2026-01-14 13:21:52,458 - INFO - --------------------------------------------------
2026-01-14 13:21:52,463 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:22:01,732 - INFO - [Train] [26/90] | Loss: 0.4599 | Train Acc: 83.56%
2026-01-14 13:22:04,101 - INFO - [Valid] [26/90] | Loss: 0.5548 | Val Acc: 75.52%
2026-01-14 13:22:04,127 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.6433 | F1: 0.7088
2026-01-14 13:22:04,127 - INFO - [Metrics for 'normal'] | Precision: 0.7346 | Recall: 0.8516 | F1: 0.7888
2026-01-14 13:22:04,135 - INFO - --------------------------------------------------
2026-01-14 13:22:04,141 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:22:14,439 - INFO - [Train] [27/90] | Loss: 0.4467 | Train Acc: 84.52%
2026-01-14 13:22:17,239 - INFO - [Valid] [27/90] | Loss: 0.5505 | Val Acc: 78.17%
2026-01-14 13:22:17,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.7643 | Recall: 0.7643 | F1: 0.7643
2026-01-14 13:22:17,251 - INFO - [Metrics for 'normal'] | Precision: 0.7967 | Recall: 0.7967 | F1: 0.7967
2026-01-14 13:22:17,256 - INFO - --------------------------------------------------
2026-01-14 13:22:17,259 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:22:25,642 - INFO - [Train] [28/90] | Loss: 0.4560 | Train Acc: 83.04%
2026-01-14 13:22:28,027 - INFO - [Valid] [28/90] | Loss: 0.5360 | Val Acc: 79.65%
2026-01-14 13:22:28,041 - INFO - [Metrics for 'abnormal'] | Precision: 0.8188 | Recall: 0.7197 | F1: 0.7661
2026-01-14 13:22:28,042 - INFO - [Metrics for 'normal'] | Precision: 0.7811 | Recall: 0.8626 | F1: 0.8198
2026-01-14 13:22:28,047 - INFO - --------------------------------------------------
2026-01-14 13:22:28,050 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:22:38,581 - INFO - [Train] [29/90] | Loss: 0.4355 | Train Acc: 85.27%
2026-01-14 13:22:41,044 - INFO - [Valid] [29/90] | Loss: 0.5374 | Val Acc: 77.29%
2026-01-14 13:22:41,055 - INFO - [Metrics for 'abnormal'] | Precision: 0.7703 | Recall: 0.7261 | F1: 0.7475
2026-01-14 13:22:41,056 - INFO - [Metrics for 'normal'] | Precision: 0.7749 | Recall: 0.8132 | F1: 0.7936
2026-01-14 13:22:41,060 - INFO - --------------------------------------------------
2026-01-14 13:22:41,063 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:22:52,322 - INFO - [Train] [30/90] | Loss: 0.4384 | Train Acc: 85.27%
2026-01-14 13:22:55,572 - INFO - [Valid] [30/90] | Loss: 0.5467 | Val Acc: 79.06%
2026-01-14 13:22:55,589 - INFO - [Metrics for 'abnormal'] | Precision: 0.7416 | Recall: 0.8408 | F1: 0.7881
2026-01-14 13:22:55,593 - INFO - [Metrics for 'normal'] | Precision: 0.8447 | Recall: 0.7473 | F1: 0.7930
2026-01-14 13:22:55,603 - INFO - --------------------------------------------------
2026-01-14 13:22:55,608 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:23:05,123 - INFO - [Train] [31/90] | Loss: 0.4370 | Train Acc: 85.57%
2026-01-14 13:23:08,384 - INFO - [Valid] [31/90] | Loss: 0.5551 | Val Acc: 76.70%
2026-01-14 13:23:08,394 - INFO - [Metrics for 'abnormal'] | Precision: 0.7407 | Recall: 0.7643 | F1: 0.7524
2026-01-14 13:23:08,395 - INFO - [Metrics for 'normal'] | Precision: 0.7910 | Recall: 0.7692 | F1: 0.7799
2026-01-14 13:23:08,398 - INFO - --------------------------------------------------
2026-01-14 13:23:08,401 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:23:16,362 - INFO - [Train] [32/90] | Loss: 0.4385 | Train Acc: 84.15%
2026-01-14 13:23:19,420 - INFO - [Valid] [32/90] | Loss: 0.5556 | Val Acc: 76.70%
2026-01-14 13:23:19,435 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.6879 | F1: 0.7322
2026-01-14 13:23:19,435 - INFO - [Metrics for 'normal'] | Precision: 0.7562 | Recall: 0.8352 | F1: 0.7937
2026-01-14 13:23:19,441 - INFO - --------------------------------------------------
2026-01-14 13:23:19,445 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:23:29,272 - INFO - [Train] [33/90] | Loss: 0.4331 | Train Acc: 84.52%
2026-01-14 13:23:32,412 - INFO - [Valid] [33/90] | Loss: 0.5646 | Val Acc: 79.06%
2026-01-14 13:23:32,435 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-01-14 13:23:32,435 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-01-14 13:23:32,443 - INFO - --------------------------------------------------
2026-01-14 13:23:32,448 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:23:41,235 - INFO - [Train] [34/90] | Loss: 0.4171 | Train Acc: 87.35%
2026-01-14 13:23:44,417 - INFO - [Valid] [34/90] | Loss: 0.5742 | Val Acc: 79.06%
2026-01-14 13:23:44,430 - INFO - [Metrics for 'abnormal'] | Precision: 0.7590 | Recall: 0.8025 | F1: 0.7802
2026-01-14 13:23:44,431 - INFO - [Metrics for 'normal'] | Precision: 0.8208 | Recall: 0.7802 | F1: 0.8000
2026-01-14 13:23:44,476 - INFO - --------------------------------------------------
2026-01-14 13:23:44,480 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:23:53,029 - INFO - [Train] [35/90] | Loss: 0.4270 | Train Acc: 85.64%
2026-01-14 13:23:55,633 - INFO - [Valid] [35/90] | Loss: 0.5744 | Val Acc: 78.76%
2026-01-14 13:23:55,655 - INFO - [Metrics for 'abnormal'] | Precision: 0.7545 | Recall: 0.8025 | F1: 0.7778
2026-01-14 13:23:55,658 - INFO - [Metrics for 'normal'] | Precision: 0.8198 | Recall: 0.7747 | F1: 0.7966
2026-01-14 13:23:55,670 - INFO - --------------------------------------------------
2026-01-14 13:23:55,676 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:24:04,186 - INFO - [Train] [36/90] | Loss: 0.4048 | Train Acc: 87.35%
2026-01-14 13:24:06,615 - INFO - [Valid] [36/90] | Loss: 0.5744 | Val Acc: 74.63%
2026-01-14 13:24:06,628 - INFO - [Metrics for 'abnormal'] | Precision: 0.7178 | Recall: 0.7452 | F1: 0.7312
2026-01-14 13:24:06,628 - INFO - [Metrics for 'normal'] | Precision: 0.7727 | Recall: 0.7473 | F1: 0.7598
2026-01-14 13:24:06,632 - INFO - --------------------------------------------------
2026-01-14 13:24:06,635 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:24:16,327 - INFO - [Train] [37/90] | Loss: 0.4157 | Train Acc: 87.05%
2026-01-14 13:24:18,830 - INFO - [Valid] [37/90] | Loss: 0.5471 | Val Acc: 77.88%
2026-01-14 13:24:18,844 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-01-14 13:24:18,844 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-01-14 13:24:18,849 - INFO - --------------------------------------------------
2026-01-14 13:24:18,852 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:24:28,405 - INFO - [Train] [38/90] | Loss: 0.3996 | Train Acc: 87.87%
2026-01-14 13:24:31,046 - INFO - [Valid] [38/90] | Loss: 0.5452 | Val Acc: 79.65%
2026-01-14 13:24:31,055 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.8153 | F1: 0.7877
2026-01-14 13:24:31,056 - INFO - [Metrics for 'normal'] | Precision: 0.8304 | Recall: 0.7802 | F1: 0.8045
2026-01-14 13:24:31,059 - INFO - --------------------------------------------------
2026-01-14 13:24:31,061 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:24:40,812 - INFO - [Train] [39/90] | Loss: 0.3859 | Train Acc: 88.47%
2026-01-14 13:24:43,767 - INFO - [Valid] [39/90] | Loss: 0.5585 | Val Acc: 78.76%
2026-01-14 13:24:43,782 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-01-14 13:24:43,782 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-01-14 13:24:43,787 - INFO - --------------------------------------------------
2026-01-14 13:24:43,790 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:24:54,938 - INFO - [Train] [40/90] | Loss: 0.3955 | Train Acc: 87.43%
2026-01-14 13:24:57,240 - INFO - [Valid] [40/90] | Loss: 0.5200 | Val Acc: 79.35%
2026-01-14 13:24:57,250 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-01-14 13:24:57,250 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-01-14 13:24:57,288 - INFO - [Best Model Saved] (val loss: 0.5200) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:24:57,288 - INFO - --------------------------------------------------
2026-01-14 13:24:57,291 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:25:07,522 - INFO - [Train] [41/90] | Loss: 0.3781 | Train Acc: 89.06%
2026-01-14 13:25:09,777 - INFO - [Valid] [41/90] | Loss: 0.5794 | Val Acc: 78.76%
2026-01-14 13:25:09,806 - INFO - [Metrics for 'abnormal'] | Precision: 0.7931 | Recall: 0.7325 | F1: 0.7616
2026-01-14 13:25:09,806 - INFO - [Metrics for 'normal'] | Precision: 0.7835 | Recall: 0.8352 | F1: 0.8085
2026-01-14 13:25:09,816 - INFO - --------------------------------------------------
2026-01-14 13:25:09,821 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:25:19,707 - INFO - [Train] [42/90] | Loss: 0.3897 | Train Acc: 89.51%
2026-01-14 13:25:22,471 - INFO - [Valid] [42/90] | Loss: 0.5424 | Val Acc: 78.47%
2026-01-14 13:25:22,484 - INFO - [Metrics for 'abnormal'] | Precision: 0.8333 | Recall: 0.6688 | F1: 0.7420
2026-01-14 13:25:22,485 - INFO - [Metrics for 'normal'] | Precision: 0.7559 | Recall: 0.8846 | F1: 0.8152
2026-01-14 13:25:22,489 - INFO - --------------------------------------------------
2026-01-14 13:25:22,492 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:25:31,700 - INFO - [Train] [43/90] | Loss: 0.3904 | Train Acc: 88.32%
2026-01-14 13:25:34,399 - INFO - [Valid] [43/90] | Loss: 0.5319 | Val Acc: 77.88%
2026-01-14 13:25:34,411 - INFO - [Metrics for 'abnormal'] | Precision: 0.7181 | Recall: 0.8599 | F1: 0.7826
2026-01-14 13:25:34,412 - INFO - [Metrics for 'normal'] | Precision: 0.8543 | Recall: 0.7088 | F1: 0.7748
2026-01-14 13:25:34,416 - INFO - --------------------------------------------------
2026-01-14 13:25:34,419 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:25:43,071 - INFO - [Train] [44/90] | Loss: 0.3633 | Train Acc: 91.37%
2026-01-14 13:25:45,736 - INFO - [Valid] [44/90] | Loss: 0.5114 | Val Acc: 81.71%
2026-01-14 13:25:45,748 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 13:25:45,749 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 13:25:45,790 - INFO - [Best Model Saved] (val loss: 0.5114) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:25:45,791 - INFO - --------------------------------------------------
2026-01-14 13:25:45,794 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:25:54,477 - INFO - [Train] [45/90] | Loss: 0.3818 | Train Acc: 88.47%
2026-01-14 13:25:57,896 - INFO - [Valid] [45/90] | Loss: 0.5461 | Val Acc: 79.06%
2026-01-14 13:25:57,946 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-01-14 13:25:57,961 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-01-14 13:25:57,975 - INFO - --------------------------------------------------
2026-01-14 13:25:57,978 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:26:07,470 - INFO - [Train] [46/90] | Loss: 0.3750 | Train Acc: 89.43%
2026-01-14 13:26:11,630 - INFO - [Valid] [46/90] | Loss: 0.6773 | Val Acc: 75.52%
2026-01-14 13:26:11,654 - INFO - [Metrics for 'abnormal'] | Precision: 0.7033 | Recall: 0.8153 | F1: 0.7552
2026-01-14 13:26:11,657 - INFO - [Metrics for 'normal'] | Precision: 0.8153 | Recall: 0.7033 | F1: 0.7552
2026-01-14 13:26:11,669 - INFO - --------------------------------------------------
2026-01-14 13:26:11,672 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:26:20,015 - INFO - [Train] [47/90] | Loss: 0.3693 | Train Acc: 89.58%
2026-01-14 13:26:22,549 - INFO - [Valid] [47/90] | Loss: 0.5246 | Val Acc: 79.94%
2026-01-14 13:26:22,630 - INFO - [Metrics for 'abnormal'] | Precision: 0.7908 | Recall: 0.7707 | F1: 0.7806
2026-01-14 13:26:22,631 - INFO - [Metrics for 'normal'] | Precision: 0.8065 | Recall: 0.8242 | F1: 0.8152
2026-01-14 13:26:22,634 - INFO - --------------------------------------------------
2026-01-14 13:26:22,637 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:26:31,544 - INFO - [Train] [48/90] | Loss: 0.3558 | Train Acc: 90.18%
2026-01-14 13:26:35,104 - INFO - [Valid] [48/90] | Loss: 0.5383 | Val Acc: 79.35%
2026-01-14 13:26:35,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8280 | F1: 0.7879
2026-01-14 13:26:35,262 - INFO - [Metrics for 'normal'] | Precision: 0.8373 | Recall: 0.7637 | F1: 0.7989
2026-01-14 13:26:35,266 - INFO - --------------------------------------------------
2026-01-14 13:26:35,268 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:26:43,853 - INFO - [Train] [49/90] | Loss: 0.3470 | Train Acc: 90.25%
2026-01-14 13:26:47,657 - INFO - [Valid] [49/90] | Loss: 0.5457 | Val Acc: 77.58%
2026-01-14 13:26:47,685 - INFO - [Metrics for 'abnormal'] | Precision: 0.7956 | Recall: 0.6943 | F1: 0.7415
2026-01-14 13:26:47,688 - INFO - [Metrics for 'normal'] | Precision: 0.7624 | Recall: 0.8462 | F1: 0.8021
2026-01-14 13:26:47,696 - INFO - --------------------------------------------------
2026-01-14 13:26:47,702 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:26:56,277 - INFO - [Train] [50/90] | Loss: 0.3389 | Train Acc: 91.52%
2026-01-14 13:26:58,996 - INFO - [Valid] [50/90] | Loss: 0.5776 | Val Acc: 79.35%
2026-01-14 13:26:59,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.7919 | Recall: 0.7516 | F1: 0.7712
2026-01-14 13:26:59,009 - INFO - [Metrics for 'normal'] | Precision: 0.7947 | Recall: 0.8297 | F1: 0.8118
2026-01-14 13:26:59,013 - INFO - --------------------------------------------------
2026-01-14 13:26:59,017 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:27:08,236 - INFO - [Train] [51/90] | Loss: 0.3560 | Train Acc: 90.85%
2026-01-14 13:27:12,083 - INFO - [Valid] [51/90] | Loss: 0.5301 | Val Acc: 77.29%
2026-01-14 13:27:12,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.7439 | Recall: 0.7771 | F1: 0.7601
2026-01-14 13:27:12,097 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7692 | F1: 0.7843
2026-01-14 13:27:12,101 - INFO - --------------------------------------------------
2026-01-14 13:27:12,105 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:27:20,353 - INFO - [Train] [52/90] | Loss: 0.3393 | Train Acc: 90.92%
2026-01-14 13:27:23,623 - INFO - [Valid] [52/90] | Loss: 0.5864 | Val Acc: 77.88%
2026-01-14 13:27:23,636 - INFO - [Metrics for 'abnormal'] | Precision: 0.8015 | Recall: 0.6943 | F1: 0.7440
2026-01-14 13:27:23,637 - INFO - [Metrics for 'normal'] | Precision: 0.7635 | Recall: 0.8516 | F1: 0.8052
2026-01-14 13:27:23,642 - INFO - --------------------------------------------------
2026-01-14 13:27:23,645 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:27:32,748 - INFO - [Train] [53/90] | Loss: 0.3393 | Train Acc: 91.96%
2026-01-14 13:27:36,213 - INFO - [Valid] [53/90] | Loss: 0.5631 | Val Acc: 80.53%
2026-01-14 13:27:36,225 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.7580 | F1: 0.7829
2026-01-14 13:27:36,225 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8462 | F1: 0.8235
2026-01-14 13:27:36,229 - INFO - --------------------------------------------------
2026-01-14 13:27:36,231 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:27:45,656 - INFO - [Train] [54/90] | Loss: 0.3379 | Train Acc: 91.89%
2026-01-14 13:27:48,958 - INFO - [Valid] [54/90] | Loss: 0.5606 | Val Acc: 77.88%
2026-01-14 13:27:48,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.7662 | Recall: 0.7516 | F1: 0.7588
2026-01-14 13:27:48,987 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8022 | F1: 0.7956
2026-01-14 13:27:48,992 - INFO - --------------------------------------------------
2026-01-14 13:27:48,995 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:27:58,411 - INFO - [Train] [55/90] | Loss: 0.3301 | Train Acc: 93.75%
2026-01-14 13:28:01,055 - INFO - [Valid] [55/90] | Loss: 0.5486 | Val Acc: 76.99%
2026-01-14 13:28:01,097 - INFO - [Metrics for 'abnormal'] | Precision: 0.7337 | Recall: 0.7898 | F1: 0.7607
2026-01-14 13:28:01,101 - INFO - [Metrics for 'normal'] | Precision: 0.8059 | Recall: 0.7527 | F1: 0.7784
2026-01-14 13:28:01,109 - INFO - --------------------------------------------------
2026-01-14 13:28:01,114 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:28:09,572 - INFO - [Train] [56/90] | Loss: 0.3160 | Train Acc: 93.23%
2026-01-14 13:28:12,326 - INFO - [Valid] [56/90] | Loss: 0.5277 | Val Acc: 76.99%
2026-01-14 13:28:12,358 - INFO - [Metrics for 'abnormal'] | Precision: 0.7582 | Recall: 0.7389 | F1: 0.7484
2026-01-14 13:28:12,358 - INFO - [Metrics for 'normal'] | Precision: 0.7796 | Recall: 0.7967 | F1: 0.7880
2026-01-14 13:28:12,363 - INFO - --------------------------------------------------
2026-01-14 13:28:12,366 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:28:22,143 - INFO - [Train] [57/90] | Loss: 0.3119 | Train Acc: 93.45%
2026-01-14 13:28:25,367 - INFO - [Valid] [57/90] | Loss: 0.5634 | Val Acc: 77.58%
2026-01-14 13:28:25,385 - INFO - [Metrics for 'abnormal'] | Precision: 0.7263 | Recall: 0.8280 | F1: 0.7738
2026-01-14 13:28:25,389 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7308 | F1: 0.7778
2026-01-14 13:28:25,396 - INFO - --------------------------------------------------
2026-01-14 13:28:25,402 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:28:34,925 - INFO - [Train] [58/90] | Loss: 0.3166 | Train Acc: 93.38%
2026-01-14 13:28:37,651 - INFO - [Valid] [58/90] | Loss: 0.5766 | Val Acc: 78.17%
2026-01-14 13:28:37,662 - INFO - [Metrics for 'abnormal'] | Precision: 0.7456 | Recall: 0.8025 | F1: 0.7730
2026-01-14 13:28:37,662 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.7637 | F1: 0.7898
2026-01-14 13:28:37,666 - INFO - --------------------------------------------------
2026-01-14 13:28:37,668 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:28:48,573 - INFO - [Train] [59/90] | Loss: 0.3052 | Train Acc: 94.35%
2026-01-14 13:28:51,277 - INFO - [Valid] [59/90] | Loss: 0.5947 | Val Acc: 76.70%
2026-01-14 13:28:51,289 - INFO - [Metrics for 'abnormal'] | Precision: 0.7378 | Recall: 0.7707 | F1: 0.7539
2026-01-14 13:28:51,290 - INFO - [Metrics for 'normal'] | Precision: 0.7943 | Recall: 0.7637 | F1: 0.7787
2026-01-14 13:28:51,295 - INFO - --------------------------------------------------
2026-01-14 13:28:51,298 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:29:01,667 - INFO - [Train] [60/90] | Loss: 0.3067 | Train Acc: 93.75%
2026-01-14 13:29:05,304 - INFO - [Valid] [60/90] | Loss: 0.5751 | Val Acc: 80.24%
2026-01-14 13:29:05,316 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:29:05,317 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:29:05,322 - INFO - --------------------------------------------------
2026-01-14 13:29:05,338 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:29:13,705 - INFO - [Train] [61/90] | Loss: 0.3047 | Train Acc: 94.20%
2026-01-14 13:29:16,871 - INFO - [Valid] [61/90] | Loss: 0.5658 | Val Acc: 78.76%
2026-01-14 13:29:16,878 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-01-14 13:29:16,879 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-01-14 13:29:16,881 - INFO - --------------------------------------------------
2026-01-14 13:29:16,883 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:29:26,235 - INFO - [Train] [62/90] | Loss: 0.2927 | Train Acc: 95.24%
2026-01-14 13:29:29,386 - INFO - [Valid] [62/90] | Loss: 0.5585 | Val Acc: 78.76%
2026-01-14 13:29:29,401 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 13:29:29,402 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 13:29:29,407 - INFO - --------------------------------------------------
2026-01-14 13:29:29,411 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:29:37,726 - INFO - [Train] [63/90] | Loss: 0.3022 | Train Acc: 94.35%
2026-01-14 13:29:40,656 - INFO - [Valid] [63/90] | Loss: 0.5605 | Val Acc: 81.12%
2026-01-14 13:29:40,689 - INFO - [Metrics for 'abnormal'] | Precision: 0.8121 | Recall: 0.7707 | F1: 0.7908
2026-01-14 13:29:40,689 - INFO - [Metrics for 'normal'] | Precision: 0.8105 | Recall: 0.8462 | F1: 0.8280
2026-01-14 13:29:40,700 - INFO - --------------------------------------------------
2026-01-14 13:29:40,709 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:29:49,174 - INFO - [Train] [64/90] | Loss: 0.2897 | Train Acc: 95.09%
2026-01-14 13:29:52,196 - INFO - [Valid] [64/90] | Loss: 0.5310 | Val Acc: 79.35%
2026-01-14 13:29:52,211 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 13:29:52,212 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 13:29:52,216 - INFO - --------------------------------------------------
2026-01-14 13:29:52,219 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:30:02,221 - INFO - [Train] [65/90] | Loss: 0.2991 | Train Acc: 94.72%
2026-01-14 13:30:05,322 - INFO - [Valid] [65/90] | Loss: 0.5578 | Val Acc: 80.24%
2026-01-14 13:30:05,341 - INFO - [Metrics for 'abnormal'] | Precision: 0.8082 | Recall: 0.7516 | F1: 0.7789
2026-01-14 13:30:05,342 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8462 | F1: 0.8213
2026-01-14 13:30:05,345 - INFO - --------------------------------------------------
2026-01-14 13:30:05,348 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:30:13,402 - INFO - [Train] [66/90] | Loss: 0.2950 | Train Acc: 95.39%
2026-01-14 13:30:16,467 - INFO - [Valid] [66/90] | Loss: 0.5571 | Val Acc: 78.76%
2026-01-14 13:30:16,482 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.8153 | F1: 0.7805
2026-01-14 13:30:16,482 - INFO - [Metrics for 'normal'] | Precision: 0.8274 | Recall: 0.7637 | F1: 0.7943
2026-01-14 13:30:16,486 - INFO - --------------------------------------------------
2026-01-14 13:30:16,488 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:30:25,098 - INFO - [Train] [67/90] | Loss: 0.2839 | Train Acc: 95.83%
2026-01-14 13:30:28,196 - INFO - [Valid] [67/90] | Loss: 0.5727 | Val Acc: 79.35%
2026-01-14 13:30:28,211 - INFO - [Metrics for 'abnormal'] | Precision: 0.7843 | Recall: 0.7643 | F1: 0.7742
2026-01-14 13:30:28,212 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.8187 | F1: 0.8098
2026-01-14 13:30:28,219 - INFO - --------------------------------------------------
2026-01-14 13:30:28,221 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:30:36,216 - INFO - [Train] [68/90] | Loss: 0.2749 | Train Acc: 96.88%
2026-01-14 13:30:38,998 - INFO - [Valid] [68/90] | Loss: 0.5548 | Val Acc: 81.12%
2026-01-14 13:30:39,013 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:30:39,014 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:30:39,018 - INFO - --------------------------------------------------
2026-01-14 13:30:39,022 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:30:47,210 - INFO - [Train] [69/90] | Loss: 0.2821 | Train Acc: 95.98%
2026-01-14 13:30:49,750 - INFO - [Valid] [69/90] | Loss: 0.5523 | Val Acc: 80.53%
2026-01-14 13:30:49,760 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-01-14 13:30:49,761 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-01-14 13:30:49,765 - INFO - --------------------------------------------------
2026-01-14 13:30:49,767 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:30:58,478 - INFO - [Train] [70/90] | Loss: 0.2791 | Train Acc: 95.76%
2026-01-14 13:31:01,014 - INFO - [Valid] [70/90] | Loss: 0.5632 | Val Acc: 78.76%
2026-01-14 13:31:01,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.7607 | Recall: 0.7898 | F1: 0.7750
2026-01-14 13:31:01,037 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.7857 | F1: 0.7989
2026-01-14 13:31:01,044 - INFO - --------------------------------------------------
2026-01-14 13:31:01,050 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:31:11,153 - INFO - [Train] [71/90] | Loss: 0.2758 | Train Acc: 96.21%
2026-01-14 13:31:14,621 - INFO - [Valid] [71/90] | Loss: 0.5513 | Val Acc: 80.53%
2026-01-14 13:31:14,640 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-01-14 13:31:14,640 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-01-14 13:31:14,646 - INFO - --------------------------------------------------
2026-01-14 13:31:14,651 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:31:25,104 - INFO - [Train] [72/90] | Loss: 0.2802 | Train Acc: 96.28%
2026-01-14 13:31:27,485 - INFO - [Valid] [72/90] | Loss: 0.5706 | Val Acc: 79.94%
2026-01-14 13:31:27,504 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 13:31:27,505 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 13:31:27,510 - INFO - --------------------------------------------------
2026-01-14 13:31:27,512 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:31:36,665 - INFO - [Train] [73/90] | Loss: 0.2766 | Train Acc: 96.28%
2026-01-14 13:31:39,481 - INFO - [Valid] [73/90] | Loss: 0.5525 | Val Acc: 79.94%
2026-01-14 13:31:39,492 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-01-14 13:31:39,493 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-01-14 13:31:39,497 - INFO - --------------------------------------------------
2026-01-14 13:31:39,499 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:31:48,575 - INFO - [Train] [74/90] | Loss: 0.2656 | Train Acc: 97.17%
2026-01-14 13:31:50,578 - INFO - [Valid] [74/90] | Loss: 0.5900 | Val Acc: 77.88%
2026-01-14 13:31:50,591 - INFO - [Metrics for 'abnormal'] | Precision: 0.7330 | Recall: 0.8217 | F1: 0.7748
2026-01-14 13:31:50,592 - INFO - [Metrics for 'normal'] | Precision: 0.8282 | Recall: 0.7418 | F1: 0.7826
2026-01-14 13:31:50,597 - INFO - --------------------------------------------------
2026-01-14 13:31:50,600 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:31:59,090 - INFO - [Train] [75/90] | Loss: 0.2631 | Train Acc: 97.40%
2026-01-14 13:32:01,773 - INFO - [Valid] [75/90] | Loss: 0.5630 | Val Acc: 78.76%
2026-01-14 13:32:01,799 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-01-14 13:32:01,799 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-01-14 13:32:01,804 - INFO - --------------------------------------------------
2026-01-14 13:32:01,808 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:32:10,110 - INFO - [Train] [76/90] | Loss: 0.2742 | Train Acc: 96.28%
2026-01-14 13:32:13,599 - INFO - [Valid] [76/90] | Loss: 0.5527 | Val Acc: 79.94%
2026-01-14 13:32:13,641 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 13:32:13,642 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 13:32:13,652 - INFO - --------------------------------------------------
2026-01-14 13:32:13,659 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:32:22,559 - INFO - [Train] [77/90] | Loss: 0.2767 | Train Acc: 96.13%
2026-01-14 13:32:26,863 - INFO - [Valid] [77/90] | Loss: 0.5514 | Val Acc: 79.35%
2026-01-14 13:32:26,890 - INFO - [Metrics for 'abnormal'] | Precision: 0.7843 | Recall: 0.7643 | F1: 0.7742
2026-01-14 13:32:26,890 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.8187 | F1: 0.8098
2026-01-14 13:32:26,897 - INFO - --------------------------------------------------
2026-01-14 13:32:26,902 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:32:36,222 - INFO - [Train] [78/90] | Loss: 0.2609 | Train Acc: 97.10%
2026-01-14 13:32:39,144 - INFO - [Valid] [78/90] | Loss: 0.5614 | Val Acc: 80.53%
2026-01-14 13:32:39,155 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-01-14 13:32:39,156 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-01-14 13:32:39,161 - INFO - --------------------------------------------------
2026-01-14 13:32:39,164 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:32:47,863 - INFO - [Train] [79/90] | Loss: 0.2579 | Train Acc: 97.32%
2026-01-14 13:32:50,905 - INFO - [Valid] [79/90] | Loss: 0.5509 | Val Acc: 80.24%
2026-01-14 13:32:50,914 - INFO - [Metrics for 'abnormal'] | Precision: 0.8041 | Recall: 0.7580 | F1: 0.7803
2026-01-14 13:32:50,914 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8407 | F1: 0.8204
2026-01-14 13:32:50,917 - INFO - --------------------------------------------------
2026-01-14 13:32:50,918 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:33:00,714 - INFO - [Train] [80/90] | Loss: 0.2625 | Train Acc: 97.17%
2026-01-14 13:33:03,459 - INFO - [Valid] [80/90] | Loss: 0.5359 | Val Acc: 79.06%
2026-01-14 13:33:03,471 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.7834 | F1: 0.7760
2026-01-14 13:33:03,471 - INFO - [Metrics for 'normal'] | Precision: 0.8101 | Recall: 0.7967 | F1: 0.8033
2026-01-14 13:33:03,477 - INFO - --------------------------------------------------
2026-01-14 13:33:03,480 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:33:13,427 - INFO - [Train] [81/90] | Loss: 0.2748 | Train Acc: 96.13%
2026-01-14 13:33:16,992 - INFO - [Valid] [81/90] | Loss: 0.5519 | Val Acc: 79.65%
2026-01-14 13:33:17,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-01-14 13:33:17,009 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-01-14 13:33:17,013 - INFO - --------------------------------------------------
2026-01-14 13:33:17,018 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:33:26,277 - INFO - [Train] [82/90] | Loss: 0.2587 | Train Acc: 96.95%
2026-01-14 13:33:28,844 - INFO - [Valid] [82/90] | Loss: 0.5849 | Val Acc: 80.24%
2026-01-14 13:33:28,858 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 13:33:28,859 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 13:33:28,862 - INFO - --------------------------------------------------
2026-01-14 13:33:28,864 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:33:39,240 - INFO - [Train] [83/90] | Loss: 0.2558 | Train Acc: 97.77%
2026-01-14 13:33:41,862 - INFO - [Valid] [83/90] | Loss: 0.5575 | Val Acc: 81.12%
2026-01-14 13:33:41,884 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 13:33:41,885 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 13:33:41,889 - INFO - --------------------------------------------------
2026-01-14 13:33:41,891 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:33:50,625 - INFO - [Train] [84/90] | Loss: 0.2511 | Train Acc: 97.47%
2026-01-14 13:33:52,714 - INFO - [Valid] [84/90] | Loss: 0.5636 | Val Acc: 78.76%
2026-01-14 13:33:52,726 - INFO - [Metrics for 'abnormal'] | Precision: 0.7607 | Recall: 0.7898 | F1: 0.7750
2026-01-14 13:33:52,726 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.7857 | F1: 0.7989
2026-01-14 13:33:52,730 - INFO - --------------------------------------------------
2026-01-14 13:33:52,733 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:34:01,964 - INFO - [Train] [85/90] | Loss: 0.2568 | Train Acc: 97.54%
2026-01-14 13:34:05,588 - INFO - [Valid] [85/90] | Loss: 0.5778 | Val Acc: 79.94%
2026-01-14 13:34:05,597 - INFO - [Metrics for 'abnormal'] | Precision: 0.8069 | Recall: 0.7452 | F1: 0.7748
2026-01-14 13:34:05,597 - INFO - [Metrics for 'normal'] | Precision: 0.7938 | Recall: 0.8462 | F1: 0.8191
2026-01-14 13:34:05,601 - INFO - --------------------------------------------------
2026-01-14 13:34:05,603 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:34:14,670 - INFO - [Train] [86/90] | Loss: 0.2439 | Train Acc: 98.21%
2026-01-14 13:34:16,676 - INFO - [Valid] [86/90] | Loss: 0.5666 | Val Acc: 79.94%
2026-01-14 13:34:16,690 - INFO - [Metrics for 'abnormal'] | Precision: 0.7947 | Recall: 0.7643 | F1: 0.7792
2026-01-14 13:34:16,690 - INFO - [Metrics for 'normal'] | Precision: 0.8032 | Recall: 0.8297 | F1: 0.8162
2026-01-14 13:34:16,699 - INFO - --------------------------------------------------
2026-01-14 13:34:16,701 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:34:24,757 - INFO - [Train] [87/90] | Loss: 0.2577 | Train Acc: 97.47%
2026-01-14 13:34:26,692 - INFO - [Valid] [87/90] | Loss: 0.5561 | Val Acc: 80.83%
2026-01-14 13:34:26,701 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 13:34:26,702 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 13:34:26,709 - INFO - --------------------------------------------------
2026-01-14 13:34:26,713 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:34:34,294 - INFO - [Train] [88/90] | Loss: 0.2631 | Train Acc: 97.25%
2026-01-14 13:34:36,349 - INFO - [Valid] [88/90] | Loss: 0.5448 | Val Acc: 80.24%
2026-01-14 13:34:36,361 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:34:36,361 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:34:36,365 - INFO - --------------------------------------------------
2026-01-14 13:34:36,367 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:34:44,258 - INFO - [Train] [89/90] | Loss: 0.2632 | Train Acc: 97.02%
2026-01-14 13:34:46,606 - INFO - [Valid] [89/90] | Loss: 0.5740 | Val Acc: 80.83%
2026-01-14 13:34:46,629 - INFO - [Metrics for 'abnormal'] | Precision: 0.8067 | Recall: 0.7707 | F1: 0.7883
2026-01-14 13:34:46,629 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.8407 | F1: 0.8248
2026-01-14 13:34:46,634 - INFO - --------------------------------------------------
2026-01-14 13:34:46,637 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:34:53,407 - INFO - [Train] [90/90] | Loss: 0.2513 | Train Acc: 97.62%
2026-01-14 13:34:55,768 - INFO - [Valid] [90/90] | Loss: 0.5587 | Val Acc: 79.65%
2026-01-14 13:34:55,779 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-01-14 13:34:55,781 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-01-14 13:34:55,787 - INFO - ==================================================
2026-01-14 13:34:55,788 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:34:55,789 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:34:55,790 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:34:55,979 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:34:55,982 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 13:34:55,983 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:34:56,833 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 13:34:56,833 - INFO - ==================================================
2026-01-14 13:34:56,974 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/best_model.pth'
2026-01-14 13:34:56,975 - INFO - ==================================================
2026-01-14 13:34:56,975 - INFO - Test 모드를 시작합니다.
2026-01-14 13:34:57,309 - INFO - 연산량 (MACs): 0.0039 GMACs per sample
2026-01-14 13:34:57,310 - INFO - 연산량 (FLOPs): 0.0077 GFLOPs per sample
2026-01-14 13:34:57,310 - INFO - ==================================================
2026-01-14 13:34:57,310 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:34:58,675 - INFO - 샘플 당 평균 Forward Pass 시간: 7.22ms (std: 9.05ms), FPS: 162.79 (std: 27.96) (1개 샘플 x 100회 반복)
2026-01-14 13:34:58,676 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 57.83 MB
2026-01-14 13:34:58,676 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:35:02,865 - INFO - [Test] Loss: 0.4417 | Test Acc: 81.71%
2026-01-14 13:35:02,877 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 13:35:02,877 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 13:35:03,653 - INFO - ==================================================
2026-01-14 13:35:03,654 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/confusion_matrix_20260114_131737.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/confusion_matrix_20260114_131737.pdf'
2026-01-14 13:35:03,654 - INFO - ==================================================
2026-01-14 13:35:03,654 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:35:06,681 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/model_fp32_20260114_131737.onnx'에 저장되었습니다. (크기: 0.14 MB)
2026-01-14 13:35:07,130 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2538.63 MB (증가량: 6.57 MB)
2026-01-14 13:35:07,130 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:35:08,473 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 7.38ms (std: 27.81ms)
2026-01-14 13:35:08,473 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 400.04 FPS (std: 219.39) (1개 샘플 x 100회 반복)
2026-01-14 13:35:08,474 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2539.63 MB (순수 증가량: 0.50 MB)
2026-01-14 13:35:08,474 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2539.63 MB (전체 증가량: 7.57 MB)
2026-01-14 13:35:11,848 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.71%
2026-01-14 13:35:11,869 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 13:35:11,872 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 13:35:12,750 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/val_acc.pdf'
2026-01-14 13:35:13,233 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/train_val_acc.pdf'
2026-01-14 13:35:13,720 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/F1_normal.pdf'
2026-01-14 13:35:14,185 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/val_loss.pdf'
2026-01-14 13:35:14,696 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/learning_rate.pdf'
2026-01-14 13:35:20,036 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_131737/graph_20260114_131737/compile.pdf'
