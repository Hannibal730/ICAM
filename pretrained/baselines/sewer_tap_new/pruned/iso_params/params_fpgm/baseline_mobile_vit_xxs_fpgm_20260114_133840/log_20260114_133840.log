2026-01-14 13:38:40,712 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/log_20260114_133840.log'에 저장됩니다.
2026-01-14 13:38:40,719 - INFO - ==================================================
2026-01-14 13:38:40,719 - INFO - config.yaml:
2026-01-14 13:38:40,719 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobile_vit_xxs
  use_fpgm_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:38:40,721 - INFO - ==================================================
2026-01-14 13:38:40,787 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:38:40,791 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:38:40,796 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:38:40,809 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:38:40,810 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:38:40,811 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:38:40,812 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:38:41,210 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:38:41,250 - INFO - ==================================================
2026-01-14 13:38:41,250 - INFO - 모델 파라미터 수:
2026-01-14 13:38:41,251 - INFO -   - 총 파라미터: 951,666 개
2026-01-14 13:38:41,251 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-01-14 13:38:41,251 - INFO - ================================================================================
2026-01-14 13:38:41,251 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:38:41,251 - INFO - ================================================================================
2026-01-14 13:38:41,251 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:38:41,253 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:38:41,253 - INFO - ==================================================
2026-01-14 13:38:41,254 - INFO - train 모드를 시작합니다.
2026-01-14 13:38:41,254 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:38:41,254 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:38:41,254 - INFO - --------------------------------------------------
2026-01-14 13:38:41,257 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:38:54,667 - INFO - [Train] [1/10] | Loss: 0.5202 | Train Acc: 78.42%
2026-01-14 13:38:59,370 - INFO - [Valid] [1/10] | Loss: 0.5367 | Val Acc: 81.12%
2026-01-14 13:38:59,388 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 13:38:59,389 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 13:38:59,445 - INFO - [Best Model Saved] (val loss: 0.5367) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:38:59,446 - INFO - --------------------------------------------------
2026-01-14 13:38:59,449 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:39:08,658 - INFO - [Train] [2/10] | Loss: 0.4599 | Train Acc: 83.41%
2026-01-14 13:39:11,614 - INFO - [Valid] [2/10] | Loss: 0.5198 | Val Acc: 82.30%
2026-01-14 13:39:11,627 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 13:39:11,627 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 13:39:11,688 - INFO - [Best Model Saved] (val loss: 0.5198) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:39:11,688 - INFO - --------------------------------------------------
2026-01-14 13:39:11,693 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:39:20,899 - INFO - [Train] [3/10] | Loss: 0.4303 | Train Acc: 85.71%
2026-01-14 13:39:23,445 - INFO - [Valid] [3/10] | Loss: 0.5055 | Val Acc: 82.30%
2026-01-14 13:39:23,460 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-01-14 13:39:23,461 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-01-14 13:39:23,528 - INFO - [Best Model Saved] (val loss: 0.5055) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:39:23,528 - INFO - --------------------------------------------------
2026-01-14 13:39:23,532 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:39:30,311 - INFO - [Train] [4/10] | Loss: 0.3910 | Train Acc: 87.87%
2026-01-14 13:39:32,519 - INFO - [Valid] [4/10] | Loss: 0.5675 | Val Acc: 79.94%
2026-01-14 13:39:32,536 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-01-14 13:39:32,537 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-01-14 13:39:32,541 - INFO - --------------------------------------------------
2026-01-14 13:39:32,544 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:39:40,605 - INFO - [Train] [5/10] | Loss: 0.3789 | Train Acc: 89.36%
2026-01-14 13:39:42,667 - INFO - [Valid] [5/10] | Loss: 0.5791 | Val Acc: 79.35%
2026-01-14 13:39:42,677 - INFO - [Metrics for 'abnormal'] | Precision: 0.7377 | Recall: 0.8599 | F1: 0.7941
2026-01-14 13:39:42,677 - INFO - [Metrics for 'normal'] | Precision: 0.8590 | Recall: 0.7363 | F1: 0.7929
2026-01-14 13:39:42,680 - INFO - --------------------------------------------------
2026-01-14 13:39:42,682 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:39:49,937 - INFO - [Train] [6/10] | Loss: 0.3613 | Train Acc: 90.40%
2026-01-14 13:39:51,677 - INFO - [Valid] [6/10] | Loss: 0.5166 | Val Acc: 79.94%
2026-01-14 13:39:51,690 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-01-14 13:39:51,691 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-01-14 13:39:51,696 - INFO - --------------------------------------------------
2026-01-14 13:39:51,702 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:39:57,629 - INFO - [Train] [7/10] | Loss: 0.3114 | Train Acc: 93.82%
2026-01-14 13:39:59,147 - INFO - [Valid] [7/10] | Loss: 0.5038 | Val Acc: 81.12%
2026-01-14 13:39:59,156 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 13:39:59,156 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 13:39:59,188 - INFO - [Best Model Saved] (val loss: 0.5038) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:39:59,189 - INFO - --------------------------------------------------
2026-01-14 13:39:59,191 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:40:04,586 - INFO - [Train] [8/10] | Loss: 0.2891 | Train Acc: 95.46%
2026-01-14 13:40:06,088 - INFO - [Valid] [8/10] | Loss: 0.4947 | Val Acc: 80.24%
2026-01-14 13:40:06,100 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-01-14 13:40:06,101 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-01-14 13:40:06,151 - INFO - [Best Model Saved] (val loss: 0.4947) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:40:06,152 - INFO - --------------------------------------------------
2026-01-14 13:40:06,154 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:40:11,936 - INFO - [Train] [9/10] | Loss: 0.2672 | Train Acc: 96.88%
2026-01-14 13:40:13,365 - INFO - [Valid] [9/10] | Loss: 0.4887 | Val Acc: 84.37%
2026-01-14 13:40:13,374 - INFO - [Metrics for 'abnormal'] | Precision: 0.8210 | Recall: 0.8471 | F1: 0.8339
2026-01-14 13:40:13,374 - INFO - [Metrics for 'normal'] | Precision: 0.8644 | Recall: 0.8407 | F1: 0.8524
2026-01-14 13:40:13,412 - INFO - [Best Model Saved] (val loss: 0.4887) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:40:13,412 - INFO - --------------------------------------------------
2026-01-14 13:40:13,415 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:40:18,401 - INFO - [Train] [10/10] | Loss: 0.2587 | Train Acc: 97.32%
2026-01-14 13:40:20,298 - INFO - [Valid] [10/10] | Loss: 0.4994 | Val Acc: 82.89%
2026-01-14 13:40:20,310 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 13:40:20,311 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 13:40:20,318 - INFO - ================================================================================
2026-01-14 13:40:20,318 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:40:20,319 - INFO - ================================================================================
2026-01-14 13:40:20,460 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:40:20,461 - INFO - ================================================================================
2026-01-14 13:40:20,461 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:40:20,463 - INFO - 원본 모델 파라미터: 0.9517M
2026-01-14 13:40:20,581 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:20,582 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,583 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,164 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:40:22,164 - INFO - ==================================================
2026-01-14 13:40:22,166 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.3049M (감소율: 67.96%)
2026-01-14 13:40:22,206 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:22,206 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,207 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,868 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:40:22,869 - INFO - ==================================================
2026-01-14 13:40:22,871 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1109M (감소율: 88.35%)
2026-01-14 13:40:22,934 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:22,934 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,936 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,904 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:40:23,905 - INFO - ==================================================
2026-01-14 13:40:23,907 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0459M (감소율: 95.18%)
2026-01-14 13:40:23,958 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:23,958 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,960 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:24,834 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:40:24,834 - INFO - ==================================================
2026-01-14 13:40:24,837 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0214M (감소율: 97.76%)
2026-01-14 13:40:24,882 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:24,882 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:24,883 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,630 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 13:40:25,630 - INFO - ==================================================
2026-01-14 13:40:25,634 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0337M (감소율: 96.46%)
2026-01-14 13:40:25,684 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:25,684 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,686 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:26,623 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 13:40:26,624 - INFO - ==================================================
2026-01-14 13:40:26,627 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0272M (감소율: 97.14%)
2026-01-14 13:40:26,690 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:26,691 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:26,692 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,514 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:40:27,517 - INFO - ==================================================
2026-01-14 13:40:27,522 - INFO -   [탐색  7] 희소도: 0.9049 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:27,569 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:27,570 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,571 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:28,653 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9087890624999999)에 맞춰 변경되었습니다.
2026-01-14 13:40:28,654 - INFO - ==================================================
2026-01-14 13:40:28,657 - INFO -   [탐색  8] 희소도: 0.9088 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:28,722 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:28,723 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:28,724 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,522 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9068554687499999)에 맞춰 변경되었습니다.
2026-01-14 13:40:29,523 - INFO - ==================================================
2026-01-14 13:40:29,526 - INFO -   [탐색  9] 희소도: 0.9069 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:29,589 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:29,589 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,591 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,380 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9058886718749999)에 맞춰 변경되었습니다.
2026-01-14 13:40:30,381 - INFO - ==================================================
2026-01-14 13:40:30,383 - INFO -   [탐색 10] 희소도: 0.9059 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:30,424 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:30,425 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,426 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9063720703124999)에 맞춰 변경되었습니다.
2026-01-14 13:40:30,971 - INFO - ==================================================
2026-01-14 13:40:30,973 - INFO -   [탐색 11] 희소도: 0.9064 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:31,016 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:31,017 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,018 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,803 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9061303710937498)에 맞춰 변경되었습니다.
2026-01-14 13:40:31,804 - INFO - ==================================================
2026-01-14 13:40:31,806 - INFO -   [탐색 12] 희소도: 0.9061 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:31,866 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:31,866 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,868 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,032 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062512207031248)에 맞춰 변경되었습니다.
2026-01-14 13:40:33,033 - INFO - ==================================================
2026-01-14 13:40:33,036 - INFO -   [탐색 13] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:33,129 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:33,129 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,130 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,872 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9061907958984373)에 맞춰 변경되었습니다.
2026-01-14 13:40:33,874 - INFO - ==================================================
2026-01-14 13:40:33,876 - INFO -   [탐색 14] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:33,943 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:33,943 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,945 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,822 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062210083007811)에 맞춰 변경되었습니다.
2026-01-14 13:40:34,823 - INFO - ==================================================
2026-01-14 13:40:34,825 - INFO -   [탐색 15] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:34,862 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:34,862 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,863 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,658 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906236114501953)에 맞춰 변경되었습니다.
2026-01-14 13:40:35,658 - INFO - ==================================================
2026-01-14 13:40:35,662 - INFO -   [탐색 16] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:35,733 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:35,733 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,734 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,567 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062436676025389)에 맞춰 변경되었습니다.
2026-01-14 13:40:36,568 - INFO - ==================================================
2026-01-14 13:40:36,571 - INFO -   [탐색 17] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:36,631 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:36,632 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,633 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,517 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062474441528319)에 맞춰 변경되었습니다.
2026-01-14 13:40:37,517 - INFO - ==================================================
2026-01-14 13:40:37,520 - INFO -   [탐색 18] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:37,574 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:37,574 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,575 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:38,278 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062493324279783)에 맞춰 변경되었습니다.
2026-01-14 13:40:38,278 - INFO - ==================================================
2026-01-14 13:40:38,284 - INFO -   [탐색 19] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:38,337 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:38,337 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:38,339 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,009 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062502765655516)에 맞춰 변경되었습니다.
2026-01-14 13:40:39,009 - INFO - ==================================================
2026-01-14 13:40:39,012 - INFO -   [탐색 20] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:39,081 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:39,081 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,083 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,804 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249804496765)에 맞춰 변경되었습니다.
2026-01-14 13:40:39,805 - INFO - ==================================================
2026-01-14 13:40:39,807 - INFO -   [탐색 21] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:39,855 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:39,855 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,856 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:40,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500405311582)에 맞춰 변경되었습니다.
2026-01-14 13:40:40,569 - INFO - ==================================================
2026-01-14 13:40:40,572 - INFO -   [탐색 22] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:40,632 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:40,633 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:40,634 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,693 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499225139615)에 맞춰 변경되었습니다.
2026-01-14 13:40:41,694 - INFO - ==================================================
2026-01-14 13:40:41,697 - INFO -   [탐색 23] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:41,747 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:41,748 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,749 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,513 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499815225599)에 맞춰 변경되었습니다.
2026-01-14 13:40:42,514 - INFO - ==================================================
2026-01-14 13:40:42,516 - INFO -   [탐색 24] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:42,561 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:42,562 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,563 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,382 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906250011026859)에 맞춰 변경되었습니다.
2026-01-14 13:40:43,383 - INFO - ==================================================
2026-01-14 13:40:43,385 - INFO -   [탐색 25] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:43,447 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:43,448 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,449 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,952 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499962747095)에 맞춰 변경되었습니다.
2026-01-14 13:40:43,952 - INFO - ==================================================
2026-01-14 13:40:43,954 - INFO -   [탐색 26] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:43,996 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:43,996 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,996 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:44,735 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500036507842)에 맞춰 변경되었습니다.
2026-01-14 13:40:44,735 - INFO - ==================================================
2026-01-14 13:40:44,738 - INFO -   [탐색 27] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:44,798 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:44,798 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:44,800 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,916 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999627469)에 맞춰 변경되었습니다.
2026-01-14 13:40:45,917 - INFO - ==================================================
2026-01-14 13:40:45,921 - INFO -   [탐색 28] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:45,993 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:45,993 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,995 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:46,744 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500018067656)에 맞춰 변경되었습니다.
2026-01-14 13:40:46,745 - INFO - ==================================================
2026-01-14 13:40:46,749 - INFO -   [탐색 29] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:46,811 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:46,812 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:46,814 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500008847563)에 맞춰 변경되었습니다.
2026-01-14 13:40:47,585 - INFO - ==================================================
2026-01-14 13:40:47,588 - INFO -   [탐색 30] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:47,648 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:47,648 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,649 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:48,466 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500004237516)에 맞춰 변경되었습니다.
2026-01-14 13:40:48,467 - INFO - ==================================================
2026-01-14 13:40:48,469 - INFO -   [탐색 31] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:48,528 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:48,528 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:48,530 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,352 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500001932492)에 맞춰 변경되었습니다.
2026-01-14 13:40:49,353 - INFO - ==================================================
2026-01-14 13:40:49,355 - INFO -   [탐색 32] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:49,415 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:49,416 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,417 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,385 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906250000077998)에 맞춰 변경되었습니다.
2026-01-14 13:40:50,385 - INFO - ==================================================
2026-01-14 13:40:50,387 - INFO -   [탐색 33] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:50,425 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:50,425 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,426 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,008 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000203725)에 맞춰 변경되었습니다.
2026-01-14 13:40:51,008 - INFO - ==================================================
2026-01-14 13:40:51,012 - INFO -   [탐색 34] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:51,075 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:51,076 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,078 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,674 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999915596)에 맞춰 변경되었습니다.
2026-01-14 13:40:51,675 - INFO - ==================================================
2026-01-14 13:40:51,677 - INFO -   [탐색 35] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:51,745 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:51,745 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,746 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,341 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000059661)에 맞춰 변경되었습니다.
2026-01-14 13:40:52,341 - INFO - ==================================================
2026-01-14 13:40:52,344 - INFO -   [탐색 36] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:52,394 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:52,395 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,396 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:53,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999987629)에 맞춰 변경되었습니다.
2026-01-14 13:40:53,238 - INFO - ==================================================
2026-01-14 13:40:53,240 - INFO -   [탐색 37] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:53,295 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:53,296 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:53,297 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:54,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000023646)에 맞춰 변경되었습니다.
2026-01-14 13:40:54,404 - INFO - ==================================================
2026-01-14 13:40:54,408 - INFO -   [탐색 38] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:54,471 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:54,471 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:54,473 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,384 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000005638)에 맞춰 변경되었습니다.
2026-01-14 13:40:55,384 - INFO - ==================================================
2026-01-14 13:40:55,387 - INFO -   [탐색 39] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:55,451 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:55,452 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,453 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:56,282 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999996634)에 맞춰 변경되었습니다.
2026-01-14 13:40:56,283 - INFO - ==================================================
2026-01-14 13:40:56,286 - INFO -   [탐색 40] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:56,346 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:56,347 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:56,349 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,161 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000001136)에 맞춰 변경되었습니다.
2026-01-14 13:40:57,162 - INFO - ==================================================
2026-01-14 13:40:57,164 - INFO -   [탐색 41] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:57,223 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:57,223 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,224 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,927 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999998885)에 맞춰 변경되었습니다.
2026-01-14 13:40:57,927 - INFO - ==================================================
2026-01-14 13:40:57,930 - INFO -   [탐색 42] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:57,981 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:57,982 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,984 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,980 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000011)에 맞춰 변경되었습니다.
2026-01-14 13:40:58,981 - INFO - ==================================================
2026-01-14 13:40:58,984 - INFO -   [탐색 43] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:40:59,030 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:59,030 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:59,031 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:59,757 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999448)에 맞춰 변경되었습니다.
2026-01-14 13:40:59,757 - INFO - ==================================================
2026-01-14 13:40:59,760 - INFO -   [탐색 44] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:40:59,816 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:59,816 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:59,820 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:00,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999729)에 맞춰 변경되었습니다.
2026-01-14 13:41:00,672 - INFO - ==================================================
2026-01-14 13:41:00,677 - INFO -   [탐색 45] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:00,738 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:00,739 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:00,740 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:01,517 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249999999987)에 맞춰 변경되었습니다.
2026-01-14 13:41:01,518 - INFO - ==================================================
2026-01-14 13:41:01,521 - INFO -   [탐색 46] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:01,577 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:01,578 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:01,579 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:02,373 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249999999994)에 맞춰 변경되었습니다.
2026-01-14 13:41:02,373 - INFO - ==================================================
2026-01-14 13:41:02,376 - INFO -   [탐색 47] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:02,436 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:02,436 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:02,438 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:03,562 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999976)에 맞춰 변경되었습니다.
2026-01-14 13:41:03,562 - INFO - ==================================================
2026-01-14 13:41:03,568 - INFO -   [탐색 48] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:03,637 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:03,637 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:03,639 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:04,764 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999993)에 맞춰 변경되었습니다.
2026-01-14 13:41:04,765 - INFO - ==================================================
2026-01-14 13:41:04,768 - INFO -   [탐색 49] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:04,827 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:04,828 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:04,829 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:05,449 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000002)에 맞춰 변경되었습니다.
2026-01-14 13:41:05,450 - INFO - ==================================================
2026-01-14 13:41:05,452 - INFO -   [탐색 50] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:41:05,513 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:05,514 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:05,516 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:06,586 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999998)에 맞춰 변경되었습니다.
2026-01-14 13:41:06,586 - INFO - ==================================================
2026-01-14 13:41:06,589 - INFO -   [탐색 51] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:06,649 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:06,649 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:06,650 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:07,782 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:07,783 - INFO - ==================================================
2026-01-14 13:41:07,788 - INFO -   [탐색 52] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:07,906 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:07,907 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:07,908 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:09,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000001)에 맞춰 변경되었습니다.
2026-01-14 13:41:09,309 - INFO - ==================================================
2026-01-14 13:41:09,313 - INFO -   [탐색 53] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 13:41:09,428 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:09,431 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:09,432 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:10,175 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:10,175 - INFO - ==================================================
2026-01-14 13:41:10,177 - INFO -   [탐색 54] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:10,240 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:10,241 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:10,242 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:11,470 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:11,470 - INFO - ==================================================
2026-01-14 13:41:11,473 - INFO -   [탐색 55] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:11,547 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:11,547 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:11,549 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:12,368 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:12,368 - INFO - ==================================================
2026-01-14 13:41:12,371 - INFO -   [탐색 56] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:12,427 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:12,428 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:12,429 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:13,291 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:13,291 - INFO - ==================================================
2026-01-14 13:41:13,293 - INFO -   [탐색 57] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:13,334 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:13,335 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:13,336 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:14,408 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:14,409 - INFO - ==================================================
2026-01-14 13:41:14,414 - INFO -   [탐색 58] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:14,487 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:14,488 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:14,490 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:15,408 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:15,408 - INFO - ==================================================
2026-01-14 13:41:15,411 - INFO -   [탐색 59] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:15,506 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:15,507 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:15,509 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:16,278 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:16,279 - INFO - ==================================================
2026-01-14 13:41:16,282 - INFO -   [탐색 60] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:16,339 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:16,340 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:16,342 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:17,491 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:17,492 - INFO - ==================================================
2026-01-14 13:41:17,495 - INFO -   [탐색 61] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:17,567 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:17,568 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:17,569 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:18,936 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:18,936 - INFO - ==================================================
2026-01-14 13:41:18,938 - INFO -   [탐색 62] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:18,984 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:18,985 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:18,986 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:19,872 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:19,872 - INFO - ==================================================
2026-01-14 13:41:19,875 - INFO -   [탐색 63] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:20,242 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:20,243 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:20,244 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:21,148 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:21,148 - INFO - ==================================================
2026-01-14 13:41:21,152 - INFO -   [탐색 64] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:21,266 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:21,266 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:21,268 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:21,977 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:21,977 - INFO - ==================================================
2026-01-14 13:41:21,983 - INFO -   [탐색 65] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:22,111 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:22,111 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:22,112 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:23,110 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:23,110 - INFO - ==================================================
2026-01-14 13:41:23,113 - INFO -   [탐색 66] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:23,179 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:23,180 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:23,182 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:24,204 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:24,204 - INFO - ==================================================
2026-01-14 13:41:24,206 - INFO -   [탐색 67] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:24,270 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:24,270 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:24,272 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:25,717 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:25,718 - INFO - ==================================================
2026-01-14 13:41:25,722 - INFO -   [탐색 68] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:25,785 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:25,785 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:25,787 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:26,812 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:26,812 - INFO - ==================================================
2026-01-14 13:41:26,819 - INFO -   [탐색 69] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:26,964 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:26,965 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:26,967 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:28,489 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:28,490 - INFO - ==================================================
2026-01-14 13:41:28,502 - INFO -   [탐색 70] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:28,594 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:28,595 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:28,596 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:29,562 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:29,563 - INFO - ==================================================
2026-01-14 13:41:29,566 - INFO -   [탐색 71] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:29,624 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:29,625 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:29,626 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:30,443 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:30,444 - INFO - ==================================================
2026-01-14 13:41:30,447 - INFO -   [탐색 72] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:30,517 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:30,518 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:30,520 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:31,719 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:31,720 - INFO - ==================================================
2026-01-14 13:41:31,725 - INFO -   [탐색 73] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:31,788 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:31,788 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:31,790 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:32,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:32,648 - INFO - ==================================================
2026-01-14 13:41:32,651 - INFO -   [탐색 74] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:32,717 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:32,718 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:32,719 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:33,686 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:33,687 - INFO - ==================================================
2026-01-14 13:41:33,690 - INFO -   [탐색 75] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:33,751 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:33,752 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:33,753 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:34,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:34,682 - INFO - ==================================================
2026-01-14 13:41:34,684 - INFO -   [탐색 76] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:34,743 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:34,743 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:34,745 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:35,809 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:35,810 - INFO - ==================================================
2026-01-14 13:41:35,812 - INFO -   [탐색 77] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:35,873 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:35,873 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:35,875 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:37,070 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:37,070 - INFO - ==================================================
2026-01-14 13:41:37,077 - INFO -   [탐색 78] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:37,176 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:37,177 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:37,179 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:38,366 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:38,367 - INFO - ==================================================
2026-01-14 13:41:38,373 - INFO -   [탐색 79] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:38,427 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:38,428 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:38,429 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:39,353 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:39,353 - INFO - ==================================================
2026-01-14 13:41:39,355 - INFO -   [탐색 80] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:39,427 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:39,428 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:39,430 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:40,715 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:40,716 - INFO - ==================================================
2026-01-14 13:41:40,718 - INFO -   [탐색 81] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:40,773 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:40,774 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:40,775 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:41,682 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:41,683 - INFO - ==================================================
2026-01-14 13:41:41,685 - INFO -   [탐색 82] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:41,749 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:41,750 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:41,752 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:43,232 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:43,232 - INFO - ==================================================
2026-01-14 13:41:43,237 - INFO -   [탐색 83] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:43,302 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:43,303 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:43,304 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:44,439 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:44,439 - INFO - ==================================================
2026-01-14 13:41:44,442 - INFO -   [탐색 84] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:44,537 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:44,537 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:44,543 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:46,080 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:46,080 - INFO - ==================================================
2026-01-14 13:41:46,083 - INFO -   [탐색 85] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:46,172 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:46,173 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:46,175 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:47,288 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:47,289 - INFO - ==================================================
2026-01-14 13:41:47,292 - INFO -   [탐색 86] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:47,357 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:47,358 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:47,360 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:48,588 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:48,589 - INFO - ==================================================
2026-01-14 13:41:48,591 - INFO -   [탐색 87] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:48,661 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:48,662 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:48,663 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:49,921 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:49,921 - INFO - ==================================================
2026-01-14 13:41:49,925 - INFO -   [탐색 88] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:49,978 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:49,978 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:49,979 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:50,570 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:50,570 - INFO - ==================================================
2026-01-14 13:41:50,578 - INFO -   [탐색 89] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:50,700 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:50,701 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:50,707 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:51,585 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:51,586 - INFO - ==================================================
2026-01-14 13:41:51,589 - INFO -   [탐색 90] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:51,649 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:51,649 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:51,650 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:52,391 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:52,391 - INFO - ==================================================
2026-01-14 13:41:52,393 - INFO -   [탐색 91] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:52,440 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:52,441 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:52,442 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:53,152 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:53,153 - INFO - ==================================================
2026-01-14 13:41:53,155 - INFO -   [탐색 92] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:53,260 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:53,260 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:53,262 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:55,975 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:55,975 - INFO - ==================================================
2026-01-14 13:41:55,979 - INFO -   [탐색 93] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:56,042 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:56,042 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:56,043 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:57,085 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:57,086 - INFO - ==================================================
2026-01-14 13:41:57,088 - INFO -   [탐색 94] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:57,180 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:57,181 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:57,182 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:59,195 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:41:59,196 - INFO - ==================================================
2026-01-14 13:41:59,199 - INFO -   [탐색 95] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:41:59,256 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:59,256 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:59,258 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:42:00,104 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:42:00,105 - INFO - ==================================================
2026-01-14 13:42:00,108 - INFO -   [탐색 96] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:42:00,170 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:42:00,170 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:42:00,172 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:42:01,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:42:01,061 - INFO - ==================================================
2026-01-14 13:42:01,064 - INFO -   [탐색 97] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:42:01,126 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:42:01,127 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:42:01,129 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:42:02,420 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:42:02,421 - INFO - ==================================================
2026-01-14 13:42:02,425 - INFO -   [탐색 98] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:42:02,482 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:42:02,483 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:42:02,485 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:42:03,609 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:42:03,609 - INFO - ==================================================
2026-01-14 13:42:03,612 - INFO -   [탐색 99] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:42:03,677 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:42:03,678 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:42:03,679 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:42:04,869 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 13:42:04,870 - INFO - ==================================================
2026-01-14 13:42:04,875 - INFO -   [탐색 100] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 13:42:04,875 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9049 입니다.
2026-01-14 13:42:04,875 - INFO - ================================================================================
2026-01-14 13:42:04,882 - INFO - 계산된 Pruning 정보(희소도: 0.9049)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:42:05,046 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:42:05,295 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:42:05,296 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:42:05,296 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:42:06,084 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:42:06,084 - INFO - ==================================================
2026-01-14 13:42:06,094 - INFO - ==================================================
2026-01-14 13:42:06,095 - INFO - 모델 파라미터 수:
2026-01-14 13:42:06,095 - INFO -   - 총 파라미터: 31,612 개
2026-01-14 13:42:06,095 - INFO -   - 학습 가능한 파라미터: 31,612 개
2026-01-14 13:42:06,340 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:42:06,522 - INFO - FLOPs가 0.5384 GFLOPs에서 0.0171 GFLOPs로 감소했습니다 (감소율: 96.83%).
2026-01-14 13:42:06,523 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:42:06,523 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:42:06,525 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:42:06,526 - INFO - ==================================================
2026-01-14 13:42:06,526 - INFO - train 모드를 시작합니다.
2026-01-14 13:42:06,526 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:42:06,526 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:42:06,526 - INFO - --------------------------------------------------
2026-01-14 13:42:06,529 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:42:15,797 - INFO - [Train] [11/90] | Loss: 0.6203 | Train Acc: 66.82%
2026-01-14 13:42:18,785 - INFO - [Valid] [11/90] | Loss: 0.5580 | Val Acc: 71.68%
2026-01-14 13:42:18,803 - INFO - [Metrics for 'abnormal'] | Precision: 0.6943 | Recall: 0.6943 | F1: 0.6943
2026-01-14 13:42:18,803 - INFO - [Metrics for 'normal'] | Precision: 0.7363 | Recall: 0.7363 | F1: 0.7363
2026-01-14 13:42:18,850 - INFO - [Best Model Saved] (val loss: 0.5580) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:42:18,850 - INFO - --------------------------------------------------
2026-01-14 13:42:18,854 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:42:28,186 - INFO - [Train] [12/90] | Loss: 0.5464 | Train Acc: 74.48%
2026-01-14 13:42:31,607 - INFO - [Valid] [12/90] | Loss: 0.5658 | Val Acc: 73.16%
2026-01-14 13:42:31,620 - INFO - [Metrics for 'abnormal'] | Precision: 0.7171 | Recall: 0.6943 | F1: 0.7055
2026-01-14 13:42:31,621 - INFO - [Metrics for 'normal'] | Precision: 0.7433 | Recall: 0.7637 | F1: 0.7534
2026-01-14 13:42:31,626 - INFO - --------------------------------------------------
2026-01-14 13:42:31,631 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:42:43,511 - INFO - [Train] [13/90] | Loss: 0.5200 | Train Acc: 78.35%
2026-01-14 13:42:45,949 - INFO - [Valid] [13/90] | Loss: 0.5566 | Val Acc: 74.93%
2026-01-14 13:42:45,962 - INFO - [Metrics for 'abnormal'] | Precision: 0.7368 | Recall: 0.7134 | F1: 0.7249
2026-01-14 13:42:45,963 - INFO - [Metrics for 'normal'] | Precision: 0.7594 | Recall: 0.7802 | F1: 0.7696
2026-01-14 13:42:46,007 - INFO - [Best Model Saved] (val loss: 0.5566) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:42:46,008 - INFO - --------------------------------------------------
2026-01-14 13:42:46,011 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:42:56,301 - INFO - [Train] [14/90] | Loss: 0.5164 | Train Acc: 79.39%
2026-01-14 13:42:58,847 - INFO - [Valid] [14/90] | Loss: 0.5850 | Val Acc: 71.98%
2026-01-14 13:42:58,860 - INFO - [Metrics for 'abnormal'] | Precision: 0.6685 | Recall: 0.7834 | F1: 0.7214
2026-01-14 13:42:58,861 - INFO - [Metrics for 'normal'] | Precision: 0.7806 | Recall: 0.6648 | F1: 0.7181
2026-01-14 13:42:58,865 - INFO - --------------------------------------------------
2026-01-14 13:42:58,869 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:43:08,711 - INFO - [Train] [15/90] | Loss: 0.4926 | Train Acc: 80.28%
2026-01-14 13:43:11,426 - INFO - [Valid] [15/90] | Loss: 0.5809 | Val Acc: 74.34%
2026-01-14 13:43:11,450 - INFO - [Metrics for 'abnormal'] | Precision: 0.7035 | Recall: 0.7707 | F1: 0.7356
2026-01-14 13:43:11,452 - INFO - [Metrics for 'normal'] | Precision: 0.7844 | Recall: 0.7198 | F1: 0.7507
2026-01-14 13:43:11,461 - INFO - --------------------------------------------------
2026-01-14 13:43:11,468 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:43:22,933 - INFO - [Train] [16/90] | Loss: 0.4839 | Train Acc: 81.70%
2026-01-14 13:43:25,998 - INFO - [Valid] [16/90] | Loss: 0.5774 | Val Acc: 73.75%
2026-01-14 13:43:26,020 - INFO - [Metrics for 'abnormal'] | Precision: 0.6809 | Recall: 0.8153 | F1: 0.7420
2026-01-14 13:43:26,024 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.6703 | F1: 0.7327
2026-01-14 13:43:26,028 - INFO - --------------------------------------------------
2026-01-14 13:43:26,035 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:43:36,582 - INFO - [Train] [17/90] | Loss: 0.4850 | Train Acc: 80.95%
2026-01-14 13:43:39,756 - INFO - [Valid] [17/90] | Loss: 0.5345 | Val Acc: 74.93%
2026-01-14 13:43:39,775 - INFO - [Metrics for 'abnormal'] | Precision: 0.7222 | Recall: 0.7452 | F1: 0.7335
2026-01-14 13:43:39,778 - INFO - [Metrics for 'normal'] | Precision: 0.7740 | Recall: 0.7527 | F1: 0.7632
2026-01-14 13:43:39,829 - INFO - [Best Model Saved] (val loss: 0.5345) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:43:39,829 - INFO - --------------------------------------------------
2026-01-14 13:43:39,833 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:43:50,042 - INFO - [Train] [18/90] | Loss: 0.4671 | Train Acc: 82.74%
2026-01-14 13:43:53,543 - INFO - [Valid] [18/90] | Loss: 0.5903 | Val Acc: 74.34%
2026-01-14 13:43:53,558 - INFO - [Metrics for 'abnormal'] | Precision: 0.6944 | Recall: 0.7962 | F1: 0.7418
2026-01-14 13:43:53,559 - INFO - [Metrics for 'normal'] | Precision: 0.7987 | Recall: 0.6978 | F1: 0.7449
2026-01-14 13:43:53,563 - INFO - --------------------------------------------------
2026-01-14 13:43:53,568 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:44:02,317 - INFO - [Train] [19/90] | Loss: 0.4603 | Train Acc: 83.18%
2026-01-14 13:44:05,465 - INFO - [Valid] [19/90] | Loss: 0.5892 | Val Acc: 73.75%
2026-01-14 13:44:05,477 - INFO - [Metrics for 'abnormal'] | Precision: 0.6889 | Recall: 0.7898 | F1: 0.7359
2026-01-14 13:44:05,478 - INFO - [Metrics for 'normal'] | Precision: 0.7925 | Recall: 0.6923 | F1: 0.7390
2026-01-14 13:44:05,482 - INFO - --------------------------------------------------
2026-01-14 13:44:05,487 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:44:16,158 - INFO - [Train] [20/90] | Loss: 0.4716 | Train Acc: 83.18%
2026-01-14 13:44:19,847 - INFO - [Valid] [20/90] | Loss: 0.5597 | Val Acc: 74.63%
2026-01-14 13:44:19,872 - INFO - [Metrics for 'abnormal'] | Precision: 0.6878 | Recall: 0.8280 | F1: 0.7514
2026-01-14 13:44:19,872 - INFO - [Metrics for 'normal'] | Precision: 0.8200 | Recall: 0.6758 | F1: 0.7410
2026-01-14 13:44:19,880 - INFO - --------------------------------------------------
2026-01-14 13:44:19,887 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:44:29,900 - INFO - [Train] [21/90] | Loss: 0.4524 | Train Acc: 83.71%
2026-01-14 13:44:31,734 - INFO - [Valid] [21/90] | Loss: 0.5820 | Val Acc: 73.75%
2026-01-14 13:44:31,747 - INFO - [Metrics for 'abnormal'] | Precision: 0.6828 | Recall: 0.8089 | F1: 0.7405
2026-01-14 13:44:31,747 - INFO - [Metrics for 'normal'] | Precision: 0.8039 | Recall: 0.6758 | F1: 0.7343
2026-01-14 13:44:31,752 - INFO - --------------------------------------------------
2026-01-14 13:44:31,755 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:44:41,445 - INFO - [Train] [22/90] | Loss: 0.4412 | Train Acc: 85.04%
2026-01-14 13:44:43,855 - INFO - [Valid] [22/90] | Loss: 0.5793 | Val Acc: 74.63%
2026-01-14 13:44:43,884 - INFO - [Metrics for 'abnormal'] | Precision: 0.7383 | Recall: 0.7006 | F1: 0.7190
2026-01-14 13:44:43,884 - INFO - [Metrics for 'normal'] | Precision: 0.7526 | Recall: 0.7857 | F1: 0.7688
2026-01-14 13:44:43,892 - INFO - --------------------------------------------------
2026-01-14 13:44:43,899 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:44:54,527 - INFO - [Train] [23/90] | Loss: 0.4363 | Train Acc: 84.67%
2026-01-14 13:44:57,074 - INFO - [Valid] [23/90] | Loss: 0.5546 | Val Acc: 76.40%
2026-01-14 13:44:57,085 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7389 | F1: 0.7436
2026-01-14 13:44:57,085 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.7857 | F1: 0.7814
2026-01-14 13:44:57,089 - INFO - --------------------------------------------------
2026-01-14 13:44:57,093 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:45:07,130 - INFO - [Train] [24/90] | Loss: 0.4349 | Train Acc: 85.94%
2026-01-14 13:45:09,683 - INFO - [Valid] [24/90] | Loss: 0.5771 | Val Acc: 75.81%
2026-01-14 13:45:09,694 - INFO - [Metrics for 'abnormal'] | Precision: 0.7698 | Recall: 0.6815 | F1: 0.7230
2026-01-14 13:45:09,695 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.8242 | F1: 0.7853
2026-01-14 13:45:09,699 - INFO - --------------------------------------------------
2026-01-14 13:45:09,702 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:45:18,052 - INFO - [Train] [25/90] | Loss: 0.4319 | Train Acc: 84.52%
2026-01-14 13:45:20,659 - INFO - [Valid] [25/90] | Loss: 0.5509 | Val Acc: 76.40%
2026-01-14 13:45:20,669 - INFO - [Metrics for 'abnormal'] | Precision: 0.7550 | Recall: 0.7261 | F1: 0.7403
2026-01-14 13:45:20,669 - INFO - [Metrics for 'normal'] | Precision: 0.7713 | Recall: 0.7967 | F1: 0.7838
2026-01-14 13:45:20,675 - INFO - --------------------------------------------------
2026-01-14 13:45:20,677 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:45:30,506 - INFO - [Train] [26/90] | Loss: 0.4234 | Train Acc: 85.71%
2026-01-14 13:45:33,294 - INFO - [Valid] [26/90] | Loss: 0.5944 | Val Acc: 74.93%
2026-01-14 13:45:33,307 - INFO - [Metrics for 'abnormal'] | Precision: 0.6800 | Recall: 0.8662 | F1: 0.7619
2026-01-14 13:45:33,307 - INFO - [Metrics for 'normal'] | Precision: 0.8489 | Recall: 0.6484 | F1: 0.7352
2026-01-14 13:45:33,311 - INFO - --------------------------------------------------
2026-01-14 13:45:33,315 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:45:43,560 - INFO - [Train] [27/90] | Loss: 0.4258 | Train Acc: 85.49%
2026-01-14 13:45:45,977 - INFO - [Valid] [27/90] | Loss: 0.5471 | Val Acc: 77.29%
2026-01-14 13:45:45,990 - INFO - [Metrics for 'abnormal'] | Precision: 0.7532 | Recall: 0.7580 | F1: 0.7556
2026-01-14 13:45:45,991 - INFO - [Metrics for 'normal'] | Precision: 0.7901 | Recall: 0.7857 | F1: 0.7879
2026-01-14 13:45:45,996 - INFO - --------------------------------------------------
2026-01-14 13:45:45,999 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:45:56,094 - INFO - [Train] [28/90] | Loss: 0.4095 | Train Acc: 87.05%
2026-01-14 13:45:58,233 - INFO - [Valid] [28/90] | Loss: 0.5328 | Val Acc: 78.47%
2026-01-14 13:45:58,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:45:58,244 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:45:58,288 - INFO - [Best Model Saved] (val loss: 0.5328) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:45:58,288 - INFO - --------------------------------------------------
2026-01-14 13:45:58,291 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:46:08,112 - INFO - [Train] [29/90] | Loss: 0.4068 | Train Acc: 86.83%
2026-01-14 13:46:11,290 - INFO - [Valid] [29/90] | Loss: 0.5917 | Val Acc: 76.70%
2026-01-14 13:46:11,357 - INFO - [Metrics for 'abnormal'] | Precision: 0.7010 | Recall: 0.8662 | F1: 0.7749
2026-01-14 13:46:11,357 - INFO - [Metrics for 'normal'] | Precision: 0.8552 | Recall: 0.6813 | F1: 0.7584
2026-01-14 13:46:11,376 - INFO - --------------------------------------------------
2026-01-14 13:46:11,385 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:46:23,264 - INFO - [Train] [30/90] | Loss: 0.3958 | Train Acc: 87.65%
2026-01-14 13:46:26,271 - INFO - [Valid] [30/90] | Loss: 0.5686 | Val Acc: 77.88%
2026-01-14 13:46:26,283 - INFO - [Metrics for 'abnormal'] | Precision: 0.7440 | Recall: 0.7962 | F1: 0.7692
2026-01-14 13:46:26,283 - INFO - [Metrics for 'normal'] | Precision: 0.8129 | Recall: 0.7637 | F1: 0.7875
2026-01-14 13:46:26,288 - INFO - --------------------------------------------------
2026-01-14 13:46:26,291 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:46:35,880 - INFO - [Train] [31/90] | Loss: 0.3982 | Train Acc: 88.62%
2026-01-14 13:46:38,421 - INFO - [Valid] [31/90] | Loss: 0.5926 | Val Acc: 76.99%
2026-01-14 13:46:38,447 - INFO - [Metrics for 'abnormal'] | Precision: 0.7283 | Recall: 0.8025 | F1: 0.7636
2026-01-14 13:46:38,447 - INFO - [Metrics for 'normal'] | Precision: 0.8133 | Recall: 0.7418 | F1: 0.7759
2026-01-14 13:46:38,456 - INFO - --------------------------------------------------
2026-01-14 13:46:38,465 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:46:47,764 - INFO - [Train] [32/90] | Loss: 0.3874 | Train Acc: 87.95%
2026-01-14 13:46:50,398 - INFO - [Valid] [32/90] | Loss: 0.5833 | Val Acc: 76.40%
2026-01-14 13:46:50,411 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.7707 | F1: 0.7516
2026-01-14 13:46:50,411 - INFO - [Metrics for 'normal'] | Precision: 0.7931 | Recall: 0.7582 | F1: 0.7753
2026-01-14 13:46:50,415 - INFO - --------------------------------------------------
2026-01-14 13:46:50,418 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:47:00,021 - INFO - [Train] [33/90] | Loss: 0.3823 | Train Acc: 88.62%
2026-01-14 13:47:03,095 - INFO - [Valid] [33/90] | Loss: 0.6053 | Val Acc: 75.81%
2026-01-14 13:47:03,120 - INFO - [Metrics for 'abnormal'] | Precision: 0.6866 | Recall: 0.8790 | F1: 0.7709
2026-01-14 13:47:03,120 - INFO - [Metrics for 'normal'] | Precision: 0.8623 | Recall: 0.6538 | F1: 0.7438
2026-01-14 13:47:03,127 - INFO - --------------------------------------------------
2026-01-14 13:47:03,133 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:47:12,876 - INFO - [Train] [34/90] | Loss: 0.3897 | Train Acc: 87.72%
2026-01-14 13:47:15,515 - INFO - [Valid] [34/90] | Loss: 0.6260 | Val Acc: 74.63%
2026-01-14 13:47:15,524 - INFO - [Metrics for 'abnormal'] | Precision: 0.8381 | Recall: 0.5605 | F1: 0.6718
2026-01-14 13:47:15,524 - INFO - [Metrics for 'normal'] | Precision: 0.7051 | Recall: 0.9066 | F1: 0.7933
2026-01-14 13:47:15,527 - INFO - --------------------------------------------------
2026-01-14 13:47:15,529 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:47:25,950 - INFO - [Train] [35/90] | Loss: 0.4026 | Train Acc: 87.28%
2026-01-14 13:47:28,280 - INFO - [Valid] [35/90] | Loss: 0.5747 | Val Acc: 77.58%
2026-01-14 13:47:28,294 - INFO - [Metrics for 'abnormal'] | Precision: 0.7288 | Recall: 0.8217 | F1: 0.7725
2026-01-14 13:47:28,294 - INFO - [Metrics for 'normal'] | Precision: 0.8272 | Recall: 0.7363 | F1: 0.7791
2026-01-14 13:47:28,300 - INFO - --------------------------------------------------
2026-01-14 13:47:28,304 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:47:37,763 - INFO - [Train] [36/90] | Loss: 0.3862 | Train Acc: 89.06%
2026-01-14 13:47:40,519 - INFO - [Valid] [36/90] | Loss: 0.5928 | Val Acc: 76.11%
2026-01-14 13:47:40,536 - INFO - [Metrics for 'abnormal'] | Precision: 0.8276 | Recall: 0.6115 | F1: 0.7033
2026-01-14 13:47:40,536 - INFO - [Metrics for 'normal'] | Precision: 0.7265 | Recall: 0.8901 | F1: 0.8000
2026-01-14 13:47:40,541 - INFO - --------------------------------------------------
2026-01-14 13:47:40,544 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:47:50,401 - INFO - [Train] [37/90] | Loss: 0.3752 | Train Acc: 89.43%
2026-01-14 13:47:52,776 - INFO - [Valid] [37/90] | Loss: 0.5814 | Val Acc: 78.17%
2026-01-14 13:47:52,801 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7261 | F1: 0.7550
2026-01-14 13:47:52,801 - INFO - [Metrics for 'normal'] | Precision: 0.7784 | Recall: 0.8297 | F1: 0.8032
2026-01-14 13:47:52,812 - INFO - --------------------------------------------------
2026-01-14 13:47:52,819 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:48:03,326 - INFO - [Train] [38/90] | Loss: 0.3769 | Train Acc: 90.03%
2026-01-14 13:48:05,887 - INFO - [Valid] [38/90] | Loss: 0.5665 | Val Acc: 77.58%
2026-01-14 13:48:05,902 - INFO - [Metrics for 'abnormal'] | Precision: 0.7166 | Recall: 0.8535 | F1: 0.7791
2026-01-14 13:48:05,902 - INFO - [Metrics for 'normal'] | Precision: 0.8487 | Recall: 0.7088 | F1: 0.7725
2026-01-14 13:48:05,908 - INFO - --------------------------------------------------
2026-01-14 13:48:05,912 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:48:16,241 - INFO - [Train] [39/90] | Loss: 0.3774 | Train Acc: 90.10%
2026-01-14 13:48:19,149 - INFO - [Valid] [39/90] | Loss: 0.6261 | Val Acc: 74.04%
2026-01-14 13:48:19,162 - INFO - [Metrics for 'abnormal'] | Precision: 0.6683 | Recall: 0.8726 | F1: 0.7569
2026-01-14 13:48:19,162 - INFO - [Metrics for 'normal'] | Precision: 0.8507 | Recall: 0.6264 | F1: 0.7215
2026-01-14 13:48:19,166 - INFO - --------------------------------------------------
2026-01-14 13:48:19,169 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:48:28,732 - INFO - [Train] [40/90] | Loss: 0.3610 | Train Acc: 90.55%
2026-01-14 13:48:31,456 - INFO - [Valid] [40/90] | Loss: 0.5747 | Val Acc: 77.88%
2026-01-14 13:48:31,470 - INFO - [Metrics for 'abnormal'] | Precision: 0.7887 | Recall: 0.7134 | F1: 0.7492
2026-01-14 13:48:31,471 - INFO - [Metrics for 'normal'] | Precision: 0.7716 | Recall: 0.8352 | F1: 0.8021
2026-01-14 13:48:31,475 - INFO - --------------------------------------------------
2026-01-14 13:48:31,477 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:48:40,925 - INFO - [Train] [41/90] | Loss: 0.3625 | Train Acc: 89.66%
2026-01-14 13:48:43,109 - INFO - [Valid] [41/90] | Loss: 0.5906 | Val Acc: 75.52%
2026-01-14 13:48:43,120 - INFO - [Metrics for 'abnormal'] | Precision: 0.6927 | Recall: 0.8471 | F1: 0.7622
2026-01-14 13:48:43,121 - INFO - [Metrics for 'normal'] | Precision: 0.8367 | Recall: 0.6758 | F1: 0.7477
2026-01-14 13:48:43,125 - INFO - --------------------------------------------------
2026-01-14 13:48:43,129 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:48:52,766 - INFO - [Train] [42/90] | Loss: 0.3760 | Train Acc: 89.51%
2026-01-14 13:48:55,324 - INFO - [Valid] [42/90] | Loss: 0.6428 | Val Acc: 73.16%
2026-01-14 13:48:55,335 - INFO - [Metrics for 'abnormal'] | Precision: 0.6557 | Recall: 0.8854 | F1: 0.7534
2026-01-14 13:48:55,335 - INFO - [Metrics for 'normal'] | Precision: 0.8583 | Recall: 0.5989 | F1: 0.7055
2026-01-14 13:48:55,339 - INFO - --------------------------------------------------
2026-01-14 13:48:55,342 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:49:05,000 - INFO - [Train] [43/90] | Loss: 0.3666 | Train Acc: 89.66%
2026-01-14 13:49:07,527 - INFO - [Valid] [43/90] | Loss: 0.5560 | Val Acc: 78.76%
2026-01-14 13:49:07,549 - INFO - [Metrics for 'abnormal'] | Precision: 0.8102 | Recall: 0.7070 | F1: 0.7551
2026-01-14 13:49:07,549 - INFO - [Metrics for 'normal'] | Precision: 0.7723 | Recall: 0.8571 | F1: 0.8125
2026-01-14 13:49:07,561 - INFO - --------------------------------------------------
2026-01-14 13:49:07,566 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:49:16,499 - INFO - [Train] [44/90] | Loss: 0.3636 | Train Acc: 89.81%
2026-01-14 13:49:18,768 - INFO - [Valid] [44/90] | Loss: 0.5672 | Val Acc: 80.24%
2026-01-14 13:49:18,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:49:18,781 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:49:18,786 - INFO - --------------------------------------------------
2026-01-14 13:49:18,790 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:49:30,020 - INFO - [Train] [45/90] | Loss: 0.3747 | Train Acc: 88.91%
2026-01-14 13:49:32,236 - INFO - [Valid] [45/90] | Loss: 0.5546 | Val Acc: 76.99%
2026-01-14 13:49:32,244 - INFO - [Metrics for 'abnormal'] | Precision: 0.8062 | Recall: 0.6624 | F1: 0.7273
2026-01-14 13:49:32,244 - INFO - [Metrics for 'normal'] | Precision: 0.7476 | Recall: 0.8626 | F1: 0.8010
2026-01-14 13:49:32,247 - INFO - --------------------------------------------------
2026-01-14 13:49:32,249 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:49:41,200 - INFO - [Train] [46/90] | Loss: 0.3512 | Train Acc: 90.85%
2026-01-14 13:49:44,221 - INFO - [Valid] [46/90] | Loss: 0.5578 | Val Acc: 78.47%
2026-01-14 13:49:44,235 - INFO - [Metrics for 'abnormal'] | Precision: 0.7838 | Recall: 0.7389 | F1: 0.7607
2026-01-14 13:49:44,235 - INFO - [Metrics for 'normal'] | Precision: 0.7853 | Recall: 0.8242 | F1: 0.8043
2026-01-14 13:49:44,241 - INFO - --------------------------------------------------
2026-01-14 13:49:44,245 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:49:55,182 - INFO - [Train] [47/90] | Loss: 0.3625 | Train Acc: 90.55%
2026-01-14 13:49:57,360 - INFO - [Valid] [47/90] | Loss: 0.5828 | Val Acc: 79.06%
2026-01-14 13:49:57,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-01-14 13:49:57,375 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-01-14 13:49:57,384 - INFO - --------------------------------------------------
2026-01-14 13:49:57,389 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:50:07,448 - INFO - [Train] [48/90] | Loss: 0.3492 | Train Acc: 91.67%
2026-01-14 13:50:09,721 - INFO - [Valid] [48/90] | Loss: 0.6133 | Val Acc: 75.52%
2026-01-14 13:50:09,734 - INFO - [Metrics for 'abnormal'] | Precision: 0.8246 | Recall: 0.5987 | F1: 0.6937
2026-01-14 13:50:09,735 - INFO - [Metrics for 'normal'] | Precision: 0.7200 | Recall: 0.8901 | F1: 0.7961
2026-01-14 13:50:09,739 - INFO - --------------------------------------------------
2026-01-14 13:50:09,743 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:50:21,694 - INFO - [Train] [49/90] | Loss: 0.3464 | Train Acc: 90.33%
2026-01-14 13:50:24,810 - INFO - [Valid] [49/90] | Loss: 0.5723 | Val Acc: 76.99%
2026-01-14 13:50:24,824 - INFO - [Metrics for 'abnormal'] | Precision: 0.7365 | Recall: 0.7834 | F1: 0.7593
2026-01-14 13:50:24,825 - INFO - [Metrics for 'normal'] | Precision: 0.8023 | Recall: 0.7582 | F1: 0.7797
2026-01-14 13:50:24,830 - INFO - --------------------------------------------------
2026-01-14 13:50:24,834 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:50:34,129 - INFO - [Train] [50/90] | Loss: 0.3264 | Train Acc: 93.01%
2026-01-14 13:50:36,775 - INFO - [Valid] [50/90] | Loss: 0.6144 | Val Acc: 76.40%
2026-01-14 13:50:36,800 - INFO - [Metrics for 'abnormal'] | Precision: 0.7452 | Recall: 0.7452 | F1: 0.7452
2026-01-14 13:50:36,801 - INFO - [Metrics for 'normal'] | Precision: 0.7802 | Recall: 0.7802 | F1: 0.7802
2026-01-14 13:50:36,808 - INFO - --------------------------------------------------
2026-01-14 13:50:36,813 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:50:46,264 - INFO - [Train] [51/90] | Loss: 0.3429 | Train Acc: 91.67%
2026-01-14 13:50:49,397 - INFO - [Valid] [51/90] | Loss: 0.5745 | Val Acc: 77.29%
2026-01-14 13:50:49,406 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.8153 | F1: 0.7688
2026-01-14 13:50:49,407 - INFO - [Metrics for 'normal'] | Precision: 0.8221 | Recall: 0.7363 | F1: 0.7768
2026-01-14 13:50:49,410 - INFO - --------------------------------------------------
2026-01-14 13:50:49,413 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:50:58,963 - INFO - [Train] [52/90] | Loss: 0.3514 | Train Acc: 90.85%
2026-01-14 13:51:02,632 - INFO - [Valid] [52/90] | Loss: 0.5425 | Val Acc: 78.76%
2026-01-14 13:51:02,648 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-01-14 13:51:02,649 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-01-14 13:51:02,655 - INFO - --------------------------------------------------
2026-01-14 13:51:02,658 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:51:10,717 - INFO - [Train] [53/90] | Loss: 0.3390 | Train Acc: 91.74%
2026-01-14 13:51:14,010 - INFO - [Valid] [53/90] | Loss: 0.5919 | Val Acc: 77.88%
2026-01-14 13:51:14,055 - INFO - [Metrics for 'abnormal'] | Precision: 0.7971 | Recall: 0.7006 | F1: 0.7458
2026-01-14 13:51:14,055 - INFO - [Metrics for 'normal'] | Precision: 0.7662 | Recall: 0.8462 | F1: 0.8042
2026-01-14 13:51:14,065 - INFO - --------------------------------------------------
2026-01-14 13:51:14,073 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:51:23,525 - INFO - [Train] [54/90] | Loss: 0.3453 | Train Acc: 91.44%
2026-01-14 13:51:27,480 - INFO - [Valid] [54/90] | Loss: 0.5737 | Val Acc: 78.47%
2026-01-14 13:51:27,492 - INFO - [Metrics for 'abnormal'] | Precision: 0.7442 | Recall: 0.8153 | F1: 0.7781
2026-01-14 13:51:27,493 - INFO - [Metrics for 'normal'] | Precision: 0.8263 | Recall: 0.7582 | F1: 0.7908
2026-01-14 13:51:27,497 - INFO - --------------------------------------------------
2026-01-14 13:51:27,500 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:51:36,325 - INFO - [Train] [55/90] | Loss: 0.3472 | Train Acc: 91.37%
2026-01-14 13:51:39,809 - INFO - [Valid] [55/90] | Loss: 0.5666 | Val Acc: 78.17%
2026-01-14 13:51:39,821 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.7898 | F1: 0.7702
2026-01-14 13:51:39,822 - INFO - [Metrics for 'normal'] | Precision: 0.8103 | Recall: 0.7747 | F1: 0.7921
2026-01-14 13:51:39,828 - INFO - --------------------------------------------------
2026-01-14 13:51:39,831 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:51:47,953 - INFO - [Train] [56/90] | Loss: 0.3295 | Train Acc: 92.41%
2026-01-14 13:51:51,418 - INFO - [Valid] [56/90] | Loss: 0.5730 | Val Acc: 75.52%
2026-01-14 13:51:51,427 - INFO - [Metrics for 'abnormal'] | Precision: 0.6814 | Recall: 0.8854 | F1: 0.7701
2026-01-14 13:51:51,428 - INFO - [Metrics for 'normal'] | Precision: 0.8667 | Recall: 0.6429 | F1: 0.7382
2026-01-14 13:51:51,431 - INFO - --------------------------------------------------
2026-01-14 13:51:51,434 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:52:02,151 - INFO - [Train] [57/90] | Loss: 0.3363 | Train Acc: 91.59%
2026-01-14 13:52:05,562 - INFO - [Valid] [57/90] | Loss: 0.5612 | Val Acc: 77.29%
2026-01-14 13:52:05,573 - INFO - [Metrics for 'abnormal'] | Precision: 0.7857 | Recall: 0.7006 | F1: 0.7407
2026-01-14 13:52:05,574 - INFO - [Metrics for 'normal'] | Precision: 0.7638 | Recall: 0.8352 | F1: 0.7979
2026-01-14 13:52:05,578 - INFO - --------------------------------------------------
2026-01-14 13:52:05,582 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:52:16,478 - INFO - [Train] [58/90] | Loss: 0.3308 | Train Acc: 92.78%
2026-01-14 13:52:18,638 - INFO - [Valid] [58/90] | Loss: 0.6018 | Val Acc: 76.40%
2026-01-14 13:52:18,651 - INFO - [Metrics for 'abnormal'] | Precision: 0.7081 | Recall: 0.8344 | F1: 0.7661
2026-01-14 13:52:18,652 - INFO - [Metrics for 'normal'] | Precision: 0.8312 | Recall: 0.7033 | F1: 0.7619
2026-01-14 13:52:18,656 - INFO - --------------------------------------------------
2026-01-14 13:52:18,660 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:52:28,612 - INFO - [Train] [59/90] | Loss: 0.3375 | Train Acc: 92.41%
2026-01-14 13:52:30,764 - INFO - [Valid] [59/90] | Loss: 0.5685 | Val Acc: 78.17%
2026-01-14 13:52:30,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-01-14 13:52:30,774 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-01-14 13:52:30,778 - INFO - --------------------------------------------------
2026-01-14 13:52:30,785 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:52:40,087 - INFO - [Train] [60/90] | Loss: 0.3216 | Train Acc: 93.53%
2026-01-14 13:52:42,329 - INFO - [Valid] [60/90] | Loss: 0.5624 | Val Acc: 78.47%
2026-01-14 13:52:42,342 - INFO - [Metrics for 'abnormal'] | Precision: 0.7800 | Recall: 0.7452 | F1: 0.7622
2026-01-14 13:52:42,343 - INFO - [Metrics for 'normal'] | Precision: 0.7884 | Recall: 0.8187 | F1: 0.8032
2026-01-14 13:52:42,349 - INFO - --------------------------------------------------
2026-01-14 13:52:42,353 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:52:51,138 - INFO - [Train] [61/90] | Loss: 0.3375 | Train Acc: 91.00%
2026-01-14 13:52:54,695 - INFO - [Valid] [61/90] | Loss: 0.5505 | Val Acc: 77.88%
2026-01-14 13:52:54,718 - INFO - [Metrics for 'abnormal'] | Precision: 0.7808 | Recall: 0.7261 | F1: 0.7525
2026-01-14 13:52:54,718 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.8242 | F1: 0.8000
2026-01-14 13:52:54,722 - INFO - --------------------------------------------------
2026-01-14 13:52:54,724 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:53:04,089 - INFO - [Train] [62/90] | Loss: 0.3249 | Train Acc: 92.49%
2026-01-14 13:53:06,668 - INFO - [Valid] [62/90] | Loss: 0.5679 | Val Acc: 79.65%
2026-01-14 13:53:06,682 - INFO - [Metrics for 'abnormal'] | Precision: 0.7973 | Recall: 0.7516 | F1: 0.7738
2026-01-14 13:53:06,682 - INFO - [Metrics for 'normal'] | Precision: 0.7958 | Recall: 0.8352 | F1: 0.8150
2026-01-14 13:53:06,686 - INFO - --------------------------------------------------
2026-01-14 13:53:06,688 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:53:16,289 - INFO - [Train] [63/90] | Loss: 0.3259 | Train Acc: 92.19%
2026-01-14 13:53:19,167 - INFO - [Valid] [63/90] | Loss: 0.5662 | Val Acc: 79.94%
2026-01-14 13:53:19,177 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8471 | F1: 0.7964
2026-01-14 13:53:19,177 - INFO - [Metrics for 'normal'] | Precision: 0.8519 | Recall: 0.7582 | F1: 0.8023
2026-01-14 13:53:19,180 - INFO - --------------------------------------------------
2026-01-14 13:53:19,184 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:53:28,764 - INFO - [Train] [64/90] | Loss: 0.3117 | Train Acc: 93.38%
2026-01-14 13:53:31,453 - INFO - [Valid] [64/90] | Loss: 0.5544 | Val Acc: 79.35%
2026-01-14 13:53:31,461 - INFO - [Metrics for 'abnormal'] | Precision: 0.7919 | Recall: 0.7516 | F1: 0.7712
2026-01-14 13:53:31,462 - INFO - [Metrics for 'normal'] | Precision: 0.7947 | Recall: 0.8297 | F1: 0.8118
2026-01-14 13:53:31,465 - INFO - --------------------------------------------------
2026-01-14 13:53:31,468 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:53:40,857 - INFO - [Train] [65/90] | Loss: 0.3231 | Train Acc: 92.56%
2026-01-14 13:53:43,069 - INFO - [Valid] [65/90] | Loss: 0.5658 | Val Acc: 79.35%
2026-01-14 13:53:43,081 - INFO - [Metrics for 'abnormal'] | Precision: 0.7669 | Recall: 0.7962 | F1: 0.7812
2026-01-14 13:53:43,082 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.7912 | F1: 0.8045
2026-01-14 13:53:43,086 - INFO - --------------------------------------------------
2026-01-14 13:53:43,090 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:53:53,141 - INFO - [Train] [66/90] | Loss: 0.3117 | Train Acc: 93.38%
2026-01-14 13:53:55,674 - INFO - [Valid] [66/90] | Loss: 0.5924 | Val Acc: 77.29%
2026-01-14 13:53:55,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7222 | Recall: 0.8280 | F1: 0.7715
2026-01-14 13:53:55,686 - INFO - [Metrics for 'normal'] | Precision: 0.8302 | Recall: 0.7253 | F1: 0.7742
2026-01-14 13:53:55,690 - INFO - --------------------------------------------------
2026-01-14 13:53:55,693 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:54:05,476 - INFO - [Train] [67/90] | Loss: 0.3135 | Train Acc: 93.82%
2026-01-14 13:54:08,047 - INFO - [Valid] [67/90] | Loss: 0.5763 | Val Acc: 79.06%
2026-01-14 13:54:08,060 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 13:54:08,060 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 13:54:08,065 - INFO - --------------------------------------------------
2026-01-14 13:54:08,069 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:54:18,697 - INFO - [Train] [68/90] | Loss: 0.2989 | Train Acc: 94.42%
2026-01-14 13:54:21,106 - INFO - [Valid] [68/90] | Loss: 0.5919 | Val Acc: 78.17%
2026-01-14 13:54:21,116 - INFO - [Metrics for 'abnormal'] | Precision: 0.7399 | Recall: 0.8153 | F1: 0.7758
2026-01-14 13:54:21,117 - INFO - [Metrics for 'normal'] | Precision: 0.8253 | Recall: 0.7527 | F1: 0.7874
2026-01-14 13:54:21,121 - INFO - --------------------------------------------------
2026-01-14 13:54:21,124 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:54:32,243 - INFO - [Train] [69/90] | Loss: 0.3049 | Train Acc: 93.90%
2026-01-14 13:54:35,361 - INFO - [Valid] [69/90] | Loss: 0.5885 | Val Acc: 80.53%
2026-01-14 13:54:35,373 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 13:54:35,374 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 13:54:35,383 - INFO - --------------------------------------------------
2026-01-14 13:54:35,389 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:54:44,722 - INFO - [Train] [70/90] | Loss: 0.3139 | Train Acc: 94.05%
2026-01-14 13:54:47,695 - INFO - [Valid] [70/90] | Loss: 0.5853 | Val Acc: 79.06%
2026-01-14 13:54:47,706 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-01-14 13:54:47,707 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-01-14 13:54:47,712 - INFO - --------------------------------------------------
2026-01-14 13:54:47,716 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:54:57,618 - INFO - [Train] [71/90] | Loss: 0.3162 | Train Acc: 93.38%
2026-01-14 13:55:00,404 - INFO - [Valid] [71/90] | Loss: 0.5605 | Val Acc: 81.12%
2026-01-14 13:55:00,416 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-01-14 13:55:00,417 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-01-14 13:55:00,421 - INFO - --------------------------------------------------
2026-01-14 13:55:00,425 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:55:09,349 - INFO - [Train] [72/90] | Loss: 0.3180 | Train Acc: 92.19%
2026-01-14 13:55:12,094 - INFO - [Valid] [72/90] | Loss: 0.5663 | Val Acc: 79.35%
2026-01-14 13:55:12,107 - INFO - [Metrics for 'abnormal'] | Precision: 0.7669 | Recall: 0.7962 | F1: 0.7812
2026-01-14 13:55:12,107 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.7912 | F1: 0.8045
2026-01-14 13:55:12,112 - INFO - --------------------------------------------------
2026-01-14 13:55:12,117 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:55:18,624 - INFO - [Train] [73/90] | Loss: 0.2955 | Train Acc: 94.87%
2026-01-14 13:55:20,706 - INFO - [Valid] [73/90] | Loss: 0.5824 | Val Acc: 79.35%
2026-01-14 13:55:20,717 - INFO - [Metrics for 'abnormal'] | Precision: 0.7806 | Recall: 0.7707 | F1: 0.7756
2026-01-14 13:55:20,717 - INFO - [Metrics for 'normal'] | Precision: 0.8043 | Recall: 0.8132 | F1: 0.8087
2026-01-14 13:55:20,721 - INFO - --------------------------------------------------
2026-01-14 13:55:20,724 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:55:31,087 - INFO - [Train] [74/90] | Loss: 0.2959 | Train Acc: 94.87%
2026-01-14 13:55:34,558 - INFO - [Valid] [74/90] | Loss: 0.5609 | Val Acc: 79.94%
2026-01-14 13:55:34,584 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 13:55:34,588 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 13:55:34,595 - INFO - --------------------------------------------------
2026-01-14 13:55:34,597 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:55:41,064 - INFO - [Train] [75/90] | Loss: 0.3155 | Train Acc: 93.38%
2026-01-14 13:55:42,752 - INFO - [Valid] [75/90] | Loss: 0.5721 | Val Acc: 79.94%
2026-01-14 13:55:42,764 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 13:55:42,764 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 13:55:42,769 - INFO - --------------------------------------------------
2026-01-14 13:55:42,773 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:55:48,720 - INFO - [Train] [76/90] | Loss: 0.2936 | Train Acc: 94.57%
2026-01-14 13:55:50,375 - INFO - [Valid] [76/90] | Loss: 0.5563 | Val Acc: 79.94%
2026-01-14 13:55:50,385 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 13:55:50,386 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 13:55:50,390 - INFO - --------------------------------------------------
2026-01-14 13:55:50,393 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:55:56,134 - INFO - [Train] [77/90] | Loss: 0.2986 | Train Acc: 94.42%
2026-01-14 13:55:57,682 - INFO - [Valid] [77/90] | Loss: 0.5799 | Val Acc: 77.29%
2026-01-14 13:55:57,693 - INFO - [Metrics for 'abnormal'] | Precision: 0.7299 | Recall: 0.8089 | F1: 0.7674
2026-01-14 13:55:57,694 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.7418 | F1: 0.7781
2026-01-14 13:55:57,697 - INFO - --------------------------------------------------
2026-01-14 13:55:57,700 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:56:03,325 - INFO - [Train] [78/90] | Loss: 0.3067 | Train Acc: 94.20%
2026-01-14 13:56:06,247 - INFO - [Valid] [78/90] | Loss: 0.5920 | Val Acc: 79.35%
2026-01-14 13:56:06,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.8085 | Recall: 0.7261 | F1: 0.7651
2026-01-14 13:56:06,260 - INFO - [Metrics for 'normal'] | Precision: 0.7828 | Recall: 0.8516 | F1: 0.8158
2026-01-14 13:56:06,263 - INFO - --------------------------------------------------
2026-01-14 13:56:06,267 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:56:11,560 - INFO - [Train] [79/90] | Loss: 0.2958 | Train Acc: 94.12%
2026-01-14 13:56:13,181 - INFO - [Valid] [79/90] | Loss: 0.5970 | Val Acc: 80.24%
2026-01-14 13:56:13,190 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 13:56:13,191 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 13:56:13,194 - INFO - --------------------------------------------------
2026-01-14 13:56:13,197 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:56:18,337 - INFO - [Train] [80/90] | Loss: 0.2932 | Train Acc: 95.01%
2026-01-14 13:56:19,783 - INFO - [Valid] [80/90] | Loss: 0.5924 | Val Acc: 80.53%
2026-01-14 13:56:19,792 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7962 | F1: 0.7911
2026-01-14 13:56:19,793 - INFO - [Metrics for 'normal'] | Precision: 0.8222 | Recall: 0.8132 | F1: 0.8177
2026-01-14 13:56:19,796 - INFO - --------------------------------------------------
2026-01-14 13:56:19,799 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:56:24,907 - INFO - [Train] [81/90] | Loss: 0.2924 | Train Acc: 94.64%
2026-01-14 13:56:26,408 - INFO - [Valid] [81/90] | Loss: 0.5827 | Val Acc: 79.94%
2026-01-14 13:56:26,419 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-01-14 13:56:26,419 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-01-14 13:56:26,425 - INFO - --------------------------------------------------
2026-01-14 13:56:26,428 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:56:31,456 - INFO - [Train] [82/90] | Loss: 0.2947 | Train Acc: 94.05%
2026-01-14 13:56:32,834 - INFO - [Valid] [82/90] | Loss: 0.5811 | Val Acc: 79.35%
2026-01-14 13:56:32,844 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-01-14 13:56:32,844 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-01-14 13:56:32,847 - INFO - --------------------------------------------------
2026-01-14 13:56:32,849 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:56:37,481 - INFO - [Train] [83/90] | Loss: 0.2926 | Train Acc: 94.49%
2026-01-14 13:56:39,085 - INFO - [Valid] [83/90] | Loss: 0.5733 | Val Acc: 79.65%
2026-01-14 13:56:39,095 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-01-14 13:56:39,096 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-01-14 13:56:39,100 - INFO - --------------------------------------------------
2026-01-14 13:56:39,102 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:56:45,484 - INFO - [Train] [84/90] | Loss: 0.2907 | Train Acc: 94.94%
2026-01-14 13:56:46,892 - INFO - [Valid] [84/90] | Loss: 0.5782 | Val Acc: 81.12%
2026-01-14 13:56:46,905 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 13:56:46,905 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 13:56:46,910 - INFO - --------------------------------------------------
2026-01-14 13:56:46,913 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:56:51,458 - INFO - [Train] [85/90] | Loss: 0.2833 | Train Acc: 95.39%
2026-01-14 13:56:52,853 - INFO - [Valid] [85/90] | Loss: 0.5974 | Val Acc: 78.76%
2026-01-14 13:56:52,862 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-01-14 13:56:52,862 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-01-14 13:56:52,865 - INFO - --------------------------------------------------
2026-01-14 13:56:52,867 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:56:57,464 - INFO - [Train] [86/90] | Loss: 0.2831 | Train Acc: 95.24%
2026-01-14 13:56:58,806 - INFO - [Valid] [86/90] | Loss: 0.5807 | Val Acc: 80.24%
2026-01-14 13:56:58,814 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:56:58,815 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:56:58,818 - INFO - --------------------------------------------------
2026-01-14 13:56:58,820 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:57:03,198 - INFO - [Train] [87/90] | Loss: 0.2961 | Train Acc: 94.87%
2026-01-14 13:57:04,403 - INFO - [Valid] [87/90] | Loss: 0.5836 | Val Acc: 78.76%
2026-01-14 13:57:04,412 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.8153 | F1: 0.7805
2026-01-14 13:57:04,413 - INFO - [Metrics for 'normal'] | Precision: 0.8274 | Recall: 0.7637 | F1: 0.7943
2026-01-14 13:57:04,415 - INFO - --------------------------------------------------
2026-01-14 13:57:04,417 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:57:08,777 - INFO - [Train] [88/90] | Loss: 0.2953 | Train Acc: 94.42%
2026-01-14 13:57:10,027 - INFO - [Valid] [88/90] | Loss: 0.5878 | Val Acc: 79.35%
2026-01-14 13:57:10,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-01-14 13:57:10,036 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-01-14 13:57:10,039 - INFO - --------------------------------------------------
2026-01-14 13:57:10,041 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:57:14,622 - INFO - [Train] [89/90] | Loss: 0.2852 | Train Acc: 95.16%
2026-01-14 13:57:15,861 - INFO - [Valid] [89/90] | Loss: 0.5849 | Val Acc: 79.94%
2026-01-14 13:57:15,870 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 13:57:15,870 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 13:57:15,873 - INFO - --------------------------------------------------
2026-01-14 13:57:15,875 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:57:20,463 - INFO - [Train] [90/90] | Loss: 0.2948 | Train Acc: 94.35%
2026-01-14 13:57:21,657 - INFO - [Valid] [90/90] | Loss: 0.5943 | Val Acc: 77.58%
2026-01-14 13:57:21,664 - INFO - [Metrics for 'abnormal'] | Precision: 0.7396 | Recall: 0.7962 | F1: 0.7669
2026-01-14 13:57:21,664 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.7582 | F1: 0.7841
2026-01-14 13:57:21,668 - INFO - ==================================================
2026-01-14 13:57:21,668 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:57:21,668 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:57:21,668 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:57:21,707 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:57:21,721 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:57:21,722 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:57:21,722 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:57:21,723 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:57:22,450 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:57:22,451 - INFO - ==================================================
2026-01-14 13:57:22,516 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/best_model.pth'
2026-01-14 13:57:22,517 - INFO - ==================================================
2026-01-14 13:57:22,517 - INFO - Test 모드를 시작합니다.
2026-01-14 13:57:22,661 - INFO - 연산량 (MACs): 0.0085 GMACs per sample
2026-01-14 13:57:22,661 - INFO - 연산량 (FLOPs): 0.0171 GFLOPs per sample
2026-01-14 13:57:22,661 - INFO - ==================================================
2026-01-14 13:57:22,661 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:57:23,975 - INFO - 샘플 당 평균 Forward Pass 시간: 8.66ms (std: 1.99ms), FPS: 120.46 (std: 22.16) (1개 샘플 x 100회 반복)
2026-01-14 13:57:23,975 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 38.17 MB
2026-01-14 13:57:23,975 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:57:26,401 - INFO - [Test] Loss: 0.4714 | Test Acc: 78.47%
2026-01-14 13:57:26,416 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:57:26,417 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:57:26,898 - INFO - ==================================================
2026-01-14 13:57:26,898 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/confusion_matrix_20260114_133840.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/confusion_matrix_20260114_133840.pdf'
2026-01-14 13:57:26,898 - INFO - ==================================================
2026-01-14 13:57:26,898 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:57:28,206 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/model_fp32_20260114_133840.onnx'에 저장되었습니다. (크기: 0.34 MB)
2026-01-14 13:57:28,536 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2562.54 MB (증가량: 6.88 MB)
2026-01-14 13:57:28,536 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:57:29,786 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 9.29ms (std: 2.08ms)
2026-01-14 13:57:29,786 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 111.94 FPS (std: 19.84) (1개 샘플 x 100회 반복)
2026-01-14 13:57:29,786 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2571.09 MB (순수 증가량: 8.55 MB)
2026-01-14 13:57:29,787 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2571.09 MB (전체 증가량: 15.43 MB)
2026-01-14 13:57:32,668 - INFO - [Test (ONNX)] | Test Acc (ONNX): 78.47%
2026-01-14 13:57:32,679 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:57:32,679 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:57:33,097 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/val_acc.pdf'
2026-01-14 13:57:33,578 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/train_val_acc.pdf'
2026-01-14 13:57:33,892 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/F1_normal.pdf'
2026-01-14 13:57:34,254 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/val_loss.pdf'
2026-01-14 13:57:34,566 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/learning_rate.pdf'
2026-01-14 13:57:38,526 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_133840/graph_20260114_133840/compile.pdf'
