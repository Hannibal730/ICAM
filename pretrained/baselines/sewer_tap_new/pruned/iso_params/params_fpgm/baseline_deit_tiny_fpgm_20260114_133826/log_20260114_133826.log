2026-01-14 13:38:26,513 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/log_20260114_133826.log'에 저장됩니다.
2026-01-14 13:38:26,519 - INFO - ==================================================
2026-01-14 13:38:26,519 - INFO - config.yaml:
2026-01-14 13:38:26,519 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: deit_tiny
  use_fpgm_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:38:26,520 - INFO - ==================================================
2026-01-14 13:38:26,591 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:38:26,592 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:38:26,592 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:38:26,608 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:38:26,609 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:38:26,611 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:38:26,611 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:38:29,413 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:38:29,417 - INFO - ==================================================
2026-01-14 13:38:29,418 - INFO - 모델 파라미터 수:
2026-01-14 13:38:29,419 - INFO -   - 총 파라미터: 5,524,802 개
2026-01-14 13:38:29,419 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-01-14 13:38:29,421 - INFO - ================================================================================
2026-01-14 13:38:29,421 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:38:29,421 - INFO - ================================================================================
2026-01-14 13:38:29,422 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:38:29,424 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:38:29,424 - INFO - ==================================================
2026-01-14 13:38:29,424 - INFO - train 모드를 시작합니다.
2026-01-14 13:38:29,425 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:38:29,426 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:38:29,426 - INFO - --------------------------------------------------
2026-01-14 13:38:29,428 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:38:39,714 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-01-14 13:38:43,661 - INFO - [Valid] [1/10] | Loss: 0.6723 | Val Acc: 59.88%
2026-01-14 13:38:43,696 - INFO - [Metrics for 'abnormal'] | Precision: 0.5484 | Recall: 0.7580 | F1: 0.6364
2026-01-14 13:38:43,697 - INFO - [Metrics for 'normal'] | Precision: 0.6885 | Recall: 0.4615 | F1: 0.5526
2026-01-14 13:38:43,843 - INFO - [Best Model Saved] (val loss: 0.6723) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:38:43,843 - INFO - --------------------------------------------------
2026-01-14 13:38:43,845 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:38:53,021 - INFO - [Train] [2/10] | Loss: 0.6456 | Train Acc: 65.18%
2026-01-14 13:38:56,245 - INFO - [Valid] [2/10] | Loss: 0.6480 | Val Acc: 63.72%
2026-01-14 13:38:56,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.7297 | Recall: 0.3439 | F1: 0.4675
2026-01-14 13:38:56,260 - INFO - [Metrics for 'normal'] | Precision: 0.6113 | Recall: 0.8901 | F1: 0.7248
2026-01-14 13:38:56,337 - INFO - [Best Model Saved] (val loss: 0.6480) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:38:56,338 - INFO - --------------------------------------------------
2026-01-14 13:38:56,340 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:39:05,318 - INFO - [Train] [3/10] | Loss: 0.6115 | Train Acc: 67.19%
2026-01-14 13:39:08,216 - INFO - [Valid] [3/10] | Loss: 0.6387 | Val Acc: 64.60%
2026-01-14 13:39:08,238 - INFO - [Metrics for 'abnormal'] | Precision: 0.5815 | Recall: 0.8408 | F1: 0.6875
2026-01-14 13:39:08,239 - INFO - [Metrics for 'normal'] | Precision: 0.7768 | Recall: 0.4780 | F1: 0.5918
2026-01-14 13:39:08,309 - INFO - [Best Model Saved] (val loss: 0.6387) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:39:08,309 - INFO - --------------------------------------------------
2026-01-14 13:39:08,311 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:39:17,691 - INFO - [Train] [4/10] | Loss: 0.5844 | Train Acc: 71.88%
2026-01-14 13:39:21,096 - INFO - [Valid] [4/10] | Loss: 0.5776 | Val Acc: 71.98%
2026-01-14 13:39:21,121 - INFO - [Metrics for 'abnormal'] | Precision: 0.6615 | Recall: 0.8089 | F1: 0.7278
2026-01-14 13:39:21,121 - INFO - [Metrics for 'normal'] | Precision: 0.7959 | Recall: 0.6429 | F1: 0.7112
2026-01-14 13:39:21,190 - INFO - [Best Model Saved] (val loss: 0.5776) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:39:21,190 - INFO - --------------------------------------------------
2026-01-14 13:39:21,192 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:39:29,083 - INFO - [Train] [5/10] | Loss: 0.5355 | Train Acc: 78.50%
2026-01-14 13:39:31,693 - INFO - [Valid] [5/10] | Loss: 0.5770 | Val Acc: 72.27%
2026-01-14 13:39:31,702 - INFO - [Metrics for 'abnormal'] | Precision: 0.6465 | Recall: 0.8854 | F1: 0.7473
2026-01-14 13:39:31,702 - INFO - [Metrics for 'normal'] | Precision: 0.8548 | Recall: 0.5824 | F1: 0.6928
2026-01-14 13:39:31,759 - INFO - [Best Model Saved] (val loss: 0.5770) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:39:31,760 - INFO - --------------------------------------------------
2026-01-14 13:39:31,762 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:39:39,231 - INFO - [Train] [6/10] | Loss: 0.5329 | Train Acc: 77.46%
2026-01-14 13:39:41,640 - INFO - [Valid] [6/10] | Loss: 0.5504 | Val Acc: 75.52%
2026-01-14 13:39:41,656 - INFO - [Metrics for 'abnormal'] | Precision: 0.7056 | Recall: 0.8089 | F1: 0.7537
2026-01-14 13:39:41,657 - INFO - [Metrics for 'normal'] | Precision: 0.8113 | Recall: 0.7088 | F1: 0.7566
2026-01-14 13:39:41,724 - INFO - [Best Model Saved] (val loss: 0.5504) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:39:41,724 - INFO - --------------------------------------------------
2026-01-14 13:39:41,726 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:39:48,681 - INFO - [Train] [7/10] | Loss: 0.5029 | Train Acc: 79.76%
2026-01-14 13:39:50,566 - INFO - [Valid] [7/10] | Loss: 0.5600 | Val Acc: 76.40%
2026-01-14 13:39:50,579 - INFO - [Metrics for 'abnormal'] | Precision: 0.8407 | Recall: 0.6051 | F1: 0.7037
2026-01-14 13:39:50,580 - INFO - [Metrics for 'normal'] | Precision: 0.7257 | Recall: 0.9011 | F1: 0.8039
2026-01-14 13:39:50,585 - INFO - --------------------------------------------------
2026-01-14 13:39:50,587 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:39:56,837 - INFO - [Train] [8/10] | Loss: 0.4888 | Train Acc: 81.18%
2026-01-14 13:39:58,203 - INFO - [Valid] [8/10] | Loss: 0.5326 | Val Acc: 76.99%
2026-01-14 13:39:58,214 - INFO - [Metrics for 'abnormal'] | Precision: 0.8110 | Recall: 0.6561 | F1: 0.7254
2026-01-14 13:39:58,214 - INFO - [Metrics for 'normal'] | Precision: 0.7453 | Recall: 0.8681 | F1: 0.8020
2026-01-14 13:39:58,258 - INFO - [Best Model Saved] (val loss: 0.5326) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:39:58,258 - INFO - --------------------------------------------------
2026-01-14 13:39:58,259 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:40:03,659 - INFO - [Train] [9/10] | Loss: 0.4868 | Train Acc: 80.80%
2026-01-14 13:40:05,083 - INFO - [Valid] [9/10] | Loss: 0.5334 | Val Acc: 77.58%
2026-01-14 13:40:05,094 - INFO - [Metrics for 'abnormal'] | Precision: 0.8240 | Recall: 0.6561 | F1: 0.7305
2026-01-14 13:40:05,095 - INFO - [Metrics for 'normal'] | Precision: 0.7477 | Recall: 0.8791 | F1: 0.8081
2026-01-14 13:40:05,099 - INFO - --------------------------------------------------
2026-01-14 13:40:05,101 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:40:11,036 - INFO - [Train] [10/10] | Loss: 0.4771 | Train Acc: 81.55%
2026-01-14 13:40:12,451 - INFO - [Valid] [10/10] | Loss: 0.5266 | Val Acc: 75.81%
2026-01-14 13:40:12,465 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.7389 | F1: 0.7389
2026-01-14 13:40:12,466 - INFO - [Metrics for 'normal'] | Precision: 0.7747 | Recall: 0.7747 | F1: 0.7747
2026-01-14 13:40:12,529 - INFO - [Best Model Saved] (val loss: 0.5266) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:40:12,531 - INFO - ================================================================================
2026-01-14 13:40:12,532 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:40:12,532 - INFO - ================================================================================
2026-01-14 13:40:12,600 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:40:12,601 - INFO - ================================================================================
2026-01-14 13:40:12,601 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:40:12,603 - INFO - 원본 모델 파라미터: 5.5248M
2026-01-14 13:40:12,670 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,670 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,671 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,335 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,335 - INFO - ==================================================
2026-01-14 13:40:13,337 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.8881M (감소율: 65.83%)
2026-01-14 13:40:13,365 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,365 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,366 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,869 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,869 - INFO - ==================================================
2026-01-14 13:40:13,871 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.7436M (감소율: 86.54%)
2026-01-14 13:40:13,905 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,905 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,906 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,477 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,477 - INFO - ==================================================
2026-01-14 13:40:14,479 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.3258M (감소율: 94.10%)
2026-01-14 13:40:14,501 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,502 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,502 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,677 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,678 - INFO - ==================================================
2026-01-14 13:40:15,680 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.1581M (감소율: 97.14%)
2026-01-14 13:40:15,720 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,720 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,721 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,331 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,332 - INFO - ==================================================
2026-01-14 13:40:16,333 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0843M (감소율: 98.47%)
2026-01-14 13:40:16,367 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,368 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,368 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,859 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,859 - INFO - ==================================================
2026-01-14 13:40:16,862 - INFO -   [탐색  6] 희소도: 0.9745 -> 파라미터: 0.0500M (감소율: 99.09%)
2026-01-14 13:40:16,897 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,897 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,898 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,429 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9822656249999999)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,430 - INFO - ==================================================
2026-01-14 13:40:17,431 - INFO -   [탐색  7] 희소도: 0.9823 -> 파라미터: 0.0388M (감소율: 99.30%)
2026-01-14 13:40:17,453 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,454 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,454 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:18,035 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9861328125)에 맞춰 변경되었습니다.
2026-01-14 13:40:18,035 - INFO - ==================================================
2026-01-14 13:40:18,038 - INFO -   [탐색  8] 희소도: 0.9861 -> 파라미터: 0.0280M (감소율: 99.49%)
2026-01-14 13:40:18,083 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:18,084 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:18,085 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,035 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9841992187499999)에 맞춰 변경되었습니다.
2026-01-14 13:40:19,036 - INFO - ==================================================
2026-01-14 13:40:19,038 - INFO -   [탐색  9] 희소도: 0.9842 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:19,074 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:19,075 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,076 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,787 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 13:40:19,787 - INFO - ==================================================
2026-01-14 13:40:19,789 - INFO -   [탐색 10] 희소도: 0.9852 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:19,820 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:19,821 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,822 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,315 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9846826171874999)에 맞춰 변경되었습니다.
2026-01-14 13:40:20,316 - INFO - ==================================================
2026-01-14 13:40:20,318 - INFO -   [탐색 11] 희소도: 0.9847 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:20,347 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:20,347 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,347 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,921 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9844409179687499)에 맞춰 변경되었습니다.
2026-01-14 13:40:20,922 - INFO - ==================================================
2026-01-14 13:40:20,924 - INFO -   [탐색 12] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:20,961 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:20,962 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,963 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:21,915 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843200683593749)에 맞춰 변경되었습니다.
2026-01-14 13:40:21,916 - INFO - ==================================================
2026-01-14 13:40:21,918 - INFO -   [탐색 13] 희소도: 0.9843 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:21,953 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:21,953 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:21,955 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,431 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843804931640624)에 맞춰 변경되었습니다.
2026-01-14 13:40:22,431 - INFO - ==================================================
2026-01-14 13:40:22,433 - INFO -   [탐색 14] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:22,458 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:22,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,459 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,008 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843502807617186)에 맞춰 변경되었습니다.
2026-01-14 13:40:23,008 - INFO - ==================================================
2026-01-14 13:40:23,009 - INFO -   [탐색 15] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:23,043 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:23,043 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,044 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,552 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843653869628906)에 맞춰 변경되었습니다.
2026-01-14 13:40:23,552 - INFO - ==================================================
2026-01-14 13:40:23,553 - INFO -   [탐색 16] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:23,574 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:23,574 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,575 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,947 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843729400634764)에 맞춰 변경되었습니다.
2026-01-14 13:40:23,947 - INFO - ==================================================
2026-01-14 13:40:23,948 - INFO -   [탐색 17] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:23,968 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:23,968 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,968 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:24,689 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843767166137694)에 맞춰 변경되었습니다.
2026-01-14 13:40:24,690 - INFO - ==================================================
2026-01-14 13:40:24,692 - INFO -   [탐색 18] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:24,726 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:24,727 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:24,728 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,276 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843748283386229)에 맞춰 변경되었습니다.
2026-01-14 13:40:25,277 - INFO - ==================================================
2026-01-14 13:40:25,279 - INFO -   [탐색 19] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:25,313 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:25,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,315 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,839 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843757724761961)에 맞춰 변경되었습니다.
2026-01-14 13:40:25,840 - INFO - ==================================================
2026-01-14 13:40:25,842 - INFO -   [탐색 20] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:25,875 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:25,876 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,877 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:26,440 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843753004074095)에 맞춰 변경되었습니다.
2026-01-14 13:40:26,441 - INFO - ==================================================
2026-01-14 13:40:26,443 - INFO -   [탐색 21] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:26,475 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:26,476 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:26,477 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,034 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750643730163)에 맞춰 변경되었습니다.
2026-01-14 13:40:27,034 - INFO - ==================================================
2026-01-14 13:40:27,036 - INFO -   [탐색 22] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:27,068 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:27,069 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,070 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,898 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749463558196)에 맞춰 변경되었습니다.
2026-01-14 13:40:27,899 - INFO - ==================================================
2026-01-14 13:40:27,901 - INFO -   [탐색 23] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:27,928 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:27,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,930 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:28,439 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750053644179)에 맞춰 변경되었습니다.
2026-01-14 13:40:28,439 - INFO - ==================================================
2026-01-14 13:40:28,441 - INFO -   [탐색 24] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:28,471 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:28,471 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:28,472 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:28,978 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749758601188)에 맞춰 변경되었습니다.
2026-01-14 13:40:28,979 - INFO - ==================================================
2026-01-14 13:40:28,981 - INFO -   [탐색 25] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:29,017 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:29,018 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,018 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,519 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749906122683)에 맞춰 변경되었습니다.
2026-01-14 13:40:29,520 - INFO - ==================================================
2026-01-14 13:40:29,522 - INFO -   [탐색 26] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:29,554 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:29,554 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,555 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,073 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749979883432)에 맞춰 변경되었습니다.
2026-01-14 13:40:30,073 - INFO - ==================================================
2026-01-14 13:40:30,074 - INFO -   [탐색 27] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:30,098 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:30,098 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,099 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,723 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750016763806)에 맞춰 변경되었습니다.
2026-01-14 13:40:30,723 - INFO - ==================================================
2026-01-14 13:40:30,725 - INFO -   [탐색 28] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:30,745 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:30,745 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,745 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,271 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749998323619)에 맞춰 변경되었습니다.
2026-01-14 13:40:31,272 - INFO - ==================================================
2026-01-14 13:40:31,274 - INFO -   [탐색 29] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:31,308 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:31,309 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,310 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,830 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750007543712)에 맞춰 변경되었습니다.
2026-01-14 13:40:31,830 - INFO - ==================================================
2026-01-14 13:40:31,832 - INFO -   [탐색 30] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:31,864 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:31,865 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,866 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:32,340 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750002933666)에 맞춰 변경되었습니다.
2026-01-14 13:40:32,340 - INFO - ==================================================
2026-01-14 13:40:32,341 - INFO -   [탐색 31] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:32,365 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:32,365 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:32,366 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:32,846 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000628642)에 맞춰 변경되었습니다.
2026-01-14 13:40:32,846 - INFO - ==================================================
2026-01-14 13:40:32,848 - INFO -   [탐색 32] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:32,886 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:32,887 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:32,888 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984374999947613)에 맞춰 변경되었습니다.
2026-01-14 13:40:33,681 - INFO - ==================================================
2026-01-14 13:40:33,683 - INFO -   [탐색 33] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:33,707 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:33,707 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,708 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,161 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000052386)에 맞춰 변경되었습니다.
2026-01-14 13:40:34,162 - INFO - ==================================================
2026-01-14 13:40:34,163 - INFO -   [탐색 34] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:34,188 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:34,188 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,189 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,662 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999764257)에 맞춰 변경되었습니다.
2026-01-14 13:40:34,663 - INFO - ==================================================
2026-01-14 13:40:34,666 - INFO -   [탐색 35] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:34,700 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:34,701 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,702 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,175 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999908322)에 맞춰 변경되었습니다.
2026-01-14 13:40:35,176 - INFO - ==================================================
2026-01-14 13:40:35,178 - INFO -   [탐색 36] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:35,215 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:35,215 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,216 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,723 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999980353)에 맞춰 변경되었습니다.
2026-01-14 13:40:35,724 - INFO - ==================================================
2026-01-14 13:40:35,725 - INFO -   [탐색 37] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:35,749 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:35,750 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,750 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,434 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000016369)에 맞춰 변경되었습니다.
2026-01-14 13:40:36,435 - INFO - ==================================================
2026-01-14 13:40:36,436 - INFO -   [탐색 38] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:36,459 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:36,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,460 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,868 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999998361)에 맞춰 변경되었습니다.
2026-01-14 13:40:36,869 - INFO - ==================================================
2026-01-14 13:40:36,870 - INFO -   [탐색 39] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:36,890 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:36,890 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,891 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,260 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000007365)에 맞춰 변경되었습니다.
2026-01-14 13:40:37,260 - INFO - ==================================================
2026-01-14 13:40:37,261 - INFO -   [탐색 40] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:37,284 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:37,285 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,285 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,731 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000002863)에 맞춰 변경되었습니다.
2026-01-14 13:40:37,732 - INFO - ==================================================
2026-01-14 13:40:37,733 - INFO -   [탐색 41] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:37,766 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:37,766 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,767 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:38,617 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000613)에 맞춰 변경되었습니다.
2026-01-14 13:40:38,617 - INFO - ==================================================
2026-01-14 13:40:38,619 - INFO -   [탐색 42] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:38,646 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:38,646 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:38,647 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,208 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999487)에 맞춰 변경되었습니다.
2026-01-14 13:40:39,208 - INFO - ==================================================
2026-01-14 13:40:39,210 - INFO -   [탐색 43] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:39,242 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:39,243 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,243 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375000000005)에 맞춰 변경되었습니다.
2026-01-14 13:40:39,821 - INFO - ==================================================
2026-01-14 13:40:39,823 - INFO -   [탐색 44] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:39,858 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:39,859 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,860 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:40,463 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999769)에 맞춰 변경되었습니다.
2026-01-14 13:40:40,464 - INFO - ==================================================
2026-01-14 13:40:40,465 - INFO -   [탐색 45] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:40,499 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:40,499 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:40,500 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,020 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999909)에 맞춰 변경되었습니다.
2026-01-14 13:40:41,021 - INFO - ==================================================
2026-01-14 13:40:41,022 - INFO -   [탐색 46] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:41,049 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:41,049 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,050 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,740 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984374999999998)에 맞춰 변경되었습니다.
2026-01-14 13:40:41,740 - INFO - ==================================================
2026-01-14 13:40:41,742 - INFO -   [탐색 47] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:41,767 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:41,768 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,769 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,353 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000016)에 맞춰 변경되었습니다.
2026-01-14 13:40:42,353 - INFO - ==================================================
2026-01-14 13:40:42,355 - INFO -   [탐색 48] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:42,388 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:42,389 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,390 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,957 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999998)에 맞춰 변경되었습니다.
2026-01-14 13:40:42,958 - INFO - ==================================================
2026-01-14 13:40:42,959 - INFO -   [탐색 49] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:42,995 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:42,996 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,997 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,481 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000007)에 맞춰 변경되었습니다.
2026-01-14 13:40:43,481 - INFO - ==================================================
2026-01-14 13:40:43,486 - INFO -   [탐색 50] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:43,516 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:43,516 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,517 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,860 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000002)에 맞춰 변경되었습니다.
2026-01-14 13:40:43,860 - INFO - ==================================================
2026-01-14 13:40:43,861 - INFO -   [탐색 51] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:43,880 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:43,881 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,881 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:44,592 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:44,593 - INFO - ==================================================
2026-01-14 13:40:44,595 - INFO -   [탐색 52] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:44,623 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:44,624 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:44,625 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000001)에 맞춰 변경되었습니다.
2026-01-14 13:40:45,214 - INFO - ==================================================
2026-01-14 13:40:45,215 - INFO -   [탐색 53] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 13:40:45,252 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:45,252 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,253 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,790 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:45,791 - INFO - ==================================================
2026-01-14 13:40:45,793 - INFO -   [탐색 54] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:45,827 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:45,828 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,829 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:46,393 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:46,394 - INFO - ==================================================
2026-01-14 13:40:46,396 - INFO -   [탐색 55] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:46,429 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:46,429 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:46,430 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,000 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:47,000 - INFO - ==================================================
2026-01-14 13:40:47,002 - INFO -   [탐색 56] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:47,034 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:47,035 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,035 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,926 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:47,926 - INFO - ==================================================
2026-01-14 13:40:47,928 - INFO -   [탐색 57] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:47,962 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:47,962 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,963 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:48,575 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:48,576 - INFO - ==================================================
2026-01-14 13:40:48,578 - INFO -   [탐색 58] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:48,613 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:48,614 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:48,615 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,175 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:49,175 - INFO - ==================================================
2026-01-14 13:40:49,177 - INFO -   [탐색 59] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:49,201 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:49,201 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,202 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:49,682 - INFO - ==================================================
2026-01-14 13:40:49,684 - INFO -   [탐색 60] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:49,716 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:49,717 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,718 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,220 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:50,220 - INFO - ==================================================
2026-01-14 13:40:50,221 - INFO -   [탐색 61] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:50,244 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:50,244 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,244 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,910 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:50,910 - INFO - ==================================================
2026-01-14 13:40:50,912 - INFO -   [탐색 62] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:50,932 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:50,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,933 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,396 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:51,397 - INFO - ==================================================
2026-01-14 13:40:51,398 - INFO -   [탐색 63] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:51,417 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:51,418 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,418 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,922 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:51,923 - INFO - ==================================================
2026-01-14 13:40:51,925 - INFO -   [탐색 64] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:51,958 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:51,959 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,960 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,405 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:52,405 - INFO - ==================================================
2026-01-14 13:40:52,407 - INFO -   [탐색 65] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:52,430 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:52,431 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,432 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,936 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:52,936 - INFO - ==================================================
2026-01-14 13:40:52,938 - INFO -   [탐색 66] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:53,238 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:53,238 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:53,240 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:53,889 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:53,890 - INFO - ==================================================
2026-01-14 13:40:53,892 - INFO -   [탐색 67] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:53,933 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:53,934 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:53,935 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:54,636 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:54,636 - INFO - ==================================================
2026-01-14 13:40:54,638 - INFO -   [탐색 68] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:54,676 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:54,677 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:54,678 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,288 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:55,289 - INFO - ==================================================
2026-01-14 13:40:55,291 - INFO -   [탐색 69] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:55,328 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:55,328 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,329 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,879 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:55,879 - INFO - ==================================================
2026-01-14 13:40:55,881 - INFO -   [탐색 70] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:55,911 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:55,912 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,913 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:56,683 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:56,683 - INFO - ==================================================
2026-01-14 13:40:56,685 - INFO -   [탐색 71] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:56,709 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:56,710 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:56,710 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,120 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:57,120 - INFO - ==================================================
2026-01-14 13:40:57,121 - INFO -   [탐색 72] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:57,142 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:57,142 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,143 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,493 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:57,494 - INFO - ==================================================
2026-01-14 13:40:57,495 - INFO -   [탐색 73] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:57,520 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:57,520 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,521 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,036 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:58,037 - INFO - ==================================================
2026-01-14 13:40:58,039 - INFO -   [탐색 74] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:58,073 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:58,073 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,074 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,612 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:58,613 - INFO - ==================================================
2026-01-14 13:40:58,614 - INFO -   [탐색 75] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:58,648 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:58,649 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,650 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:40:59,464 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:40:59,465 - INFO - ==================================================
2026-01-14 13:40:59,467 - INFO -   [탐색 76] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:40:59,505 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:59,506 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:59,507 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:00,250 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:00,251 - INFO - ==================================================
2026-01-14 13:41:00,253 - INFO -   [탐색 77] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:00,295 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:00,296 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:00,297 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:01,216 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:01,217 - INFO - ==================================================
2026-01-14 13:41:01,219 - INFO -   [탐색 78] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:01,259 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:01,260 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:01,261 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:01,833 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:01,834 - INFO - ==================================================
2026-01-14 13:41:01,835 - INFO -   [탐색 79] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:01,861 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:01,862 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:01,862 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:02,465 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:02,466 - INFO - ==================================================
2026-01-14 13:41:02,475 - INFO -   [탐색 80] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:02,526 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:02,527 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:02,528 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:03,550 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:03,551 - INFO - ==================================================
2026-01-14 13:41:03,554 - INFO -   [탐색 81] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:03,588 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:03,589 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:03,590 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:04,159 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:04,159 - INFO - ==================================================
2026-01-14 13:41:04,161 - INFO -   [탐색 82] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:04,194 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:04,194 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:04,195 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:04,779 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:04,779 - INFO - ==================================================
2026-01-14 13:41:04,781 - INFO -   [탐색 83] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:04,819 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:04,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:04,820 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:05,400 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:05,400 - INFO - ==================================================
2026-01-14 13:41:05,402 - INFO -   [탐색 84] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:05,433 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:05,434 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:05,435 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:06,262 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:06,262 - INFO - ==================================================
2026-01-14 13:41:06,264 - INFO -   [탐색 85] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:06,305 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:06,305 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:06,306 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:07,204 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:07,205 - INFO - ==================================================
2026-01-14 13:41:07,208 - INFO -   [탐색 86] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:07,247 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:07,248 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:07,249 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:07,902 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:07,903 - INFO - ==================================================
2026-01-14 13:41:07,905 - INFO -   [탐색 87] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:07,939 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:07,940 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:07,941 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:08,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:08,822 - INFO - ==================================================
2026-01-14 13:41:08,824 - INFO -   [탐색 88] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:08,861 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:08,861 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:08,862 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:09,462 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:09,462 - INFO - ==================================================
2026-01-14 13:41:09,463 - INFO -   [탐색 89] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:09,491 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:09,495 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:09,495 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:10,299 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:10,299 - INFO - ==================================================
2026-01-14 13:41:10,301 - INFO -   [탐색 90] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:10,376 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:10,378 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:10,379 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:12,010 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:12,011 - INFO - ==================================================
2026-01-14 13:41:12,015 - INFO -   [탐색 91] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:12,052 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:12,053 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:12,054 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:12,748 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:12,748 - INFO - ==================================================
2026-01-14 13:41:12,751 - INFO -   [탐색 92] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:12,796 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:12,798 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:12,799 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:13,479 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:13,479 - INFO - ==================================================
2026-01-14 13:41:13,481 - INFO -   [탐색 93] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:13,511 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:13,511 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:13,512 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:14,005 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:14,005 - INFO - ==================================================
2026-01-14 13:41:14,006 - INFO -   [탐색 94] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:14,036 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:14,036 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:14,037 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:14,714 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:14,714 - INFO - ==================================================
2026-01-14 13:41:14,716 - INFO -   [탐색 95] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:15,052 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:15,052 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:15,053 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:15,689 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:15,690 - INFO - ==================================================
2026-01-14 13:41:15,694 - INFO -   [탐색 96] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:15,732 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:15,733 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:15,734 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:16,559 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:16,560 - INFO - ==================================================
2026-01-14 13:41:16,562 - INFO -   [탐색 97] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:16,596 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:16,598 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:16,599 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:17,161 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:17,162 - INFO - ==================================================
2026-01-14 13:41:17,163 - INFO -   [탐색 98] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:17,196 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:17,197 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:17,198 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:17,853 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:17,853 - INFO - ==================================================
2026-01-14 13:41:17,855 - INFO -   [탐색 99] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:17,917 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:17,919 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:17,920 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:19,329 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 13:41:19,330 - INFO - ==================================================
2026-01-14 13:41:19,333 - INFO -   [탐색 100] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 13:41:19,333 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9852 입니다.
2026-01-14 13:41:19,334 - INFO - ================================================================================
2026-01-14 13:41:19,337 - INFO - 계산된 Pruning 정보(희소도: 0.9852)를 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:41:19,378 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:41:19,472 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:41:19,473 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:41:19,474 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:41:20,107 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 13:41:20,108 - INFO - ==================================================
2026-01-14 13:41:20,111 - INFO - ==================================================
2026-01-14 13:41:20,111 - INFO - 모델 파라미터 수:
2026-01-14 13:41:20,111 - INFO -   - 총 파라미터: 28,092 개
2026-01-14 13:41:20,112 - INFO -   - 학습 가능한 파라미터: 28,092 개
2026-01-14 13:41:20,155 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:41:20,265 - INFO - FLOPs가 2.1493 GFLOPs에서 0.0081 GFLOPs로 감소했습니다 (감소율: 99.62%).
2026-01-14 13:41:20,269 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:41:20,269 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:41:20,271 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:41:20,271 - INFO - ==================================================
2026-01-14 13:41:20,271 - INFO - train 모드를 시작합니다.
2026-01-14 13:41:20,271 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:41:20,272 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:41:20,272 - INFO - --------------------------------------------------
2026-01-14 13:41:20,275 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:41:27,645 - INFO - [Train] [11/90] | Loss: 0.6844 | Train Acc: 61.24%
2026-01-14 13:41:30,206 - INFO - [Valid] [11/90] | Loss: 0.7004 | Val Acc: 46.31%
2026-01-14 13:41:30,222 - INFO - [Metrics for 'abnormal'] | Precision: 0.4631 | Recall: 1.0000 | F1: 0.6331
2026-01-14 13:41:30,223 - INFO - [Metrics for 'normal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:41:30,260 - INFO - [Best Model Saved] (val loss: 0.7004) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:41:30,261 - INFO - --------------------------------------------------
2026-01-14 13:41:30,264 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:41:36,852 - INFO - [Train] [12/90] | Loss: 0.6955 | Train Acc: 48.59%
2026-01-14 13:41:39,278 - INFO - [Valid] [12/90] | Loss: 0.6942 | Val Acc: 46.31%
2026-01-14 13:41:39,288 - INFO - [Metrics for 'abnormal'] | Precision: 0.4631 | Recall: 1.0000 | F1: 0.6331
2026-01-14 13:41:39,288 - INFO - [Metrics for 'normal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:41:39,306 - INFO - [Best Model Saved] (val loss: 0.6942) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:41:39,307 - INFO - --------------------------------------------------
2026-01-14 13:41:39,308 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:41:47,193 - INFO - [Train] [13/90] | Loss: 0.6935 | Train Acc: 49.11%
2026-01-14 13:41:49,750 - INFO - [Valid] [13/90] | Loss: 0.6925 | Val Acc: 53.69%
2026-01-14 13:41:49,764 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:41:49,765 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:41:49,793 - INFO - [Best Model Saved] (val loss: 0.6925) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:41:49,794 - INFO - --------------------------------------------------
2026-01-14 13:41:49,797 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:41:57,381 - INFO - [Train] [14/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 13:41:59,834 - INFO - [Valid] [14/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:41:59,842 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:41:59,843 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:41:59,862 - INFO - [Best Model Saved] (val loss: 0.6923) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:41:59,862 - INFO - --------------------------------------------------
2026-01-14 13:41:59,864 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:42:07,243 - INFO - [Train] [15/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:42:10,144 - INFO - [Valid] [15/90] | Loss: 0.6925 | Val Acc: 53.69%
2026-01-14 13:42:10,154 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:42:10,154 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:42:10,158 - INFO - --------------------------------------------------
2026-01-14 13:42:10,160 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:42:18,283 - INFO - [Train] [16/90] | Loss: 0.6931 | Train Acc: 51.26%
2026-01-14 13:42:21,583 - INFO - [Valid] [16/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:42:21,602 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:42:21,606 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:42:21,647 - INFO - [Best Model Saved] (val loss: 0.6922) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:42:21,648 - INFO - --------------------------------------------------
2026-01-14 13:42:21,650 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:42:30,267 - INFO - [Train] [17/90] | Loss: 0.6933 | Train Acc: 51.41%
2026-01-14 13:42:32,658 - INFO - [Valid] [17/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 13:42:32,676 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:42:32,677 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:42:32,683 - INFO - --------------------------------------------------
2026-01-14 13:42:32,686 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:42:42,415 - INFO - [Train] [18/90] | Loss: 0.6930 | Train Acc: 51.49%
2026-01-14 13:42:45,385 - INFO - [Valid] [18/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:42:45,399 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:42:45,399 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:42:45,404 - INFO - --------------------------------------------------
2026-01-14 13:42:45,410 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:42:55,258 - INFO - [Train] [19/90] | Loss: 0.6931 | Train Acc: 51.26%
2026-01-14 13:42:57,241 - INFO - [Valid] [19/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:42:57,249 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:42:57,250 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:42:57,273 - INFO - [Best Model Saved] (val loss: 0.6922) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:42:57,273 - INFO - --------------------------------------------------
2026-01-14 13:42:57,275 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:43:05,792 - INFO - [Train] [20/90] | Loss: 0.6931 | Train Acc: 51.26%
2026-01-14 13:43:08,372 - INFO - [Valid] [20/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 13:43:08,386 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:43:08,386 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:43:08,391 - INFO - --------------------------------------------------
2026-01-14 13:43:08,394 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:43:17,511 - INFO - [Train] [21/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 13:43:21,428 - INFO - [Valid] [21/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 13:43:21,440 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:43:21,441 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:43:21,469 - INFO - [Best Model Saved] (val loss: 0.6920) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:43:21,470 - INFO - --------------------------------------------------
2026-01-14 13:43:21,471 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:43:29,796 - INFO - [Train] [22/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 13:43:32,968 - INFO - [Valid] [22/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 13:43:32,977 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:43:32,977 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:43:32,984 - INFO - --------------------------------------------------
2026-01-14 13:43:33,011 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:43:42,082 - INFO - [Train] [23/90] | Loss: 0.6930 | Train Acc: 51.49%
2026-01-14 13:43:46,062 - INFO - [Valid] [23/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:43:46,077 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:43:46,078 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:43:46,084 - INFO - --------------------------------------------------
2026-01-14 13:43:46,086 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:43:55,211 - INFO - [Train] [24/90] | Loss: 0.6930 | Train Acc: 51.49%
2026-01-14 13:43:58,001 - INFO - [Valid] [24/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 13:43:58,014 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:43:58,015 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:43:58,074 - INFO - [Best Model Saved] (val loss: 0.6920) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:43:58,074 - INFO - --------------------------------------------------
2026-01-14 13:43:58,078 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:44:07,455 - INFO - [Train] [25/90] | Loss: 0.6931 | Train Acc: 51.26%
2026-01-14 13:44:10,377 - INFO - [Valid] [25/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 13:44:10,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:44:10,390 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:44:10,394 - INFO - --------------------------------------------------
2026-01-14 13:44:10,397 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:44:18,882 - INFO - [Train] [26/90] | Loss: 0.6930 | Train Acc: 51.19%
2026-01-14 13:44:21,569 - INFO - [Valid] [26/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:44:21,583 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:44:21,584 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:44:21,590 - INFO - --------------------------------------------------
2026-01-14 13:44:21,593 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:44:31,325 - INFO - [Train] [27/90] | Loss: 0.6931 | Train Acc: 51.34%
2026-01-14 13:44:33,569 - INFO - [Valid] [27/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:44:33,579 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:44:33,579 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:44:33,582 - INFO - --------------------------------------------------
2026-01-14 13:44:33,584 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:44:43,487 - INFO - [Train] [28/90] | Loss: 0.6930 | Train Acc: 51.49%
2026-01-14 13:44:47,004 - INFO - [Valid] [28/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:44:47,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:44:47,040 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:44:47,049 - INFO - --------------------------------------------------
2026-01-14 13:44:47,055 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:44:55,452 - INFO - [Train] [29/90] | Loss: 0.6930 | Train Acc: 51.49%
2026-01-14 13:44:58,576 - INFO - [Valid] [29/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:44:58,596 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:44:58,597 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:44:58,600 - INFO - --------------------------------------------------
2026-01-14 13:44:58,602 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:45:07,145 - INFO - [Train] [30/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 13:45:10,331 - INFO - [Valid] [30/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:45:10,359 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:45:10,359 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:45:10,370 - INFO - --------------------------------------------------
2026-01-14 13:45:10,372 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:45:18,490 - INFO - [Train] [31/90] | Loss: 0.6931 | Train Acc: 51.49%
2026-01-14 13:45:21,213 - INFO - [Valid] [31/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 13:45:21,225 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:45:21,225 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:45:21,230 - INFO - --------------------------------------------------
2026-01-14 13:45:21,233 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:45:29,920 - INFO - [Train] [32/90] | Loss: 0.6932 | Train Acc: 51.34%
2026-01-14 13:45:32,552 - INFO - [Valid] [32/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:45:32,564 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:45:32,564 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:45:32,568 - INFO - --------------------------------------------------
2026-01-14 13:45:32,570 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:45:41,800 - INFO - [Train] [33/90] | Loss: 0.6931 | Train Acc: 51.12%
2026-01-14 13:45:44,373 - INFO - [Valid] [33/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:45:44,392 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:45:44,392 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:45:44,398 - INFO - --------------------------------------------------
2026-01-14 13:45:44,400 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:45:53,773 - INFO - [Train] [34/90] | Loss: 0.6931 | Train Acc: 51.26%
2026-01-14 13:45:57,118 - INFO - [Valid] [34/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:45:57,137 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:45:57,138 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:45:57,142 - INFO - --------------------------------------------------
2026-01-14 13:45:57,145 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:46:06,446 - INFO - [Train] [35/90] | Loss: 0.6931 | Train Acc: 51.41%
2026-01-14 13:46:09,256 - INFO - [Valid] [35/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:46:09,287 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:46:09,287 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:46:09,293 - INFO - --------------------------------------------------
2026-01-14 13:46:09,295 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:46:18,511 - INFO - [Train] [36/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:46:21,365 - INFO - [Valid] [36/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 13:46:21,391 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:46:21,392 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:46:21,403 - INFO - --------------------------------------------------
2026-01-14 13:46:21,406 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:46:29,903 - INFO - [Train] [37/90] | Loss: 0.6931 | Train Acc: 51.34%
2026-01-14 13:46:32,788 - INFO - [Valid] [37/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 13:46:32,800 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:46:32,801 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:46:32,805 - INFO - --------------------------------------------------
2026-01-14 13:46:32,808 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:46:42,508 - INFO - [Train] [38/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:46:44,939 - INFO - [Valid] [38/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:46:44,953 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:46:44,953 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:46:44,958 - INFO - --------------------------------------------------
2026-01-14 13:46:44,961 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:46:54,196 - INFO - [Train] [39/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:46:57,377 - INFO - [Valid] [39/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:46:57,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:46:57,390 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:46:57,394 - INFO - --------------------------------------------------
2026-01-14 13:46:57,397 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:47:05,227 - INFO - [Train] [40/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:47:08,492 - INFO - [Valid] [40/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:47:08,520 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:47:08,520 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:47:08,534 - INFO - --------------------------------------------------
2026-01-14 13:47:08,536 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:47:17,492 - INFO - [Train] [41/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 13:47:20,437 - INFO - [Valid] [41/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 13:47:20,452 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:47:20,453 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:47:20,486 - INFO - [Best Model Saved] (val loss: 0.6920) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:47:20,487 - INFO - --------------------------------------------------
2026-01-14 13:47:20,489 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:47:29,830 - INFO - [Train] [42/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 13:47:32,830 - INFO - [Valid] [42/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 13:47:32,842 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:47:32,843 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:47:32,873 - INFO - [Best Model Saved] (val loss: 0.6920) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:47:32,873 - INFO - --------------------------------------------------
2026-01-14 13:47:32,876 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:47:41,555 - INFO - [Train] [43/90] | Loss: 0.6931 | Train Acc: 51.12%
2026-01-14 13:47:44,466 - INFO - [Valid] [43/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 13:47:44,480 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:47:44,481 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:47:44,486 - INFO - --------------------------------------------------
2026-01-14 13:47:44,488 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:47:52,873 - INFO - [Train] [44/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:47:56,008 - INFO - [Valid] [44/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:47:56,021 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:47:56,021 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:47:56,026 - INFO - --------------------------------------------------
2026-01-14 13:47:56,028 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:48:04,991 - INFO - [Train] [45/90] | Loss: 0.6930 | Train Acc: 51.49%
2026-01-14 13:48:09,432 - INFO - [Valid] [45/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 13:48:09,444 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:48:09,444 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:48:09,449 - INFO - --------------------------------------------------
2026-01-14 13:48:09,451 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:48:19,086 - INFO - [Train] [46/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:48:22,272 - INFO - [Valid] [46/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:48:22,285 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:48:22,286 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:48:22,291 - INFO - --------------------------------------------------
2026-01-14 13:48:22,294 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:48:30,951 - INFO - [Train] [47/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:48:34,277 - INFO - [Valid] [47/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:48:34,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:48:34,308 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:48:34,311 - INFO - --------------------------------------------------
2026-01-14 13:48:34,316 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:48:42,917 - INFO - [Train] [48/90] | Loss: 0.6929 | Train Acc: 51.56%
2026-01-14 13:48:45,468 - INFO - [Valid] [48/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:48:45,493 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:48:45,494 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:48:45,498 - INFO - --------------------------------------------------
2026-01-14 13:48:45,501 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:48:54,494 - INFO - [Train] [49/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:48:56,996 - INFO - [Valid] [49/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:48:57,006 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:48:57,006 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:48:57,010 - INFO - --------------------------------------------------
2026-01-14 13:48:57,012 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:49:07,032 - INFO - [Train] [50/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:49:09,647 - INFO - [Valid] [50/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:49:09,659 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:49:09,660 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:49:09,664 - INFO - --------------------------------------------------
2026-01-14 13:49:09,667 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:49:18,714 - INFO - [Train] [51/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:49:21,191 - INFO - [Valid] [51/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:49:21,212 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:49:21,213 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:49:21,229 - INFO - --------------------------------------------------
2026-01-14 13:49:21,231 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:49:31,324 - INFO - [Train] [52/90] | Loss: 0.6930 | Train Acc: 51.19%
2026-01-14 13:49:33,002 - INFO - [Valid] [52/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:49:33,024 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:49:33,028 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:49:33,032 - INFO - --------------------------------------------------
2026-01-14 13:49:33,042 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:49:43,204 - INFO - [Train] [53/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:49:45,277 - INFO - [Valid] [53/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:49:45,303 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:49:45,304 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:49:45,313 - INFO - --------------------------------------------------
2026-01-14 13:49:45,319 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:49:55,262 - INFO - [Train] [54/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:49:57,395 - INFO - [Valid] [54/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:49:57,421 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:49:57,421 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:49:57,429 - INFO - --------------------------------------------------
2026-01-14 13:49:57,434 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:50:06,997 - INFO - [Train] [55/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:50:09,499 - INFO - [Valid] [55/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:50:09,525 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:50:09,526 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:50:09,529 - INFO - --------------------------------------------------
2026-01-14 13:50:09,531 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:50:20,127 - INFO - [Train] [56/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:50:22,323 - INFO - [Valid] [56/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:50:22,392 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:50:22,393 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:50:22,396 - INFO - --------------------------------------------------
2026-01-14 13:50:22,398 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:50:32,554 - INFO - [Train] [57/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:50:34,602 - INFO - [Valid] [57/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:50:34,619 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:50:34,623 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:50:34,631 - INFO - --------------------------------------------------
2026-01-14 13:50:34,633 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:50:44,385 - INFO - [Train] [58/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:50:46,477 - INFO - [Valid] [58/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:50:46,502 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:50:46,506 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:50:46,511 - INFO - --------------------------------------------------
2026-01-14 13:50:46,521 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:50:56,487 - INFO - [Train] [59/90] | Loss: 0.6931 | Train Acc: 51.19%
2026-01-14 13:50:59,018 - INFO - [Valid] [59/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:50:59,047 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:50:59,047 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:50:59,061 - INFO - --------------------------------------------------
2026-01-14 13:50:59,067 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:51:08,352 - INFO - [Train] [60/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:51:10,418 - INFO - [Valid] [60/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:51:10,431 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:51:10,431 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:51:10,436 - INFO - --------------------------------------------------
2026-01-14 13:51:10,438 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:51:19,747 - INFO - [Train] [61/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:51:22,957 - INFO - [Valid] [61/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:51:22,980 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:51:22,980 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:51:22,984 - INFO - --------------------------------------------------
2026-01-14 13:51:22,986 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:51:31,600 - INFO - [Train] [62/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:51:34,177 - INFO - [Valid] [62/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:51:34,189 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:51:34,190 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:51:34,194 - INFO - --------------------------------------------------
2026-01-14 13:51:34,196 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:51:44,327 - INFO - [Train] [63/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 13:51:47,265 - INFO - [Valid] [63/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:51:47,277 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:51:47,278 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:51:47,282 - INFO - --------------------------------------------------
2026-01-14 13:51:47,284 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:51:56,723 - INFO - [Train] [64/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 13:51:59,432 - INFO - [Valid] [64/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:51:59,455 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:51:59,456 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:51:59,461 - INFO - --------------------------------------------------
2026-01-14 13:51:59,464 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:52:08,538 - INFO - [Train] [65/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 13:52:11,091 - INFO - [Valid] [65/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:52:11,103 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:52:11,104 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:52:11,108 - INFO - --------------------------------------------------
2026-01-14 13:52:11,110 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:52:20,824 - INFO - [Train] [66/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 13:52:23,892 - INFO - [Valid] [66/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:52:23,903 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:52:23,904 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:52:23,908 - INFO - --------------------------------------------------
2026-01-14 13:52:23,910 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:52:32,963 - INFO - [Train] [67/90] | Loss: 0.6931 | Train Acc: 51.19%
2026-01-14 13:52:35,846 - INFO - [Valid] [67/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:52:35,876 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:52:35,879 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:52:35,892 - INFO - --------------------------------------------------
2026-01-14 13:52:35,894 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:52:43,936 - INFO - [Train] [68/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 13:52:47,536 - INFO - [Valid] [68/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:52:47,551 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:52:47,552 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:52:47,557 - INFO - --------------------------------------------------
2026-01-14 13:52:47,560 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:52:56,666 - INFO - [Train] [69/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:53:00,083 - INFO - [Valid] [69/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:53:00,095 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:53:00,095 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:53:00,100 - INFO - --------------------------------------------------
2026-01-14 13:53:00,102 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:53:08,745 - INFO - [Train] [70/90] | Loss: 0.6929 | Train Acc: 51.19%
2026-01-14 13:53:11,329 - INFO - [Valid] [70/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:53:11,341 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:53:11,342 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:53:11,346 - INFO - --------------------------------------------------
2026-01-14 13:53:11,349 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:53:19,393 - INFO - [Train] [71/90] | Loss: 0.6930 | Train Acc: 51.12%
2026-01-14 13:53:22,279 - INFO - [Valid] [71/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:53:22,301 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:53:22,303 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:53:22,307 - INFO - --------------------------------------------------
2026-01-14 13:53:22,309 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:53:31,226 - INFO - [Train] [72/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:53:33,739 - INFO - [Valid] [72/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:53:33,753 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:53:33,753 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:53:33,760 - INFO - --------------------------------------------------
2026-01-14 13:53:33,763 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:53:42,854 - INFO - [Train] [73/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 13:53:45,833 - INFO - [Valid] [73/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:53:45,856 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:53:45,857 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:53:45,867 - INFO - --------------------------------------------------
2026-01-14 13:53:45,873 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:53:55,371 - INFO - [Train] [74/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:53:58,010 - INFO - [Valid] [74/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:53:58,023 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:53:58,024 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:53:58,029 - INFO - --------------------------------------------------
2026-01-14 13:53:58,032 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:54:07,367 - INFO - [Train] [75/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:54:10,281 - INFO - [Valid] [75/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:54:10,293 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:54:10,293 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:54:10,298 - INFO - --------------------------------------------------
2026-01-14 13:54:10,300 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:54:19,491 - INFO - [Train] [76/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:54:21,264 - INFO - [Valid] [76/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:54:21,275 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:54:21,276 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:54:21,279 - INFO - --------------------------------------------------
2026-01-14 13:54:21,281 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:54:30,576 - INFO - [Train] [77/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 13:54:32,905 - INFO - [Valid] [77/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:54:32,917 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:54:32,918 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:54:32,922 - INFO - --------------------------------------------------
2026-01-14 13:54:32,925 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:54:42,623 - INFO - [Train] [78/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:54:45,137 - INFO - [Valid] [78/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:54:45,151 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:54:45,152 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:54:45,158 - INFO - --------------------------------------------------
2026-01-14 13:54:45,160 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:54:54,389 - INFO - [Train] [79/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:54:56,773 - INFO - [Valid] [79/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:54:56,785 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:54:56,786 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:54:56,790 - INFO - --------------------------------------------------
2026-01-14 13:54:56,793 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:55:05,695 - INFO - [Train] [80/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:55:08,642 - INFO - [Valid] [80/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:55:08,652 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:55:08,652 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:55:08,656 - INFO - --------------------------------------------------
2026-01-14 13:55:08,658 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:55:15,577 - INFO - [Train] [81/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 13:55:17,287 - INFO - [Valid] [81/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:55:17,300 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:55:17,300 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:55:17,304 - INFO - --------------------------------------------------
2026-01-14 13:55:17,307 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:55:25,458 - INFO - [Train] [82/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:55:28,356 - INFO - [Valid] [82/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:55:28,369 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:55:28,370 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:55:28,374 - INFO - --------------------------------------------------
2026-01-14 13:55:28,377 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:55:37,699 - INFO - [Train] [83/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 13:55:39,665 - INFO - [Valid] [83/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:55:39,678 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:55:39,678 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:55:39,682 - INFO - --------------------------------------------------
2026-01-14 13:55:39,684 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:55:46,148 - INFO - [Train] [84/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:55:47,829 - INFO - [Valid] [84/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:55:47,841 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:55:47,842 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:55:47,846 - INFO - --------------------------------------------------
2026-01-14 13:55:47,848 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:55:54,014 - INFO - [Train] [85/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:55:55,562 - INFO - [Valid] [85/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:55:55,573 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:55:55,573 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:55:55,576 - INFO - --------------------------------------------------
2026-01-14 13:55:55,577 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:56:01,100 - INFO - [Train] [86/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 13:56:02,678 - INFO - [Valid] [86/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:56:02,695 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:02,696 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:02,706 - INFO - --------------------------------------------------
2026-01-14 13:56:02,711 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:56:08,947 - INFO - [Train] [87/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 13:56:10,496 - INFO - [Valid] [87/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:56:10,508 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:10,509 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:10,513 - INFO - --------------------------------------------------
2026-01-14 13:56:10,516 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:56:15,572 - INFO - [Train] [88/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:56:17,011 - INFO - [Valid] [88/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:56:17,023 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:17,023 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:17,027 - INFO - --------------------------------------------------
2026-01-14 13:56:17,029 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:56:22,029 - INFO - [Train] [89/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:56:23,473 - INFO - [Valid] [89/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 13:56:23,484 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:23,484 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:23,488 - INFO - --------------------------------------------------
2026-01-14 13:56:23,489 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:56:28,304 - INFO - [Train] [90/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 13:56:29,790 - INFO - [Valid] [90/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 13:56:29,802 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:29,802 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:29,808 - INFO - ==================================================
2026-01-14 13:56:29,808 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:56:29,808 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:56:29,808 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:56:30,945 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:56:30,946 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:56:30,948 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:56:30,948 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:56:30,949 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:56:31,389 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 13:56:31,389 - INFO - ==================================================
2026-01-14 13:56:31,438 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/best_model.pth'
2026-01-14 13:56:31,439 - INFO - ==================================================
2026-01-14 13:56:31,439 - INFO - Test 모드를 시작합니다.
2026-01-14 13:56:31,590 - INFO - 연산량 (MACs): 0.0040 GMACs per sample
2026-01-14 13:56:31,591 - INFO - 연산량 (FLOPs): 0.0081 GFLOPs per sample
2026-01-14 13:56:31,591 - INFO - ==================================================
2026-01-14 13:56:31,591 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:56:32,809 - INFO - 샘플 당 평균 Forward Pass 시간: 5.62ms (std: 1.18ms), FPS: 184.61 (std: 32.58) (1개 샘플 x 100회 반복)
2026-01-14 13:56:32,810 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 104.15 MB
2026-01-14 13:56:32,810 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:56:35,115 - INFO - [Test] Loss: 0.6918 | Test Acc: 53.69%
2026-01-14 13:56:35,125 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:35,125 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:35,676 - INFO - ==================================================
2026-01-14 13:56:35,677 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/confusion_matrix_20260114_133826.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/confusion_matrix_20260114_133826.pdf'
2026-01-14 13:56:35,677 - INFO - ==================================================
2026-01-14 13:56:35,677 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:56:37,223 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/model_fp32_20260114_133826.onnx'에 저장되었습니다. (크기: 0.24 MB)
2026-01-14 13:56:37,625 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2379.69 MB (증가량: 1.11 MB)
2026-01-14 13:56:37,625 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:56:39,140 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 8.74ms (std: 2.92ms)
2026-01-14 13:56:39,141 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 123.93 FPS (std: 30.66) (1개 샘플 x 100회 반복)
2026-01-14 13:56:39,141 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2386.08 MB (순수 증가량: 1.50 MB)
2026-01-14 13:56:39,141 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2386.08 MB (전체 증가량: 7.51 MB)
2026-01-14 13:56:44,342 - INFO - [Test (ONNX)] | Test Acc (ONNX): 53.69%
2026-01-14 13:56:44,353 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 13:56:44,353 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 13:56:44,795 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/val_acc.pdf'
2026-01-14 13:56:45,212 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/train_val_acc.pdf'
2026-01-14 13:56:45,552 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/F1_normal.pdf'
2026-01-14 13:56:46,071 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/val_loss.pdf'
2026-01-14 13:56:46,436 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/learning_rate.pdf'
2026-01-14 13:56:50,817 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_fpgm_20260114_133826/graph_20260114_133826/compile.pdf'
