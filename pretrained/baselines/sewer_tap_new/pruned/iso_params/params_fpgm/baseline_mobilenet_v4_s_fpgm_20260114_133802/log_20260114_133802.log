2026-01-14 13:38:02,840 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/log_20260114_133802.log'에 저장됩니다.
2026-01-14 13:38:02,847 - INFO - ==================================================
2026-01-14 13:38:02,847 - INFO - config.yaml:
2026-01-14 13:38:02,847 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobilenet_v4_s
  use_fpgm_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:38:02,848 - INFO - ==================================================
2026-01-14 13:38:02,901 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:38:02,902 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:38:02,902 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:38:02,910 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:38:02,910 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:38:02,911 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:38:02,911 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:38:03,275 - INFO - ==================================================
2026-01-14 13:38:03,275 - INFO - 모델 파라미터 수:
2026-01-14 13:38:03,275 - INFO -   - 총 파라미터: 2,495,586 개
2026-01-14 13:38:03,275 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-01-14 13:38:03,275 - INFO - ================================================================================
2026-01-14 13:38:03,275 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:38:03,275 - INFO - ================================================================================
2026-01-14 13:38:03,275 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:38:03,276 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:38:03,277 - INFO - ==================================================
2026-01-14 13:38:03,277 - INFO - train 모드를 시작합니다.
2026-01-14 13:38:03,277 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:38:03,277 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:38:03,277 - INFO - --------------------------------------------------
2026-01-14 13:38:03,279 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:38:09,739 - INFO - [Train] [1/10] | Loss: 2.8358 | Train Acc: 66.89%
2026-01-14 13:38:12,621 - INFO - [Valid] [1/10] | Loss: 1.8340 | Val Acc: 55.75%
2026-01-14 13:38:12,634 - INFO - [Metrics for 'abnormal'] | Precision: 0.7059 | Recall: 0.0764 | F1: 0.1379
2026-01-14 13:38:12,634 - INFO - [Metrics for 'normal'] | Precision: 0.5497 | Recall: 0.9725 | F1: 0.7024
2026-01-14 13:38:12,675 - INFO - [Best Model Saved] (val loss: 1.8340) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:38:12,675 - INFO - --------------------------------------------------
2026-01-14 13:38:12,677 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:38:18,418 - INFO - [Train] [2/10] | Loss: 0.6808 | Train Acc: 73.59%
2026-01-14 13:38:20,374 - INFO - [Valid] [2/10] | Loss: 0.7685 | Val Acc: 61.36%
2026-01-14 13:38:20,385 - INFO - [Metrics for 'abnormal'] | Precision: 0.5699 | Recall: 0.6752 | F1: 0.6181
2026-01-14 13:38:20,386 - INFO - [Metrics for 'normal'] | Precision: 0.6667 | Recall: 0.5604 | F1: 0.6090
2026-01-14 13:38:20,443 - INFO - [Best Model Saved] (val loss: 0.7685) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:38:20,444 - INFO - --------------------------------------------------
2026-01-14 13:38:20,445 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:38:26,957 - INFO - [Train] [3/10] | Loss: 0.7337 | Train Acc: 70.01%
2026-01-14 13:38:29,164 - INFO - [Valid] [3/10] | Loss: 0.9074 | Val Acc: 63.72%
2026-01-14 13:38:29,174 - INFO - [Metrics for 'abnormal'] | Precision: 0.6441 | Recall: 0.4841 | F1: 0.5527
2026-01-14 13:38:29,174 - INFO - [Metrics for 'normal'] | Precision: 0.6335 | Recall: 0.7692 | F1: 0.6948
2026-01-14 13:38:29,178 - INFO - --------------------------------------------------
2026-01-14 13:38:29,180 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:38:36,732 - INFO - [Train] [4/10] | Loss: 0.6416 | Train Acc: 74.70%
2026-01-14 13:38:38,702 - INFO - [Valid] [4/10] | Loss: 1.1089 | Val Acc: 71.09%
2026-01-14 13:38:38,713 - INFO - [Metrics for 'abnormal'] | Precision: 0.8831 | Recall: 0.4331 | F1: 0.5812
2026-01-14 13:38:38,714 - INFO - [Metrics for 'normal'] | Precision: 0.6603 | Recall: 0.9505 | F1: 0.7793
2026-01-14 13:38:38,719 - INFO - --------------------------------------------------
2026-01-14 13:38:38,722 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:38:47,155 - INFO - [Train] [5/10] | Loss: 0.6056 | Train Acc: 75.45%
2026-01-14 13:38:50,162 - INFO - [Valid] [5/10] | Loss: 0.8064 | Val Acc: 69.32%
2026-01-14 13:38:50,200 - INFO - [Metrics for 'abnormal'] | Precision: 0.6118 | Recall: 0.9236 | F1: 0.7360
2026-01-14 13:38:50,204 - INFO - [Metrics for 'normal'] | Precision: 0.8824 | Recall: 0.4945 | F1: 0.6338
2026-01-14 13:38:50,211 - INFO - --------------------------------------------------
2026-01-14 13:38:50,218 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:38:59,560 - INFO - [Train] [6/10] | Loss: 0.5363 | Train Acc: 79.54%
2026-01-14 13:39:03,776 - INFO - [Valid] [6/10] | Loss: 0.5816 | Val Acc: 77.88%
2026-01-14 13:39:03,802 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.7389 | F1: 0.7557
2026-01-14 13:39:03,802 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.8132 | F1: 0.7978
2026-01-14 13:39:03,911 - INFO - [Best Model Saved] (val loss: 0.5816) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:39:03,913 - INFO - --------------------------------------------------
2026-01-14 13:39:03,915 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:39:12,863 - INFO - [Train] [7/10] | Loss: 0.5184 | Train Acc: 80.43%
2026-01-14 13:39:16,062 - INFO - [Valid] [7/10] | Loss: 0.5221 | Val Acc: 82.01%
2026-01-14 13:39:16,087 - INFO - [Metrics for 'abnormal'] | Precision: 0.8077 | Recall: 0.8025 | F1: 0.8051
2026-01-14 13:39:16,090 - INFO - [Metrics for 'normal'] | Precision: 0.8306 | Recall: 0.8352 | F1: 0.8329
2026-01-14 13:39:16,186 - INFO - [Best Model Saved] (val loss: 0.5221) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:39:16,186 - INFO - --------------------------------------------------
2026-01-14 13:39:16,189 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:39:24,160 - INFO - [Train] [8/10] | Loss: 0.5071 | Train Acc: 80.51%
2026-01-14 13:39:26,371 - INFO - [Valid] [8/10] | Loss: 0.5351 | Val Acc: 78.47%
2026-01-14 13:39:26,382 - INFO - [Metrics for 'abnormal'] | Precision: 0.7593 | Recall: 0.7834 | F1: 0.7712
2026-01-14 13:39:26,382 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.7857 | F1: 0.7967
2026-01-14 13:39:26,387 - INFO - --------------------------------------------------
2026-01-14 13:39:26,390 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:39:33,725 - INFO - [Train] [9/10] | Loss: 0.4666 | Train Acc: 82.81%
2026-01-14 13:39:35,831 - INFO - [Valid] [9/10] | Loss: 0.5332 | Val Acc: 78.76%
2026-01-14 13:39:35,843 - INFO - [Metrics for 'abnormal'] | Precision: 0.8102 | Recall: 0.7070 | F1: 0.7551
2026-01-14 13:39:35,844 - INFO - [Metrics for 'normal'] | Precision: 0.7723 | Recall: 0.8571 | F1: 0.8125
2026-01-14 13:39:35,849 - INFO - --------------------------------------------------
2026-01-14 13:39:35,852 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:39:42,783 - INFO - [Train] [10/10] | Loss: 0.4479 | Train Acc: 83.71%
2026-01-14 13:39:45,683 - INFO - [Valid] [10/10] | Loss: 0.5278 | Val Acc: 79.35%
2026-01-14 13:39:45,720 - INFO - [Metrics for 'abnormal'] | Precision: 0.7669 | Recall: 0.7962 | F1: 0.7812
2026-01-14 13:39:45,720 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.7912 | F1: 0.8045
2026-01-14 13:39:45,727 - INFO - ================================================================================
2026-01-14 13:39:45,729 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:39:45,729 - INFO - ================================================================================
2026-01-14 13:39:46,146 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:39:46,151 - INFO - ================================================================================
2026-01-14 13:39:46,151 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:39:46,153 - INFO - 원본 모델 파라미터: 2.4956M
2026-01-14 13:39:46,314 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:46,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:46,755 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:39:46,756 - INFO - ==================================================
2026-01-14 13:39:46,757 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.6554M (감소율: 73.74%)
2026-01-14 13:39:46,796 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:46,796 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:47,051 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:47,052 - INFO - ==================================================
2026-01-14 13:39:47,054 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1807M (감소율: 92.76%)
2026-01-14 13:39:47,111 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:47,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:47,339 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:39:47,340 - INFO - ==================================================
2026-01-14 13:39:47,341 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0548M (감소율: 97.80%)
2026-01-14 13:39:47,387 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:47,388 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:47,549 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:39:47,549 - INFO - ==================================================
2026-01-14 13:39:47,551 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0186M (감소율: 99.25%)
2026-01-14 13:39:47,606 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:47,607 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:48,370 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 13:39:48,371 - INFO - ==================================================
2026-01-14 13:39:48,373 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0343M (감소율: 98.63%)
2026-01-14 13:39:48,431 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:48,432 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:48,711 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 13:39:48,712 - INFO - ==================================================
2026-01-14 13:39:48,714 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0259M (감소율: 98.96%)
2026-01-14 13:39:48,767 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:48,768 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:49,001 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 13:39:49,002 - INFO - ==================================================
2026-01-14 13:39:49,004 - INFO -   [탐색  7] 희소도: 0.9049 -> 파라미터: 0.0304M (감소율: 98.78%)
2026-01-14 13:39:49,061 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:49,062 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:49,346 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9010546875000001)에 맞춰 변경되었습니다.
2026-01-14 13:39:49,346 - INFO - ==================================================
2026-01-14 13:39:49,348 - INFO -   [탐색  8] 희소도: 0.9011 -> 파라미터: 0.0317M (감소율: 98.73%)
2026-01-14 13:39:49,389 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:49,390 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:49,960 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9029882812500001)에 맞춰 변경되었습니다.
2026-01-14 13:39:49,960 - INFO - ==================================================
2026-01-14 13:39:49,963 - INFO -   [탐색  9] 희소도: 0.9030 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:50,013 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:50,013 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:50,277 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9020214843750001)에 맞춰 변경되었습니다.
2026-01-14 13:39:50,278 - INFO - ==================================================
2026-01-14 13:39:50,280 - INFO -   [탐색 10] 희소도: 0.9020 -> 파라미터: 0.0316M (감소율: 98.73%)
2026-01-14 13:39:50,325 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:50,326 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:50,485 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 13:39:50,486 - INFO - ==================================================
2026-01-14 13:39:50,488 - INFO -   [탐색 11] 희소도: 0.9025 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:50,527 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:50,528 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:50,697 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90226318359375)에 맞춰 변경되었습니다.
2026-01-14 13:39:50,697 - INFO - ==================================================
2026-01-14 13:39:50,699 - INFO -   [탐색 12] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:50,747 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:50,747 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:50,964 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902384033203125)에 맞춰 변경되었습니다.
2026-01-14 13:39:50,965 - INFO - ==================================================
2026-01-14 13:39:50,968 - INFO -   [탐색 13] 희소도: 0.9024 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:51,033 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:51,034 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:51,332 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023236083984375)에 맞춰 변경되었습니다.
2026-01-14 13:39:51,333 - INFO - ==================================================
2026-01-14 13:39:51,336 - INFO -   [탐색 14] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:51,395 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:51,395 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:51,623 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023538208007813)에 맞춰 변경되었습니다.
2026-01-14 13:39:51,623 - INFO - ==================================================
2026-01-14 13:39:51,625 - INFO -   [탐색 15] 희소도: 0.9024 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:51,705 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:51,706 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:51,888 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023387145996093)에 맞춰 변경되었습니다.
2026-01-14 13:39:51,888 - INFO - ==================================================
2026-01-14 13:39:51,891 - INFO -   [탐색 16] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:51,940 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:51,941 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:52,250 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023462677001953)에 맞춰 변경되었습니다.
2026-01-14 13:39:52,250 - INFO - ==================================================
2026-01-14 13:39:52,251 - INFO -   [탐색 17] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:52,293 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:52,294 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:52,483 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023424911499023)에 맞춰 변경되었습니다.
2026-01-14 13:39:52,483 - INFO - ==================================================
2026-01-14 13:39:52,485 - INFO -   [탐색 18] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:52,523 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:52,524 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:52,703 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023443794250487)에 맞춰 변경되었습니다.
2026-01-14 13:39:52,704 - INFO - ==================================================
2026-01-14 13:39:52,705 - INFO -   [탐색 19] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:52,745 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:52,745 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:52,949 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023434352874755)에 맞춰 변경되었습니다.
2026-01-14 13:39:52,950 - INFO - ==================================================
2026-01-14 13:39:52,952 - INFO -   [탐색 20] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:53,007 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:53,008 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:54,058 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023439073562621)에 맞춰 변경되었습니다.
2026-01-14 13:39:54,059 - INFO - ==================================================
2026-01-14 13:39:54,062 - INFO -   [탐색 21] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:54,142 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:54,142 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:54,504 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023436713218689)에 맞춰 변경되었습니다.
2026-01-14 13:39:54,504 - INFO - ==================================================
2026-01-14 13:39:54,507 - INFO -   [탐색 22] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:54,567 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:54,568 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:54,898 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437893390656)에 맞춰 변경되었습니다.
2026-01-14 13:39:54,898 - INFO - ==================================================
2026-01-14 13:39:54,901 - INFO -   [탐색 23] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:54,953 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:54,953 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:55,232 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437303304672)에 맞춰 변경되었습니다.
2026-01-14 13:39:55,233 - INFO - ==================================================
2026-01-14 13:39:55,235 - INFO -   [탐색 24] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:55,290 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:55,291 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:55,485 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437598347663)에 맞춰 변경되었습니다.
2026-01-14 13:39:55,486 - INFO - ==================================================
2026-01-14 13:39:55,487 - INFO -   [탐색 25] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:55,572 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:55,573 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:55,924 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437450826168)에 맞춰 변경되었습니다.
2026-01-14 13:39:55,925 - INFO - ==================================================
2026-01-14 13:39:55,926 - INFO -   [탐색 26] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:55,959 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:55,959 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:56,179 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437524586916)에 맞춰 변경되었습니다.
2026-01-14 13:39:56,179 - INFO - ==================================================
2026-01-14 13:39:56,182 - INFO -   [탐색 27] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:56,220 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:56,221 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:56,579 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437487706543)에 맞춰 변경되었습니다.
2026-01-14 13:39:56,580 - INFO - ==================================================
2026-01-14 13:39:56,582 - INFO -   [탐색 28] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:56,624 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:56,625 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:56,856 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343750614673)에 맞춰 변경되었습니다.
2026-01-14 13:39:56,856 - INFO - ==================================================
2026-01-14 13:39:56,857 - INFO -   [탐색 29] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:56,889 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:56,890 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,078 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437496926636)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,078 - INFO - ==================================================
2026-01-14 13:39:57,080 - INFO -   [탐색 30] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:57,126 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,126 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,324 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437501536683)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,324 - INFO - ==================================================
2026-01-14 13:39:57,326 - INFO -   [탐색 31] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:57,365 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,366 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,928 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499231659)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,928 - INFO - ==================================================
2026-01-14 13:39:57,931 - INFO -   [탐색 32] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:57,970 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,970 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,130 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343750038417)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,131 - INFO - ==================================================
2026-01-14 13:39:58,132 - INFO -   [탐색 33] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:58,171 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,172 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,314 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499807915)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,315 - INFO - ==================================================
2026-01-14 13:39:58,316 - INFO -   [탐색 34] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:58,355 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,356 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,539 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500096043)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,540 - INFO - ==================================================
2026-01-14 13:39:58,542 - INFO -   [탐색 35] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:58,580 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,580 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,748 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499951978)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,748 - INFO - ==================================================
2026-01-14 13:39:58,751 - INFO -   [탐색 36] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:58,803 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,803 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,008 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500024011)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,009 - INFO - ==================================================
2026-01-14 13:39:59,012 - INFO -   [탐색 37] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:59,056 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,057 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,344 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499987994)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,345 - INFO - ==================================================
2026-01-14 13:39:59,351 - INFO -   [탐색 38] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:59,462 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,467 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500006002)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,669 - INFO - ==================================================
2026-01-14 13:39:59,671 - INFO -   [탐색 39] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:39:59,725 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,726 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,885 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499996998)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,886 - INFO - ==================================================
2026-01-14 13:39:59,888 - INFO -   [탐색 40] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:39:59,928 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:00,111 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375000015)에 맞춰 변경되었습니다.
2026-01-14 13:40:00,112 - INFO - ==================================================
2026-01-14 13:40:00,114 - INFO -   [탐색 41] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:00,211 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:00,213 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:00,553 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343749999925)에 맞춰 변경되었습니다.
2026-01-14 13:40:00,554 - INFO - ==================================================
2026-01-14 13:40:00,555 - INFO -   [탐색 42] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:00,592 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:00,592 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:01,361 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000375)에 맞춰 변경되었습니다.
2026-01-14 13:40:01,362 - INFO - ==================================================
2026-01-14 13:40:01,365 - INFO -   [탐색 43] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:01,424 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:01,425 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:01,752 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999812)에 맞춰 변경되었습니다.
2026-01-14 13:40:01,753 - INFO - ==================================================
2026-01-14 13:40:01,755 - INFO -   [탐색 44] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:01,810 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:01,811 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,121 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000093)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,121 - INFO - ==================================================
2026-01-14 13:40:02,123 - INFO -   [탐색 45] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:02,161 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,162 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,518 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999953)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,520 - INFO - ==================================================
2026-01-14 13:40:02,522 - INFO -   [탐색 46] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:02,576 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,577 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,922 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000023)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,922 - INFO - ==================================================
2026-01-14 13:40:02,924 - INFO -   [탐색 47] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:02,977 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,977 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,272 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999989)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,272 - INFO - ==================================================
2026-01-14 13:40:03,274 - INFO -   [탐색 48] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:03,306 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,306 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,532 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000007)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,532 - INFO - ==================================================
2026-01-14 13:40:03,534 - INFO -   [탐색 49] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:03,574 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,574 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,771 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999998)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,772 - INFO - ==================================================
2026-01-14 13:40:03,774 - INFO -   [탐색 50] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:03,826 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,827 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,076 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000002)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,077 - INFO - ==================================================
2026-01-14 13:40:04,079 - INFO -   [탐색 51] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:04,130 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,131 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,354 - INFO - ==================================================
2026-01-14 13:40:04,356 - INFO -   [탐색 52] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:04,408 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,408 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,667 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000001)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,668 - INFO - ==================================================
2026-01-14 13:40:04,671 - INFO -   [탐색 53] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 13:40:04,729 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,729 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,931 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,931 - INFO - ==================================================
2026-01-14 13:40:04,933 - INFO -   [탐색 54] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:04,972 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,972 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,570 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,571 - INFO - ==================================================
2026-01-14 13:40:05,574 - INFO -   [탐색 55] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:05,628 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:05,630 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,775 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,776 - INFO - ==================================================
2026-01-14 13:40:05,777 - INFO -   [탐색 56] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:05,816 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:05,817 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,964 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,965 - INFO - ==================================================
2026-01-14 13:40:05,967 - INFO -   [탐색 57] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:06,005 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,006 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,181 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,181 - INFO - ==================================================
2026-01-14 13:40:06,183 - INFO -   [탐색 58] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:06,221 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,221 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,451 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,452 - INFO - ==================================================
2026-01-14 13:40:06,454 - INFO -   [탐색 59] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:06,507 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,744 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,745 - INFO - ==================================================
2026-01-14 13:40:06,747 - INFO -   [탐색 60] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:06,789 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,789 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,974 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,974 - INFO - ==================================================
2026-01-14 13:40:06,977 - INFO -   [탐색 61] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:07,016 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,017 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,242 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,243 - INFO - ==================================================
2026-01-14 13:40:07,245 - INFO -   [탐색 62] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:07,286 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,287 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,552 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,552 - INFO - ==================================================
2026-01-14 13:40:07,554 - INFO -   [탐색 63] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:07,641 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,642 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,931 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,931 - INFO - ==================================================
2026-01-14 13:40:07,932 - INFO -   [탐색 64] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:07,975 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,975 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:08,152 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:08,153 - INFO - ==================================================
2026-01-14 13:40:08,154 - INFO -   [탐색 65] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:08,193 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:08,194 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:08,535 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:08,535 - INFO - ==================================================
2026-01-14 13:40:08,538 - INFO -   [탐색 66] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:08,592 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:08,593 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:08,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:08,906 - INFO - ==================================================
2026-01-14 13:40:08,908 - INFO -   [탐색 67] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:08,951 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:08,951 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:09,135 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:09,137 - INFO - ==================================================
2026-01-14 13:40:09,139 - INFO -   [탐색 68] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:09,621 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:09,622 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:09,947 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:09,947 - INFO - ==================================================
2026-01-14 13:40:09,950 - INFO -   [탐색 69] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:09,981 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:09,981 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,249 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,250 - INFO - ==================================================
2026-01-14 13:40:10,251 - INFO -   [탐색 70] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:10,288 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:10,288 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,629 - INFO - ==================================================
2026-01-14 13:40:10,631 - INFO -   [탐색 71] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:10,687 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:10,687 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,962 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,962 - INFO - ==================================================
2026-01-14 13:40:10,964 - INFO -   [탐색 72] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:11,006 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,006 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,227 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,227 - INFO - ==================================================
2026-01-14 13:40:11,231 - INFO -   [탐색 73] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:11,284 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,285 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,541 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,541 - INFO - ==================================================
2026-01-14 13:40:11,545 - INFO -   [탐색 74] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:11,598 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,599 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,909 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,909 - INFO - ==================================================
2026-01-14 13:40:11,911 - INFO -   [탐색 75] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:11,949 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,950 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,105 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,105 - INFO - ==================================================
2026-01-14 13:40:12,107 - INFO -   [탐색 76] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:12,145 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,146 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,278 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,279 - INFO - ==================================================
2026-01-14 13:40:12,281 - INFO -   [탐색 77] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:12,320 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,320 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,480 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,480 - INFO - ==================================================
2026-01-14 13:40:12,482 - INFO -   [탐색 78] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:12,525 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,526 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,692 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,692 - INFO - ==================================================
2026-01-14 13:40:12,694 - INFO -   [탐색 79] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:12,725 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,725 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,917 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,917 - INFO - ==================================================
2026-01-14 13:40:12,919 - INFO -   [탐색 80] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:12,970 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,970 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,171 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,171 - INFO - ==================================================
2026-01-14 13:40:13,173 - INFO -   [탐색 81] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:13,217 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,218 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,745 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,746 - INFO - ==================================================
2026-01-14 13:40:13,749 - INFO -   [탐색 82] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:13,786 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,787 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,971 - INFO - ==================================================
2026-01-14 13:40:13,973 - INFO -   [탐색 83] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:14,010 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,011 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,173 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,174 - INFO - ==================================================
2026-01-14 13:40:14,176 - INFO -   [탐색 84] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:14,213 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,214 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,435 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,435 - INFO - ==================================================
2026-01-14 13:40:14,437 - INFO -   [탐색 85] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:14,496 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,496 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,707 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,707 - INFO - ==================================================
2026-01-14 13:40:14,710 - INFO -   [탐색 86] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:14,764 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,765 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,973 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,974 - INFO - ==================================================
2026-01-14 13:40:14,977 - INFO -   [탐색 87] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:15,030 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,031 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,209 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,210 - INFO - ==================================================
2026-01-14 13:40:15,212 - INFO -   [탐색 88] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:15,246 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,246 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,462 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,463 - INFO - ==================================================
2026-01-14 13:40:15,465 - INFO -   [탐색 89] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:15,516 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,517 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,778 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,778 - INFO - ==================================================
2026-01-14 13:40:15,780 - INFO -   [탐색 90] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:15,831 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,831 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,056 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,057 - INFO - ==================================================
2026-01-14 13:40:16,058 - INFO -   [탐색 91] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:16,095 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,095 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,307 - INFO - ==================================================
2026-01-14 13:40:16,308 - INFO -   [탐색 92] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:16,343 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,343 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,535 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,535 - INFO - ==================================================
2026-01-14 13:40:16,537 - INFO -   [탐색 93] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:16,569 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,569 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,761 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,761 - INFO - ==================================================
2026-01-14 13:40:16,762 - INFO -   [탐색 94] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:17,074 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,075 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,301 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,301 - INFO - ==================================================
2026-01-14 13:40:17,304 - INFO -   [탐색 95] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:17,348 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,348 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,569 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,569 - INFO - ==================================================
2026-01-14 13:40:17,572 - INFO -   [탐색 96] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:17,622 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,623 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,786 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,786 - INFO - ==================================================
2026-01-14 13:40:17,788 - INFO -   [탐색 97] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:17,841 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,842 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:18,031 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:18,031 - INFO - ==================================================
2026-01-14 13:40:18,034 - INFO -   [탐색 98] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:18,073 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:18,073 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:18,274 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:18,274 - INFO - ==================================================
2026-01-14 13:40:18,276 - INFO -   [탐색 99] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:18,328 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:18,328 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:18,606 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 13:40:18,606 - INFO - ==================================================
2026-01-14 13:40:18,609 - INFO -   [탐색 100] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 13:40:18,610 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9025 입니다.
2026-01-14 13:40:18,610 - INFO - ================================================================================
2026-01-14 13:40:18,615 - INFO - 계산된 Pruning 정보(희소도: 0.9025)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:40:18,666 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:40:18,792 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:18,793 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 13:40:19,047 - INFO - ==================================================
2026-01-14 13:40:19,050 - INFO - ==================================================
2026-01-14 13:40:19,051 - INFO - 모델 파라미터 수:
2026-01-14 13:40:19,051 - INFO -   - 총 파라미터: 31,233 개
2026-01-14 13:40:19,051 - INFO -   - 학습 가능한 파라미터: 31,233 개
2026-01-14 13:40:19,155 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:40:19,283 - INFO - FLOPs가 0.3853 GFLOPs에서 0.0077 GFLOPs로 감소했습니다 (감소율: 97.99%).
2026-01-14 13:40:19,284 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:40:19,284 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:40:19,286 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:40:19,287 - INFO - ==================================================
2026-01-14 13:40:19,287 - INFO - train 모드를 시작합니다.
2026-01-14 13:40:19,287 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:40:19,288 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:40:19,288 - INFO - --------------------------------------------------
2026-01-14 13:40:19,290 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:40:24,121 - INFO - [Train] [11/90] | Loss: 0.8009 | Train Acc: 63.39%
2026-01-14 13:40:25,640 - INFO - [Valid] [11/90] | Loss: 0.6370 | Val Acc: 67.85%
2026-01-14 13:40:25,654 - INFO - [Metrics for 'abnormal'] | Precision: 0.6333 | Recall: 0.7261 | F1: 0.6766
2026-01-14 13:40:25,654 - INFO - [Metrics for 'normal'] | Precision: 0.7296 | Recall: 0.6374 | F1: 0.6804
2026-01-14 13:40:25,697 - INFO - [Best Model Saved] (val loss: 0.6370) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:40:25,697 - INFO - --------------------------------------------------
2026-01-14 13:40:25,700 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:40:30,753 - INFO - [Train] [12/90] | Loss: 0.5967 | Train Acc: 72.32%
2026-01-14 13:40:32,255 - INFO - [Valid] [12/90] | Loss: 0.6157 | Val Acc: 64.60%
2026-01-14 13:40:32,265 - INFO - [Metrics for 'abnormal'] | Precision: 0.5761 | Recall: 0.8917 | F1: 0.7000
2026-01-14 13:40:32,266 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.4341 | F1: 0.5683
2026-01-14 13:40:32,297 - INFO - [Best Model Saved] (val loss: 0.6157) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:40:32,298 - INFO - --------------------------------------------------
2026-01-14 13:40:32,300 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:40:37,566 - INFO - [Train] [13/90] | Loss: 0.5918 | Train Acc: 72.02%
2026-01-14 13:40:39,221 - INFO - [Valid] [13/90] | Loss: 0.6985 | Val Acc: 61.65%
2026-01-14 13:40:39,232 - INFO - [Metrics for 'abnormal'] | Precision: 0.5605 | Recall: 0.7962 | F1: 0.6579
2026-01-14 13:40:39,232 - INFO - [Metrics for 'normal'] | Precision: 0.7241 | Recall: 0.4615 | F1: 0.5638
2026-01-14 13:40:39,237 - INFO - --------------------------------------------------
2026-01-14 13:40:39,240 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:40:44,127 - INFO - [Train] [14/90] | Loss: 0.5739 | Train Acc: 72.17%
2026-01-14 13:40:45,643 - INFO - [Valid] [14/90] | Loss: 1.0213 | Val Acc: 54.28%
2026-01-14 13:40:45,656 - INFO - [Metrics for 'abnormal'] | Precision: 0.5033 | Recall: 0.9745 | F1: 0.6638
2026-01-14 13:40:45,656 - INFO - [Metrics for 'normal'] | Precision: 0.8857 | Recall: 0.1703 | F1: 0.2857
2026-01-14 13:40:45,661 - INFO - --------------------------------------------------
2026-01-14 13:40:45,664 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:40:50,691 - INFO - [Train] [15/90] | Loss: 0.5473 | Train Acc: 75.74%
2026-01-14 13:40:52,134 - INFO - [Valid] [15/90] | Loss: 0.5578 | Val Acc: 73.75%
2026-01-14 13:40:52,157 - INFO - [Metrics for 'abnormal'] | Precision: 0.7048 | Recall: 0.7452 | F1: 0.7245
2026-01-14 13:40:52,157 - INFO - [Metrics for 'normal'] | Precision: 0.7688 | Recall: 0.7308 | F1: 0.7493
2026-01-14 13:40:52,197 - INFO - [Best Model Saved] (val loss: 0.5578) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:40:52,198 - INFO - --------------------------------------------------
2026-01-14 13:40:52,200 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:40:57,347 - INFO - [Train] [16/90] | Loss: 0.5606 | Train Acc: 74.70%
2026-01-14 13:40:58,999 - INFO - [Valid] [16/90] | Loss: 0.5558 | Val Acc: 73.75%
2026-01-14 13:40:59,010 - INFO - [Metrics for 'abnormal'] | Precision: 0.7698 | Recall: 0.6178 | F1: 0.6855
2026-01-14 13:40:59,010 - INFO - [Metrics for 'normal'] | Precision: 0.7183 | Recall: 0.8407 | F1: 0.7747
2026-01-14 13:40:59,054 - INFO - [Best Model Saved] (val loss: 0.5558) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:40:59,055 - INFO - --------------------------------------------------
2026-01-14 13:40:59,057 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:41:05,359 - INFO - [Train] [17/90] | Loss: 0.5483 | Train Acc: 74.93%
2026-01-14 13:41:07,127 - INFO - [Valid] [17/90] | Loss: 0.5524 | Val Acc: 74.93%
2026-01-14 13:41:07,138 - INFO - [Metrics for 'abnormal'] | Precision: 0.7338 | Recall: 0.7197 | F1: 0.7267
2026-01-14 13:41:07,139 - INFO - [Metrics for 'normal'] | Precision: 0.7622 | Recall: 0.7747 | F1: 0.7684
2026-01-14 13:41:07,178 - INFO - [Best Model Saved] (val loss: 0.5524) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:41:07,179 - INFO - --------------------------------------------------
2026-01-14 13:41:07,182 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:41:13,684 - INFO - [Train] [18/90] | Loss: 0.5265 | Train Acc: 78.20%
2026-01-14 13:41:15,295 - INFO - [Valid] [18/90] | Loss: 0.5984 | Val Acc: 71.98%
2026-01-14 13:41:15,305 - INFO - [Metrics for 'abnormal'] | Precision: 0.6667 | Recall: 0.7898 | F1: 0.7230
2026-01-14 13:41:15,305 - INFO - [Metrics for 'normal'] | Precision: 0.7843 | Recall: 0.6593 | F1: 0.7164
2026-01-14 13:41:15,309 - INFO - --------------------------------------------------
2026-01-14 13:41:15,311 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:41:21,963 - INFO - [Train] [19/90] | Loss: 0.5257 | Train Acc: 77.60%
2026-01-14 13:41:24,359 - INFO - [Valid] [19/90] | Loss: 0.5752 | Val Acc: 75.52%
2026-01-14 13:41:24,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7284 | Recall: 0.7516 | F1: 0.7398
2026-01-14 13:41:24,375 - INFO - [Metrics for 'normal'] | Precision: 0.7797 | Recall: 0.7582 | F1: 0.7688
2026-01-14 13:41:24,379 - INFO - --------------------------------------------------
2026-01-14 13:41:24,382 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:41:31,871 - INFO - [Train] [20/90] | Loss: 0.5206 | Train Acc: 78.79%
2026-01-14 13:41:34,334 - INFO - [Valid] [20/90] | Loss: 0.5429 | Val Acc: 75.22%
2026-01-14 13:41:34,349 - INFO - [Metrics for 'abnormal'] | Precision: 0.7267 | Recall: 0.7452 | F1: 0.7358
2026-01-14 13:41:34,349 - INFO - [Metrics for 'normal'] | Precision: 0.7753 | Recall: 0.7582 | F1: 0.7667
2026-01-14 13:41:34,395 - INFO - [Best Model Saved] (val loss: 0.5429) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:41:34,395 - INFO - --------------------------------------------------
2026-01-14 13:41:34,398 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:41:41,376 - INFO - [Train] [21/90] | Loss: 0.5160 | Train Acc: 79.17%
2026-01-14 13:41:43,479 - INFO - [Valid] [21/90] | Loss: 0.5508 | Val Acc: 76.99%
2026-01-14 13:41:43,493 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.7325 | F1: 0.7468
2026-01-14 13:41:43,494 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8022 | F1: 0.7892
2026-01-14 13:41:43,498 - INFO - --------------------------------------------------
2026-01-14 13:41:43,501 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:41:50,492 - INFO - [Train] [22/90] | Loss: 0.5087 | Train Acc: 79.91%
2026-01-14 13:41:52,989 - INFO - [Valid] [22/90] | Loss: 0.5396 | Val Acc: 76.11%
2026-01-14 13:41:53,002 - INFO - [Metrics for 'abnormal'] | Precision: 0.7184 | Recall: 0.7962 | F1: 0.7553
2026-01-14 13:41:53,002 - INFO - [Metrics for 'normal'] | Precision: 0.8061 | Recall: 0.7308 | F1: 0.7666
2026-01-14 13:41:53,073 - INFO - [Best Model Saved] (val loss: 0.5396) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:41:53,073 - INFO - --------------------------------------------------
2026-01-14 13:41:53,076 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:42:01,559 - INFO - [Train] [23/90] | Loss: 0.5025 | Train Acc: 79.91%
2026-01-14 13:42:03,714 - INFO - [Valid] [23/90] | Loss: 0.5825 | Val Acc: 76.40%
2026-01-14 13:42:03,732 - INFO - [Metrics for 'abnormal'] | Precision: 0.7016 | Recall: 0.8535 | F1: 0.7701
2026-01-14 13:42:03,733 - INFO - [Metrics for 'normal'] | Precision: 0.8446 | Recall: 0.6868 | F1: 0.7576
2026-01-14 13:42:03,738 - INFO - --------------------------------------------------
2026-01-14 13:42:03,740 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:42:12,247 - INFO - [Train] [24/90] | Loss: 0.5059 | Train Acc: 79.46%
2026-01-14 13:42:15,173 - INFO - [Valid] [24/90] | Loss: 0.5766 | Val Acc: 74.93%
2026-01-14 13:42:15,198 - INFO - [Metrics for 'abnormal'] | Precision: 0.7169 | Recall: 0.7580 | F1: 0.7368
2026-01-14 13:42:15,199 - INFO - [Metrics for 'normal'] | Precision: 0.7803 | Recall: 0.7418 | F1: 0.7606
2026-01-14 13:42:15,206 - INFO - --------------------------------------------------
2026-01-14 13:42:15,214 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:42:23,527 - INFO - [Train] [25/90] | Loss: 0.5023 | Train Acc: 79.32%
2026-01-14 13:42:26,958 - INFO - [Valid] [25/90] | Loss: 0.5396 | Val Acc: 78.76%
2026-01-14 13:42:26,971 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-01-14 13:42:26,972 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-01-14 13:42:26,977 - INFO - --------------------------------------------------
2026-01-14 13:42:26,980 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:42:35,035 - INFO - [Train] [26/90] | Loss: 0.4800 | Train Acc: 81.62%
2026-01-14 13:42:38,254 - INFO - [Valid] [26/90] | Loss: 0.5668 | Val Acc: 75.52%
2026-01-14 13:42:38,276 - INFO - [Metrics for 'abnormal'] | Precision: 0.8033 | Recall: 0.6242 | F1: 0.7025
2026-01-14 13:42:38,276 - INFO - [Metrics for 'normal'] | Precision: 0.7281 | Recall: 0.8681 | F1: 0.7920
2026-01-14 13:42:38,285 - INFO - --------------------------------------------------
2026-01-14 13:42:38,290 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:42:45,957 - INFO - [Train] [27/90] | Loss: 0.4909 | Train Acc: 80.95%
2026-01-14 13:42:48,957 - INFO - [Valid] [27/90] | Loss: 0.5603 | Val Acc: 76.99%
2026-01-14 13:42:48,969 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.7261 | F1: 0.7451
2026-01-14 13:42:48,970 - INFO - [Metrics for 'normal'] | Precision: 0.7737 | Recall: 0.8077 | F1: 0.7903
2026-01-14 13:42:48,974 - INFO - --------------------------------------------------
2026-01-14 13:42:48,977 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:42:57,621 - INFO - [Train] [28/90] | Loss: 0.4861 | Train Acc: 81.03%
2026-01-14 13:43:00,344 - INFO - [Valid] [28/90] | Loss: 0.5688 | Val Acc: 77.58%
2026-01-14 13:43:00,358 - INFO - [Metrics for 'abnormal'] | Precision: 0.8045 | Recall: 0.6815 | F1: 0.7379
2026-01-14 13:43:00,359 - INFO - [Metrics for 'normal'] | Precision: 0.7573 | Recall: 0.8571 | F1: 0.8041
2026-01-14 13:43:00,363 - INFO - --------------------------------------------------
2026-01-14 13:43:00,366 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:43:10,067 - INFO - [Train] [29/90] | Loss: 0.4721 | Train Acc: 81.40%
2026-01-14 13:43:13,280 - INFO - [Valid] [29/90] | Loss: 0.5938 | Val Acc: 73.45%
2026-01-14 13:43:13,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.8851 | Recall: 0.4904 | F1: 0.6311
2026-01-14 13:43:13,305 - INFO - [Metrics for 'normal'] | Precision: 0.6825 | Recall: 0.9451 | F1: 0.7926
2026-01-14 13:43:13,312 - INFO - --------------------------------------------------
2026-01-14 13:43:13,317 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:43:23,987 - INFO - [Train] [30/90] | Loss: 0.4738 | Train Acc: 83.48%
2026-01-14 13:43:27,061 - INFO - [Valid] [30/90] | Loss: 0.5396 | Val Acc: 77.88%
2026-01-14 13:43:27,114 - INFO - [Metrics for 'abnormal'] | Precision: 0.7303 | Recall: 0.8280 | F1: 0.7761
2026-01-14 13:43:27,118 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7363 | F1: 0.7813
2026-01-14 13:43:27,200 - INFO - [Best Model Saved] (val loss: 0.5396) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:43:27,200 - INFO - --------------------------------------------------
2026-01-14 13:43:27,203 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:43:36,729 - INFO - [Train] [31/90] | Loss: 0.4601 | Train Acc: 83.41%
2026-01-14 13:43:39,775 - INFO - [Valid] [31/90] | Loss: 0.5791 | Val Acc: 76.99%
2026-01-14 13:43:39,788 - INFO - [Metrics for 'abnormal'] | Precision: 0.7582 | Recall: 0.7389 | F1: 0.7484
2026-01-14 13:43:39,789 - INFO - [Metrics for 'normal'] | Precision: 0.7796 | Recall: 0.7967 | F1: 0.7880
2026-01-14 13:43:39,794 - INFO - --------------------------------------------------
2026-01-14 13:43:39,797 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:43:48,167 - INFO - [Train] [32/90] | Loss: 0.4727 | Train Acc: 83.48%
2026-01-14 13:43:50,861 - INFO - [Valid] [32/90] | Loss: 0.5416 | Val Acc: 77.58%
2026-01-14 13:43:50,891 - INFO - [Metrics for 'abnormal'] | Precision: 0.7455 | Recall: 0.7834 | F1: 0.7640
2026-01-14 13:43:50,895 - INFO - [Metrics for 'normal'] | Precision: 0.8046 | Recall: 0.7692 | F1: 0.7865
2026-01-14 13:43:50,908 - INFO - --------------------------------------------------
2026-01-14 13:43:50,912 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:44:00,384 - INFO - [Train] [33/90] | Loss: 0.4559 | Train Acc: 83.26%
2026-01-14 13:44:02,641 - INFO - [Valid] [33/90] | Loss: 0.5612 | Val Acc: 75.52%
2026-01-14 13:44:02,653 - INFO - [Metrics for 'abnormal'] | Precision: 0.7534 | Recall: 0.7006 | F1: 0.7261
2026-01-14 13:44:02,654 - INFO - [Metrics for 'normal'] | Precision: 0.7565 | Recall: 0.8022 | F1: 0.7787
2026-01-14 13:44:02,658 - INFO - --------------------------------------------------
2026-01-14 13:44:02,661 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:44:11,274 - INFO - [Train] [34/90] | Loss: 0.4517 | Train Acc: 84.60%
2026-01-14 13:44:14,594 - INFO - [Valid] [34/90] | Loss: 0.5728 | Val Acc: 77.58%
2026-01-14 13:44:14,612 - INFO - [Metrics for 'abnormal'] | Precision: 0.7872 | Recall: 0.7070 | F1: 0.7450
2026-01-14 13:44:14,613 - INFO - [Metrics for 'normal'] | Precision: 0.7677 | Recall: 0.8352 | F1: 0.8000
2026-01-14 13:44:14,621 - INFO - --------------------------------------------------
2026-01-14 13:44:14,626 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:44:22,348 - INFO - [Train] [35/90] | Loss: 0.4818 | Train Acc: 81.85%
2026-01-14 13:44:25,183 - INFO - [Valid] [35/90] | Loss: 0.5846 | Val Acc: 76.70%
2026-01-14 13:44:25,194 - INFO - [Metrics for 'abnormal'] | Precision: 0.7097 | Recall: 0.8408 | F1: 0.7697
2026-01-14 13:44:25,194 - INFO - [Metrics for 'normal'] | Precision: 0.8366 | Recall: 0.7033 | F1: 0.7642
2026-01-14 13:44:25,198 - INFO - --------------------------------------------------
2026-01-14 13:44:25,200 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:44:33,731 - INFO - [Train] [36/90] | Loss: 0.4495 | Train Acc: 84.15%
2026-01-14 13:44:37,630 - INFO - [Valid] [36/90] | Loss: 0.5905 | Val Acc: 75.81%
2026-01-14 13:44:37,859 - INFO - [Metrics for 'abnormal'] | Precision: 0.7246 | Recall: 0.7707 | F1: 0.7469
2026-01-14 13:44:37,860 - INFO - [Metrics for 'normal'] | Precision: 0.7907 | Recall: 0.7473 | F1: 0.7684
2026-01-14 13:44:37,864 - INFO - --------------------------------------------------
2026-01-14 13:44:37,867 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:44:46,431 - INFO - [Train] [37/90] | Loss: 0.4480 | Train Acc: 84.30%
2026-01-14 13:44:49,209 - INFO - [Valid] [37/90] | Loss: 0.5683 | Val Acc: 77.29%
2026-01-14 13:44:49,222 - INFO - [Metrics for 'abnormal'] | Precision: 0.7198 | Recall: 0.8344 | F1: 0.7729
2026-01-14 13:44:49,223 - INFO - [Metrics for 'normal'] | Precision: 0.8344 | Recall: 0.7198 | F1: 0.7729
2026-01-14 13:44:49,228 - INFO - --------------------------------------------------
2026-01-14 13:44:49,231 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:45:00,628 - INFO - [Train] [38/90] | Loss: 0.4383 | Train Acc: 85.34%
2026-01-14 13:45:03,362 - INFO - [Valid] [38/90] | Loss: 0.5456 | Val Acc: 78.17%
2026-01-14 13:45:03,377 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-01-14 13:45:03,377 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-01-14 13:45:03,381 - INFO - --------------------------------------------------
2026-01-14 13:45:03,384 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:45:11,633 - INFO - [Train] [39/90] | Loss: 0.4303 | Train Acc: 86.01%
2026-01-14 13:45:14,511 - INFO - [Valid] [39/90] | Loss: 0.6590 | Val Acc: 71.68%
2026-01-14 13:45:14,522 - INFO - [Metrics for 'abnormal'] | Precision: 0.8280 | Recall: 0.4904 | F1: 0.6160
2026-01-14 13:45:14,522 - INFO - [Metrics for 'normal'] | Precision: 0.6748 | Recall: 0.9121 | F1: 0.7757
2026-01-14 13:45:14,526 - INFO - --------------------------------------------------
2026-01-14 13:45:14,528 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:45:22,131 - INFO - [Train] [40/90] | Loss: 0.4350 | Train Acc: 84.82%
2026-01-14 13:45:25,150 - INFO - [Valid] [40/90] | Loss: 0.5573 | Val Acc: 77.29%
2026-01-14 13:45:25,162 - INFO - [Metrics for 'abnormal'] | Precision: 0.7597 | Recall: 0.7452 | F1: 0.7524
2026-01-14 13:45:25,163 - INFO - [Metrics for 'normal'] | Precision: 0.7838 | Recall: 0.7967 | F1: 0.7902
2026-01-14 13:45:25,167 - INFO - --------------------------------------------------
2026-01-14 13:45:25,171 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:45:33,728 - INFO - [Train] [41/90] | Loss: 0.4278 | Train Acc: 85.34%
2026-01-14 13:45:37,241 - INFO - [Valid] [41/90] | Loss: 0.5671 | Val Acc: 76.40%
2026-01-14 13:45:37,268 - INFO - [Metrics for 'abnormal'] | Precision: 0.8468 | Recall: 0.5987 | F1: 0.7015
2026-01-14 13:45:37,269 - INFO - [Metrics for 'normal'] | Precision: 0.7237 | Recall: 0.9066 | F1: 0.8049
2026-01-14 13:45:37,274 - INFO - --------------------------------------------------
2026-01-14 13:45:37,277 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:45:45,981 - INFO - [Train] [42/90] | Loss: 0.4328 | Train Acc: 85.79%
2026-01-14 13:45:49,549 - INFO - [Valid] [42/90] | Loss: 0.5341 | Val Acc: 80.53%
2026-01-14 13:45:49,658 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-01-14 13:45:49,658 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-01-14 13:45:49,702 - INFO - [Best Model Saved] (val loss: 0.5341) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:45:49,702 - INFO - --------------------------------------------------
2026-01-14 13:45:49,705 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:45:58,898 - INFO - [Train] [43/90] | Loss: 0.4314 | Train Acc: 85.49%
2026-01-14 13:46:01,847 - INFO - [Valid] [43/90] | Loss: 0.5524 | Val Acc: 76.11%
2026-01-14 13:46:01,887 - INFO - [Metrics for 'abnormal'] | Precision: 0.7065 | Recall: 0.8280 | F1: 0.7625
2026-01-14 13:46:01,887 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.7033 | F1: 0.7596
2026-01-14 13:46:01,892 - INFO - --------------------------------------------------
2026-01-14 13:46:01,895 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:46:10,667 - INFO - [Train] [44/90] | Loss: 0.4172 | Train Acc: 85.57%
2026-01-14 13:46:14,235 - INFO - [Valid] [44/90] | Loss: 0.5304 | Val Acc: 80.24%
2026-01-14 13:46:14,247 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 13:46:14,248 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 13:46:14,288 - INFO - [Best Model Saved] (val loss: 0.5304) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:46:14,289 - INFO - --------------------------------------------------
2026-01-14 13:46:14,291 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:46:24,388 - INFO - [Train] [45/90] | Loss: 0.4193 | Train Acc: 86.83%
2026-01-14 13:46:27,649 - INFO - [Valid] [45/90] | Loss: 0.5869 | Val Acc: 79.06%
2026-01-14 13:46:27,660 - INFO - [Metrics for 'abnormal'] | Precision: 0.7337 | Recall: 0.8599 | F1: 0.7918
2026-01-14 13:46:27,661 - INFO - [Metrics for 'normal'] | Precision: 0.8581 | Recall: 0.7308 | F1: 0.7893
2026-01-14 13:46:27,665 - INFO - --------------------------------------------------
2026-01-14 13:46:27,667 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:46:37,664 - INFO - [Train] [46/90] | Loss: 0.4001 | Train Acc: 88.10%
2026-01-14 13:46:40,890 - INFO - [Valid] [46/90] | Loss: 0.5442 | Val Acc: 78.76%
2026-01-14 13:46:40,901 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-01-14 13:46:40,902 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-01-14 13:46:40,906 - INFO - --------------------------------------------------
2026-01-14 13:46:40,909 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:46:49,920 - INFO - [Train] [47/90] | Loss: 0.4057 | Train Acc: 86.90%
2026-01-14 13:46:52,763 - INFO - [Valid] [47/90] | Loss: 0.5539 | Val Acc: 80.53%
2026-01-14 13:46:52,777 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-01-14 13:46:52,778 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-01-14 13:46:52,782 - INFO - --------------------------------------------------
2026-01-14 13:46:52,785 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:47:01,847 - INFO - [Train] [48/90] | Loss: 0.4002 | Train Acc: 87.87%
2026-01-14 13:47:04,246 - INFO - [Valid] [48/90] | Loss: 0.5460 | Val Acc: 75.81%
2026-01-14 13:47:04,266 - INFO - [Metrics for 'abnormal'] | Precision: 0.7451 | Recall: 0.7261 | F1: 0.7355
2026-01-14 13:47:04,267 - INFO - [Metrics for 'normal'] | Precision: 0.7688 | Recall: 0.7857 | F1: 0.7772
2026-01-14 13:47:04,274 - INFO - --------------------------------------------------
2026-01-14 13:47:04,279 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:47:13,527 - INFO - [Train] [49/90] | Loss: 0.4024 | Train Acc: 87.43%
2026-01-14 13:47:15,974 - INFO - [Valid] [49/90] | Loss: 0.5499 | Val Acc: 77.29%
2026-01-14 13:47:15,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.7439 | Recall: 0.7771 | F1: 0.7601
2026-01-14 13:47:15,984 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7692 | F1: 0.7843
2026-01-14 13:47:15,988 - INFO - --------------------------------------------------
2026-01-14 13:47:15,990 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:47:25,848 - INFO - [Train] [50/90] | Loss: 0.3883 | Train Acc: 87.87%
2026-01-14 13:47:28,251 - INFO - [Valid] [50/90] | Loss: 0.5491 | Val Acc: 76.70%
2026-01-14 13:47:28,264 - INFO - [Metrics for 'abnormal'] | Precision: 0.7438 | Recall: 0.7580 | F1: 0.7508
2026-01-14 13:47:28,265 - INFO - [Metrics for 'normal'] | Precision: 0.7877 | Recall: 0.7747 | F1: 0.7812
2026-01-14 13:47:28,270 - INFO - --------------------------------------------------
2026-01-14 13:47:28,273 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:47:37,543 - INFO - [Train] [51/90] | Loss: 0.4099 | Train Acc: 87.50%
2026-01-14 13:47:40,751 - INFO - [Valid] [51/90] | Loss: 0.5116 | Val Acc: 81.42%
2026-01-14 13:47:40,761 - INFO - [Metrics for 'abnormal'] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 13:47:40,761 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 13:47:40,794 - INFO - [Best Model Saved] (val loss: 0.5116) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:47:40,795 - INFO - --------------------------------------------------
2026-01-14 13:47:40,797 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:47:49,860 - INFO - [Train] [52/90] | Loss: 0.3862 | Train Acc: 87.57%
2026-01-14 13:47:52,248 - INFO - [Valid] [52/90] | Loss: 0.5515 | Val Acc: 79.06%
2026-01-14 13:47:52,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.8308 | Recall: 0.6879 | F1: 0.7526
2026-01-14 13:47:52,259 - INFO - [Metrics for 'normal'] | Precision: 0.7656 | Recall: 0.8791 | F1: 0.8184
2026-01-14 13:47:52,263 - INFO - --------------------------------------------------
2026-01-14 13:47:52,265 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:48:00,879 - INFO - [Train] [53/90] | Loss: 0.3857 | Train Acc: 88.02%
2026-01-14 13:48:03,383 - INFO - [Valid] [53/90] | Loss: 0.5570 | Val Acc: 81.71%
2026-01-14 13:48:03,399 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:48:03,402 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:48:03,407 - INFO - --------------------------------------------------
2026-01-14 13:48:03,409 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:48:12,388 - INFO - [Train] [54/90] | Loss: 0.3825 | Train Acc: 88.91%
2026-01-14 13:48:15,109 - INFO - [Valid] [54/90] | Loss: 0.5654 | Val Acc: 78.17%
2026-01-14 13:48:15,122 - INFO - [Metrics for 'abnormal'] | Precision: 0.7610 | Recall: 0.7707 | F1: 0.7658
2026-01-14 13:48:15,122 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7912 | F1: 0.7956
2026-01-14 13:48:15,127 - INFO - --------------------------------------------------
2026-01-14 13:48:15,130 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:48:24,039 - INFO - [Train] [55/90] | Loss: 0.3724 | Train Acc: 89.21%
2026-01-14 13:48:27,012 - INFO - [Valid] [55/90] | Loss: 0.5430 | Val Acc: 79.35%
2026-01-14 13:48:27,024 - INFO - [Metrics for 'abnormal'] | Precision: 0.7277 | Recall: 0.8854 | F1: 0.7989
2026-01-14 13:48:27,024 - INFO - [Metrics for 'normal'] | Precision: 0.8784 | Recall: 0.7143 | F1: 0.7879
2026-01-14 13:48:27,029 - INFO - --------------------------------------------------
2026-01-14 13:48:27,032 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:48:36,324 - INFO - [Train] [56/90] | Loss: 0.3717 | Train Acc: 88.76%
2026-01-14 13:48:38,994 - INFO - [Valid] [56/90] | Loss: 0.5493 | Val Acc: 77.88%
2026-01-14 13:48:39,012 - INFO - [Metrics for 'abnormal'] | Precision: 0.7971 | Recall: 0.7006 | F1: 0.7458
2026-01-14 13:48:39,012 - INFO - [Metrics for 'normal'] | Precision: 0.7662 | Recall: 0.8462 | F1: 0.8042
2026-01-14 13:48:39,018 - INFO - --------------------------------------------------
2026-01-14 13:48:39,021 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:48:48,590 - INFO - [Train] [57/90] | Loss: 0.3678 | Train Acc: 91.00%
2026-01-14 13:48:51,183 - INFO - [Valid] [57/90] | Loss: 0.6006 | Val Acc: 79.06%
2026-01-14 13:48:51,194 - INFO - [Metrics for 'abnormal'] | Precision: 0.7240 | Recall: 0.8854 | F1: 0.7966
2026-01-14 13:48:51,194 - INFO - [Metrics for 'normal'] | Precision: 0.8776 | Recall: 0.7088 | F1: 0.7842
2026-01-14 13:48:51,197 - INFO - --------------------------------------------------
2026-01-14 13:48:51,200 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:48:59,718 - INFO - [Train] [58/90] | Loss: 0.3790 | Train Acc: 88.84%
2026-01-14 13:49:02,807 - INFO - [Valid] [58/90] | Loss: 0.5231 | Val Acc: 80.24%
2026-01-14 13:49:02,832 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:49:02,832 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:49:02,841 - INFO - --------------------------------------------------
2026-01-14 13:49:02,850 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:49:10,788 - INFO - [Train] [59/90] | Loss: 0.3653 | Train Acc: 89.88%
2026-01-14 13:49:14,234 - INFO - [Valid] [59/90] | Loss: 0.6483 | Val Acc: 77.29%
2026-01-14 13:49:14,250 - INFO - [Metrics for 'abnormal'] | Precision: 0.7247 | Recall: 0.8217 | F1: 0.7701
2026-01-14 13:49:14,250 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.7308 | F1: 0.7755
2026-01-14 13:49:14,277 - INFO - --------------------------------------------------
2026-01-14 13:49:14,280 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:49:21,768 - INFO - [Train] [60/90] | Loss: 0.3695 | Train Acc: 89.81%
2026-01-14 13:49:25,003 - INFO - [Valid] [60/90] | Loss: 0.5451 | Val Acc: 80.24%
2026-01-14 13:49:25,026 - INFO - [Metrics for 'abnormal'] | Precision: 0.8082 | Recall: 0.7516 | F1: 0.7789
2026-01-14 13:49:25,026 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8462 | F1: 0.8213
2026-01-14 13:49:25,033 - INFO - --------------------------------------------------
2026-01-14 13:49:25,039 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:49:32,942 - INFO - [Train] [61/90] | Loss: 0.3559 | Train Acc: 90.55%
2026-01-14 13:49:36,528 - INFO - [Valid] [61/90] | Loss: 0.5794 | Val Acc: 78.17%
2026-01-14 13:49:36,541 - INFO - [Metrics for 'abnormal'] | Precision: 0.7823 | Recall: 0.7325 | F1: 0.7566
2026-01-14 13:49:36,541 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.8242 | F1: 0.8021
2026-01-14 13:49:36,577 - INFO - --------------------------------------------------
2026-01-14 13:49:36,614 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:49:44,998 - INFO - [Train] [62/90] | Loss: 0.3473 | Train Acc: 90.55%
2026-01-14 13:49:47,834 - INFO - [Valid] [62/90] | Loss: 0.5633 | Val Acc: 78.17%
2026-01-14 13:49:47,846 - INFO - [Metrics for 'abnormal'] | Precision: 0.7748 | Recall: 0.7452 | F1: 0.7597
2026-01-14 13:49:47,846 - INFO - [Metrics for 'normal'] | Precision: 0.7872 | Recall: 0.8132 | F1: 0.8000
2026-01-14 13:49:47,850 - INFO - --------------------------------------------------
2026-01-14 13:49:47,853 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:49:57,011 - INFO - [Train] [63/90] | Loss: 0.3585 | Train Acc: 90.03%
2026-01-14 13:49:59,816 - INFO - [Valid] [63/90] | Loss: 0.5764 | Val Acc: 79.35%
2026-01-14 13:49:59,853 - INFO - [Metrics for 'abnormal'] | Precision: 0.8042 | Recall: 0.7325 | F1: 0.7667
2026-01-14 13:49:59,853 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.8462 | F1: 0.8148
2026-01-14 13:49:59,863 - INFO - --------------------------------------------------
2026-01-14 13:49:59,870 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:50:08,638 - INFO - [Train] [64/90] | Loss: 0.3465 | Train Acc: 92.11%
2026-01-14 13:50:10,663 - INFO - [Valid] [64/90] | Loss: 0.5555 | Val Acc: 78.76%
2026-01-14 13:50:10,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7931 | Recall: 0.7325 | F1: 0.7616
2026-01-14 13:50:10,686 - INFO - [Metrics for 'normal'] | Precision: 0.7835 | Recall: 0.8352 | F1: 0.8085
2026-01-14 13:50:10,692 - INFO - --------------------------------------------------
2026-01-14 13:50:10,696 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:50:20,548 - INFO - [Train] [65/90] | Loss: 0.3531 | Train Acc: 91.15%
2026-01-14 13:50:22,814 - INFO - [Valid] [65/90] | Loss: 0.5495 | Val Acc: 79.06%
2026-01-14 13:50:22,836 - INFO - [Metrics for 'abnormal'] | Precision: 0.7756 | Recall: 0.7707 | F1: 0.7732
2026-01-14 13:50:22,837 - INFO - [Metrics for 'normal'] | Precision: 0.8033 | Recall: 0.8077 | F1: 0.8055
2026-01-14 13:50:22,845 - INFO - --------------------------------------------------
2026-01-14 13:50:22,850 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:50:32,410 - INFO - [Train] [66/90] | Loss: 0.3579 | Train Acc: 89.06%
2026-01-14 13:50:34,882 - INFO - [Valid] [66/90] | Loss: 0.5671 | Val Acc: 80.83%
2026-01-14 13:50:34,906 - INFO - [Metrics for 'abnormal'] | Precision: 0.8286 | Recall: 0.7389 | F1: 0.7811
2026-01-14 13:50:34,908 - INFO - [Metrics for 'normal'] | Precision: 0.7940 | Recall: 0.8681 | F1: 0.8294
2026-01-14 13:50:34,916 - INFO - --------------------------------------------------
2026-01-14 13:50:34,922 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:50:44,492 - INFO - [Train] [67/90] | Loss: 0.3392 | Train Acc: 92.04%
2026-01-14 13:50:46,432 - INFO - [Valid] [67/90] | Loss: 0.5764 | Val Acc: 79.65%
2026-01-14 13:50:46,459 - INFO - [Metrics for 'abnormal'] | Precision: 0.8188 | Recall: 0.7197 | F1: 0.7661
2026-01-14 13:50:46,461 - INFO - [Metrics for 'normal'] | Precision: 0.7811 | Recall: 0.8626 | F1: 0.8198
2026-01-14 13:50:46,468 - INFO - --------------------------------------------------
2026-01-14 13:50:46,476 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:50:56,045 - INFO - [Train] [68/90] | Loss: 0.3390 | Train Acc: 92.11%
2026-01-14 13:50:58,480 - INFO - [Valid] [68/90] | Loss: 0.5984 | Val Acc: 75.81%
2026-01-14 13:50:58,503 - INFO - [Metrics for 'abnormal'] | Precision: 0.7329 | Recall: 0.7516 | F1: 0.7421
2026-01-14 13:50:58,514 - INFO - [Metrics for 'normal'] | Precision: 0.7809 | Recall: 0.7637 | F1: 0.7722
2026-01-14 13:50:58,523 - INFO - --------------------------------------------------
2026-01-14 13:50:58,527 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:51:07,055 - INFO - [Train] [69/90] | Loss: 0.3430 | Train Acc: 91.67%
2026-01-14 13:51:09,463 - INFO - [Valid] [69/90] | Loss: 0.5661 | Val Acc: 78.76%
2026-01-14 13:51:09,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 13:51:09,476 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 13:51:09,480 - INFO - --------------------------------------------------
2026-01-14 13:51:09,483 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:51:19,628 - INFO - [Train] [70/90] | Loss: 0.3297 | Train Acc: 92.78%
2026-01-14 13:51:22,253 - INFO - [Valid] [70/90] | Loss: 0.5387 | Val Acc: 79.06%
2026-01-14 13:51:22,269 - INFO - [Metrics for 'abnormal'] | Precision: 0.7905 | Recall: 0.7452 | F1: 0.7672
2026-01-14 13:51:22,270 - INFO - [Metrics for 'normal'] | Precision: 0.7906 | Recall: 0.8297 | F1: 0.8097
2026-01-14 13:51:22,274 - INFO - --------------------------------------------------
2026-01-14 13:51:22,277 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:51:30,491 - INFO - [Train] [71/90] | Loss: 0.3303 | Train Acc: 91.67%
2026-01-14 13:51:33,322 - INFO - [Valid] [71/90] | Loss: 0.5387 | Val Acc: 82.01%
2026-01-14 13:51:33,335 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.7898 | F1: 0.8026
2026-01-14 13:51:33,335 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.8462 | F1: 0.8347
2026-01-14 13:51:33,340 - INFO - --------------------------------------------------
2026-01-14 13:51:33,342 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:51:43,484 - INFO - [Train] [72/90] | Loss: 0.3286 | Train Acc: 92.63%
2026-01-14 13:51:45,588 - INFO - [Valid] [72/90] | Loss: 0.5500 | Val Acc: 78.17%
2026-01-14 13:51:45,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.7712 | Recall: 0.7516 | F1: 0.7613
2026-01-14 13:51:45,601 - INFO - [Metrics for 'normal'] | Precision: 0.7903 | Recall: 0.8077 | F1: 0.7989
2026-01-14 13:51:45,605 - INFO - --------------------------------------------------
2026-01-14 13:51:45,608 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:51:55,699 - INFO - [Train] [73/90] | Loss: 0.3246 | Train Acc: 93.53%
2026-01-14 13:51:57,725 - INFO - [Valid] [73/90] | Loss: 0.5760 | Val Acc: 78.47%
2026-01-14 13:51:57,747 - INFO - [Metrics for 'abnormal'] | Precision: 0.8043 | Recall: 0.7070 | F1: 0.7525
2026-01-14 13:51:57,748 - INFO - [Metrics for 'normal'] | Precision: 0.7711 | Recall: 0.8516 | F1: 0.8094
2026-01-14 13:51:57,752 - INFO - --------------------------------------------------
2026-01-14 13:51:57,755 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:52:06,692 - INFO - [Train] [74/90] | Loss: 0.3212 | Train Acc: 93.45%
2026-01-14 13:52:08,821 - INFO - [Valid] [74/90] | Loss: 0.5925 | Val Acc: 78.17%
2026-01-14 13:52:08,835 - INFO - [Metrics for 'abnormal'] | Precision: 0.7456 | Recall: 0.8025 | F1: 0.7730
2026-01-14 13:52:08,835 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.7637 | F1: 0.7898
2026-01-14 13:52:08,839 - INFO - --------------------------------------------------
2026-01-14 13:52:08,841 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:52:18,018 - INFO - [Train] [75/90] | Loss: 0.3184 | Train Acc: 93.23%
2026-01-14 13:52:20,497 - INFO - [Valid] [75/90] | Loss: 0.5689 | Val Acc: 79.06%
2026-01-14 13:52:20,511 - INFO - [Metrics for 'abnormal'] | Precision: 0.8071 | Recall: 0.7197 | F1: 0.7609
2026-01-14 13:52:20,512 - INFO - [Metrics for 'normal'] | Precision: 0.7789 | Recall: 0.8516 | F1: 0.8136
2026-01-14 13:52:20,517 - INFO - --------------------------------------------------
2026-01-14 13:52:20,520 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:52:30,653 - INFO - [Train] [76/90] | Loss: 0.3262 | Train Acc: 93.08%
2026-01-14 13:52:32,931 - INFO - [Valid] [76/90] | Loss: 0.5998 | Val Acc: 77.88%
2026-01-14 13:52:32,944 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-01-14 13:52:32,945 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-01-14 13:52:32,949 - INFO - --------------------------------------------------
2026-01-14 13:52:32,952 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:52:41,387 - INFO - [Train] [77/90] | Loss: 0.3305 | Train Acc: 92.56%
2026-01-14 13:52:44,022 - INFO - [Valid] [77/90] | Loss: 0.5917 | Val Acc: 78.47%
2026-01-14 13:52:44,044 - INFO - [Metrics for 'abnormal'] | Precision: 0.7658 | Recall: 0.7707 | F1: 0.7683
2026-01-14 13:52:44,045 - INFO - [Metrics for 'normal'] | Precision: 0.8011 | Recall: 0.7967 | F1: 0.7989
2026-01-14 13:52:44,054 - INFO - --------------------------------------------------
2026-01-14 13:52:44,058 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:52:53,463 - INFO - [Train] [78/90] | Loss: 0.3085 | Train Acc: 94.35%
2026-01-14 13:52:55,980 - INFO - [Valid] [78/90] | Loss: 0.5982 | Val Acc: 79.06%
2026-01-14 13:52:55,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.8071 | Recall: 0.7197 | F1: 0.7609
2026-01-14 13:52:55,992 - INFO - [Metrics for 'normal'] | Precision: 0.7789 | Recall: 0.8516 | F1: 0.8136
2026-01-14 13:52:55,997 - INFO - --------------------------------------------------
2026-01-14 13:52:55,999 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:53:05,225 - INFO - [Train] [79/90] | Loss: 0.3140 | Train Acc: 94.72%
2026-01-14 13:53:08,020 - INFO - [Valid] [79/90] | Loss: 0.6066 | Val Acc: 76.70%
2026-01-14 13:53:08,032 - INFO - [Metrics for 'abnormal'] | Precision: 0.7786 | Recall: 0.6943 | F1: 0.7340
2026-01-14 13:53:08,032 - INFO - [Metrics for 'normal'] | Precision: 0.7588 | Recall: 0.8297 | F1: 0.7927
2026-01-14 13:53:08,036 - INFO - --------------------------------------------------
2026-01-14 13:53:08,038 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:53:16,702 - INFO - [Train] [80/90] | Loss: 0.3066 | Train Acc: 93.97%
2026-01-14 13:53:19,433 - INFO - [Valid] [80/90] | Loss: 0.5960 | Val Acc: 77.88%
2026-01-14 13:53:19,445 - INFO - [Metrics for 'abnormal'] | Precision: 0.7662 | Recall: 0.7516 | F1: 0.7588
2026-01-14 13:53:19,446 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8022 | F1: 0.7956
2026-01-14 13:53:19,450 - INFO - --------------------------------------------------
2026-01-14 13:53:19,454 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:53:29,111 - INFO - [Train] [81/90] | Loss: 0.3270 | Train Acc: 93.45%
2026-01-14 13:53:31,597 - INFO - [Valid] [81/90] | Loss: 0.5814 | Val Acc: 76.99%
2026-01-14 13:53:31,606 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.7325 | F1: 0.7468
2026-01-14 13:53:31,607 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8022 | F1: 0.7892
2026-01-14 13:53:31,611 - INFO - --------------------------------------------------
2026-01-14 13:53:31,613 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:53:40,044 - INFO - [Train] [82/90] | Loss: 0.3049 | Train Acc: 94.49%
2026-01-14 13:53:43,015 - INFO - [Valid] [82/90] | Loss: 0.5991 | Val Acc: 77.88%
2026-01-14 13:53:43,026 - INFO - [Metrics for 'abnormal'] | Precision: 0.7770 | Recall: 0.7325 | F1: 0.7541
2026-01-14 13:53:43,026 - INFO - [Metrics for 'normal'] | Precision: 0.7801 | Recall: 0.8187 | F1: 0.7989
2026-01-14 13:53:43,030 - INFO - --------------------------------------------------
2026-01-14 13:53:43,033 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:53:51,111 - INFO - [Train] [83/90] | Loss: 0.3003 | Train Acc: 94.49%
2026-01-14 13:53:54,856 - INFO - [Valid] [83/90] | Loss: 0.5913 | Val Acc: 78.17%
2026-01-14 13:53:54,868 - INFO - [Metrics for 'abnormal'] | Precision: 0.7748 | Recall: 0.7452 | F1: 0.7597
2026-01-14 13:53:54,869 - INFO - [Metrics for 'normal'] | Precision: 0.7872 | Recall: 0.8132 | F1: 0.8000
2026-01-14 13:53:54,873 - INFO - --------------------------------------------------
2026-01-14 13:53:54,876 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:54:04,369 - INFO - [Train] [84/90] | Loss: 0.3039 | Train Acc: 94.27%
2026-01-14 13:54:06,982 - INFO - [Valid] [84/90] | Loss: 0.6068 | Val Acc: 78.76%
2026-01-14 13:54:06,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-01-14 13:54:06,992 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-01-14 13:54:06,995 - INFO - --------------------------------------------------
2026-01-14 13:54:06,996 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:54:16,515 - INFO - [Train] [85/90] | Loss: 0.3152 | Train Acc: 93.53%
2026-01-14 13:54:19,322 - INFO - [Valid] [85/90] | Loss: 0.5995 | Val Acc: 78.17%
2026-01-14 13:54:19,331 - INFO - [Metrics for 'abnormal'] | Precision: 0.7643 | Recall: 0.7643 | F1: 0.7643
2026-01-14 13:54:19,332 - INFO - [Metrics for 'normal'] | Precision: 0.7967 | Recall: 0.7967 | F1: 0.7967
2026-01-14 13:54:19,335 - INFO - --------------------------------------------------
2026-01-14 13:54:19,337 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:54:27,951 - INFO - [Train] [86/90] | Loss: 0.2980 | Train Acc: 94.42%
2026-01-14 13:54:31,330 - INFO - [Valid] [86/90] | Loss: 0.5919 | Val Acc: 79.06%
2026-01-14 13:54:31,351 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-01-14 13:54:31,352 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-01-14 13:54:31,360 - INFO - --------------------------------------------------
2026-01-14 13:54:31,366 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:54:39,817 - INFO - [Train] [87/90] | Loss: 0.3021 | Train Acc: 94.27%
2026-01-14 13:54:42,488 - INFO - [Valid] [87/90] | Loss: 0.5842 | Val Acc: 79.06%
2026-01-14 13:54:42,500 - INFO - [Metrics for 'abnormal'] | Precision: 0.7867 | Recall: 0.7516 | F1: 0.7687
2026-01-14 13:54:42,501 - INFO - [Metrics for 'normal'] | Precision: 0.7937 | Recall: 0.8242 | F1: 0.8086
2026-01-14 13:54:42,505 - INFO - --------------------------------------------------
2026-01-14 13:54:42,508 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:54:50,797 - INFO - [Train] [88/90] | Loss: 0.3083 | Train Acc: 93.90%
2026-01-14 13:54:53,835 - INFO - [Valid] [88/90] | Loss: 0.5954 | Val Acc: 78.17%
2026-01-14 13:54:53,847 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-01-14 13:54:53,847 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-01-14 13:54:53,851 - INFO - --------------------------------------------------
2026-01-14 13:54:53,853 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:55:00,895 - INFO - [Train] [89/90] | Loss: 0.3080 | Train Acc: 94.27%
2026-01-14 13:55:04,417 - INFO - [Valid] [89/90] | Loss: 0.6066 | Val Acc: 78.76%
2026-01-14 13:55:04,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.7972 | Recall: 0.7261 | F1: 0.7600
2026-01-14 13:55:04,430 - INFO - [Metrics for 'normal'] | Precision: 0.7806 | Recall: 0.8407 | F1: 0.8095
2026-01-14 13:55:04,434 - INFO - --------------------------------------------------
2026-01-14 13:55:04,437 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:55:12,241 - INFO - [Train] [90/90] | Loss: 0.2998 | Train Acc: 94.64%
2026-01-14 13:55:14,902 - INFO - [Valid] [90/90] | Loss: 0.6070 | Val Acc: 78.47%
2026-01-14 13:55:14,923 - INFO - [Metrics for 'abnormal'] | Precision: 0.7763 | Recall: 0.7516 | F1: 0.7638
2026-01-14 13:55:14,923 - INFO - [Metrics for 'normal'] | Precision: 0.7914 | Recall: 0.8132 | F1: 0.8022
2026-01-14 13:55:14,929 - INFO - ==================================================
2026-01-14 13:55:14,930 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:55:14,930 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:55:14,930 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:55:15,250 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:55:15,253 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:55:15,254 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:55:15,556 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 13:55:15,557 - INFO - ==================================================
2026-01-14 13:55:15,680 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/best_model.pth'
2026-01-14 13:55:15,680 - INFO - ==================================================
2026-01-14 13:55:15,680 - INFO - Test 모드를 시작합니다.
2026-01-14 13:55:15,844 - INFO - 연산량 (MACs): 0.0039 GMACs per sample
2026-01-14 13:55:15,845 - INFO - 연산량 (FLOPs): 0.0077 GFLOPs per sample
2026-01-14 13:55:15,846 - INFO - ==================================================
2026-01-14 13:55:15,847 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:55:17,037 - INFO - 샘플 당 평균 Forward Pass 시간: 4.77ms (std: 1.33ms), FPS: 225.74 (std: 61.66) (1개 샘플 x 100회 반복)
2026-01-14 13:55:17,037 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 57.83 MB
2026-01-14 13:55:17,037 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:55:22,298 - INFO - [Test] Loss: 0.4363 | Test Acc: 81.42%
2026-01-14 13:55:22,312 - INFO - [Metrics for 'abnormal'] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 13:55:22,313 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 13:55:23,515 - INFO - ==================================================
2026-01-14 13:55:23,516 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/confusion_matrix_20260114_133802.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/confusion_matrix_20260114_133802.pdf'
2026-01-14 13:55:23,516 - INFO - ==================================================
2026-01-14 13:55:23,517 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:55:28,003 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/model_fp32_20260114_133802.onnx'에 저장되었습니다. (크기: 0.14 MB)
2026-01-14 13:55:28,445 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2582.17 MB (증가량: 6.48 MB)
2026-01-14 13:55:28,445 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:55:30,562 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 10.59ms (std: 25.52ms)
2026-01-14 13:55:30,563 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 232.14 FPS (std: 212.74) (1개 샘플 x 100회 반복)
2026-01-14 13:55:30,565 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2583.67 MB (순수 증가량: 1.50 MB)
2026-01-14 13:55:30,565 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2583.67 MB (전체 증가량: 7.98 MB)
2026-01-14 13:55:34,515 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.42%
2026-01-14 13:55:34,537 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 13:55:34,541 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 13:55:35,166 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/val_acc.pdf'
2026-01-14 13:55:35,752 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/train_val_acc.pdf'
2026-01-14 13:55:36,358 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/F1_normal.pdf'
2026-01-14 13:55:37,053 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/val_loss.pdf'
2026-01-14 13:55:37,581 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/learning_rate.pdf'
2026-01-14 13:55:43,227 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_133802/graph_20260114_133802/compile.pdf'
