2026-01-14 13:38:13,735 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/log_20260114_133813.log'에 저장됩니다.
2026-01-14 13:38:13,744 - INFO - ==================================================
2026-01-14 13:38:13,744 - INFO - config.yaml:
2026-01-14 13:38:13,744 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: xie2019
  use_fpgm_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:38:13,745 - INFO - ==================================================
2026-01-14 13:38:13,813 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:38:13,813 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:38:13,814 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:38:13,830 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:38:13,830 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:38:13,831 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:38:13,831 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:38:14,170 - INFO - ==================================================
2026-01-14 13:38:14,171 - INFO - 모델 파라미터 수:
2026-01-14 13:38:14,171 - INFO -   - 총 파라미터: 9,160,194 개
2026-01-14 13:38:14,171 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-01-14 13:38:14,171 - INFO - ================================================================================
2026-01-14 13:38:14,171 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:38:14,171 - INFO - ================================================================================
2026-01-14 13:38:14,171 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:38:14,172 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:38:14,172 - INFO - ==================================================
2026-01-14 13:38:14,172 - INFO - train 모드를 시작합니다.
2026-01-14 13:38:14,172 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:38:14,172 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:38:14,172 - INFO - --------------------------------------------------
2026-01-14 13:38:14,172 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:38:20,844 - INFO - [Train] [1/10] | Loss: 0.5890 | Train Acc: 73.81%
2026-01-14 13:38:23,551 - INFO - [Valid] [1/10] | Loss: 0.5589 | Val Acc: 74.34%
2026-01-14 13:38:23,573 - INFO - [Metrics for 'abnormal'] | Precision: 0.7397 | Recall: 0.6879 | F1: 0.7129
2026-01-14 13:38:23,574 - INFO - [Metrics for 'normal'] | Precision: 0.7461 | Recall: 0.7912 | F1: 0.7680
2026-01-14 13:38:23,660 - INFO - [Best Model Saved] (val loss: 0.5589) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:38:23,661 - INFO - --------------------------------------------------
2026-01-14 13:38:23,661 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:38:29,637 - INFO - [Train] [2/10] | Loss: 0.5605 | Train Acc: 78.87%
2026-01-14 13:38:31,555 - INFO - [Valid] [2/10] | Loss: 0.6704 | Val Acc: 48.67%
2026-01-14 13:38:31,576 - INFO - [Metrics for 'abnormal'] | Precision: 0.4727 | Recall: 0.9363 | F1: 0.6282
2026-01-14 13:38:31,576 - INFO - [Metrics for 'normal'] | Precision: 0.6429 | Recall: 0.0989 | F1: 0.1714
2026-01-14 13:38:31,581 - INFO - --------------------------------------------------
2026-01-14 13:38:31,582 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:38:38,976 - INFO - [Train] [3/10] | Loss: 0.5363 | Train Acc: 80.13%
2026-01-14 13:38:40,587 - INFO - [Valid] [3/10] | Loss: 0.5338 | Val Acc: 77.29%
2026-01-14 13:38:40,598 - INFO - [Metrics for 'abnormal'] | Precision: 0.7410 | Recall: 0.7834 | F1: 0.7616
2026-01-14 13:38:40,598 - INFO - [Metrics for 'normal'] | Precision: 0.8035 | Recall: 0.7637 | F1: 0.7831
2026-01-14 13:38:40,689 - INFO - [Best Model Saved] (val loss: 0.5338) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:38:40,689 - INFO - --------------------------------------------------
2026-01-14 13:38:40,690 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:38:48,884 - INFO - [Train] [4/10] | Loss: 0.5100 | Train Acc: 81.18%
2026-01-14 13:38:51,854 - INFO - [Valid] [4/10] | Loss: 0.5489 | Val Acc: 76.11%
2026-01-14 13:38:51,865 - INFO - [Metrics for 'abnormal'] | Precision: 0.7639 | Recall: 0.7006 | F1: 0.7309
2026-01-14 13:38:51,866 - INFO - [Metrics for 'normal'] | Precision: 0.7590 | Recall: 0.8132 | F1: 0.7851
2026-01-14 13:38:51,870 - INFO - --------------------------------------------------
2026-01-14 13:38:51,871 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:39:01,517 - INFO - [Train] [5/10] | Loss: 0.4853 | Train Acc: 81.18%
2026-01-14 13:39:05,343 - INFO - [Valid] [5/10] | Loss: 0.5250 | Val Acc: 78.17%
2026-01-14 13:39:05,367 - INFO - [Metrics for 'abnormal'] | Precision: 0.7371 | Recall: 0.8217 | F1: 0.7771
2026-01-14 13:39:05,367 - INFO - [Metrics for 'normal'] | Precision: 0.8293 | Recall: 0.7473 | F1: 0.7861
2026-01-14 13:39:05,515 - INFO - [Best Model Saved] (val loss: 0.5250) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:39:05,515 - INFO - --------------------------------------------------
2026-01-14 13:39:05,515 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:39:15,303 - INFO - [Train] [6/10] | Loss: 0.4717 | Train Acc: 84.15%
2026-01-14 13:39:17,700 - INFO - [Valid] [6/10] | Loss: 0.5076 | Val Acc: 81.12%
2026-01-14 13:39:17,710 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 13:39:17,710 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 13:39:17,794 - INFO - [Best Model Saved] (val loss: 0.5076) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:39:17,795 - INFO - --------------------------------------------------
2026-01-14 13:39:17,795 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:39:25,460 - INFO - [Train] [7/10] | Loss: 0.4586 | Train Acc: 83.85%
2026-01-14 13:39:28,052 - INFO - [Valid] [7/10] | Loss: 0.5123 | Val Acc: 79.06%
2026-01-14 13:39:28,064 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-01-14 13:39:28,065 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-01-14 13:39:28,070 - INFO - --------------------------------------------------
2026-01-14 13:39:28,070 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:39:35,075 - INFO - [Train] [8/10] | Loss: 0.4460 | Train Acc: 84.38%
2026-01-14 13:39:37,259 - INFO - [Valid] [8/10] | Loss: 0.5111 | Val Acc: 80.24%
2026-01-14 13:39:37,284 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 13:39:37,284 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 13:39:37,295 - INFO - --------------------------------------------------
2026-01-14 13:39:37,296 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:39:44,436 - INFO - [Train] [9/10] | Loss: 0.4337 | Train Acc: 85.71%
2026-01-14 13:39:46,696 - INFO - [Valid] [9/10] | Loss: 0.5046 | Val Acc: 80.83%
2026-01-14 13:39:46,710 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 13:39:46,711 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 13:39:46,805 - INFO - [Best Model Saved] (val loss: 0.5046) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:39:46,805 - INFO - --------------------------------------------------
2026-01-14 13:39:46,806 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:39:53,050 - INFO - [Train] [10/10] | Loss: 0.4320 | Train Acc: 85.64%
2026-01-14 13:39:55,225 - INFO - [Valid] [10/10] | Loss: 0.5116 | Val Acc: 79.65%
2026-01-14 13:39:55,237 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-01-14 13:39:55,237 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-01-14 13:39:55,241 - INFO - ================================================================================
2026-01-14 13:39:55,241 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:39:55,241 - INFO - ================================================================================
2026-01-14 13:39:55,290 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:39:55,290 - INFO - ================================================================================
2026-01-14 13:39:55,290 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:39:55,290 - INFO - 원본 모델 파라미터: 9.1602M
2026-01-14 13:39:55,298 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:55,299 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:56,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:39:56,059 - INFO - ==================================================
2026-01-14 13:39:56,059 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 2.3194M (감소율: 74.68%)
2026-01-14 13:39:56,063 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:56,063 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:56,596 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:56,597 - INFO - ==================================================
2026-01-14 13:39:56,597 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.5934M (감소율: 93.52%)
2026-01-14 13:39:56,601 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:56,601 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,086 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,087 - INFO - ==================================================
2026-01-14 13:39:57,088 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.1643M (감소율: 98.21%)
2026-01-14 13:39:57,093 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,093 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,629 - INFO - ==================================================
2026-01-14 13:39:57,629 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-01-14 13:39:57,633 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,633 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,237 - INFO - ==================================================
2026-01-14 13:39:58,238 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0151M (감소율: 99.84%)
2026-01-14 13:39:58,242 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,243 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,787 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.94359375)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,788 - INFO - ==================================================
2026-01-14 13:39:58,788 - INFO -   [탐색  6] 희소도: 0.9436 -> 파라미터: 0.0290M (감소율: 99.68%)
2026-01-14 13:39:58,793 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,794 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,621 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9358593749999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,621 - INFO - ==================================================
2026-01-14 13:39:59,622 - INFO -   [탐색  7] 희소도: 0.9359 -> 파라미터: 0.0379M (감소율: 99.59%)
2026-01-14 13:39:59,625 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,625 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:00,193 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9397265625)에 맞춰 변경되었습니다.
2026-01-14 13:40:00,193 - INFO - ==================================================
2026-01-14 13:40:00,194 - INFO -   [탐색  8] 희소도: 0.9397 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:00,198 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:00,198 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:00,804 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93779296875)에 맞춰 변경되었습니다.
2026-01-14 13:40:00,804 - INFO - ==================================================
2026-01-14 13:40:00,805 - INFO -   [탐색  9] 희소도: 0.9378 -> 파라미터: 0.0321M (감소율: 99.65%)
2026-01-14 13:40:00,811 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:00,812 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:01,389 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 13:40:01,389 - INFO - ==================================================
2026-01-14 13:40:01,389 - INFO -   [탐색 10] 희소도: 0.9388 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:01,394 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:01,394 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,275 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9392431640625)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,275 - INFO - ==================================================
2026-01-14 13:40:02,276 - INFO -   [탐색 11] 희소도: 0.9392 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:02,279 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,280 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,864 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93948486328125)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,864 - INFO - ==================================================
2026-01-14 13:40:02,865 - INFO -   [탐색 12] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:02,870 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,870 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,417 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939364013671875)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,417 - INFO - ==================================================
2026-01-14 13:40:03,418 - INFO -   [탐색 13] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:03,421 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,421 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,939 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394244384765625)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,940 - INFO - ==================================================
2026-01-14 13:40:03,940 - INFO -   [탐색 14] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:03,943 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,943 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,646 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394546508789063)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,646 - INFO - ==================================================
2026-01-14 13:40:04,647 - INFO -   [탐색 15] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:04,650 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,651 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,193 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394395446777344)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,194 - INFO - ==================================================
2026-01-14 13:40:05,194 - INFO -   [탐색 16] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:05,198 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:05,199 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,839 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394470977783204)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,840 - INFO - ==================================================
2026-01-14 13:40:05,840 - INFO -   [탐색 17] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:05,845 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:05,846 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,482 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394508743286134)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,482 - INFO - ==================================================
2026-01-14 13:40:06,483 - INFO -   [탐색 18] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:06,487 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,487 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,006 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394527626037599)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,007 - INFO - ==================================================
2026-01-14 13:40:07,007 - INFO -   [탐색 19] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:07,011 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,012 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,542 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394537067413331)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,543 - INFO - ==================================================
2026-01-14 13:40:07,543 - INFO -   [탐색 20] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:07,548 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,549 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:08,429 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394532346725465)에 맞춰 변경되었습니다.
2026-01-14 13:40:08,429 - INFO - ==================================================
2026-01-14 13:40:08,430 - INFO -   [탐색 21] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:08,435 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:08,435 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:09,033 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394529986381532)에 맞춰 변경되었습니다.
2026-01-14 13:40:09,033 - INFO - ==================================================
2026-01-14 13:40:09,034 - INFO -   [탐색 22] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:09,038 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:09,038 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:09,566 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531166553499)에 맞춰 변경되었습니다.
2026-01-14 13:40:09,566 - INFO - ==================================================
2026-01-14 13:40:09,567 - INFO -   [탐색 23] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:09,571 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:09,571 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,082 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531756639481)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,083 - INFO - ==================================================
2026-01-14 13:40:10,083 - INFO -   [탐색 24] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:10,086 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:10,086 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453146159649)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,681 - INFO - ==================================================
2026-01-14 13:40:10,681 - INFO -   [탐색 25] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:10,686 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:10,686 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531314074994)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,214 - INFO - ==================================================
2026-01-14 13:40:11,214 - INFO -   [탐색 26] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:11,218 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,218 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,885 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531240314247)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,885 - INFO - ==================================================
2026-01-14 13:40:11,885 - INFO -   [탐색 27] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:11,889 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,889 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,412 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453127719462)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,413 - INFO - ==================================================
2026-01-14 13:40:12,413 - INFO -   [탐색 28] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:12,417 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,417 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,965 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531258754433)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,965 - INFO - ==================================================
2026-01-14 13:40:12,965 - INFO -   [탐색 29] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:12,969 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,969 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,445 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249534339)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,446 - INFO - ==================================================
2026-01-14 13:40:13,446 - INFO -   [탐색 30] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:13,449 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,450 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,965 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531254144386)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,965 - INFO - ==================================================
2026-01-14 13:40:13,965 - INFO -   [탐색 31] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:13,969 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,969 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,553 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531251839362)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,553 - INFO - ==================================================
2026-01-14 13:40:14,554 - INFO -   [탐색 32] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:14,557 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,557 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,056 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250686851)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,056 - INFO - ==================================================
2026-01-14 13:40:15,056 - INFO -   [탐색 33] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:15,060 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,060 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250110595)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,582 - INFO - ==================================================
2026-01-14 13:40:15,582 - INFO -   [탐색 34] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:15,585 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,585 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,332 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249822466)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,332 - INFO - ==================================================
2026-01-14 13:40:16,333 - INFO -   [탐색 35] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:16,335 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,335 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,790 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249966531)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,790 - INFO - ==================================================
2026-01-14 13:40:16,791 - INFO -   [탐색 36] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:16,793 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,794 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,263 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250038562)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,263 - INFO - ==================================================
2026-01-14 13:40:17,264 - INFO -   [탐색 37] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:17,268 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,269 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,804 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250002547)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,805 - INFO - ==================================================
2026-01-14 13:40:17,805 - INFO -   [탐색 38] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:17,810 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,811 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:18,365 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249984539)에 맞춰 변경되었습니다.
2026-01-14 13:40:18,366 - INFO - ==================================================
2026-01-14 13:40:18,366 - INFO -   [탐색 39] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:18,371 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:18,372 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,069 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249993543)에 맞춰 변경되었습니다.
2026-01-14 13:40:19,070 - INFO - ==================================================
2026-01-14 13:40:19,070 - INFO -   [탐색 40] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:19,076 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:19,076 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:19,587 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249998045)에 맞춰 변경되었습니다.
2026-01-14 13:40:19,587 - INFO - ==================================================
2026-01-14 13:40:19,587 - INFO -   [탐색 41] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:19,591 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:19,591 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,340 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000295)에 맞춰 변경되었습니다.
2026-01-14 13:40:20,340 - INFO - ==================================================
2026-01-14 13:40:20,341 - INFO -   [탐색 42] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:20,345 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:20,345 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:20,942 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453124999917)에 맞춰 변경되었습니다.
2026-01-14 13:40:20,942 - INFO - ==================================================
2026-01-14 13:40:20,943 - INFO -   [탐색 43] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:20,947 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:20,948 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:21,587 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999732)에 맞춰 변경되었습니다.
2026-01-14 13:40:21,587 - INFO - ==================================================
2026-01-14 13:40:21,587 - INFO -   [탐색 44] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:21,591 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:21,591 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,128 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000013)에 맞춰 변경되었습니다.
2026-01-14 13:40:22,129 - INFO - ==================================================
2026-01-14 13:40:22,129 - INFO -   [탐색 45] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:22,133 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:22,134 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:22,680 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999873)에 맞춰 변경되었습니다.
2026-01-14 13:40:22,681 - INFO - ==================================================
2026-01-14 13:40:22,682 - INFO -   [탐색 46] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:22,687 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:22,687 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:23,301 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999943)에 맞춰 변경되었습니다.
2026-01-14 13:40:23,301 - INFO - ==================================================
2026-01-14 13:40:23,301 - INFO -   [탐색 47] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:23,305 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:23,305 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:24,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999978)에 맞춰 변경되었습니다.
2026-01-14 13:40:24,047 - INFO - ==================================================
2026-01-14 13:40:24,047 - INFO -   [탐색 48] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:24,050 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:24,051 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:24,662 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999996)에 맞춰 변경되었습니다.
2026-01-14 13:40:24,664 - INFO - ==================================================
2026-01-14 13:40:24,664 - INFO -   [탐색 49] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:24,668 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:24,669 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,200 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000004)에 맞춰 변경되었습니다.
2026-01-14 13:40:25,200 - INFO - ==================================================
2026-01-14 13:40:25,201 - INFO -   [탐색 50] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:25,205 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:25,205 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:25,764 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:25,764 - INFO - ==================================================
2026-01-14 13:40:25,765 - INFO -   [탐색 51] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:25,769 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:25,769 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:26,384 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000002)에 맞춰 변경되었습니다.
2026-01-14 13:40:26,384 - INFO - ==================================================
2026-01-14 13:40:26,385 - INFO -   [탐색 52] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:26,389 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:26,390 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,294 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000001)에 맞춰 변경되었습니다.
2026-01-14 13:40:27,295 - INFO - ==================================================
2026-01-14 13:40:27,295 - INFO -   [탐색 53] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 13:40:27,299 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:27,299 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:27,913 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:27,913 - INFO - ==================================================
2026-01-14 13:40:27,914 - INFO -   [탐색 54] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:27,919 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:27,920 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:28,512 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:28,512 - INFO - ==================================================
2026-01-14 13:40:28,513 - INFO -   [탐색 55] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:28,518 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:28,519 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,164 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:29,165 - INFO - ==================================================
2026-01-14 13:40:29,166 - INFO -   [탐색 56] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:29,171 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:29,172 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:29,980 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:29,981 - INFO - ==================================================
2026-01-14 13:40:29,981 - INFO -   [탐색 57] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:29,984 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:29,984 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:30,458 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:30,458 - INFO - ==================================================
2026-01-14 13:40:30,459 - INFO -   [탐색 58] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:30,462 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:30,462 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,052 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:31,052 - INFO - ==================================================
2026-01-14 13:40:31,053 - INFO -   [탐색 59] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:31,057 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:31,058 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:31,625 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:31,626 - INFO - ==================================================
2026-01-14 13:40:31,627 - INFO -   [탐색 60] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:31,630 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:31,630 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:32,351 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:32,351 - INFO - ==================================================
2026-01-14 13:40:32,352 - INFO -   [탐색 61] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:32,356 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:32,357 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:32,988 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:32,989 - INFO - ==================================================
2026-01-14 13:40:32,990 - INFO -   [탐색 62] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:32,993 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:32,993 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:33,638 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:33,639 - INFO - ==================================================
2026-01-14 13:40:33,639 - INFO -   [탐색 63] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:33,644 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:33,644 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:34,381 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:34,381 - INFO - ==================================================
2026-01-14 13:40:34,382 - INFO -   [탐색 64] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:34,387 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:34,388 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,290 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:35,290 - INFO - ==================================================
2026-01-14 13:40:35,290 - INFO -   [탐색 65] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:35,295 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:35,295 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:35,796 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:35,796 - INFO - ==================================================
2026-01-14 13:40:35,797 - INFO -   [탐색 66] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:35,800 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:35,800 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,392 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:36,392 - INFO - ==================================================
2026-01-14 13:40:36,393 - INFO -   [탐색 67] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:36,397 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:36,398 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:36,931 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:36,932 - INFO - ==================================================
2026-01-14 13:40:36,932 - INFO -   [탐색 68] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:36,935 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:36,935 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:37,691 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:37,692 - INFO - ==================================================
2026-01-14 13:40:37,692 - INFO -   [탐색 69] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:37,698 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:37,698 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:38,407 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:38,407 - INFO - ==================================================
2026-01-14 13:40:38,408 - INFO -   [탐색 70] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:38,412 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:38,412 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:39,047 - INFO - ==================================================
2026-01-14 13:40:39,047 - INFO -   [탐색 71] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:39,051 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:39,051 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:39,788 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:39,789 - INFO - ==================================================
2026-01-14 13:40:39,789 - INFO -   [탐색 72] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:39,793 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:39,794 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:40,897 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:40,897 - INFO - ==================================================
2026-01-14 13:40:40,899 - INFO -   [탐색 73] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:40,904 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:40,905 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:41,635 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:41,636 - INFO - ==================================================
2026-01-14 13:40:41,636 - INFO -   [탐색 74] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:41,641 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:41,643 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,216 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:42,217 - INFO - ==================================================
2026-01-14 13:40:42,217 - INFO -   [탐색 75] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:42,220 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:42,221 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:42,737 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:42,737 - INFO - ==================================================
2026-01-14 13:40:42,738 - INFO -   [탐색 76] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:42,741 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:42,742 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,408 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:43,408 - INFO - ==================================================
2026-01-14 13:40:43,408 - INFO -   [탐색 77] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:43,411 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:43,411 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:43,864 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:43,865 - INFO - ==================================================
2026-01-14 13:40:43,865 - INFO -   [탐색 78] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:43,868 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:43,868 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:44,355 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:44,355 - INFO - ==================================================
2026-01-14 13:40:44,356 - INFO -   [탐색 79] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:44,361 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:44,361 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:44,959 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:44,960 - INFO - ==================================================
2026-01-14 13:40:44,960 - INFO -   [탐색 80] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:44,963 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:44,963 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:45,533 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:45,534 - INFO - ==================================================
2026-01-14 13:40:45,534 - INFO -   [탐색 81] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:45,539 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:45,540 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:46,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:46,214 - INFO - ==================================================
2026-01-14 13:40:46,214 - INFO -   [탐색 82] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:46,220 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:46,220 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,210 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:47,210 - INFO - ==================================================
2026-01-14 13:40:47,211 - INFO -   [탐색 83] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:47,215 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:47,215 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:47,821 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:47,821 - INFO - ==================================================
2026-01-14 13:40:47,822 - INFO -   [탐색 84] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:47,826 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:47,826 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:48,452 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:48,452 - INFO - ==================================================
2026-01-14 13:40:48,452 - INFO -   [탐색 85] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:48,458 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:48,458 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,035 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:49,036 - INFO - ==================================================
2026-01-14 13:40:49,036 - INFO -   [탐색 86] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:49,039 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:49,040 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:49,667 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:49,667 - INFO - ==================================================
2026-01-14 13:40:49,667 - INFO -   [탐색 87] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:49,680 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:49,680 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:50,338 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:50,338 - INFO - ==================================================
2026-01-14 13:40:50,338 - INFO -   [탐색 88] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:50,342 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:50,342 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,206 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:51,207 - INFO - ==================================================
2026-01-14 13:40:51,207 - INFO -   [탐색 89] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:51,213 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:51,214 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:51,785 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:51,785 - INFO - ==================================================
2026-01-14 13:40:51,785 - INFO -   [탐색 90] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:51,788 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:51,788 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:52,269 - INFO - ==================================================
2026-01-14 13:40:52,269 - INFO -   [탐색 91] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:52,273 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:52,274 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:52,977 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:52,977 - INFO - ==================================================
2026-01-14 13:40:52,977 - INFO -   [탐색 92] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:52,982 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:52,982 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:53,735 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:53,735 - INFO - ==================================================
2026-01-14 13:40:53,735 - INFO -   [탐색 93] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:53,740 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:53,740 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:54,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:54,647 - INFO - ==================================================
2026-01-14 13:40:54,648 - INFO -   [탐색 94] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:54,652 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:54,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,305 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:55,306 - INFO - ==================================================
2026-01-14 13:40:55,306 - INFO -   [탐색 95] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:55,311 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:55,312 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:55,955 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:55,956 - INFO - ==================================================
2026-01-14 13:40:55,956 - INFO -   [탐색 96] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:55,961 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:55,961 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:56,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:56,905 - INFO - ==================================================
2026-01-14 13:40:56,906 - INFO -   [탐색 97] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:56,909 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:56,909 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:57,415 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:57,416 - INFO - ==================================================
2026-01-14 13:40:57,416 - INFO -   [탐색 98] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:57,419 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:57,420 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,091 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:58,091 - INFO - ==================================================
2026-01-14 13:40:58,091 - INFO -   [탐색 99] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:58,095 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:58,095 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:58,620 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 13:40:58,621 - INFO - ==================================================
2026-01-14 13:40:58,621 - INFO -   [탐색 100] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 13:40:58,621 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9388 입니다.
2026-01-14 13:40:58,621 - INFO - ================================================================================
2026-01-14 13:40:58,623 - INFO - 계산된 Pruning 정보(희소도: 0.9388)를 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:40:58,628 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:40:58,638 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:58,638 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:59,221 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 13:40:59,223 - INFO - ==================================================
2026-01-14 13:40:59,223 - INFO - ==================================================
2026-01-14 13:40:59,224 - INFO - 모델 파라미터 수:
2026-01-14 13:40:59,224 - INFO -   - 총 파라미터: 31,591 개
2026-01-14 13:40:59,225 - INFO -   - 학습 가능한 파라미터: 31,591 개
2026-01-14 13:40:59,235 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:40:59,246 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1107 GFLOPs로 감소했습니다 (감소율: 96.14%).
2026-01-14 13:40:59,247 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:40:59,247 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:40:59,248 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:40:59,249 - INFO - ==================================================
2026-01-14 13:40:59,249 - INFO - train 모드를 시작합니다.
2026-01-14 13:40:59,249 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:40:59,250 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:40:59,250 - INFO - --------------------------------------------------
2026-01-14 13:40:59,251 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:41:05,329 - INFO - [Train] [11/90] | Loss: 0.6275 | Train Acc: 65.92%
2026-01-14 13:41:06,982 - INFO - [Valid] [11/90] | Loss: 0.6148 | Val Acc: 65.78%
2026-01-14 13:41:06,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.5911 | Recall: 0.8471 | F1: 0.6963
2026-01-14 13:41:06,996 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.4945 | F1: 0.6081
2026-01-14 13:41:07,005 - INFO - [Best Model Saved] (val loss: 0.6148) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:41:07,005 - INFO - --------------------------------------------------
2026-01-14 13:41:07,006 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:41:14,040 - INFO - [Train] [12/90] | Loss: 0.5537 | Train Acc: 76.56%
2026-01-14 13:41:15,983 - INFO - [Valid] [12/90] | Loss: 0.5697 | Val Acc: 73.16%
2026-01-14 13:41:15,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.6964 | Recall: 0.7452 | F1: 0.7200
2026-01-14 13:41:15,992 - INFO - [Metrics for 'normal'] | Precision: 0.7661 | Recall: 0.7198 | F1: 0.7422
2026-01-14 13:41:15,998 - INFO - [Best Model Saved] (val loss: 0.5697) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:41:15,999 - INFO - --------------------------------------------------
2026-01-14 13:41:15,999 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:41:22,754 - INFO - [Train] [13/90] | Loss: 0.5426 | Train Acc: 78.57%
2026-01-14 13:41:24,998 - INFO - [Valid] [13/90] | Loss: 0.5503 | Val Acc: 74.93%
2026-01-14 13:41:25,014 - INFO - [Metrics for 'abnormal'] | Precision: 0.7222 | Recall: 0.7452 | F1: 0.7335
2026-01-14 13:41:25,015 - INFO - [Metrics for 'normal'] | Precision: 0.7740 | Recall: 0.7527 | F1: 0.7632
2026-01-14 13:41:25,025 - INFO - [Best Model Saved] (val loss: 0.5503) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:41:25,026 - INFO - --------------------------------------------------
2026-01-14 13:41:25,027 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:41:32,044 - INFO - [Train] [14/90] | Loss: 0.5205 | Train Acc: 79.69%
2026-01-14 13:41:34,466 - INFO - [Valid] [14/90] | Loss: 0.5511 | Val Acc: 75.22%
2026-01-14 13:41:34,479 - INFO - [Metrics for 'abnormal'] | Precision: 0.7160 | Recall: 0.7707 | F1: 0.7423
2026-01-14 13:41:34,482 - INFO - [Metrics for 'normal'] | Precision: 0.7882 | Recall: 0.7363 | F1: 0.7614
2026-01-14 13:41:34,490 - INFO - --------------------------------------------------
2026-01-14 13:41:34,514 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:41:41,315 - INFO - [Train] [15/90] | Loss: 0.5039 | Train Acc: 81.25%
2026-01-14 13:41:43,215 - INFO - [Valid] [15/90] | Loss: 0.5419 | Val Acc: 75.22%
2026-01-14 13:41:43,229 - INFO - [Metrics for 'abnormal'] | Precision: 0.7239 | Recall: 0.7516 | F1: 0.7375
2026-01-14 13:41:43,230 - INFO - [Metrics for 'normal'] | Precision: 0.7784 | Recall: 0.7527 | F1: 0.7654
2026-01-14 13:41:43,240 - INFO - [Best Model Saved] (val loss: 0.5419) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:41:43,241 - INFO - --------------------------------------------------
2026-01-14 13:41:43,242 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:41:50,778 - INFO - [Train] [16/90] | Loss: 0.5024 | Train Acc: 81.25%
2026-01-14 13:41:52,842 - INFO - [Valid] [16/90] | Loss: 0.5458 | Val Acc: 75.81%
2026-01-14 13:41:52,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.7168 | Recall: 0.7898 | F1: 0.7515
2026-01-14 13:41:52,854 - INFO - [Metrics for 'normal'] | Precision: 0.8012 | Recall: 0.7308 | F1: 0.7644
2026-01-14 13:41:52,858 - INFO - --------------------------------------------------
2026-01-14 13:41:52,859 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:42:00,356 - INFO - [Train] [17/90] | Loss: 0.5039 | Train Acc: 81.40%
2026-01-14 13:42:02,218 - INFO - [Valid] [17/90] | Loss: 0.5431 | Val Acc: 75.22%
2026-01-14 13:42:02,231 - INFO - [Metrics for 'abnormal'] | Precision: 0.7160 | Recall: 0.7707 | F1: 0.7423
2026-01-14 13:42:02,235 - INFO - [Metrics for 'normal'] | Precision: 0.7882 | Recall: 0.7363 | F1: 0.7614
2026-01-14 13:42:02,240 - INFO - --------------------------------------------------
2026-01-14 13:42:02,241 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:42:11,796 - INFO - [Train] [18/90] | Loss: 0.5146 | Train Acc: 80.51%
2026-01-14 13:42:14,599 - INFO - [Valid] [18/90] | Loss: 0.5302 | Val Acc: 76.70%
2026-01-14 13:42:14,612 - INFO - [Metrics for 'abnormal'] | Precision: 0.7294 | Recall: 0.7898 | F1: 0.7584
2026-01-14 13:42:14,613 - INFO - [Metrics for 'normal'] | Precision: 0.8047 | Recall: 0.7473 | F1: 0.7749
2026-01-14 13:42:14,619 - INFO - [Best Model Saved] (val loss: 0.5302) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:42:14,619 - INFO - --------------------------------------------------
2026-01-14 13:42:14,620 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:42:23,325 - INFO - [Train] [19/90] | Loss: 0.5032 | Train Acc: 80.43%
2026-01-14 13:42:26,504 - INFO - [Valid] [19/90] | Loss: 0.5377 | Val Acc: 75.52%
2026-01-14 13:42:26,519 - INFO - [Metrics for 'abnormal'] | Precision: 0.7151 | Recall: 0.7834 | F1: 0.7477
2026-01-14 13:42:26,519 - INFO - [Metrics for 'normal'] | Precision: 0.7964 | Recall: 0.7308 | F1: 0.7622
2026-01-14 13:42:26,523 - INFO - --------------------------------------------------
2026-01-14 13:42:26,525 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:42:35,179 - INFO - [Train] [20/90] | Loss: 0.5010 | Train Acc: 80.80%
2026-01-14 13:42:38,722 - INFO - [Valid] [20/90] | Loss: 0.5322 | Val Acc: 77.29%
2026-01-14 13:42:38,742 - INFO - [Metrics for 'abnormal'] | Precision: 0.7740 | Recall: 0.7197 | F1: 0.7459
2026-01-14 13:42:38,742 - INFO - [Metrics for 'normal'] | Precision: 0.7720 | Recall: 0.8187 | F1: 0.7947
2026-01-14 13:42:38,746 - INFO - --------------------------------------------------
2026-01-14 13:42:38,747 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:42:46,691 - INFO - [Train] [21/90] | Loss: 0.4856 | Train Acc: 82.66%
2026-01-14 13:42:49,527 - INFO - [Valid] [21/90] | Loss: 0.5196 | Val Acc: 77.58%
2026-01-14 13:42:49,549 - INFO - [Metrics for 'abnormal'] | Precision: 0.7832 | Recall: 0.7134 | F1: 0.7467
2026-01-14 13:42:49,552 - INFO - [Metrics for 'normal'] | Precision: 0.7704 | Recall: 0.8297 | F1: 0.7989
2026-01-14 13:42:49,570 - INFO - [Best Model Saved] (val loss: 0.5196) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:42:49,570 - INFO - --------------------------------------------------
2026-01-14 13:42:49,571 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:42:57,845 - INFO - [Train] [22/90] | Loss: 0.4951 | Train Acc: 81.85%
2026-01-14 13:43:00,733 - INFO - [Valid] [22/90] | Loss: 0.5458 | Val Acc: 75.52%
2026-01-14 13:43:00,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.7126 | Recall: 0.7898 | F1: 0.7492
2026-01-14 13:43:00,744 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7253 | F1: 0.7608
2026-01-14 13:43:00,748 - INFO - --------------------------------------------------
2026-01-14 13:43:00,749 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:43:10,363 - INFO - [Train] [23/90] | Loss: 0.5042 | Train Acc: 81.92%
2026-01-14 13:43:14,197 - INFO - [Valid] [23/90] | Loss: 0.5280 | Val Acc: 76.70%
2026-01-14 13:43:14,226 - INFO - [Metrics for 'abnormal'] | Precision: 0.7566 | Recall: 0.7325 | F1: 0.7443
2026-01-14 13:43:14,230 - INFO - [Metrics for 'normal'] | Precision: 0.7754 | Recall: 0.7967 | F1: 0.7859
2026-01-14 13:43:14,239 - INFO - --------------------------------------------------
2026-01-14 13:43:14,240 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:43:22,412 - INFO - [Train] [24/90] | Loss: 0.4984 | Train Acc: 80.95%
2026-01-14 13:43:25,347 - INFO - [Valid] [24/90] | Loss: 0.5165 | Val Acc: 76.40%
2026-01-14 13:43:25,358 - INFO - [Metrics for 'abnormal'] | Precision: 0.7175 | Recall: 0.8089 | F1: 0.7605
2026-01-14 13:43:25,359 - INFO - [Metrics for 'normal'] | Precision: 0.8148 | Recall: 0.7253 | F1: 0.7674
2026-01-14 13:43:25,367 - INFO - [Best Model Saved] (val loss: 0.5165) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:43:25,368 - INFO - --------------------------------------------------
2026-01-14 13:43:25,368 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:43:33,888 - INFO - [Train] [25/90] | Loss: 0.4937 | Train Acc: 82.29%
2026-01-14 13:43:36,339 - INFO - [Valid] [25/90] | Loss: 0.5177 | Val Acc: 79.94%
2026-01-14 13:43:36,350 - INFO - [Metrics for 'abnormal'] | Precision: 0.8156 | Recall: 0.7325 | F1: 0.7718
2026-01-14 13:43:36,350 - INFO - [Metrics for 'normal'] | Precision: 0.7879 | Recall: 0.8571 | F1: 0.8211
2026-01-14 13:43:36,354 - INFO - --------------------------------------------------
2026-01-14 13:43:36,354 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:43:46,089 - INFO - [Train] [26/90] | Loss: 0.4835 | Train Acc: 82.89%
2026-01-14 13:43:48,656 - INFO - [Valid] [26/90] | Loss: 0.5255 | Val Acc: 76.70%
2026-01-14 13:43:48,667 - INFO - [Metrics for 'abnormal'] | Precision: 0.7407 | Recall: 0.7643 | F1: 0.7524
2026-01-14 13:43:48,668 - INFO - [Metrics for 'normal'] | Precision: 0.7910 | Recall: 0.7692 | F1: 0.7799
2026-01-14 13:43:48,672 - INFO - --------------------------------------------------
2026-01-14 13:43:48,673 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:43:57,480 - INFO - [Train] [27/90] | Loss: 0.4846 | Train Acc: 82.66%
2026-01-14 13:44:00,364 - INFO - [Valid] [27/90] | Loss: 0.5348 | Val Acc: 78.47%
2026-01-14 13:44:00,378 - INFO - [Metrics for 'abnormal'] | Precision: 0.8387 | Recall: 0.6624 | F1: 0.7402
2026-01-14 13:44:00,378 - INFO - [Metrics for 'normal'] | Precision: 0.7535 | Recall: 0.8901 | F1: 0.8161
2026-01-14 13:44:00,383 - INFO - --------------------------------------------------
2026-01-14 13:44:00,384 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:44:08,556 - INFO - [Train] [28/90] | Loss: 0.4896 | Train Acc: 82.14%
2026-01-14 13:44:11,473 - INFO - [Valid] [28/90] | Loss: 0.5237 | Val Acc: 76.99%
2026-01-14 13:44:11,499 - INFO - [Metrics for 'abnormal'] | Precision: 0.7207 | Recall: 0.8217 | F1: 0.7679
2026-01-14 13:44:11,503 - INFO - [Metrics for 'normal'] | Precision: 0.8250 | Recall: 0.7253 | F1: 0.7719
2026-01-14 13:44:11,507 - INFO - --------------------------------------------------
2026-01-14 13:44:11,507 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:44:19,483 - INFO - [Train] [29/90] | Loss: 0.4914 | Train Acc: 82.29%
2026-01-14 13:44:22,033 - INFO - [Valid] [29/90] | Loss: 0.5317 | Val Acc: 79.65%
2026-01-14 13:44:22,057 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.7134 | F1: 0.7645
2026-01-14 13:44:22,058 - INFO - [Metrics for 'normal'] | Precision: 0.7783 | Recall: 0.8681 | F1: 0.8208
2026-01-14 13:44:22,063 - INFO - --------------------------------------------------
2026-01-14 13:44:22,064 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:44:31,766 - INFO - [Train] [30/90] | Loss: 0.4795 | Train Acc: 82.81%
2026-01-14 13:44:33,916 - INFO - [Valid] [30/90] | Loss: 0.5238 | Val Acc: 78.47%
2026-01-14 13:44:33,948 - INFO - [Metrics for 'abnormal'] | Precision: 0.8231 | Recall: 0.6815 | F1: 0.7456
2026-01-14 13:44:33,948 - INFO - [Metrics for 'normal'] | Precision: 0.7608 | Recall: 0.8736 | F1: 0.8133
2026-01-14 13:44:33,960 - INFO - --------------------------------------------------
2026-01-14 13:44:33,960 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:44:43,155 - INFO - [Train] [31/90] | Loss: 0.4802 | Train Acc: 83.33%
2026-01-14 13:44:45,240 - INFO - [Valid] [31/90] | Loss: 0.5175 | Val Acc: 78.47%
2026-01-14 13:44:45,276 - INFO - [Metrics for 'abnormal'] | Precision: 0.7877 | Recall: 0.7325 | F1: 0.7591
2026-01-14 13:44:45,276 - INFO - [Metrics for 'normal'] | Precision: 0.7824 | Recall: 0.8297 | F1: 0.8053
2026-01-14 13:44:45,283 - INFO - --------------------------------------------------
2026-01-14 13:44:45,283 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:44:53,405 - INFO - [Train] [32/90] | Loss: 0.4765 | Train Acc: 82.22%
2026-01-14 13:44:55,997 - INFO - [Valid] [32/90] | Loss: 0.5138 | Val Acc: 78.76%
2026-01-14 13:44:56,010 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-01-14 13:44:56,011 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-01-14 13:44:56,020 - INFO - [Best Model Saved] (val loss: 0.5138) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:44:56,020 - INFO - --------------------------------------------------
2026-01-14 13:44:56,021 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:45:05,859 - INFO - [Train] [33/90] | Loss: 0.4748 | Train Acc: 82.89%
2026-01-14 13:45:08,493 - INFO - [Valid] [33/90] | Loss: 0.5115 | Val Acc: 78.47%
2026-01-14 13:45:08,502 - INFO - [Metrics for 'abnormal'] | Precision: 0.7561 | Recall: 0.7898 | F1: 0.7726
2026-01-14 13:45:08,502 - INFO - [Metrics for 'normal'] | Precision: 0.8114 | Recall: 0.7802 | F1: 0.7955
2026-01-14 13:45:08,507 - INFO - [Best Model Saved] (val loss: 0.5115) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:45:08,508 - INFO - --------------------------------------------------
2026-01-14 13:45:08,508 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:45:18,283 - INFO - [Train] [34/90] | Loss: 0.4771 | Train Acc: 82.29%
2026-01-14 13:45:21,384 - INFO - [Valid] [34/90] | Loss: 0.5120 | Val Acc: 79.35%
2026-01-14 13:45:21,408 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7389 | F1: 0.7682
2026-01-14 13:45:21,412 - INFO - [Metrics for 'normal'] | Precision: 0.7887 | Recall: 0.8407 | F1: 0.8138
2026-01-14 13:45:21,420 - INFO - --------------------------------------------------
2026-01-14 13:45:21,420 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:45:31,305 - INFO - [Train] [35/90] | Loss: 0.4705 | Train Acc: 83.56%
2026-01-14 13:45:33,892 - INFO - [Valid] [35/90] | Loss: 0.5128 | Val Acc: 80.83%
2026-01-14 13:45:33,917 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 13:45:33,918 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 13:45:33,927 - INFO - --------------------------------------------------
2026-01-14 13:45:33,931 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:45:42,533 - INFO - [Train] [36/90] | Loss: 0.4590 | Train Acc: 84.15%
2026-01-14 13:45:45,054 - INFO - [Valid] [36/90] | Loss: 0.5077 | Val Acc: 78.47%
2026-01-14 13:45:45,068 - INFO - [Metrics for 'abnormal'] | Precision: 0.7561 | Recall: 0.7898 | F1: 0.7726
2026-01-14 13:45:45,068 - INFO - [Metrics for 'normal'] | Precision: 0.8114 | Recall: 0.7802 | F1: 0.7955
2026-01-14 13:45:45,078 - INFO - [Best Model Saved] (val loss: 0.5077) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:45:45,079 - INFO - --------------------------------------------------
2026-01-14 13:45:45,079 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:45:53,875 - INFO - [Train] [37/90] | Loss: 0.4580 | Train Acc: 84.45%
2026-01-14 13:45:56,584 - INFO - [Valid] [37/90] | Loss: 0.5071 | Val Acc: 81.42%
2026-01-14 13:45:56,595 - INFO - [Metrics for 'abnormal'] | Precision: 0.8219 | Recall: 0.7643 | F1: 0.7921
2026-01-14 13:45:56,595 - INFO - [Metrics for 'normal'] | Precision: 0.8083 | Recall: 0.8571 | F1: 0.8320
2026-01-14 13:45:56,626 - INFO - [Best Model Saved] (val loss: 0.5071) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:45:56,626 - INFO - --------------------------------------------------
2026-01-14 13:45:56,626 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:46:06,377 - INFO - [Train] [38/90] | Loss: 0.4754 | Train Acc: 83.11%
2026-01-14 13:46:08,762 - INFO - [Valid] [38/90] | Loss: 0.4916 | Val Acc: 81.12%
2026-01-14 13:46:08,773 - INFO - [Metrics for 'abnormal'] | Precision: 0.8252 | Recall: 0.7516 | F1: 0.7867
2026-01-14 13:46:08,773 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8626 | F1: 0.8307
2026-01-14 13:46:08,783 - INFO - [Best Model Saved] (val loss: 0.4916) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:46:08,784 - INFO - --------------------------------------------------
2026-01-14 13:46:08,784 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:46:17,163 - INFO - [Train] [39/90] | Loss: 0.4565 | Train Acc: 84.52%
2026-01-14 13:46:20,407 - INFO - [Valid] [39/90] | Loss: 0.4966 | Val Acc: 80.83%
2026-01-14 13:46:20,440 - INFO - [Metrics for 'abnormal'] | Precision: 0.8108 | Recall: 0.7643 | F1: 0.7869
2026-01-14 13:46:20,446 - INFO - [Metrics for 'normal'] | Precision: 0.8063 | Recall: 0.8462 | F1: 0.8257
2026-01-14 13:46:20,449 - INFO - --------------------------------------------------
2026-01-14 13:46:20,454 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:46:28,830 - INFO - [Train] [40/90] | Loss: 0.4613 | Train Acc: 84.30%
2026-01-14 13:46:31,914 - INFO - [Valid] [40/90] | Loss: 0.4915 | Val Acc: 80.53%
2026-01-14 13:46:31,926 - INFO - [Metrics for 'abnormal'] | Precision: 0.8138 | Recall: 0.7516 | F1: 0.7815
2026-01-14 13:46:31,927 - INFO - [Metrics for 'normal'] | Precision: 0.7990 | Recall: 0.8516 | F1: 0.8245
2026-01-14 13:46:31,935 - INFO - [Best Model Saved] (val loss: 0.4915) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:46:31,936 - INFO - --------------------------------------------------
2026-01-14 13:46:31,936 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:46:39,992 - INFO - [Train] [41/90] | Loss: 0.4556 | Train Acc: 83.78%
2026-01-14 13:46:43,092 - INFO - [Valid] [41/90] | Loss: 0.4928 | Val Acc: 79.94%
2026-01-14 13:46:43,110 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-01-14 13:46:43,111 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-01-14 13:46:43,116 - INFO - --------------------------------------------------
2026-01-14 13:46:43,117 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:46:50,897 - INFO - [Train] [42/90] | Loss: 0.4446 | Train Acc: 84.82%
2026-01-14 13:46:53,980 - INFO - [Valid] [42/90] | Loss: 0.4933 | Val Acc: 79.94%
2026-01-14 13:46:53,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 13:46:53,992 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 13:46:53,996 - INFO - --------------------------------------------------
2026-01-14 13:46:53,997 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:47:02,481 - INFO - [Train] [43/90] | Loss: 0.4464 | Train Acc: 84.82%
2026-01-14 13:47:05,246 - INFO - [Valid] [43/90] | Loss: 0.4900 | Val Acc: 80.53%
2026-01-14 13:47:05,269 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.7580 | F1: 0.7829
2026-01-14 13:47:05,277 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8462 | F1: 0.8235
2026-01-14 13:47:05,295 - INFO - [Best Model Saved] (val loss: 0.4900) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:47:05,295 - INFO - --------------------------------------------------
2026-01-14 13:47:05,296 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:47:14,355 - INFO - [Train] [44/90] | Loss: 0.4546 | Train Acc: 84.45%
2026-01-14 13:47:17,033 - INFO - [Valid] [44/90] | Loss: 0.4944 | Val Acc: 79.94%
2026-01-14 13:47:17,067 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-01-14 13:47:17,067 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-01-14 13:47:17,078 - INFO - --------------------------------------------------
2026-01-14 13:47:17,079 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:47:27,593 - INFO - [Train] [45/90] | Loss: 0.4506 | Train Acc: 85.57%
2026-01-14 13:47:30,161 - INFO - [Valid] [45/90] | Loss: 0.4933 | Val Acc: 79.06%
2026-01-14 13:47:30,176 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-01-14 13:47:30,177 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-01-14 13:47:30,182 - INFO - --------------------------------------------------
2026-01-14 13:47:30,183 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:47:38,690 - INFO - [Train] [46/90] | Loss: 0.4448 | Train Acc: 84.90%
2026-01-14 13:47:41,493 - INFO - [Valid] [46/90] | Loss: 0.5175 | Val Acc: 76.11%
2026-01-14 13:47:41,506 - INFO - [Metrics for 'abnormal'] | Precision: 0.7043 | Recall: 0.8344 | F1: 0.7638
2026-01-14 13:47:41,508 - INFO - [Metrics for 'normal'] | Precision: 0.8301 | Recall: 0.6978 | F1: 0.7582
2026-01-14 13:47:41,512 - INFO - --------------------------------------------------
2026-01-14 13:47:41,513 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:47:50,313 - INFO - [Train] [47/90] | Loss: 0.4409 | Train Acc: 85.94%
2026-01-14 13:47:52,563 - INFO - [Valid] [47/90] | Loss: 0.5015 | Val Acc: 80.83%
2026-01-14 13:47:52,575 - INFO - [Metrics for 'abnormal'] | Precision: 0.8286 | Recall: 0.7389 | F1: 0.7811
2026-01-14 13:47:52,576 - INFO - [Metrics for 'normal'] | Precision: 0.7940 | Recall: 0.8681 | F1: 0.8294
2026-01-14 13:47:52,580 - INFO - --------------------------------------------------
2026-01-14 13:47:52,581 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:48:00,912 - INFO - [Train] [48/90] | Loss: 0.4418 | Train Acc: 84.52%
2026-01-14 13:48:03,767 - INFO - [Valid] [48/90] | Loss: 0.5012 | Val Acc: 79.94%
2026-01-14 13:48:03,802 - INFO - [Metrics for 'abnormal'] | Precision: 0.7602 | Recall: 0.8280 | F1: 0.7927
2026-01-14 13:48:03,803 - INFO - [Metrics for 'normal'] | Precision: 0.8393 | Recall: 0.7747 | F1: 0.8057
2026-01-14 13:48:03,812 - INFO - --------------------------------------------------
2026-01-14 13:48:03,815 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:48:13,367 - INFO - [Train] [49/90] | Loss: 0.4441 | Train Acc: 85.27%
2026-01-14 13:48:15,863 - INFO - [Valid] [49/90] | Loss: 0.4948 | Val Acc: 78.47%
2026-01-14 13:48:15,878 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8025 | F1: 0.7754
2026-01-14 13:48:15,879 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.7692 | F1: 0.7932
2026-01-14 13:48:15,884 - INFO - --------------------------------------------------
2026-01-14 13:48:15,884 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:48:24,207 - INFO - [Train] [50/90] | Loss: 0.4335 | Train Acc: 86.38%
2026-01-14 13:48:26,970 - INFO - [Valid] [50/90] | Loss: 0.4906 | Val Acc: 80.53%
2026-01-14 13:48:26,983 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7962 | F1: 0.7911
2026-01-14 13:48:26,984 - INFO - [Metrics for 'normal'] | Precision: 0.8222 | Recall: 0.8132 | F1: 0.8177
2026-01-14 13:48:26,989 - INFO - --------------------------------------------------
2026-01-14 13:48:26,990 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:48:35,445 - INFO - [Train] [51/90] | Loss: 0.4305 | Train Acc: 85.94%
2026-01-14 13:48:38,778 - INFO - [Valid] [51/90] | Loss: 0.4864 | Val Acc: 81.12%
2026-01-14 13:48:38,789 - INFO - [Metrics for 'abnormal'] | Precision: 0.8163 | Recall: 0.7643 | F1: 0.7895
2026-01-14 13:48:38,790 - INFO - [Metrics for 'normal'] | Precision: 0.8073 | Recall: 0.8516 | F1: 0.8289
2026-01-14 13:48:38,799 - INFO - [Best Model Saved] (val loss: 0.4864) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:48:38,800 - INFO - --------------------------------------------------
2026-01-14 13:48:38,801 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:48:46,137 - INFO - [Train] [52/90] | Loss: 0.4273 | Train Acc: 85.86%
2026-01-14 13:48:48,507 - INFO - [Valid] [52/90] | Loss: 0.5060 | Val Acc: 80.24%
2026-01-14 13:48:48,516 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 13:48:48,517 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 13:48:48,520 - INFO - --------------------------------------------------
2026-01-14 13:48:48,521 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:48:56,860 - INFO - [Train] [53/90] | Loss: 0.4305 | Train Acc: 86.01%
2026-01-14 13:49:00,100 - INFO - [Valid] [53/90] | Loss: 0.4902 | Val Acc: 80.24%
2026-01-14 13:49:00,113 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:49:00,114 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:49:00,118 - INFO - --------------------------------------------------
2026-01-14 13:49:00,119 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:49:08,272 - INFO - [Train] [54/90] | Loss: 0.4316 | Train Acc: 86.24%
2026-01-14 13:49:10,964 - INFO - [Valid] [54/90] | Loss: 0.4925 | Val Acc: 80.24%
2026-01-14 13:49:10,975 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 13:49:10,975 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 13:49:10,980 - INFO - --------------------------------------------------
2026-01-14 13:49:10,981 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:49:19,727 - INFO - [Train] [55/90] | Loss: 0.4227 | Train Acc: 86.09%
2026-01-14 13:49:24,107 - INFO - [Valid] [55/90] | Loss: 0.4903 | Val Acc: 80.83%
2026-01-14 13:49:24,130 - INFO - [Metrics for 'abnormal'] | Precision: 0.8026 | Recall: 0.7771 | F1: 0.7896
2026-01-14 13:49:24,133 - INFO - [Metrics for 'normal'] | Precision: 0.8128 | Recall: 0.8352 | F1: 0.8238
2026-01-14 13:49:24,137 - INFO - --------------------------------------------------
2026-01-14 13:49:24,141 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:49:32,751 - INFO - [Train] [56/90] | Loss: 0.4254 | Train Acc: 86.61%
2026-01-14 13:49:36,751 - INFO - [Valid] [56/90] | Loss: 0.4908 | Val Acc: 81.12%
2026-01-14 13:49:36,764 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 13:49:36,765 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 13:49:36,769 - INFO - --------------------------------------------------
2026-01-14 13:49:36,770 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:49:45,001 - INFO - [Train] [57/90] | Loss: 0.4290 | Train Acc: 86.16%
2026-01-14 13:49:47,788 - INFO - [Valid] [57/90] | Loss: 0.5083 | Val Acc: 78.17%
2026-01-14 13:49:47,808 - INFO - [Metrics for 'abnormal'] | Precision: 0.7318 | Recall: 0.8344 | F1: 0.7798
2026-01-14 13:49:47,817 - INFO - [Metrics for 'normal'] | Precision: 0.8375 | Recall: 0.7363 | F1: 0.7836
2026-01-14 13:49:47,822 - INFO - --------------------------------------------------
2026-01-14 13:49:47,823 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:49:56,925 - INFO - [Train] [58/90] | Loss: 0.4193 | Train Acc: 87.35%
2026-01-14 13:49:59,260 - INFO - [Valid] [58/90] | Loss: 0.4876 | Val Acc: 79.94%
2026-01-14 13:49:59,268 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-01-14 13:49:59,269 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-01-14 13:49:59,272 - INFO - --------------------------------------------------
2026-01-14 13:49:59,272 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:50:08,653 - INFO - [Train] [59/90] | Loss: 0.4141 | Train Acc: 86.98%
2026-01-14 13:50:10,924 - INFO - [Valid] [59/90] | Loss: 0.4901 | Val Acc: 79.94%
2026-01-14 13:50:10,964 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 13:50:10,964 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 13:50:10,973 - INFO - --------------------------------------------------
2026-01-14 13:50:10,975 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:50:20,166 - INFO - [Train] [60/90] | Loss: 0.4267 | Train Acc: 85.94%
2026-01-14 13:50:22,046 - INFO - [Valid] [60/90] | Loss: 0.4890 | Val Acc: 79.65%
2026-01-14 13:50:22,058 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-01-14 13:50:22,059 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-01-14 13:50:22,063 - INFO - --------------------------------------------------
2026-01-14 13:50:22,064 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:50:31,630 - INFO - [Train] [61/90] | Loss: 0.4173 | Train Acc: 86.90%
2026-01-14 13:50:33,959 - INFO - [Valid] [61/90] | Loss: 0.4891 | Val Acc: 79.65%
2026-01-14 13:50:33,968 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-01-14 13:50:33,969 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-01-14 13:50:33,973 - INFO - --------------------------------------------------
2026-01-14 13:50:33,974 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:50:43,556 - INFO - [Train] [62/90] | Loss: 0.4274 | Train Acc: 86.83%
2026-01-14 13:50:45,902 - INFO - [Valid] [62/90] | Loss: 0.4825 | Val Acc: 80.83%
2026-01-14 13:50:45,911 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 13:50:45,911 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 13:50:45,917 - INFO - [Best Model Saved] (val loss: 0.4825) -> 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:50:45,917 - INFO - --------------------------------------------------
2026-01-14 13:50:45,917 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:50:55,241 - INFO - [Train] [63/90] | Loss: 0.4114 | Train Acc: 87.20%
2026-01-14 13:50:57,719 - INFO - [Valid] [63/90] | Loss: 0.4945 | Val Acc: 81.12%
2026-01-14 13:50:57,737 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 13:50:57,739 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 13:50:57,742 - INFO - --------------------------------------------------
2026-01-14 13:50:57,743 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:51:06,548 - INFO - [Train] [64/90] | Loss: 0.4032 | Train Acc: 88.10%
2026-01-14 13:51:09,024 - INFO - [Valid] [64/90] | Loss: 0.4882 | Val Acc: 81.12%
2026-01-14 13:51:09,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 13:51:09,037 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 13:51:09,041 - INFO - --------------------------------------------------
2026-01-14 13:51:09,045 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:51:17,959 - INFO - [Train] [65/90] | Loss: 0.4039 | Train Acc: 87.43%
2026-01-14 13:51:20,095 - INFO - [Valid] [65/90] | Loss: 0.4969 | Val Acc: 80.24%
2026-01-14 13:51:20,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 13:51:20,126 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 13:51:20,130 - INFO - --------------------------------------------------
2026-01-14 13:51:20,131 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:51:29,122 - INFO - [Train] [66/90] | Loss: 0.4072 | Train Acc: 87.65%
2026-01-14 13:51:31,957 - INFO - [Valid] [66/90] | Loss: 0.4943 | Val Acc: 77.88%
2026-01-14 13:51:31,969 - INFO - [Metrics for 'abnormal'] | Precision: 0.7303 | Recall: 0.8280 | F1: 0.7761
2026-01-14 13:51:31,970 - INFO - [Metrics for 'normal'] | Precision: 0.8323 | Recall: 0.7363 | F1: 0.7813
2026-01-14 13:51:31,974 - INFO - --------------------------------------------------
2026-01-14 13:51:31,975 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:51:42,035 - INFO - [Train] [67/90] | Loss: 0.4124 | Train Acc: 87.35%
2026-01-14 13:51:44,243 - INFO - [Valid] [67/90] | Loss: 0.4898 | Val Acc: 81.12%
2026-01-14 13:51:44,252 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 13:51:44,253 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 13:51:44,256 - INFO - --------------------------------------------------
2026-01-14 13:51:44,256 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:51:53,615 - INFO - [Train] [68/90] | Loss: 0.4113 | Train Acc: 87.95%
2026-01-14 13:51:56,136 - INFO - [Valid] [68/90] | Loss: 0.4855 | Val Acc: 79.94%
2026-01-14 13:51:56,146 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 13:51:56,147 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 13:51:56,151 - INFO - --------------------------------------------------
2026-01-14 13:51:56,152 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:52:04,677 - INFO - [Train] [69/90] | Loss: 0.4147 | Train Acc: 87.50%
2026-01-14 13:52:07,377 - INFO - [Valid] [69/90] | Loss: 0.4922 | Val Acc: 80.24%
2026-01-14 13:52:07,423 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-01-14 13:52:07,426 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-01-14 13:52:07,439 - INFO - --------------------------------------------------
2026-01-14 13:52:07,440 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:52:16,877 - INFO - [Train] [70/90] | Loss: 0.4122 | Train Acc: 88.10%
2026-01-14 13:52:19,061 - INFO - [Valid] [70/90] | Loss: 0.4892 | Val Acc: 80.24%
2026-01-14 13:52:19,069 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-01-14 13:52:19,070 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-01-14 13:52:19,073 - INFO - --------------------------------------------------
2026-01-14 13:52:19,074 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:52:28,387 - INFO - [Train] [71/90] | Loss: 0.3991 | Train Acc: 88.62%
2026-01-14 13:52:30,514 - INFO - [Valid] [71/90] | Loss: 0.4938 | Val Acc: 79.65%
2026-01-14 13:52:30,524 - INFO - [Metrics for 'abnormal'] | Precision: 0.7558 | Recall: 0.8280 | F1: 0.7903
2026-01-14 13:52:30,524 - INFO - [Metrics for 'normal'] | Precision: 0.8383 | Recall: 0.7692 | F1: 0.8023
2026-01-14 13:52:30,527 - INFO - --------------------------------------------------
2026-01-14 13:52:30,527 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:52:38,929 - INFO - [Train] [72/90] | Loss: 0.4014 | Train Acc: 88.24%
2026-01-14 13:52:41,302 - INFO - [Valid] [72/90] | Loss: 0.5006 | Val Acc: 78.76%
2026-01-14 13:52:41,314 - INFO - [Metrics for 'abnormal'] | Precision: 0.7374 | Recall: 0.8408 | F1: 0.7857
2026-01-14 13:52:41,314 - INFO - [Metrics for 'normal'] | Precision: 0.8438 | Recall: 0.7418 | F1: 0.7895
2026-01-14 13:52:41,318 - INFO - --------------------------------------------------
2026-01-14 13:52:41,319 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:52:50,014 - INFO - [Train] [73/90] | Loss: 0.4060 | Train Acc: 87.95%
2026-01-14 13:52:52,646 - INFO - [Valid] [73/90] | Loss: 0.4924 | Val Acc: 80.24%
2026-01-14 13:52:52,663 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 13:52:52,667 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 13:52:52,670 - INFO - --------------------------------------------------
2026-01-14 13:52:52,674 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:53:01,269 - INFO - [Train] [74/90] | Loss: 0.4007 | Train Acc: 88.17%
2026-01-14 13:53:04,969 - INFO - [Valid] [74/90] | Loss: 0.4908 | Val Acc: 79.65%
2026-01-14 13:53:05,019 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-01-14 13:53:05,019 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-01-14 13:53:05,023 - INFO - --------------------------------------------------
2026-01-14 13:53:05,023 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:53:14,729 - INFO - [Train] [75/90] | Loss: 0.3948 | Train Acc: 88.76%
2026-01-14 13:53:17,267 - INFO - [Valid] [75/90] | Loss: 0.4882 | Val Acc: 80.24%
2026-01-14 13:53:17,292 - INFO - [Metrics for 'abnormal'] | Precision: 0.7744 | Recall: 0.8089 | F1: 0.7913
2026-01-14 13:53:17,293 - INFO - [Metrics for 'normal'] | Precision: 0.8286 | Recall: 0.7967 | F1: 0.8123
2026-01-14 13:53:17,302 - INFO - --------------------------------------------------
2026-01-14 13:53:17,305 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:53:25,242 - INFO - [Train] [76/90] | Loss: 0.3959 | Train Acc: 88.54%
2026-01-14 13:53:28,050 - INFO - [Valid] [76/90] | Loss: 0.4890 | Val Acc: 80.83%
2026-01-14 13:53:28,060 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 13:53:28,061 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 13:53:28,064 - INFO - --------------------------------------------------
2026-01-14 13:53:28,064 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:53:36,726 - INFO - [Train] [77/90] | Loss: 0.4003 | Train Acc: 88.24%
2026-01-14 13:53:40,053 - INFO - [Valid] [77/90] | Loss: 0.4911 | Val Acc: 79.65%
2026-01-14 13:53:40,066 - INFO - [Metrics for 'abnormal'] | Precision: 0.7558 | Recall: 0.8280 | F1: 0.7903
2026-01-14 13:53:40,067 - INFO - [Metrics for 'normal'] | Precision: 0.8383 | Recall: 0.7692 | F1: 0.8023
2026-01-14 13:53:40,071 - INFO - --------------------------------------------------
2026-01-14 13:53:40,072 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:53:47,935 - INFO - [Train] [78/90] | Loss: 0.4050 | Train Acc: 87.87%
2026-01-14 13:53:51,115 - INFO - [Valid] [78/90] | Loss: 0.4851 | Val Acc: 79.65%
2026-01-14 13:53:51,139 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-01-14 13:53:51,139 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-01-14 13:53:51,147 - INFO - --------------------------------------------------
2026-01-14 13:53:51,148 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:53:59,582 - INFO - [Train] [79/90] | Loss: 0.4061 | Train Acc: 87.65%
2026-01-14 13:54:02,923 - INFO - [Valid] [79/90] | Loss: 0.4848 | Val Acc: 81.42%
2026-01-14 13:54:02,948 - INFO - [Metrics for 'abnormal'] | Precision: 0.7798 | Recall: 0.8344 | F1: 0.8062
2026-01-14 13:54:02,948 - INFO - [Metrics for 'normal'] | Precision: 0.8480 | Recall: 0.7967 | F1: 0.8215
2026-01-14 13:54:02,957 - INFO - --------------------------------------------------
2026-01-14 13:54:02,958 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:54:10,791 - INFO - [Train] [80/90] | Loss: 0.4033 | Train Acc: 89.14%
2026-01-14 13:54:13,829 - INFO - [Valid] [80/90] | Loss: 0.4838 | Val Acc: 81.12%
2026-01-14 13:54:13,855 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 13:54:13,856 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 13:54:13,865 - INFO - --------------------------------------------------
2026-01-14 13:54:13,869 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:54:21,729 - INFO - [Train] [81/90] | Loss: 0.4026 | Train Acc: 88.02%
2026-01-14 13:54:24,837 - INFO - [Valid] [81/90] | Loss: 0.4905 | Val Acc: 78.76%
2026-01-14 13:54:24,848 - INFO - [Metrics for 'abnormal'] | Precision: 0.7374 | Recall: 0.8408 | F1: 0.7857
2026-01-14 13:54:24,849 - INFO - [Metrics for 'normal'] | Precision: 0.8438 | Recall: 0.7418 | F1: 0.7895
2026-01-14 13:54:24,854 - INFO - --------------------------------------------------
2026-01-14 13:54:24,855 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:54:34,514 - INFO - [Train] [82/90] | Loss: 0.3943 | Train Acc: 88.54%
2026-01-14 13:54:36,975 - INFO - [Valid] [82/90] | Loss: 0.4935 | Val Acc: 79.35%
2026-01-14 13:54:36,987 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8280 | F1: 0.7879
2026-01-14 13:54:36,988 - INFO - [Metrics for 'normal'] | Precision: 0.8373 | Recall: 0.7637 | F1: 0.7989
2026-01-14 13:54:36,993 - INFO - --------------------------------------------------
2026-01-14 13:54:36,994 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:54:45,101 - INFO - [Train] [83/90] | Loss: 0.3937 | Train Acc: 88.62%
2026-01-14 13:54:47,982 - INFO - [Valid] [83/90] | Loss: 0.4894 | Val Acc: 81.42%
2026-01-14 13:54:47,994 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 13:54:47,995 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 13:54:47,999 - INFO - --------------------------------------------------
2026-01-14 13:54:48,000 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:54:56,600 - INFO - [Train] [84/90] | Loss: 0.3990 | Train Acc: 88.91%
2026-01-14 13:54:58,938 - INFO - [Valid] [84/90] | Loss: 0.4892 | Val Acc: 80.83%
2026-01-14 13:54:58,961 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 13:54:58,961 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 13:54:58,966 - INFO - --------------------------------------------------
2026-01-14 13:54:58,967 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:55:07,781 - INFO - [Train] [85/90] | Loss: 0.3950 | Train Acc: 89.66%
2026-01-14 13:55:10,077 - INFO - [Valid] [85/90] | Loss: 0.4907 | Val Acc: 78.47%
2026-01-14 13:55:10,180 - INFO - [Metrics for 'abnormal'] | Precision: 0.7386 | Recall: 0.8280 | F1: 0.7808
2026-01-14 13:55:10,181 - INFO - [Metrics for 'normal'] | Precision: 0.8344 | Recall: 0.7473 | F1: 0.7884
2026-01-14 13:55:10,184 - INFO - --------------------------------------------------
2026-01-14 13:55:10,185 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:55:17,100 - INFO - [Train] [86/90] | Loss: 0.4074 | Train Acc: 86.98%
2026-01-14 13:55:19,081 - INFO - [Valid] [86/90] | Loss: 0.4864 | Val Acc: 79.94%
2026-01-14 13:55:19,122 - INFO - [Metrics for 'abnormal'] | Precision: 0.7602 | Recall: 0.8280 | F1: 0.7927
2026-01-14 13:55:19,122 - INFO - [Metrics for 'normal'] | Precision: 0.8393 | Recall: 0.7747 | F1: 0.8057
2026-01-14 13:55:19,140 - INFO - --------------------------------------------------
2026-01-14 13:55:19,140 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:55:28,340 - INFO - [Train] [87/90] | Loss: 0.3992 | Train Acc: 88.84%
2026-01-14 13:55:33,173 - INFO - [Valid] [87/90] | Loss: 0.4862 | Val Acc: 80.83%
2026-01-14 13:55:33,214 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 13:55:33,214 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 13:55:33,225 - INFO - --------------------------------------------------
2026-01-14 13:55:33,226 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:55:39,808 - INFO - [Train] [88/90] | Loss: 0.3902 | Train Acc: 88.99%
2026-01-14 13:55:41,520 - INFO - [Valid] [88/90] | Loss: 0.4873 | Val Acc: 79.94%
2026-01-14 13:55:41,530 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 13:55:41,530 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 13:55:41,534 - INFO - --------------------------------------------------
2026-01-14 13:55:41,535 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:55:47,502 - INFO - [Train] [89/90] | Loss: 0.4036 | Train Acc: 89.21%
2026-01-14 13:55:49,051 - INFO - [Valid] [89/90] | Loss: 0.4861 | Val Acc: 81.42%
2026-01-14 13:55:49,063 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 13:55:49,064 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 13:55:49,068 - INFO - --------------------------------------------------
2026-01-14 13:55:49,068 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:55:54,911 - INFO - [Train] [90/90] | Loss: 0.3945 | Train Acc: 89.58%
2026-01-14 13:55:56,396 - INFO - [Valid] [90/90] | Loss: 0.4851 | Val Acc: 81.12%
2026-01-14 13:55:56,408 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-01-14 13:55:56,409 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-01-14 13:55:56,414 - INFO - ==================================================
2026-01-14 13:55:56,414 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:55:56,414 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:55:56,415 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:55:56,549 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:55:56,552 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:55:56,552 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:55:57,359 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 13:55:57,359 - INFO - ==================================================
2026-01-14 13:55:57,364 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/best_model.pth'
2026-01-14 13:55:57,364 - INFO - ==================================================
2026-01-14 13:55:57,364 - INFO - Test 모드를 시작합니다.
2026-01-14 13:55:57,535 - INFO - 연산량 (MACs): 0.0554 GMACs per sample
2026-01-14 13:55:57,535 - INFO - 연산량 (FLOPs): 0.1107 GFLOPs per sample
2026-01-14 13:55:57,535 - INFO - ==================================================
2026-01-14 13:55:57,536 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:55:58,050 - INFO - 샘플 당 평균 Forward Pass 시간: 0.48ms (std: 0.10ms), FPS: 2104.37 (std: 225.72) (1개 샘플 x 100회 반복)
2026-01-14 13:55:58,051 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 158.92 MB
2026-01-14 13:55:58,051 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:56:01,262 - INFO - [Test] Loss: 0.4164 | Test Acc: 80.83%
2026-01-14 13:56:01,294 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 13:56:01,294 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 13:56:02,071 - INFO - ==================================================
2026-01-14 13:56:02,071 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/confusion_matrix_20260114_133813.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/confusion_matrix_20260114_133813.pdf'
2026-01-14 13:56:02,071 - INFO - ==================================================
2026-01-14 13:56:02,071 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:56:02,270 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/model_fp32_20260114_133813.onnx'에 저장되었습니다. (크기: 0.12 MB)
2026-01-14 13:56:02,572 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2375.61 MB (증가량: 2.17 MB)
2026-01-14 13:56:02,572 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:56:03,121 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 2.98ms (std: 5.19ms)
2026-01-14 13:56:03,122 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 573.97 FPS (std: 251.60) (1개 샘플 x 100회 반복)
2026-01-14 13:56:03,122 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2382.44 MB (순수 증가량: 2.00 MB)
2026-01-14 13:56:03,123 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2382.44 MB (전체 증가량: 9.00 MB)
2026-01-14 13:56:05,729 - INFO - [Test (ONNX)] | Test Acc (ONNX): 80.83%
2026-01-14 13:56:05,749 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 13:56:05,753 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 13:56:06,213 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/val_acc.pdf'
2026-01-14 13:56:06,808 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/train_val_acc.pdf'
2026-01-14 13:56:07,309 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/F1_normal.pdf'
2026-01-14 13:56:07,859 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/val_loss.pdf'
2026-01-14 13:56:08,346 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/learning_rate.pdf'
2026-01-14 13:56:13,442 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_fpgm_20260114_133813/graph_20260114_133813/compile.pdf'
