2026-01-14 13:37:52,957 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/log_20260114_133752.log'에 저장됩니다.
2026-01-14 13:37:52,963 - INFO - ==================================================
2026-01-14 13:37:52,963 - INFO - config.yaml:
2026-01-14 13:37:52,963 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: efficientnet_b0
  use_fpgm_pruning: true
  pruning_params_target: 0.031371

2026-01-14 13:37:52,963 - INFO - ==================================================
2026-01-14 13:37:53,161 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:37:53,162 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:37:53,162 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:37:53,171 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:37:53,172 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:37:53,172 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:37:53,173 - INFO - Baseline 모델 'efficientnet_b0'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:37:53,447 - INFO - ==================================================
2026-01-14 13:37:53,447 - INFO - 모델 파라미터 수:
2026-01-14 13:37:53,447 - INFO -   - 총 파라미터: 4,010,110 개
2026-01-14 13:37:53,447 - INFO -   - 학습 가능한 파라미터: 4,010,110 개
2026-01-14 13:37:53,447 - INFO - ================================================================================
2026-01-14 13:37:53,447 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:37:53,447 - INFO - ================================================================================
2026-01-14 13:37:53,447 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:37:53,448 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:37:53,449 - INFO - ==================================================
2026-01-14 13:37:53,449 - INFO - train 모드를 시작합니다.
2026-01-14 13:37:53,449 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:37:53,449 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:37:53,449 - INFO - --------------------------------------------------
2026-01-14 13:37:53,450 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:37:59,152 - INFO - [Train] [1/10] | Loss: 0.5891 | Train Acc: 73.81%
2026-01-14 13:38:01,322 - INFO - [Valid] [1/10] | Loss: 0.5371 | Val Acc: 75.81%
2026-01-14 13:38:01,337 - INFO - [Metrics for 'abnormal'] | Precision: 0.8641 | Recall: 0.5669 | F1: 0.6846
2026-01-14 13:38:01,337 - INFO - [Metrics for 'normal'] | Precision: 0.7119 | Recall: 0.9231 | F1: 0.8038
2026-01-14 13:38:01,390 - INFO - [Best Model Saved] (val loss: 0.5371) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:38:01,391 - INFO - --------------------------------------------------
2026-01-14 13:38:01,392 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:38:06,118 - INFO - [Train] [2/10] | Loss: 0.5303 | Train Acc: 80.51%
2026-01-14 13:38:07,680 - INFO - [Valid] [2/10] | Loss: 0.5260 | Val Acc: 78.76%
2026-01-14 13:38:07,690 - INFO - [Metrics for 'abnormal'] | Precision: 0.8632 | Recall: 0.6433 | F1: 0.7372
2026-01-14 13:38:07,690 - INFO - [Metrics for 'normal'] | Precision: 0.7477 | Recall: 0.9121 | F1: 0.8218
2026-01-14 13:38:07,759 - INFO - [Best Model Saved] (val loss: 0.5260) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:38:07,759 - INFO - --------------------------------------------------
2026-01-14 13:38:07,761 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:38:12,677 - INFO - [Train] [3/10] | Loss: 0.5141 | Train Acc: 80.13%
2026-01-14 13:38:14,166 - INFO - [Valid] [3/10] | Loss: 0.5516 | Val Acc: 80.24%
2026-01-14 13:38:14,174 - INFO - [Metrics for 'abnormal'] | Precision: 0.8214 | Recall: 0.7325 | F1: 0.7744
2026-01-14 13:38:14,174 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.8626 | F1: 0.8241
2026-01-14 13:38:14,177 - INFO - --------------------------------------------------
2026-01-14 13:38:14,178 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:38:20,004 - INFO - [Train] [4/10] | Loss: 0.4747 | Train Acc: 83.41%
2026-01-14 13:38:21,612 - INFO - [Valid] [4/10] | Loss: 0.4914 | Val Acc: 80.53%
2026-01-14 13:38:21,624 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 13:38:21,624 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 13:38:21,697 - INFO - [Best Model Saved] (val loss: 0.4914) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:38:21,698 - INFO - --------------------------------------------------
2026-01-14 13:38:21,700 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:38:28,754 - INFO - [Train] [5/10] | Loss: 0.4627 | Train Acc: 83.41%
2026-01-14 13:38:30,596 - INFO - [Valid] [5/10] | Loss: 0.7486 | Val Acc: 80.24%
2026-01-14 13:38:30,606 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-01-14 13:38:30,607 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-01-14 13:38:30,611 - INFO - --------------------------------------------------
2026-01-14 13:38:30,614 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 13:38:38,497 - INFO - [Train] [6/10] | Loss: 0.4397 | Train Acc: 84.90%
2026-01-14 13:38:40,060 - INFO - [Valid] [6/10] | Loss: 0.4884 | Val Acc: 80.24%
2026-01-14 13:38:40,070 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-01-14 13:38:40,070 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-01-14 13:38:40,144 - INFO - [Best Model Saved] (val loss: 0.4884) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:38:40,145 - INFO - --------------------------------------------------
2026-01-14 13:38:40,146 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 13:38:48,070 - INFO - [Train] [7/10] | Loss: 0.4105 | Train Acc: 87.80%
2026-01-14 13:38:50,039 - INFO - [Valid] [7/10] | Loss: 0.4744 | Val Acc: 81.12%
2026-01-14 13:38:50,048 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-01-14 13:38:50,048 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-01-14 13:38:50,113 - INFO - [Best Model Saved] (val loss: 0.4744) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:38:50,114 - INFO - --------------------------------------------------
2026-01-14 13:38:50,116 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 13:38:58,932 - INFO - [Train] [8/10] | Loss: 0.3882 | Train Acc: 88.69%
2026-01-14 13:39:00,724 - INFO - [Valid] [8/10] | Loss: 0.4896 | Val Acc: 80.83%
2026-01-14 13:39:00,736 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 13:39:00,737 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 13:39:00,741 - INFO - --------------------------------------------------
2026-01-14 13:39:00,744 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 13:39:08,357 - INFO - [Train] [9/10] | Loss: 0.3407 | Train Acc: 91.37%
2026-01-14 13:39:10,706 - INFO - [Valid] [9/10] | Loss: 0.5031 | Val Acc: 82.30%
2026-01-14 13:39:10,716 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8280 | F1: 0.8125
2026-01-14 13:39:10,717 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.8187 | F1: 0.8324
2026-01-14 13:39:10,720 - INFO - --------------------------------------------------
2026-01-14 13:39:10,722 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 13:39:18,499 - INFO - [Train] [10/10] | Loss: 0.3260 | Train Acc: 92.49%
2026-01-14 13:39:21,160 - INFO - [Valid] [10/10] | Loss: 0.5110 | Val Acc: 82.01%
2026-01-14 13:39:21,179 - INFO - [Metrics for 'abnormal'] | Precision: 0.8288 | Recall: 0.7707 | F1: 0.7987
2026-01-14 13:39:21,182 - INFO - [Metrics for 'normal'] | Precision: 0.8135 | Recall: 0.8626 | F1: 0.8373
2026-01-14 13:39:21,189 - INFO - ================================================================================
2026-01-14 13:39:21,189 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 13:39:21,189 - INFO - ================================================================================
2026-01-14 13:39:21,411 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'을(를) 불러왔습니다.
2026-01-14 13:39:21,412 - INFO - ================================================================================
2026-01-14 13:39:21,412 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 13:39:21,413 - INFO - 원본 모델 파라미터: 4.0101M
2026-01-14 13:39:21,526 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:21,527 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:22,122 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 13:39:22,122 - INFO - ==================================================
2026-01-14 13:39:22,125 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.0721M (감소율: 73.26%)
2026-01-14 13:39:22,185 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:22,186 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:22,718 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:22,719 - INFO - ==================================================
2026-01-14 13:39:22,721 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.3065M (감소율: 92.36%)
2026-01-14 13:39:22,799 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:22,800 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:23,111 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 13:39:23,111 - INFO - ==================================================
2026-01-14 13:39:23,113 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0963M (감소율: 97.60%)
2026-01-14 13:39:23,161 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:23,161 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:23,709 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 13:39:23,710 - INFO - ==================================================
2026-01-14 13:39:23,713 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0360M (감소율: 99.10%)
2026-01-14 13:39:23,778 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:23,779 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:24,962 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:24,963 - INFO - ==================================================
2026-01-14 13:39:24,967 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0183M (감소율: 99.54%)
2026-01-14 13:39:25,026 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:25,027 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:25,943 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.94359375)에 맞춰 변경되었습니다.
2026-01-14 13:39:25,944 - INFO - ==================================================
2026-01-14 13:39:25,947 - INFO -   [탐색  6] 희소도: 0.9436 -> 파라미터: 0.0247M (감소율: 99.38%)
2026-01-14 13:39:26,065 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:26,066 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:26,987 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9358593749999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:26,987 - INFO - ==================================================
2026-01-14 13:39:26,990 - INFO -   [탐색  7] 희소도: 0.9359 -> 파라미터: 0.0306M (감소율: 99.24%)
2026-01-14 13:39:27,054 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:27,054 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:27,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9319921874999999)에 맞춰 변경되었습니다.
2026-01-14 13:39:27,647 - INFO - ==================================================
2026-01-14 13:39:27,649 - INFO -   [탐색  8] 희소도: 0.9320 -> 파라미터: 0.0332M (감소율: 99.17%)
2026-01-14 13:39:27,693 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:27,694 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:28,066 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9339257812499999)에 맞춰 변경되었습니다.
2026-01-14 13:39:28,066 - INFO - ==================================================
2026-01-14 13:39:28,068 - INFO -   [탐색  9] 희소도: 0.9339 -> 파라미터: 0.0317M (감소율: 99.21%)
2026-01-14 13:39:28,113 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:28,113 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:28,517 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9348925781249999)에 맞춰 변경되었습니다.
2026-01-14 13:39:28,518 - INFO - ==================================================
2026-01-14 13:39:28,520 - INFO -   [탐색 10] 희소도: 0.9349 -> 파라미터: 0.0311M (감소율: 99.22%)
2026-01-14 13:39:28,564 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:28,564 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:28,861 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 13:39:28,861 - INFO - ==================================================
2026-01-14 13:39:28,863 - INFO -   [탐색 11] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:28,907 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:28,908 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:29,289 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9341674804687499)에 맞춰 변경되었습니다.
2026-01-14 13:39:29,290 - INFO - ==================================================
2026-01-14 13:39:29,292 - INFO -   [탐색 12] 희소도: 0.9342 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:29,700 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:29,701 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:30,085 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9342883300781248)에 맞춰 변경되었습니다.
2026-01-14 13:39:30,086 - INFO - ==================================================
2026-01-14 13:39:30,091 - INFO -   [탐색 13] 희소도: 0.9343 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:30,151 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:30,152 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:30,741 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343487548828124)에 맞춰 변경되었습니다.
2026-01-14 13:39:30,741 - INFO - ==================================================
2026-01-14 13:39:30,744 - INFO -   [탐색 14] 희소도: 0.9343 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:30,865 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:30,866 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:31,270 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343789672851561)에 맞춰 변경되었습니다.
2026-01-14 13:39:31,270 - INFO - ==================================================
2026-01-14 13:39:31,274 - INFO -   [탐색 15] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:31,333 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:31,334 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:31,756 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343638610839843)에 맞춰 변경되었습니다.
2026-01-14 13:39:31,757 - INFO - ==================================================
2026-01-14 13:39:31,760 - INFO -   [탐색 16] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:31,864 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:31,865 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:32,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343714141845703)에 맞춰 변경되었습니다.
2026-01-14 13:39:32,648 - INFO - ==================================================
2026-01-14 13:39:32,651 - INFO -   [탐색 17] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:32,697 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:32,698 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:33,096 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343751907348632)에 맞춰 변경되었습니다.
2026-01-14 13:39:33,097 - INFO - ==================================================
2026-01-14 13:39:33,099 - INFO -   [탐색 18] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:33,152 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:33,153 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:33,648 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343733024597167)에 맞춰 변경되었습니다.
2026-01-14 13:39:33,648 - INFO - ==================================================
2026-01-14 13:39:33,650 - INFO -   [탐색 19] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:33,698 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:33,698 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:34,598 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93437424659729)에 맞춰 변경되었습니다.
2026-01-14 13:39:34,599 - INFO - ==================================================
2026-01-14 13:39:34,602 - INFO -   [탐색 20] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:34,643 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:34,643 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:34,967 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343747186660766)에 맞춰 변경되었습니다.
2026-01-14 13:39:34,968 - INFO - ==================================================
2026-01-14 13:39:34,970 - INFO -   [탐색 21] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:35,011 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:35,012 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:35,398 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749547004698)에 맞춰 변경되었습니다.
2026-01-14 13:39:35,399 - INFO - ==================================================
2026-01-14 13:39:35,401 - INFO -   [탐색 22] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:35,447 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:35,448 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:35,792 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750727176665)에 맞춰 변경되었습니다.
2026-01-14 13:39:35,793 - INFO - ==================================================
2026-01-14 13:39:35,795 - INFO -   [탐색 23] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:35,838 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:35,838 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:36,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750137090682)에 맞춰 변경되었습니다.
2026-01-14 13:39:36,348 - INFO - ==================================================
2026-01-14 13:39:36,354 - INFO -   [탐색 24] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:36,454 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:36,454 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:36,920 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934374984204769)에 맞춰 변경되었습니다.
2026-01-14 13:39:36,921 - INFO - ==================================================
2026-01-14 13:39:36,924 - INFO -   [탐색 25] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:36,981 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:36,982 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:37,527 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749989569186)에 맞춰 변경되었습니다.
2026-01-14 13:39:37,527 - INFO - ==================================================
2026-01-14 13:39:37,529 - INFO -   [탐색 26] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:37,580 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:37,580 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:37,949 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750063329934)에 맞춰 변경되었습니다.
2026-01-14 13:39:37,949 - INFO - ==================================================
2026-01-14 13:39:37,951 - INFO -   [탐색 27] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:38,009 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:38,010 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:39,155 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375002644956)에 맞춰 변경되었습니다.
2026-01-14 13:39:39,156 - INFO - ==================================================
2026-01-14 13:39:39,159 - INFO -   [탐색 28] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:39,216 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:39,216 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:39,812 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750008009373)에 맞춰 변경되었습니다.
2026-01-14 13:39:39,812 - INFO - ==================================================
2026-01-14 13:39:39,814 - INFO -   [탐색 29] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:39,868 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:39,869 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:40,527 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749998789279)에 맞춰 변경되었습니다.
2026-01-14 13:39:40,528 - INFO - ==================================================
2026-01-14 13:39:40,530 - INFO -   [탐색 30] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:40,573 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:40,574 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:40,919 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750003399326)에 맞춰 변경되었습니다.
2026-01-14 13:39:40,919 - INFO - ==================================================
2026-01-14 13:39:40,921 - INFO -   [탐색 31] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:40,963 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:40,964 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:41,214 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750001094302)에 맞춰 변경되었습니다.
2026-01-14 13:39:41,215 - INFO - ==================================================
2026-01-14 13:39:41,217 - INFO -   [탐색 32] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:41,274 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:41,274 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:41,717 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999941791)에 맞춰 변경되었습니다.
2026-01-14 13:39:41,718 - INFO - ==================================================
2026-01-14 13:39:41,720 - INFO -   [탐색 33] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:41,784 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:41,784 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:42,225 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000518046)에 맞춰 변경되었습니다.
2026-01-14 13:39:42,225 - INFO - ==================================================
2026-01-14 13:39:42,228 - INFO -   [탐색 34] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:42,281 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:42,282 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:42,675 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000229918)에 맞춰 변경되었습니다.
2026-01-14 13:39:42,675 - INFO - ==================================================
2026-01-14 13:39:42,677 - INFO -   [탐색 35] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:42,728 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:42,728 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:43,474 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000085854)에 맞춰 변경되었습니다.
2026-01-14 13:39:43,475 - INFO - ==================================================
2026-01-14 13:39:43,479 - INFO -   [탐색 36] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:43,526 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:43,526 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:44,002 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000013822)에 맞춰 변경되었습니다.
2026-01-14 13:39:44,002 - INFO - ==================================================
2026-01-14 13:39:44,004 - INFO -   [탐색 37] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:44,052 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:44,053 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:44,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999977806)에 맞춰 변경되었습니다.
2026-01-14 13:39:44,583 - INFO - ==================================================
2026-01-14 13:39:44,586 - INFO -   [탐색 38] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:44,647 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:44,648 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:45,139 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999995814)에 맞춰 변경되었습니다.
2026-01-14 13:39:45,140 - INFO - ==================================================
2026-01-14 13:39:45,142 - INFO -   [탐색 39] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:45,241 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:45,241 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:45,719 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000004818)에 맞춰 변경되었습니다.
2026-01-14 13:39:45,719 - INFO - ==================================================
2026-01-14 13:39:45,722 - INFO -   [탐색 40] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:45,789 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:45,790 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:46,173 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000316)에 맞춰 변경되었습니다.
2026-01-14 13:39:46,174 - INFO - ==================================================
2026-01-14 13:39:46,176 - INFO -   [탐색 41] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:46,221 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:46,221 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:46,679 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999998066)에 맞춰 변경되었습니다.
2026-01-14 13:39:46,680 - INFO - ==================================================
2026-01-14 13:39:46,682 - INFO -   [탐색 42] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:46,723 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:46,723 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:47,130 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999191)에 맞춰 변경되었습니다.
2026-01-14 13:39:47,131 - INFO - ==================================================
2026-01-14 13:39:47,133 - INFO -   [탐색 43] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:47,704 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:47,704 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:48,286 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999753)에 맞춰 변경되었습니다.
2026-01-14 13:39:48,287 - INFO - ==================================================
2026-01-14 13:39:48,290 - INFO -   [탐색 44] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:48,338 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:48,338 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:48,770 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000035)에 맞춰 변경되었습니다.
2026-01-14 13:39:48,771 - INFO - ==================================================
2026-01-14 13:39:48,774 - INFO -   [탐색 45] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:48,842 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:48,843 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:49,357 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999894)에 맞춰 변경되었습니다.
2026-01-14 13:39:49,358 - INFO - ==================================================
2026-01-14 13:39:49,360 - INFO -   [탐색 46] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:49,411 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:49,411 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:49,829 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999964)에 맞춰 변경되었습니다.
2026-01-14 13:39:49,830 - INFO - ==================================================
2026-01-14 13:39:49,832 - INFO -   [탐색 47] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:49,895 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:49,896 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:50,332 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:50,333 - INFO - ==================================================
2026-01-14 13:39:50,335 - INFO -   [탐색 48] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:50,390 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:50,391 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:50,777 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000017)에 맞춰 변경되었습니다.
2026-01-14 13:39:50,778 - INFO - ==================================================
2026-01-14 13:39:50,780 - INFO -   [탐색 49] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:50,840 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:50,841 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:51,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000008)에 맞춰 변경되었습니다.
2026-01-14 13:39:51,348 - INFO - ==================================================
2026-01-14 13:39:51,351 - INFO -   [탐색 50] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:51,418 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:51,418 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:52,217 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000004)에 맞춰 변경되었습니다.
2026-01-14 13:39:52,218 - INFO - ==================================================
2026-01-14 13:39:52,221 - INFO -   [탐색 51] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:52,264 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:52,264 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:52,610 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000002)에 맞춰 변경되었습니다.
2026-01-14 13:39:52,610 - INFO - ==================================================
2026-01-14 13:39:52,615 - INFO -   [탐색 52] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:52,705 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:52,705 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:53,151 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000001)에 맞춰 변경되었습니다.
2026-01-14 13:39:53,152 - INFO - ==================================================
2026-01-14 13:39:53,154 - INFO -   [탐색 53] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 13:39:53,198 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:53,198 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:53,606 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:53,607 - INFO - ==================================================
2026-01-14 13:39:53,609 - INFO -   [탐색 54] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:53,715 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:53,715 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:54,442 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:54,442 - INFO - ==================================================
2026-01-14 13:39:54,444 - INFO -   [탐색 55] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:54,502 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:54,502 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:55,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:55,306 - INFO - ==================================================
2026-01-14 13:39:55,308 - INFO -   [탐색 56] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:55,364 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:55,364 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:55,961 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:55,961 - INFO - ==================================================
2026-01-14 13:39:55,963 - INFO -   [탐색 57] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:55,997 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:55,998 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:56,546 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:56,546 - INFO - ==================================================
2026-01-14 13:39:56,549 - INFO -   [탐색 58] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:56,598 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:56,598 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,258 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,258 - INFO - ==================================================
2026-01-14 13:39:57,261 - INFO -   [탐색 59] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:57,304 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:57,684 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:57,685 - INFO - ==================================================
2026-01-14 13:39:57,687 - INFO -   [탐색 60] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:57,754 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:57,754 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,078 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,079 - INFO - ==================================================
2026-01-14 13:39:58,080 - INFO -   [탐색 61] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:58,122 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,123 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,437 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,438 - INFO - ==================================================
2026-01-14 13:39:58,440 - INFO -   [탐색 62] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:58,493 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,493 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:58,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:58,862 - INFO - ==================================================
2026-01-14 13:39:58,865 - INFO -   [탐색 63] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:58,924 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:58,925 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,434 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,434 - INFO - ==================================================
2026-01-14 13:39:59,437 - INFO -   [탐색 64] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:59,509 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,510 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:39:59,877 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:39:59,877 - INFO - ==================================================
2026-01-14 13:39:59,881 - INFO -   [탐색 65] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:39:59,955 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:39:59,958 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:00,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:00,269 - INFO - ==================================================
2026-01-14 13:40:00,271 - INFO -   [탐색 66] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:00,632 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:00,633 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:01,003 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:01,004 - INFO - ==================================================
2026-01-14 13:40:01,007 - INFO -   [탐색 67] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:01,051 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:01,051 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:01,487 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:01,487 - INFO - ==================================================
2026-01-14 13:40:01,490 - INFO -   [탐색 68] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:01,541 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:01,541 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,017 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,018 - INFO - ==================================================
2026-01-14 13:40:02,020 - INFO -   [탐색 69] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:02,084 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,085 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:02,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:02,583 - INFO - ==================================================
2026-01-14 13:40:02,585 - INFO -   [탐색 70] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:02,637 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:02,637 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,213 - INFO - ==================================================
2026-01-14 13:40:03,215 - INFO -   [탐색 71] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:03,251 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,251 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:03,645 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:03,645 - INFO - ==================================================
2026-01-14 13:40:03,647 - INFO -   [탐색 72] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:03,690 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:03,690 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,061 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,061 - INFO - ==================================================
2026-01-14 13:40:04,063 - INFO -   [탐색 73] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:04,106 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,106 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:04,740 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:04,741 - INFO - ==================================================
2026-01-14 13:40:04,744 - INFO -   [탐색 74] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:04,786 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:04,787 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,082 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,083 - INFO - ==================================================
2026-01-14 13:40:05,085 - INFO -   [탐색 75] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:05,126 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:05,127 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:05,577 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:05,578 - INFO - ==================================================
2026-01-14 13:40:05,580 - INFO -   [탐색 76] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:05,638 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:05,639 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,061 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,061 - INFO - ==================================================
2026-01-14 13:40:06,064 - INFO -   [탐색 77] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:06,124 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,124 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:06,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:06,628 - INFO - ==================================================
2026-01-14 13:40:06,630 - INFO -   [탐색 78] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:06,683 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:06,684 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,065 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,065 - INFO - ==================================================
2026-01-14 13:40:07,067 - INFO -   [탐색 79] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:07,111 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:07,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:07,516 - INFO - ==================================================
2026-01-14 13:40:07,518 - INFO -   [탐색 80] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:07,578 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:07,579 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:08,038 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:08,039 - INFO - ==================================================
2026-01-14 13:40:08,040 - INFO -   [탐색 81] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:08,088 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:08,089 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:08,955 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:08,955 - INFO - ==================================================
2026-01-14 13:40:08,959 - INFO -   [탐색 82] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:09,019 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:09,019 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:09,376 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:09,377 - INFO - ==================================================
2026-01-14 13:40:09,379 - INFO -   [탐색 83] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:09,436 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:09,437 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:09,980 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:09,981 - INFO - ==================================================
2026-01-14 13:40:09,982 - INFO -   [탐색 84] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:10,016 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:10,016 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,520 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,520 - INFO - ==================================================
2026-01-14 13:40:10,522 - INFO -   [탐색 85] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:10,570 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:10,571 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:10,964 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:10,964 - INFO - ==================================================
2026-01-14 13:40:10,966 - INFO -   [탐색 86] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:11,003 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,003 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,335 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,335 - INFO - ==================================================
2026-01-14 13:40:11,337 - INFO -   [탐색 87] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:11,380 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,380 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:11,752 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:11,752 - INFO - ==================================================
2026-01-14 13:40:11,754 - INFO -   [탐색 88] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:11,789 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:11,789 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,097 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,098 - INFO - ==================================================
2026-01-14 13:40:12,100 - INFO -   [탐색 89] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:12,435 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,436 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:12,732 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:12,733 - INFO - ==================================================
2026-01-14 13:40:12,735 - INFO -   [탐색 90] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:12,776 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:12,776 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,083 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,083 - INFO - ==================================================
2026-01-14 13:40:13,085 - INFO -   [탐색 91] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:13,125 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,126 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,407 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,407 - INFO - ==================================================
2026-01-14 13:40:13,409 - INFO -   [탐색 92] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:13,452 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,452 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:13,804 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:13,805 - INFO - ==================================================
2026-01-14 13:40:13,807 - INFO -   [탐색 93] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:13,849 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:13,850 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,146 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,146 - INFO - ==================================================
2026-01-14 13:40:14,148 - INFO -   [탐색 94] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:14,193 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,194 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,559 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,559 - INFO - ==================================================
2026-01-14 13:40:14,561 - INFO -   [탐색 95] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:14,602 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:14,603 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:14,990 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:14,990 - INFO - ==================================================
2026-01-14 13:40:14,992 - INFO -   [탐색 96] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:15,038 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,038 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:15,723 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:15,723 - INFO - ==================================================
2026-01-14 13:40:15,725 - INFO -   [탐색 97] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:15,763 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:15,763 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,118 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,119 - INFO - ==================================================
2026-01-14 13:40:16,120 - INFO -   [탐색 98] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:16,154 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,155 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,506 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,506 - INFO - ==================================================
2026-01-14 13:40:16,508 - INFO -   [탐색 99] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:16,542 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:16,542 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:16,866 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 13:40:16,866 - INFO - ==================================================
2026-01-14 13:40:16,868 - INFO -   [탐색 100] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 13:40:16,868 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9344 입니다.
2026-01-14 13:40:16,868 - INFO - ================================================================================
2026-01-14 13:40:16,871 - INFO - 계산된 Pruning 정보(희소도: 0.9344)를 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/pruning_info.yaml'에 저장했습니다.
2026-01-14 13:40:16,927 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 13:40:17,076 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:40:17,077 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:40:17,441 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 13:40:17,441 - INFO - ==================================================
2026-01-14 13:40:17,443 - INFO - ==================================================
2026-01-14 13:40:17,443 - INFO - 모델 파라미터 수:
2026-01-14 13:40:17,443 - INFO -   - 총 파라미터: 31,288 개
2026-01-14 13:40:17,443 - INFO -   - 학습 가능한 파라미터: 31,288 개
2026-01-14 13:40:17,537 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 13:40:17,637 - INFO - FLOPs가 0.8277 GFLOPs에서 0.0120 GFLOPs로 감소했습니다 (감소율: 98.55%).
2026-01-14 13:40:17,637 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 13:40:17,637 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:40:17,638 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 13:40:17,638 - INFO - ==================================================
2026-01-14 13:40:17,639 - INFO - train 모드를 시작합니다.
2026-01-14 13:40:17,639 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:40:17,639 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:40:17,639 - INFO - --------------------------------------------------
2026-01-14 13:40:17,640 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 13:40:22,579 - INFO - [Train] [11/90] | Loss: 0.5780 | Train Acc: 74.55%
2026-01-14 13:40:24,032 - INFO - [Valid] [11/90] | Loss: 0.5686 | Val Acc: 76.70%
2026-01-14 13:40:24,042 - INFO - [Metrics for 'abnormal'] | Precision: 0.7910 | Recall: 0.6752 | F1: 0.7285
2026-01-14 13:40:24,042 - INFO - [Metrics for 'normal'] | Precision: 0.7512 | Recall: 0.8462 | F1: 0.7959
2026-01-14 13:40:24,074 - INFO - [Best Model Saved] (val loss: 0.5686) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:40:24,074 - INFO - --------------------------------------------------
2026-01-14 13:40:24,076 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 13:40:29,139 - INFO - [Train] [12/90] | Loss: 0.5312 | Train Acc: 78.20%
2026-01-14 13:40:30,450 - INFO - [Valid] [12/90] | Loss: 0.5490 | Val Acc: 75.52%
2026-01-14 13:40:30,463 - INFO - [Metrics for 'abnormal'] | Precision: 0.8083 | Recall: 0.6178 | F1: 0.7004
2026-01-14 13:40:30,463 - INFO - [Metrics for 'normal'] | Precision: 0.7260 | Recall: 0.8736 | F1: 0.7930
2026-01-14 13:40:30,516 - INFO - [Best Model Saved] (val loss: 0.5490) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:40:30,516 - INFO - --------------------------------------------------
2026-01-14 13:40:30,519 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 13:40:35,931 - INFO - [Train] [13/90] | Loss: 0.4984 | Train Acc: 80.51%
2026-01-14 13:40:37,393 - INFO - [Valid] [13/90] | Loss: 0.5436 | Val Acc: 76.99%
2026-01-14 13:40:37,405 - INFO - [Metrics for 'abnormal'] | Precision: 0.7724 | Recall: 0.7134 | F1: 0.7417
2026-01-14 13:40:37,405 - INFO - [Metrics for 'normal'] | Precision: 0.7680 | Recall: 0.8187 | F1: 0.7926
2026-01-14 13:40:37,457 - INFO - [Best Model Saved] (val loss: 0.5436) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:40:37,457 - INFO - --------------------------------------------------
2026-01-14 13:40:37,460 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 13:40:42,740 - INFO - [Train] [14/90] | Loss: 0.4956 | Train Acc: 80.88%
2026-01-14 13:40:44,029 - INFO - [Valid] [14/90] | Loss: 0.5346 | Val Acc: 79.65%
2026-01-14 13:40:44,037 - INFO - [Metrics for 'abnormal'] | Precision: 0.7785 | Recall: 0.7834 | F1: 0.7810
2026-01-14 13:40:44,037 - INFO - [Metrics for 'normal'] | Precision: 0.8122 | Recall: 0.8077 | F1: 0.8099
2026-01-14 13:40:44,066 - INFO - [Best Model Saved] (val loss: 0.5346) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:40:44,066 - INFO - --------------------------------------------------
2026-01-14 13:40:44,068 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 13:40:49,167 - INFO - [Train] [15/90] | Loss: 0.5002 | Train Acc: 81.62%
2026-01-14 13:40:50,649 - INFO - [Valid] [15/90] | Loss: 0.5244 | Val Acc: 78.76%
2026-01-14 13:40:50,658 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.8089 | F1: 0.7791
2026-01-14 13:40:50,658 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.7692 | F1: 0.7955
2026-01-14 13:40:50,690 - INFO - [Best Model Saved] (val loss: 0.5244) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:40:50,690 - INFO - --------------------------------------------------
2026-01-14 13:40:50,691 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 13:40:56,009 - INFO - [Train] [16/90] | Loss: 0.4660 | Train Acc: 82.81%
2026-01-14 13:40:57,302 - INFO - [Valid] [16/90] | Loss: 0.5141 | Val Acc: 79.65%
2026-01-14 13:40:57,310 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.7134 | F1: 0.7645
2026-01-14 13:40:57,310 - INFO - [Metrics for 'normal'] | Precision: 0.7783 | Recall: 0.8681 | F1: 0.8208
2026-01-14 13:40:57,338 - INFO - [Best Model Saved] (val loss: 0.5141) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:40:57,338 - INFO - --------------------------------------------------
2026-01-14 13:40:57,340 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 13:41:03,464 - INFO - [Train] [17/90] | Loss: 0.4728 | Train Acc: 82.07%
2026-01-14 13:41:05,427 - INFO - [Valid] [17/90] | Loss: 0.5291 | Val Acc: 78.17%
2026-01-14 13:41:05,437 - INFO - [Metrics for 'abnormal'] | Precision: 0.8074 | Recall: 0.6943 | F1: 0.7466
2026-01-14 13:41:05,437 - INFO - [Metrics for 'normal'] | Precision: 0.7647 | Recall: 0.8571 | F1: 0.8083
2026-01-14 13:41:05,441 - INFO - --------------------------------------------------
2026-01-14 13:41:05,443 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:41:12,107 - INFO - [Train] [18/90] | Loss: 0.4765 | Train Acc: 82.14%
2026-01-14 13:41:13,833 - INFO - [Valid] [18/90] | Loss: 0.5185 | Val Acc: 80.53%
2026-01-14 13:41:13,841 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7962 | F1: 0.7911
2026-01-14 13:41:13,842 - INFO - [Metrics for 'normal'] | Precision: 0.8222 | Recall: 0.8132 | F1: 0.8177
2026-01-14 13:41:13,844 - INFO - --------------------------------------------------
2026-01-14 13:41:13,846 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:41:20,488 - INFO - [Train] [19/90] | Loss: 0.4584 | Train Acc: 83.26%
2026-01-14 13:41:22,512 - INFO - [Valid] [19/90] | Loss: 0.5777 | Val Acc: 77.58%
2026-01-14 13:41:22,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.7238 | Recall: 0.8344 | F1: 0.7751
2026-01-14 13:41:22,524 - INFO - [Metrics for 'normal'] | Precision: 0.8354 | Recall: 0.7253 | F1: 0.7765
2026-01-14 13:41:22,527 - INFO - --------------------------------------------------
2026-01-14 13:41:22,530 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:41:29,790 - INFO - [Train] [20/90] | Loss: 0.4582 | Train Acc: 83.04%
2026-01-14 13:41:31,807 - INFO - [Valid] [20/90] | Loss: 0.5416 | Val Acc: 78.17%
2026-01-14 13:41:31,815 - INFO - [Metrics for 'abnormal'] | Precision: 0.7578 | Recall: 0.7771 | F1: 0.7673
2026-01-14 13:41:31,816 - INFO - [Metrics for 'normal'] | Precision: 0.8034 | Recall: 0.7857 | F1: 0.7944
2026-01-14 13:41:31,819 - INFO - --------------------------------------------------
2026-01-14 13:41:31,822 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:41:40,467 - INFO - [Train] [21/90] | Loss: 0.4732 | Train Acc: 82.37%
2026-01-14 13:41:42,468 - INFO - [Valid] [21/90] | Loss: 0.5314 | Val Acc: 78.17%
2026-01-14 13:41:42,479 - INFO - [Metrics for 'abnormal'] | Precision: 0.7318 | Recall: 0.8344 | F1: 0.7798
2026-01-14 13:41:42,480 - INFO - [Metrics for 'normal'] | Precision: 0.8375 | Recall: 0.7363 | F1: 0.7836
2026-01-14 13:41:42,483 - INFO - --------------------------------------------------
2026-01-14 13:41:42,486 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:41:49,914 - INFO - [Train] [22/90] | Loss: 0.4394 | Train Acc: 85.34%
2026-01-14 13:41:51,742 - INFO - [Valid] [22/90] | Loss: 0.5801 | Val Acc: 75.81%
2026-01-14 13:41:51,751 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.7643 | F1: 0.7453
2026-01-14 13:41:51,751 - INFO - [Metrics for 'normal'] | Precision: 0.7874 | Recall: 0.7527 | F1: 0.7697
2026-01-14 13:41:51,756 - INFO - --------------------------------------------------
2026-01-14 13:41:51,759 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:41:59,750 - INFO - [Train] [23/90] | Loss: 0.4400 | Train Acc: 85.19%
2026-01-14 13:42:01,389 - INFO - [Valid] [23/90] | Loss: 0.5447 | Val Acc: 77.88%
2026-01-14 13:42:01,403 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.8344 | F1: 0.7774
2026-01-14 13:42:01,403 - INFO - [Metrics for 'normal'] | Precision: 0.8365 | Recall: 0.7308 | F1: 0.7801
2026-01-14 13:42:01,408 - INFO - --------------------------------------------------
2026-01-14 13:42:01,411 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:42:10,108 - INFO - [Train] [24/90] | Loss: 0.4338 | Train Acc: 84.30%
2026-01-14 13:42:12,160 - INFO - [Valid] [24/90] | Loss: 0.5460 | Val Acc: 77.88%
2026-01-14 13:42:12,169 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.7389 | F1: 0.7557
2026-01-14 13:42:12,170 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.8132 | F1: 0.7978
2026-01-14 13:42:12,173 - INFO - --------------------------------------------------
2026-01-14 13:42:12,175 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:42:21,030 - INFO - [Train] [25/90] | Loss: 0.4367 | Train Acc: 84.97%
2026-01-14 13:42:23,068 - INFO - [Valid] [25/90] | Loss: 0.5211 | Val Acc: 80.83%
2026-01-14 13:42:23,079 - INFO - [Metrics for 'abnormal'] | Precision: 0.8194 | Recall: 0.7516 | F1: 0.7841
2026-01-14 13:42:23,079 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8571 | F1: 0.8276
2026-01-14 13:42:23,083 - INFO - --------------------------------------------------
2026-01-14 13:42:23,086 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:42:31,521 - INFO - [Train] [26/90] | Loss: 0.4251 | Train Acc: 85.49%
2026-01-14 13:42:34,151 - INFO - [Valid] [26/90] | Loss: 0.6289 | Val Acc: 75.22%
2026-01-14 13:42:34,164 - INFO - [Metrics for 'abnormal'] | Precision: 0.6872 | Recall: 0.8535 | F1: 0.7614
2026-01-14 13:42:34,164 - INFO - [Metrics for 'normal'] | Precision: 0.8403 | Recall: 0.6648 | F1: 0.7423
2026-01-14 13:42:34,169 - INFO - --------------------------------------------------
2026-01-14 13:42:34,171 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:42:43,290 - INFO - [Train] [27/90] | Loss: 0.4225 | Train Acc: 85.79%
2026-01-14 13:42:45,292 - INFO - [Valid] [27/90] | Loss: 0.5548 | Val Acc: 79.35%
2026-01-14 13:42:45,303 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-01-14 13:42:45,304 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-01-14 13:42:45,307 - INFO - --------------------------------------------------
2026-01-14 13:42:45,310 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:42:54,874 - INFO - [Train] [28/90] | Loss: 0.4224 | Train Acc: 86.31%
2026-01-14 13:42:57,002 - INFO - [Valid] [28/90] | Loss: 0.6104 | Val Acc: 78.17%
2026-01-14 13:42:57,014 - INFO - [Metrics for 'abnormal'] | Precision: 0.7427 | Recall: 0.8089 | F1: 0.7744
2026-01-14 13:42:57,014 - INFO - [Metrics for 'normal'] | Precision: 0.8214 | Recall: 0.7582 | F1: 0.7886
2026-01-14 13:42:57,018 - INFO - --------------------------------------------------
2026-01-14 13:42:57,020 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:43:05,789 - INFO - [Train] [29/90] | Loss: 0.4135 | Train Acc: 86.24%
2026-01-14 13:43:08,308 - INFO - [Valid] [29/90] | Loss: 0.5937 | Val Acc: 76.11%
2026-01-14 13:43:08,317 - INFO - [Metrics for 'abnormal'] | Precision: 0.7088 | Recall: 0.8217 | F1: 0.7611
2026-01-14 13:43:08,317 - INFO - [Metrics for 'normal'] | Precision: 0.8217 | Recall: 0.7088 | F1: 0.7611
2026-01-14 13:43:08,320 - INFO - --------------------------------------------------
2026-01-14 13:43:08,322 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:43:16,724 - INFO - [Train] [30/90] | Loss: 0.4035 | Train Acc: 86.98%
2026-01-14 13:43:19,743 - INFO - [Valid] [30/90] | Loss: 0.5091 | Val Acc: 81.42%
2026-01-14 13:43:19,757 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-01-14 13:43:19,757 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-01-14 13:43:19,806 - INFO - [Best Model Saved] (val loss: 0.5091) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:43:19,806 - INFO - --------------------------------------------------
2026-01-14 13:43:19,808 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:43:28,940 - INFO - [Train] [31/90] | Loss: 0.4131 | Train Acc: 86.16%
2026-01-14 13:43:32,377 - INFO - [Valid] [31/90] | Loss: 0.5284 | Val Acc: 80.83%
2026-01-14 13:43:32,386 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 13:43:32,387 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 13:43:32,390 - INFO - --------------------------------------------------
2026-01-14 13:43:32,393 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:43:40,665 - INFO - [Train] [32/90] | Loss: 0.4170 | Train Acc: 86.24%
2026-01-14 13:43:43,846 - INFO - [Valid] [32/90] | Loss: 0.5330 | Val Acc: 80.83%
2026-01-14 13:43:43,895 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 13:43:43,896 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 13:43:43,902 - INFO - --------------------------------------------------
2026-01-14 13:43:43,908 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:43:53,013 - INFO - [Train] [33/90] | Loss: 0.4066 | Train Acc: 86.98%
2026-01-14 13:43:55,326 - INFO - [Valid] [33/90] | Loss: 0.5423 | Val Acc: 79.94%
2026-01-14 13:43:55,336 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-01-14 13:43:55,337 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-01-14 13:43:55,342 - INFO - --------------------------------------------------
2026-01-14 13:43:55,346 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:44:04,319 - INFO - [Train] [34/90] | Loss: 0.3911 | Train Acc: 87.13%
2026-01-14 13:44:07,433 - INFO - [Valid] [34/90] | Loss: 0.5012 | Val Acc: 81.42%
2026-01-14 13:44:07,448 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.7834 | F1: 0.7961
2026-01-14 13:44:07,448 - INFO - [Metrics for 'normal'] | Precision: 0.8182 | Recall: 0.8407 | F1: 0.8293
2026-01-14 13:44:07,503 - INFO - [Best Model Saved] (val loss: 0.5012) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:44:07,503 - INFO - --------------------------------------------------
2026-01-14 13:44:07,506 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:44:17,119 - INFO - [Train] [35/90] | Loss: 0.4044 | Train Acc: 87.13%
2026-01-14 13:44:19,531 - INFO - [Valid] [35/90] | Loss: 0.5195 | Val Acc: 81.42%
2026-01-14 13:44:19,543 - INFO - [Metrics for 'abnormal'] | Precision: 0.8264 | Recall: 0.7580 | F1: 0.7907
2026-01-14 13:44:19,544 - INFO - [Metrics for 'normal'] | Precision: 0.8051 | Recall: 0.8626 | F1: 0.8329
2026-01-14 13:44:19,548 - INFO - --------------------------------------------------
2026-01-14 13:44:19,551 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:44:29,665 - INFO - [Train] [36/90] | Loss: 0.4036 | Train Acc: 86.98%
2026-01-14 13:44:31,910 - INFO - [Valid] [36/90] | Loss: 0.5212 | Val Acc: 81.71%
2026-01-14 13:44:31,931 - INFO - [Metrics for 'abnormal'] | Precision: 0.8231 | Recall: 0.7707 | F1: 0.7961
2026-01-14 13:44:31,932 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.8571 | F1: 0.8342
2026-01-14 13:44:31,937 - INFO - --------------------------------------------------
2026-01-14 13:44:31,940 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:44:39,937 - INFO - [Train] [37/90] | Loss: 0.3945 | Train Acc: 88.62%
2026-01-14 13:44:42,561 - INFO - [Valid] [37/90] | Loss: 0.5675 | Val Acc: 79.35%
2026-01-14 13:44:42,570 - INFO - [Metrics for 'abnormal'] | Precision: 0.7702 | Recall: 0.7898 | F1: 0.7799
2026-01-14 13:44:42,571 - INFO - [Metrics for 'normal'] | Precision: 0.8146 | Recall: 0.7967 | F1: 0.8056
2026-01-14 13:44:42,574 - INFO - --------------------------------------------------
2026-01-14 13:44:42,577 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:44:50,219 - INFO - [Train] [38/90] | Loss: 0.4007 | Train Acc: 87.35%
2026-01-14 13:44:53,176 - INFO - [Valid] [38/90] | Loss: 0.5590 | Val Acc: 79.06%
2026-01-14 13:44:53,189 - INFO - [Metrics for 'abnormal'] | Precision: 0.7986 | Recall: 0.7325 | F1: 0.7641
2026-01-14 13:44:53,190 - INFO - [Metrics for 'normal'] | Precision: 0.7846 | Recall: 0.8407 | F1: 0.8117
2026-01-14 13:44:53,195 - INFO - --------------------------------------------------
2026-01-14 13:44:53,198 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:45:01,435 - INFO - [Train] [39/90] | Loss: 0.4000 | Train Acc: 87.57%
2026-01-14 13:45:03,876 - INFO - [Valid] [39/90] | Loss: 0.5305 | Val Acc: 80.83%
2026-01-14 13:45:03,885 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 13:45:03,885 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 13:45:03,888 - INFO - --------------------------------------------------
2026-01-14 13:45:03,890 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:45:12,157 - INFO - [Train] [40/90] | Loss: 0.3764 | Train Acc: 88.54%
2026-01-14 13:45:15,041 - INFO - [Valid] [40/90] | Loss: 0.5291 | Val Acc: 79.94%
2026-01-14 13:45:15,054 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-01-14 13:45:15,055 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-01-14 13:45:15,059 - INFO - --------------------------------------------------
2026-01-14 13:45:15,062 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:45:23,851 - INFO - [Train] [41/90] | Loss: 0.3787 | Train Acc: 88.99%
2026-01-14 13:45:27,466 - INFO - [Valid] [41/90] | Loss: 0.5371 | Val Acc: 80.53%
2026-01-14 13:45:27,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.7580 | F1: 0.7829
2026-01-14 13:45:27,475 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8462 | F1: 0.8235
2026-01-14 13:45:27,478 - INFO - --------------------------------------------------
2026-01-14 13:45:27,480 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:45:36,636 - INFO - [Train] [42/90] | Loss: 0.3647 | Train Acc: 89.88%
2026-01-14 13:45:39,440 - INFO - [Valid] [42/90] | Loss: 0.5809 | Val Acc: 80.83%
2026-01-14 13:45:39,452 - INFO - [Metrics for 'abnormal'] | Precision: 0.8151 | Recall: 0.7580 | F1: 0.7855
2026-01-14 13:45:39,452 - INFO - [Metrics for 'normal'] | Precision: 0.8031 | Recall: 0.8516 | F1: 0.8267
2026-01-14 13:45:39,456 - INFO - --------------------------------------------------
2026-01-14 13:45:39,459 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:45:47,281 - INFO - [Train] [43/90] | Loss: 0.3614 | Train Acc: 90.40%
2026-01-14 13:45:50,085 - INFO - [Valid] [43/90] | Loss: 0.5387 | Val Acc: 82.30%
2026-01-14 13:45:50,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.8702 | Recall: 0.7261 | F1: 0.7917
2026-01-14 13:45:50,096 - INFO - [Metrics for 'normal'] | Precision: 0.7933 | Recall: 0.9066 | F1: 0.8462
2026-01-14 13:45:50,100 - INFO - --------------------------------------------------
2026-01-14 13:45:50,103 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:45:59,008 - INFO - [Train] [44/90] | Loss: 0.3589 | Train Acc: 90.55%
2026-01-14 13:46:01,794 - INFO - [Valid] [44/90] | Loss: 0.5662 | Val Acc: 80.53%
2026-01-14 13:46:01,807 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-01-14 13:46:01,807 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-01-14 13:46:01,812 - INFO - --------------------------------------------------
2026-01-14 13:46:01,815 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:46:10,315 - INFO - [Train] [45/90] | Loss: 0.3644 | Train Acc: 90.10%
2026-01-14 13:46:12,892 - INFO - [Valid] [45/90] | Loss: 0.5156 | Val Acc: 82.01%
2026-01-14 13:46:12,903 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.7898 | F1: 0.8026
2026-01-14 13:46:12,904 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.8462 | F1: 0.8347
2026-01-14 13:46:12,908 - INFO - --------------------------------------------------
2026-01-14 13:46:12,911 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:46:21,724 - INFO - [Train] [46/90] | Loss: 0.3500 | Train Acc: 91.59%
2026-01-14 13:46:23,819 - INFO - [Valid] [46/90] | Loss: 0.4999 | Val Acc: 81.71%
2026-01-14 13:46:23,828 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 13:46:23,829 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 13:46:23,874 - INFO - [Best Model Saved] (val loss: 0.4999) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:46:23,875 - INFO - --------------------------------------------------
2026-01-14 13:46:23,878 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:46:33,080 - INFO - [Train] [47/90] | Loss: 0.3635 | Train Acc: 90.85%
2026-01-14 13:46:36,044 - INFO - [Valid] [47/90] | Loss: 0.5417 | Val Acc: 79.06%
2026-01-14 13:46:36,076 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.8471 | F1: 0.7893
2026-01-14 13:46:36,076 - INFO - [Metrics for 'normal'] | Precision: 0.8491 | Recall: 0.7418 | F1: 0.7918
2026-01-14 13:46:36,080 - INFO - --------------------------------------------------
2026-01-14 13:46:36,083 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:46:44,826 - INFO - [Train] [48/90] | Loss: 0.3472 | Train Acc: 91.22%
2026-01-14 13:46:48,346 - INFO - [Valid] [48/90] | Loss: 0.5633 | Val Acc: 84.07%
2026-01-14 13:46:48,356 - INFO - [Metrics for 'abnormal'] | Precision: 0.8759 | Recall: 0.7643 | F1: 0.8163
2026-01-14 13:46:48,356 - INFO - [Metrics for 'normal'] | Precision: 0.8168 | Recall: 0.9066 | F1: 0.8594
2026-01-14 13:46:48,361 - INFO - --------------------------------------------------
2026-01-14 13:46:48,364 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:46:56,249 - INFO - [Train] [49/90] | Loss: 0.3368 | Train Acc: 92.19%
2026-01-14 13:46:59,585 - INFO - [Valid] [49/90] | Loss: 0.5488 | Val Acc: 82.89%
2026-01-14 13:46:59,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.8511 | Recall: 0.7643 | F1: 0.8054
2026-01-14 13:46:59,602 - INFO - [Metrics for 'normal'] | Precision: 0.8131 | Recall: 0.8846 | F1: 0.8474
2026-01-14 13:46:59,605 - INFO - --------------------------------------------------
2026-01-14 13:46:59,609 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:47:08,650 - INFO - [Train] [50/90] | Loss: 0.3413 | Train Acc: 91.07%
2026-01-14 13:47:11,485 - INFO - [Valid] [50/90] | Loss: 0.5516 | Val Acc: 81.71%
2026-01-14 13:47:11,498 - INFO - [Metrics for 'abnormal'] | Precision: 0.7684 | Recall: 0.8662 | F1: 0.8144
2026-01-14 13:47:11,498 - INFO - [Metrics for 'normal'] | Precision: 0.8704 | Recall: 0.7747 | F1: 0.8198
2026-01-14 13:47:11,548 - INFO - --------------------------------------------------
2026-01-14 13:47:11,551 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:47:19,107 - INFO - [Train] [51/90] | Loss: 0.3439 | Train Acc: 91.89%
2026-01-14 13:47:22,420 - INFO - [Valid] [51/90] | Loss: 0.5555 | Val Acc: 83.48%
2026-01-14 13:47:22,432 - INFO - [Metrics for 'abnormal'] | Precision: 0.8531 | Recall: 0.7771 | F1: 0.8133
2026-01-14 13:47:22,436 - INFO - [Metrics for 'normal'] | Precision: 0.8214 | Recall: 0.8846 | F1: 0.8519
2026-01-14 13:47:22,441 - INFO - --------------------------------------------------
2026-01-14 13:47:22,445 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:47:30,280 - INFO - [Train] [52/90] | Loss: 0.3340 | Train Acc: 92.26%
2026-01-14 13:47:33,129 - INFO - [Valid] [52/90] | Loss: 0.5739 | Val Acc: 80.53%
2026-01-14 13:47:33,141 - INFO - [Metrics for 'abnormal'] | Precision: 0.7725 | Recall: 0.8217 | F1: 0.7963
2026-01-14 13:47:33,141 - INFO - [Metrics for 'normal'] | Precision: 0.8372 | Recall: 0.7912 | F1: 0.8136
2026-01-14 13:47:33,146 - INFO - --------------------------------------------------
2026-01-14 13:47:33,149 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:47:42,671 - INFO - [Train] [53/90] | Loss: 0.3254 | Train Acc: 92.78%
2026-01-14 13:47:45,786 - INFO - [Valid] [53/90] | Loss: 0.6001 | Val Acc: 82.30%
2026-01-14 13:47:45,798 - INFO - [Metrics for 'abnormal'] | Precision: 0.8440 | Recall: 0.7580 | F1: 0.7987
2026-01-14 13:47:45,798 - INFO - [Metrics for 'normal'] | Precision: 0.8081 | Recall: 0.8791 | F1: 0.8421
2026-01-14 13:47:45,803 - INFO - --------------------------------------------------
2026-01-14 13:47:45,806 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:47:55,305 - INFO - [Train] [54/90] | Loss: 0.3220 | Train Acc: 93.08%
2026-01-14 13:47:58,252 - INFO - [Valid] [54/90] | Loss: 0.5411 | Val Acc: 81.12%
2026-01-14 13:47:58,264 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 13:47:58,265 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 13:47:58,270 - INFO - --------------------------------------------------
2026-01-14 13:47:58,274 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:48:06,765 - INFO - [Train] [55/90] | Loss: 0.3306 | Train Acc: 92.49%
2026-01-14 13:48:09,459 - INFO - [Valid] [55/90] | Loss: 0.5291 | Val Acc: 83.19%
2026-01-14 13:48:09,480 - INFO - [Metrics for 'abnormal'] | Precision: 0.8289 | Recall: 0.8025 | F1: 0.8155
2026-01-14 13:48:09,480 - INFO - [Metrics for 'normal'] | Precision: 0.8342 | Recall: 0.8571 | F1: 0.8455
2026-01-14 13:48:09,486 - INFO - --------------------------------------------------
2026-01-14 13:48:09,488 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:48:18,495 - INFO - [Train] [56/90] | Loss: 0.3252 | Train Acc: 92.93%
2026-01-14 13:48:20,799 - INFO - [Valid] [56/90] | Loss: 0.5276 | Val Acc: 80.83%
2026-01-14 13:48:20,848 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 13:48:20,848 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 13:48:20,851 - INFO - --------------------------------------------------
2026-01-14 13:48:20,889 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:48:29,342 - INFO - [Train] [57/90] | Loss: 0.3232 | Train Acc: 93.75%
2026-01-14 13:48:32,360 - INFO - [Valid] [57/90] | Loss: 0.5465 | Val Acc: 80.53%
2026-01-14 13:48:32,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-01-14 13:48:32,373 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-01-14 13:48:32,378 - INFO - --------------------------------------------------
2026-01-14 13:48:32,382 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:48:41,248 - INFO - [Train] [58/90] | Loss: 0.3188 | Train Acc: 92.49%
2026-01-14 13:48:43,935 - INFO - [Valid] [58/90] | Loss: 0.5540 | Val Acc: 81.42%
2026-01-14 13:48:43,947 - INFO - [Metrics for 'abnormal'] | Precision: 0.8219 | Recall: 0.7643 | F1: 0.7921
2026-01-14 13:48:43,947 - INFO - [Metrics for 'normal'] | Precision: 0.8083 | Recall: 0.8571 | F1: 0.8320
2026-01-14 13:48:43,951 - INFO - --------------------------------------------------
2026-01-14 13:48:43,953 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:48:52,944 - INFO - [Train] [59/90] | Loss: 0.3092 | Train Acc: 93.97%
2026-01-14 13:48:55,514 - INFO - [Valid] [59/90] | Loss: 0.6026 | Val Acc: 81.71%
2026-01-14 13:48:55,536 - INFO - [Metrics for 'abnormal'] | Precision: 0.8322 | Recall: 0.7580 | F1: 0.7933
2026-01-14 13:48:55,536 - INFO - [Metrics for 'normal'] | Precision: 0.8061 | Recall: 0.8681 | F1: 0.8360
2026-01-14 13:48:55,546 - INFO - --------------------------------------------------
2026-01-14 13:48:55,552 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:49:04,187 - INFO - [Train] [60/90] | Loss: 0.3210 | Train Acc: 92.71%
2026-01-14 13:49:07,620 - INFO - [Valid] [60/90] | Loss: 0.5672 | Val Acc: 80.83%
2026-01-14 13:49:07,639 - INFO - [Metrics for 'abnormal'] | Precision: 0.8108 | Recall: 0.7643 | F1: 0.7869
2026-01-14 13:49:07,640 - INFO - [Metrics for 'normal'] | Precision: 0.8063 | Recall: 0.8462 | F1: 0.8257
2026-01-14 13:49:07,644 - INFO - --------------------------------------------------
2026-01-14 13:49:07,647 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:49:16,530 - INFO - [Train] [61/90] | Loss: 0.3065 | Train Acc: 94.49%
2026-01-14 13:49:19,051 - INFO - [Valid] [61/90] | Loss: 0.5847 | Val Acc: 82.89%
2026-01-14 13:49:19,064 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.8025 | F1: 0.8129
2026-01-14 13:49:19,064 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8516 | F1: 0.8424
2026-01-14 13:49:19,069 - INFO - --------------------------------------------------
2026-01-14 13:49:19,072 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:49:29,656 - INFO - [Train] [62/90] | Loss: 0.3119 | Train Acc: 94.12%
2026-01-14 13:49:32,191 - INFO - [Valid] [62/90] | Loss: 0.5681 | Val Acc: 82.01%
2026-01-14 13:49:32,204 - INFO - [Metrics for 'abnormal'] | Precision: 0.8200 | Recall: 0.7834 | F1: 0.8013
2026-01-14 13:49:32,204 - INFO - [Metrics for 'normal'] | Precision: 0.8201 | Recall: 0.8516 | F1: 0.8356
2026-01-14 13:49:32,209 - INFO - --------------------------------------------------
2026-01-14 13:49:32,211 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:49:40,905 - INFO - [Train] [63/90] | Loss: 0.3033 | Train Acc: 94.27%
2026-01-14 13:49:44,177 - INFO - [Valid] [63/90] | Loss: 0.5570 | Val Acc: 80.24%
2026-01-14 13:49:44,187 - INFO - [Metrics for 'abnormal'] | Precision: 0.7812 | Recall: 0.7962 | F1: 0.7886
2026-01-14 13:49:44,187 - INFO - [Metrics for 'normal'] | Precision: 0.8212 | Recall: 0.8077 | F1: 0.8144
2026-01-14 13:49:44,191 - INFO - --------------------------------------------------
2026-01-14 13:49:44,194 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:49:53,807 - INFO - [Train] [64/90] | Loss: 0.2916 | Train Acc: 94.64%
2026-01-14 13:49:56,224 - INFO - [Valid] [64/90] | Loss: 0.6043 | Val Acc: 82.60%
2026-01-14 13:49:56,236 - INFO - [Metrics for 'abnormal'] | Precision: 0.8451 | Recall: 0.7643 | F1: 0.8027
2026-01-14 13:49:56,237 - INFO - [Metrics for 'normal'] | Precision: 0.8122 | Recall: 0.8791 | F1: 0.8443
2026-01-14 13:49:56,241 - INFO - --------------------------------------------------
2026-01-14 13:49:56,244 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:50:05,912 - INFO - [Train] [65/90] | Loss: 0.2977 | Train Acc: 94.49%
2026-01-14 13:50:07,971 - INFO - [Valid] [65/90] | Loss: 0.6007 | Val Acc: 80.24%
2026-01-14 13:50:07,986 - INFO - [Metrics for 'abnormal'] | Precision: 0.8261 | Recall: 0.7261 | F1: 0.7729
2026-01-14 13:50:07,986 - INFO - [Metrics for 'normal'] | Precision: 0.7861 | Recall: 0.8681 | F1: 0.8251
2026-01-14 13:50:07,991 - INFO - --------------------------------------------------
2026-01-14 13:50:08,010 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:50:17,357 - INFO - [Train] [66/90] | Loss: 0.3130 | Train Acc: 94.12%
2026-01-14 13:50:20,184 - INFO - [Valid] [66/90] | Loss: 0.5642 | Val Acc: 81.12%
2026-01-14 13:50:20,196 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:50:20,196 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:50:20,199 - INFO - --------------------------------------------------
2026-01-14 13:50:20,200 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:50:29,378 - INFO - [Train] [67/90] | Loss: 0.2848 | Train Acc: 95.46%
2026-01-14 13:50:32,398 - INFO - [Valid] [67/90] | Loss: 0.5837 | Val Acc: 82.01%
2026-01-14 13:50:32,409 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.7898 | F1: 0.8026
2026-01-14 13:50:32,410 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.8462 | F1: 0.8347
2026-01-14 13:50:32,414 - INFO - --------------------------------------------------
2026-01-14 13:50:32,417 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:50:41,887 - INFO - [Train] [68/90] | Loss: 0.2952 | Train Acc: 95.16%
2026-01-14 13:50:44,130 - INFO - [Valid] [68/90] | Loss: 0.5498 | Val Acc: 81.71%
2026-01-14 13:50:44,141 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 13:50:44,141 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 13:50:44,145 - INFO - --------------------------------------------------
2026-01-14 13:50:44,148 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:50:53,663 - INFO - [Train] [69/90] | Loss: 0.2821 | Train Acc: 96.13%
2026-01-14 13:50:55,892 - INFO - [Valid] [69/90] | Loss: 0.5700 | Val Acc: 82.30%
2026-01-14 13:50:55,901 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 13:50:55,902 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 13:50:55,905 - INFO - --------------------------------------------------
2026-01-14 13:50:55,908 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:51:04,420 - INFO - [Train] [70/90] | Loss: 0.2737 | Train Acc: 96.35%
2026-01-14 13:51:07,697 - INFO - [Valid] [70/90] | Loss: 0.5599 | Val Acc: 82.01%
2026-01-14 13:51:07,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-01-14 13:51:07,747 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-01-14 13:51:07,753 - INFO - --------------------------------------------------
2026-01-14 13:51:07,758 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:51:17,754 - INFO - [Train] [71/90] | Loss: 0.2805 | Train Acc: 95.91%
2026-01-14 13:51:19,621 - INFO - [Valid] [71/90] | Loss: 0.5962 | Val Acc: 79.94%
2026-01-14 13:51:19,634 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 13:51:19,635 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 13:51:19,639 - INFO - --------------------------------------------------
2026-01-14 13:51:19,641 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:51:28,158 - INFO - [Train] [72/90] | Loss: 0.2776 | Train Acc: 95.91%
2026-01-14 13:51:30,861 - INFO - [Valid] [72/90] | Loss: 0.6023 | Val Acc: 80.83%
2026-01-14 13:51:30,871 - INFO - [Metrics for 'abnormal'] | Precision: 0.8067 | Recall: 0.7707 | F1: 0.7883
2026-01-14 13:51:30,872 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.8407 | F1: 0.8248
2026-01-14 13:51:30,875 - INFO - --------------------------------------------------
2026-01-14 13:51:30,878 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:51:42,357 - INFO - [Train] [73/90] | Loss: 0.2834 | Train Acc: 96.28%
2026-01-14 13:51:44,278 - INFO - [Valid] [73/90] | Loss: 0.5867 | Val Acc: 81.71%
2026-01-14 13:51:44,289 - INFO - [Metrics for 'abnormal'] | Precision: 0.8188 | Recall: 0.7771 | F1: 0.7974
2026-01-14 13:51:44,290 - INFO - [Metrics for 'normal'] | Precision: 0.8158 | Recall: 0.8516 | F1: 0.8333
2026-01-14 13:51:44,294 - INFO - --------------------------------------------------
2026-01-14 13:51:44,297 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:51:54,997 - INFO - [Train] [74/90] | Loss: 0.2951 | Train Acc: 95.31%
2026-01-14 13:51:57,036 - INFO - [Valid] [74/90] | Loss: 0.5695 | Val Acc: 81.71%
2026-01-14 13:51:57,102 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:51:57,102 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:51:57,105 - INFO - --------------------------------------------------
2026-01-14 13:51:57,108 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:52:07,093 - INFO - [Train] [75/90] | Loss: 0.2760 | Train Acc: 96.21%
2026-01-14 13:52:09,171 - INFO - [Valid] [75/90] | Loss: 0.5723 | Val Acc: 82.01%
2026-01-14 13:52:09,183 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-01-14 13:52:09,184 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-01-14 13:52:09,188 - INFO - --------------------------------------------------
2026-01-14 13:52:09,191 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:52:19,050 - INFO - [Train] [76/90] | Loss: 0.2862 | Train Acc: 95.91%
2026-01-14 13:52:22,364 - INFO - [Valid] [76/90] | Loss: 0.5750 | Val Acc: 81.42%
2026-01-14 13:52:22,376 - INFO - [Metrics for 'abnormal'] | Precision: 0.8264 | Recall: 0.7580 | F1: 0.7907
2026-01-14 13:52:22,377 - INFO - [Metrics for 'normal'] | Precision: 0.8051 | Recall: 0.8626 | F1: 0.8329
2026-01-14 13:52:22,381 - INFO - --------------------------------------------------
2026-01-14 13:52:22,383 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:52:31,569 - INFO - [Train] [77/90] | Loss: 0.2691 | Train Acc: 96.73%
2026-01-14 13:52:34,527 - INFO - [Valid] [77/90] | Loss: 0.5673 | Val Acc: 81.71%
2026-01-14 13:52:34,568 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 13:52:34,569 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 13:52:34,593 - INFO - --------------------------------------------------
2026-01-14 13:52:34,597 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:52:43,884 - INFO - [Train] [78/90] | Loss: 0.2840 | Train Acc: 95.61%
2026-01-14 13:52:47,787 - INFO - [Valid] [78/90] | Loss: 0.5750 | Val Acc: 83.19%
2026-01-14 13:52:47,798 - INFO - [Metrics for 'abnormal'] | Precision: 0.8378 | Recall: 0.7898 | F1: 0.8131
2026-01-14 13:52:47,798 - INFO - [Metrics for 'normal'] | Precision: 0.8272 | Recall: 0.8681 | F1: 0.8472
2026-01-14 13:52:47,802 - INFO - --------------------------------------------------
2026-01-14 13:52:47,805 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:52:57,355 - INFO - [Train] [79/90] | Loss: 0.2869 | Train Acc: 95.24%
2026-01-14 13:53:00,417 - INFO - [Valid] [79/90] | Loss: 0.5782 | Val Acc: 80.53%
2026-01-14 13:53:00,426 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-01-14 13:53:00,426 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-01-14 13:53:00,430 - INFO - --------------------------------------------------
2026-01-14 13:53:00,432 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:53:09,536 - INFO - [Train] [80/90] | Loss: 0.2769 | Train Acc: 96.13%
2026-01-14 13:53:12,601 - INFO - [Valid] [80/90] | Loss: 0.5800 | Val Acc: 81.12%
2026-01-14 13:53:12,621 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-01-14 13:53:12,622 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-01-14 13:53:12,626 - INFO - --------------------------------------------------
2026-01-14 13:53:12,629 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:53:20,274 - INFO - [Train] [81/90] | Loss: 0.2629 | Train Acc: 96.73%
2026-01-14 13:53:22,913 - INFO - [Valid] [81/90] | Loss: 0.5781 | Val Acc: 80.24%
2026-01-14 13:53:22,926 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 13:53:22,926 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 13:53:22,931 - INFO - --------------------------------------------------
2026-01-14 13:53:22,934 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:53:31,988 - INFO - [Train] [82/90] | Loss: 0.2787 | Train Acc: 96.13%
2026-01-14 13:53:34,958 - INFO - [Valid] [82/90] | Loss: 0.5879 | Val Acc: 81.71%
2026-01-14 13:53:34,988 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 13:53:34,993 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 13:53:34,997 - INFO - --------------------------------------------------
2026-01-14 13:53:34,999 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:53:44,300 - INFO - [Train] [83/90] | Loss: 0.2691 | Train Acc: 96.58%
2026-01-14 13:53:47,584 - INFO - [Valid] [83/90] | Loss: 0.5743 | Val Acc: 82.89%
2026-01-14 13:53:47,597 - INFO - [Metrics for 'abnormal'] | Precision: 0.8235 | Recall: 0.8025 | F1: 0.8129
2026-01-14 13:53:47,598 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8516 | F1: 0.8424
2026-01-14 13:53:47,602 - INFO - --------------------------------------------------
2026-01-14 13:53:47,607 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:53:55,890 - INFO - [Train] [84/90] | Loss: 0.2600 | Train Acc: 97.17%
2026-01-14 13:54:00,143 - INFO - [Valid] [84/90] | Loss: 0.5785 | Val Acc: 81.42%
2026-01-14 13:54:00,157 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 13:54:00,157 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 13:54:00,164 - INFO - --------------------------------------------------
2026-01-14 13:54:00,166 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:54:09,055 - INFO - [Train] [85/90] | Loss: 0.2728 | Train Acc: 96.13%
2026-01-14 13:54:11,865 - INFO - [Valid] [85/90] | Loss: 0.5786 | Val Acc: 82.30%
2026-01-14 13:54:11,897 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-01-14 13:54:11,908 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-01-14 13:54:11,920 - INFO - --------------------------------------------------
2026-01-14 13:54:11,922 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:54:21,133 - INFO - [Train] [86/90] | Loss: 0.2608 | Train Acc: 97.47%
2026-01-14 13:54:23,900 - INFO - [Valid] [86/90] | Loss: 0.5751 | Val Acc: 82.30%
2026-01-14 13:54:23,908 - INFO - [Metrics for 'abnormal'] | Precision: 0.8212 | Recall: 0.7898 | F1: 0.8052
2026-01-14 13:54:23,909 - INFO - [Metrics for 'normal'] | Precision: 0.8245 | Recall: 0.8516 | F1: 0.8378
2026-01-14 13:54:23,912 - INFO - --------------------------------------------------
2026-01-14 13:54:23,914 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:54:32,481 - INFO - [Train] [87/90] | Loss: 0.2636 | Train Acc: 97.17%
2026-01-14 13:54:35,409 - INFO - [Valid] [87/90] | Loss: 0.5732 | Val Acc: 82.30%
2026-01-14 13:54:35,421 - INFO - [Metrics for 'abnormal'] | Precision: 0.8212 | Recall: 0.7898 | F1: 0.8052
2026-01-14 13:54:35,422 - INFO - [Metrics for 'normal'] | Precision: 0.8245 | Recall: 0.8516 | F1: 0.8378
2026-01-14 13:54:35,427 - INFO - --------------------------------------------------
2026-01-14 13:54:35,430 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:54:44,541 - INFO - [Train] [88/90] | Loss: 0.2550 | Train Acc: 97.32%
2026-01-14 13:54:47,362 - INFO - [Valid] [88/90] | Loss: 0.5928 | Val Acc: 81.71%
2026-01-14 13:54:47,387 - INFO - [Metrics for 'abnormal'] | Precision: 0.8188 | Recall: 0.7771 | F1: 0.7974
2026-01-14 13:54:47,391 - INFO - [Metrics for 'normal'] | Precision: 0.8158 | Recall: 0.8516 | F1: 0.8333
2026-01-14 13:54:47,395 - INFO - --------------------------------------------------
2026-01-14 13:54:47,401 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:54:57,302 - INFO - [Train] [89/90] | Loss: 0.2523 | Train Acc: 97.92%
2026-01-14 13:55:00,289 - INFO - [Valid] [89/90] | Loss: 0.5736 | Val Acc: 81.12%
2026-01-14 13:55:00,300 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 13:55:00,301 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 13:55:00,305 - INFO - --------------------------------------------------
2026-01-14 13:55:00,308 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:55:09,726 - INFO - [Train] [90/90] | Loss: 0.2689 | Train Acc: 96.65%
2026-01-14 13:55:12,213 - INFO - [Valid] [90/90] | Loss: 0.5760 | Val Acc: 81.71%
2026-01-14 13:55:12,227 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 13:55:12,228 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 13:55:12,234 - INFO - ==================================================
2026-01-14 13:55:12,235 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:55:12,237 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:55:12,237 - INFO - Baseline 모델 'efficientnet_b0'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:55:12,419 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:55:12,422 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 13:55:12,423 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:55:12,879 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 13:55:12,880 - INFO - ==================================================
2026-01-14 13:55:13,033 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/best_model.pth'
2026-01-14 13:55:13,034 - INFO - ==================================================
2026-01-14 13:55:13,035 - INFO - Test 모드를 시작합니다.
2026-01-14 13:55:13,496 - INFO - 연산량 (MACs): 0.0060 GMACs per sample
2026-01-14 13:55:13,499 - INFO - 연산량 (FLOPs): 0.0120 GFLOPs per sample
2026-01-14 13:55:13,499 - INFO - ==================================================
2026-01-14 13:55:13,499 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:55:15,836 - INFO - 샘플 당 평균 Forward Pass 시간: 11.78ms (std: 11.33ms), FPS: 112.94 (std: 37.01) (1개 샘플 x 100회 반복)
2026-01-14 13:55:15,836 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 80.42 MB
2026-01-14 13:55:15,836 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:55:19,407 - INFO - [Test] Loss: 0.4233 | Test Acc: 81.71%
2026-01-14 13:55:19,439 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 13:55:19,443 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 13:55:20,308 - INFO - ==================================================
2026-01-14 13:55:20,308 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/confusion_matrix_20260114_133752.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/confusion_matrix_20260114_133752.pdf'
2026-01-14 13:55:20,308 - INFO - ==================================================
2026-01-14 13:55:20,309 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:55:24,903 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/model_fp32_20260114_133752.onnx'에 저장되었습니다. (크기: 0.18 MB)
2026-01-14 13:55:25,518 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2555.94 MB (증가량: 6.33 MB)
2026-01-14 13:55:25,519 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:55:27,153 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 12.32ms (std: 15.65ms)
2026-01-14 13:55:27,154 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 133.79 FPS (std: 65.24) (1개 샘플 x 100회 반복)
2026-01-14 13:55:27,155 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2559.44 MB (순수 증가량: 3.50 MB)
2026-01-14 13:55:27,155 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2559.44 MB (전체 증가량: 9.83 MB)
2026-01-14 13:55:31,955 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.71%
2026-01-14 13:55:31,982 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 13:55:31,982 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 13:55:32,598 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/val_acc.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/val_acc.pdf'
2026-01-14 13:55:33,424 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/train_val_acc.pdf'
2026-01-14 13:55:34,263 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/F1_normal.pdf'
2026-01-14 13:55:35,004 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/val_loss.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/val_loss.pdf'
2026-01-14 13:55:35,585 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/learning_rate.pdf'
2026-01-14 13:55:42,520 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/compile.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_fpgm_20260114_133752/graph_20260114_133752/compile.pdf'
