2026-01-14 14:00:30,486 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/log_20260114_140030.log'에 저장됩니다.
2026-01-14 14:00:30,494 - INFO - ==================================================
2026-01-14 14:00:30,494 - INFO - config.yaml:
2026-01-14 14:00:30,494 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobile_vit_xxs
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.031371

2026-01-14 14:00:30,495 - INFO - ==================================================
2026-01-14 14:00:30,587 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 14:00:30,587 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 14:00:30,588 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 14:00:30,601 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 14:00:30,602 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 14:00:30,603 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 14:00:30,603 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:00:31,030 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 14:00:31,065 - INFO - ==================================================
2026-01-14 14:00:31,066 - INFO - 모델 파라미터 수:
2026-01-14 14:00:31,066 - INFO -   - 총 파라미터: 951,666 개
2026-01-14 14:00:31,066 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-01-14 14:00:31,066 - INFO - ================================================================================
2026-01-14 14:00:31,066 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 14:00:31,066 - INFO - ================================================================================
2026-01-14 14:00:31,066 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:00:31,068 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 14:00:31,069 - INFO - ==================================================
2026-01-14 14:00:31,069 - INFO - train 모드를 시작합니다.
2026-01-14 14:00:31,069 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:00:31,069 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:00:31,069 - INFO - --------------------------------------------------
2026-01-14 14:00:31,073 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 14:00:43,029 - INFO - [Train] [1/10] | Loss: 0.5202 | Train Acc: 78.79%
2026-01-14 14:00:46,288 - INFO - [Valid] [1/10] | Loss: 0.5350 | Val Acc: 81.12%
2026-01-14 14:00:46,303 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 14:00:46,304 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 14:00:46,383 - INFO - [Best Model Saved] (val loss: 0.5350) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:00:46,385 - INFO - --------------------------------------------------
2026-01-14 14:00:46,388 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 14:00:57,637 - INFO - [Train] [2/10] | Loss: 0.4592 | Train Acc: 83.78%
2026-01-14 14:01:00,377 - INFO - [Valid] [2/10] | Loss: 0.5198 | Val Acc: 82.01%
2026-01-14 14:01:00,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 14:01:00,391 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 14:01:00,476 - INFO - [Best Model Saved] (val loss: 0.5198) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:01:00,476 - INFO - --------------------------------------------------
2026-01-14 14:01:00,479 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 14:01:10,142 - INFO - [Train] [3/10] | Loss: 0.4271 | Train Acc: 85.71%
2026-01-14 14:01:12,648 - INFO - [Valid] [3/10] | Loss: 0.5066 | Val Acc: 81.12%
2026-01-14 14:01:12,661 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 14:01:12,662 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 14:01:12,752 - INFO - [Best Model Saved] (val loss: 0.5066) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:01:12,753 - INFO - --------------------------------------------------
2026-01-14 14:01:12,755 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 14:01:23,199 - INFO - [Train] [4/10] | Loss: 0.4012 | Train Acc: 87.65%
2026-01-14 14:01:26,211 - INFO - [Valid] [4/10] | Loss: 0.5268 | Val Acc: 79.65%
2026-01-14 14:01:26,222 - INFO - [Metrics for 'abnormal'] | Precision: 0.8188 | Recall: 0.7197 | F1: 0.7661
2026-01-14 14:01:26,223 - INFO - [Metrics for 'normal'] | Precision: 0.7811 | Recall: 0.8626 | F1: 0.8198
2026-01-14 14:01:26,227 - INFO - --------------------------------------------------
2026-01-14 14:01:26,231 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 14:01:36,185 - INFO - [Train] [5/10] | Loss: 0.3806 | Train Acc: 88.62%
2026-01-14 14:01:38,840 - INFO - [Valid] [5/10] | Loss: 0.5262 | Val Acc: 82.01%
2026-01-14 14:01:38,852 - INFO - [Metrics for 'abnormal'] | Precision: 0.7824 | Recall: 0.8471 | F1: 0.8135
2026-01-14 14:01:38,853 - INFO - [Metrics for 'normal'] | Precision: 0.8580 | Recall: 0.7967 | F1: 0.8262
2026-01-14 14:01:38,857 - INFO - --------------------------------------------------
2026-01-14 14:01:38,861 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 14:01:50,828 - INFO - [Train] [6/10] | Loss: 0.3508 | Train Acc: 90.62%
2026-01-14 14:01:54,163 - INFO - [Valid] [6/10] | Loss: 0.5216 | Val Acc: 80.83%
2026-01-14 14:01:54,176 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 14:01:54,177 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 14:01:54,181 - INFO - --------------------------------------------------
2026-01-14 14:01:54,185 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 14:02:04,275 - INFO - [Train] [7/10] | Loss: 0.3104 | Train Acc: 94.35%
2026-01-14 14:02:06,238 - INFO - [Valid] [7/10] | Loss: 0.4930 | Val Acc: 81.71%
2026-01-14 14:02:06,252 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 14:02:06,253 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 14:02:06,320 - INFO - [Best Model Saved] (val loss: 0.4930) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:02:06,321 - INFO - --------------------------------------------------
2026-01-14 14:02:06,323 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 14:02:15,624 - INFO - [Train] [8/10] | Loss: 0.2834 | Train Acc: 96.13%
2026-01-14 14:02:19,843 - INFO - [Valid] [8/10] | Loss: 0.5035 | Val Acc: 83.19%
2026-01-14 14:02:19,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.8012 | Recall: 0.8471 | F1: 0.8235
2026-01-14 14:02:19,854 - INFO - [Metrics for 'normal'] | Precision: 0.8613 | Recall: 0.8187 | F1: 0.8394
2026-01-14 14:02:19,859 - INFO - --------------------------------------------------
2026-01-14 14:02:19,863 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 14:02:30,362 - INFO - [Train] [9/10] | Loss: 0.2680 | Train Acc: 97.02%
2026-01-14 14:02:32,575 - INFO - [Valid] [9/10] | Loss: 0.4797 | Val Acc: 83.78%
2026-01-14 14:02:32,585 - INFO - [Metrics for 'abnormal'] | Precision: 0.8187 | Recall: 0.8344 | F1: 0.8265
2026-01-14 14:02:32,586 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8407 | F1: 0.8476
2026-01-14 14:02:32,640 - INFO - [Best Model Saved] (val loss: 0.4797) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:02:32,641 - INFO - --------------------------------------------------
2026-01-14 14:02:32,643 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 14:02:43,189 - INFO - [Train] [10/10] | Loss: 0.2604 | Train Acc: 97.40%
2026-01-14 14:02:46,050 - INFO - [Valid] [10/10] | Loss: 0.4959 | Val Acc: 83.19%
2026-01-14 14:02:46,059 - INFO - [Metrics for 'abnormal'] | Precision: 0.8165 | Recall: 0.8217 | F1: 0.8190
2026-01-14 14:02:46,059 - INFO - [Metrics for 'normal'] | Precision: 0.8453 | Recall: 0.8407 | F1: 0.8430
2026-01-14 14:02:46,064 - INFO - ================================================================================
2026-01-14 14:02:46,065 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 14:02:46,065 - INFO - ================================================================================
2026-01-14 14:02:46,181 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'을(를) 불러왔습니다.
2026-01-14 14:02:46,182 - INFO - ================================================================================
2026-01-14 14:02:46,183 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 14:02:46,185 - INFO - 원본 모델 파라미터: 0.9517M
2026-01-14 14:02:46,355 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:46,356 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:46,360 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:55,477 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:55,479 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:02:56,656 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 14:02:56,656 - INFO - ==================================================
2026-01-14 14:02:56,658 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.3049M (감소율: 67.96%)
2026-01-14 14:02:56,716 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:56,717 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:56,720 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:06,742 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:06,744 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:08,646 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 14:03:08,649 - INFO - ==================================================
2026-01-14 14:03:08,652 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1109M (감소율: 88.35%)
2026-01-14 14:03:08,735 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:08,736 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:08,739 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:18,662 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:18,667 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:21,174 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 14:03:21,175 - INFO - ==================================================
2026-01-14 14:03:21,185 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0459M (감소율: 95.18%)
2026-01-14 14:03:21,308 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:21,309 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:21,314 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:31,334 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:31,337 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:32,261 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 14:03:32,262 - INFO - ==================================================
2026-01-14 14:03:32,265 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0214M (감소율: 97.76%)
2026-01-14 14:03:32,326 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:32,327 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:32,332 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:41,394 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:41,396 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:41,922 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 14:03:41,923 - INFO - ==================================================
2026-01-14 14:03:41,925 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0337M (감소율: 96.46%)
2026-01-14 14:03:41,964 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:41,964 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:41,967 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:50,173 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:50,175 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:50,918 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 14:03:50,919 - INFO - ==================================================
2026-01-14 14:03:50,922 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0272M (감소율: 97.14%)
2026-01-14 14:03:50,978 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:50,978 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:50,982 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:00,286 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:00,287 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:01,344 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 14:04:01,345 - INFO - ==================================================
2026-01-14 14:04:01,348 - INFO -   [탐색  7] 희소도: 0.9049 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:04:01,420 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:01,422 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:01,426 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:10,325 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:10,326 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:11,425 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9087890624999999)에 맞춰 변경되었습니다.
2026-01-14 14:04:11,426 - INFO - ==================================================
2026-01-14 14:04:11,429 - INFO -   [탐색  8] 희소도: 0.9088 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:04:11,489 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:11,490 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:11,495 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:20,245 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:20,250 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:21,041 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9068554687499999)에 맞춰 변경되었습니다.
2026-01-14 14:04:21,043 - INFO - ==================================================
2026-01-14 14:04:21,045 - INFO -   [탐색  9] 희소도: 0.9069 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:04:21,148 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:21,149 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:21,154 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:30,760 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:30,761 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:31,427 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9058886718749999)에 맞춰 변경되었습니다.
2026-01-14 14:04:31,428 - INFO - ==================================================
2026-01-14 14:04:31,432 - INFO -   [탐색 10] 희소도: 0.9059 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:04:31,476 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:31,477 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:31,481 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:40,066 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:40,068 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:41,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9063720703124999)에 맞춰 변경되었습니다.
2026-01-14 14:04:41,046 - INFO - ==================================================
2026-01-14 14:04:41,048 - INFO -   [탐색 11] 희소도: 0.9064 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:04:41,092 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:41,093 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:41,096 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:51,593 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:51,595 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:52,236 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9061303710937498)에 맞춰 변경되었습니다.
2026-01-14 14:04:52,236 - INFO - ==================================================
2026-01-14 14:04:52,239 - INFO -   [탐색 12] 희소도: 0.9061 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:04:52,301 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:52,301 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:52,306 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:02,602 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:02,603 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:04,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062512207031248)에 맞춰 변경되었습니다.
2026-01-14 14:05:04,046 - INFO - ==================================================
2026-01-14 14:05:04,050 - INFO -   [탐색 13] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:05:04,100 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:04,100 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:04,105 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:13,520 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:13,522 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:14,454 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9061907958984373)에 맞춰 변경되었습니다.
2026-01-14 14:05:14,455 - INFO - ==================================================
2026-01-14 14:05:14,458 - INFO -   [탐색 14] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:05:14,504 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:14,505 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:14,509 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:23,769 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:23,771 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:24,540 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062210083007811)에 맞춰 변경되었습니다.
2026-01-14 14:05:24,541 - INFO - ==================================================
2026-01-14 14:05:24,544 - INFO -   [탐색 15] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:05:24,604 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:24,605 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:24,610 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:33,791 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:33,792 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:34,578 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906236114501953)에 맞춰 변경되었습니다.
2026-01-14 14:05:34,579 - INFO - ==================================================
2026-01-14 14:05:34,581 - INFO -   [탐색 16] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:05:34,640 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:34,640 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:34,644 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:44,421 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:44,423 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:45,347 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062436676025389)에 맞춰 변경되었습니다.
2026-01-14 14:05:45,347 - INFO - ==================================================
2026-01-14 14:05:45,350 - INFO -   [탐색 17] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:05:45,414 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:45,415 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:45,420 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:55,238 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:55,239 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:56,679 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062474441528319)에 맞춰 변경되었습니다.
2026-01-14 14:05:56,683 - INFO - ==================================================
2026-01-14 14:05:56,688 - INFO -   [탐색 18] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:05:56,819 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:56,820 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:56,825 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:06,353 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:06,355 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:07,364 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062493324279783)에 맞춰 변경되었습니다.
2026-01-14 14:06:07,364 - INFO - ==================================================
2026-01-14 14:06:07,366 - INFO -   [탐색 19] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:06:07,437 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:07,438 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:07,443 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:17,003 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:17,009 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:17,931 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062502765655516)에 맞춰 변경되었습니다.
2026-01-14 14:06:17,932 - INFO - ==================================================
2026-01-14 14:06:17,935 - INFO -   [탐색 20] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:06:17,984 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:17,985 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:17,989 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:27,382 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:27,384 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:27,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249804496765)에 맞춰 변경되었습니다.
2026-01-14 14:06:27,952 - INFO - ==================================================
2026-01-14 14:06:27,954 - INFO -   [탐색 21] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:06:28,005 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:28,006 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:28,011 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:39,006 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:39,007 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:40,165 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500405311582)에 맞춰 변경되었습니다.
2026-01-14 14:06:40,165 - INFO - ==================================================
2026-01-14 14:06:40,183 - INFO -   [탐색 22] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:06:40,277 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:40,277 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:40,282 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:49,565 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:49,566 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:50,867 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499225139615)에 맞춰 변경되었습니다.
2026-01-14 14:06:50,868 - INFO - ==================================================
2026-01-14 14:06:50,872 - INFO -   [탐색 23] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:06:50,931 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:50,932 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:50,937 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:59,587 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:59,589 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:00,423 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499815225599)에 맞춰 변경되었습니다.
2026-01-14 14:07:00,424 - INFO - ==================================================
2026-01-14 14:07:00,427 - INFO -   [탐색 24] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:07:00,495 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:00,496 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:00,502 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:09,678 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:09,680 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:10,779 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906250011026859)에 맞춰 변경되었습니다.
2026-01-14 14:07:10,779 - INFO - ==================================================
2026-01-14 14:07:10,782 - INFO -   [탐색 25] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:07:10,890 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:10,894 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:10,898 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:20,249 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:20,252 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:21,069 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499962747095)에 맞춰 변경되었습니다.
2026-01-14 14:07:21,069 - INFO - ==================================================
2026-01-14 14:07:21,073 - INFO -   [탐색 26] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:07:21,144 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:21,145 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:21,153 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:29,733 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:29,735 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:30,428 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500036507842)에 맞춰 변경되었습니다.
2026-01-14 14:07:30,429 - INFO - ==================================================
2026-01-14 14:07:30,432 - INFO -   [탐색 27] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:07:30,485 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:30,486 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:30,490 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:39,244 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:39,252 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:40,606 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999627469)에 맞춰 변경되었습니다.
2026-01-14 14:07:40,607 - INFO - ==================================================
2026-01-14 14:07:40,611 - INFO -   [탐색 28] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:07:40,671 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:40,671 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:40,674 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:50,375 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:50,377 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:51,087 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500018067656)에 맞춰 변경되었습니다.
2026-01-14 14:07:51,087 - INFO - ==================================================
2026-01-14 14:07:51,091 - INFO -   [탐색 29] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:07:51,139 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:51,140 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:51,143 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:59,821 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:59,823 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:00,461 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500008847563)에 맞춰 변경되었습니다.
2026-01-14 14:08:00,463 - INFO - ==================================================
2026-01-14 14:08:00,467 - INFO -   [탐색 30] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:08:00,524 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:00,524 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:00,528 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:09,581 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:09,582 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:10,159 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500004237516)에 맞춰 변경되었습니다.
2026-01-14 14:08:10,160 - INFO - ==================================================
2026-01-14 14:08:10,164 - INFO -   [탐색 31] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:08:10,227 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:10,227 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:10,232 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:19,026 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:19,028 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:19,826 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500001932492)에 맞춰 변경되었습니다.
2026-01-14 14:08:19,827 - INFO - ==================================================
2026-01-14 14:08:19,829 - INFO -   [탐색 32] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:08:20,180 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:20,181 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:20,185 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:29,058 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:29,060 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:30,089 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906250000077998)에 맞춰 변경되었습니다.
2026-01-14 14:08:30,089 - INFO - ==================================================
2026-01-14 14:08:30,093 - INFO -   [탐색 33] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:08:30,153 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:30,153 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:30,158 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:39,052 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:39,053 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:39,814 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000203725)에 맞춰 변경되었습니다.
2026-01-14 14:08:39,815 - INFO - ==================================================
2026-01-14 14:08:39,818 - INFO -   [탐색 34] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:08:39,871 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:39,871 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:39,877 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:48,786 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:48,787 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:49,414 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999915596)에 맞춰 변경되었습니다.
2026-01-14 14:08:49,415 - INFO - ==================================================
2026-01-14 14:08:49,418 - INFO -   [탐색 35] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:08:49,464 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:49,465 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:49,468 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:58,444 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:58,446 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:59,386 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000059661)에 맞춰 변경되었습니다.
2026-01-14 14:08:59,387 - INFO - ==================================================
2026-01-14 14:08:59,389 - INFO -   [탐색 36] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:08:59,441 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:59,442 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:59,445 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:09,217 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:09,219 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:10,668 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999987629)에 맞춰 변경되었습니다.
2026-01-14 14:09:10,669 - INFO - ==================================================
2026-01-14 14:09:10,675 - INFO -   [탐색 37] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:09:10,742 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:10,743 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:10,749 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:20,191 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:20,193 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:20,981 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000023646)에 맞춰 변경되었습니다.
2026-01-14 14:09:20,981 - INFO - ==================================================
2026-01-14 14:09:20,984 - INFO -   [탐색 38] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:09:21,078 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:21,079 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:21,084 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:29,741 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:29,743 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:30,874 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000005638)에 맞춰 변경되었습니다.
2026-01-14 14:09:30,875 - INFO - ==================================================
2026-01-14 14:09:30,879 - INFO -   [탐색 39] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:09:30,944 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:30,945 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:30,950 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:40,593 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:40,596 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:41,832 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999996634)에 맞춰 변경되었습니다.
2026-01-14 14:09:41,832 - INFO - ==================================================
2026-01-14 14:09:41,836 - INFO -   [탐색 40] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:09:41,906 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:41,907 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:41,912 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:51,804 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:51,807 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:52,651 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000001136)에 맞춰 변경되었습니다.
2026-01-14 14:09:52,651 - INFO - ==================================================
2026-01-14 14:09:52,654 - INFO -   [탐색 41] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:09:52,713 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:52,714 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:52,717 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:02,087 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:02,093 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:03,391 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999998885)에 맞춰 변경되었습니다.
2026-01-14 14:10:03,392 - INFO - ==================================================
2026-01-14 14:10:03,399 - INFO -   [탐색 42] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:10:03,445 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:03,445 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:03,448 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:13,681 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:13,682 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:14,181 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000011)에 맞춰 변경되었습니다.
2026-01-14 14:10:14,181 - INFO - ==================================================
2026-01-14 14:10:14,184 - INFO -   [탐색 43] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:10:14,228 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:14,229 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:14,233 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:23,639 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:23,640 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:24,213 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999448)에 맞춰 변경되었습니다.
2026-01-14 14:10:24,214 - INFO - ==================================================
2026-01-14 14:10:24,217 - INFO -   [탐색 44] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:10:24,277 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:24,277 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:24,280 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:33,672 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:33,674 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:34,210 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999729)에 맞춰 변경되었습니다.
2026-01-14 14:10:34,211 - INFO - ==================================================
2026-01-14 14:10:34,214 - INFO -   [탐색 45] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:10:34,281 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:34,281 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:34,287 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:43,609 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:43,611 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:44,376 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249999999987)에 맞춰 변경되었습니다.
2026-01-14 14:10:44,377 - INFO - ==================================================
2026-01-14 14:10:44,381 - INFO -   [탐색 46] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:10:44,726 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:44,727 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:44,731 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:53,398 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:53,400 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:54,270 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.906249999999994)에 맞춰 변경되었습니다.
2026-01-14 14:10:54,271 - INFO - ==================================================
2026-01-14 14:10:54,276 - INFO -   [탐색 47] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:10:54,358 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:54,358 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:54,364 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:03,601 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:03,603 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:04,339 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999976)에 맞춰 변경되었습니다.
2026-01-14 14:11:04,340 - INFO - ==================================================
2026-01-14 14:11:04,343 - INFO -   [탐색 48] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:11:04,405 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:04,406 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:04,411 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:14,133 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:14,136 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:15,146 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999993)에 맞춰 변경되었습니다.
2026-01-14 14:11:15,147 - INFO - ==================================================
2026-01-14 14:11:15,150 - INFO -   [탐색 49] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:11:15,213 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:15,213 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:15,218 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:24,451 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:24,452 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:25,335 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000002)에 맞춰 변경되었습니다.
2026-01-14 14:11:25,335 - INFO - ==================================================
2026-01-14 14:11:25,338 - INFO -   [탐색 50] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:11:25,393 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:25,393 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:25,397 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:35,056 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:35,059 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:36,544 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062499999999998)에 맞춰 변경되었습니다.
2026-01-14 14:11:36,545 - INFO - ==================================================
2026-01-14 14:11:36,550 - INFO -   [탐색 51] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:11:36,619 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:36,620 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:36,627 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:44,604 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:44,609 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:45,712 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:11:45,713 - INFO - ==================================================
2026-01-14 14:11:45,717 - INFO -   [탐색 52] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:11:45,781 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:45,782 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:45,787 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:54,366 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:54,372 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:55,416 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9062500000000001)에 맞춰 변경되었습니다.
2026-01-14 14:11:55,417 - INFO - ==================================================
2026-01-14 14:11:55,423 - INFO -   [탐색 53] 희소도: 0.9063 -> 파라미터: 0.0292M (감소율: 96.93%)
2026-01-14 14:11:55,493 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:55,495 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:55,500 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:04,919 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:04,921 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:05,578 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:12:05,579 - INFO - ==================================================
2026-01-14 14:12:05,584 - INFO -   [탐색 54] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:12:05,644 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:05,645 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:05,650 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:14,482 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:14,484 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:16,012 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:12:16,013 - INFO - ==================================================
2026-01-14 14:12:16,016 - INFO -   [탐색 55] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:12:16,107 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:16,108 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:16,113 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:25,541 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:25,543 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:26,729 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:12:26,730 - INFO - ==================================================
2026-01-14 14:12:26,734 - INFO -   [탐색 56] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:12:26,795 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:26,795 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:26,801 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:36,075 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:36,077 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:36,729 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:12:36,729 - INFO - ==================================================
2026-01-14 14:12:36,732 - INFO -   [탐색 57] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:12:36,777 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:36,778 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:36,781 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:45,752 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:45,756 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:46,608 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:12:46,608 - INFO - ==================================================
2026-01-14 14:12:46,612 - INFO -   [탐색 58] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:12:46,731 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:46,731 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:46,863 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:57,705 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:57,707 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:58,622 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:12:58,622 - INFO - ==================================================
2026-01-14 14:12:58,629 - INFO -   [탐색 59] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:12:58,715 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:58,715 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:58,720 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:07,419 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:07,424 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:09,101 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:13:09,101 - INFO - ==================================================
2026-01-14 14:13:09,104 - INFO -   [탐색 60] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:13:09,188 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:09,190 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:09,195 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:18,408 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:18,409 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:19,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:13:19,629 - INFO - ==================================================
2026-01-14 14:13:19,633 - INFO -   [탐색 61] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:13:19,694 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:19,695 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:19,700 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:27,627 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:27,633 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:28,999 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:13:29,000 - INFO - ==================================================
2026-01-14 14:13:29,003 - INFO -   [탐색 62] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:13:29,057 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:29,057 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:29,061 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:38,379 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:38,381 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:39,028 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:13:39,028 - INFO - ==================================================
2026-01-14 14:13:39,031 - INFO -   [탐색 63] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:13:39,079 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:39,079 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:39,083 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:49,044 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:49,047 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:50,274 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:13:50,275 - INFO - ==================================================
2026-01-14 14:13:50,278 - INFO -   [탐색 64] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:13:50,335 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:50,336 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:50,341 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:58,533 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:58,534 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:59,863 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:13:59,864 - INFO - ==================================================
2026-01-14 14:13:59,868 - INFO -   [탐색 65] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:13:59,928 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:59,929 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:59,933 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:08,363 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:08,366 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:10,252 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:14:10,252 - INFO - ==================================================
2026-01-14 14:14:10,256 - INFO -   [탐색 66] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:14:10,307 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:10,308 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:10,312 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:19,422 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:19,425 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:20,551 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:14:20,552 - INFO - ==================================================
2026-01-14 14:14:20,556 - INFO -   [탐색 67] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:14:20,616 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:20,617 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:20,621 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:30,003 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:30,005 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:30,763 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:14:30,764 - INFO - ==================================================
2026-01-14 14:14:30,766 - INFO -   [탐색 68] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:14:30,812 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:30,813 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:30,816 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:40,057 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:40,059 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:40,873 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:14:40,874 - INFO - ==================================================
2026-01-14 14:14:40,877 - INFO -   [탐색 69] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:14:40,940 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:40,941 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:40,946 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:49,874 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:49,876 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:50,817 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:14:50,818 - INFO - ==================================================
2026-01-14 14:14:50,822 - INFO -   [탐색 70] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:14:50,894 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:50,894 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:50,899 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:00,299 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:00,300 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:01,462 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:15:01,462 - INFO - ==================================================
2026-01-14 14:15:01,466 - INFO -   [탐색 71] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:15:01,513 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:01,513 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:01,517 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:10,923 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:10,925 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:11,789 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:15:11,789 - INFO - ==================================================
2026-01-14 14:15:11,791 - INFO -   [탐색 72] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:15:11,851 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:11,852 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:11,858 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:21,738 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:21,740 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:22,995 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:15:22,995 - INFO - ==================================================
2026-01-14 14:15:22,998 - INFO -   [탐색 73] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:15:23,070 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:23,071 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:23,074 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:32,117 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:32,123 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:33,154 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:15:33,154 - INFO - ==================================================
2026-01-14 14:15:33,157 - INFO -   [탐색 74] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:15:33,216 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:33,217 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:33,222 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:43,431 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:43,433 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:44,979 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:15:44,979 - INFO - ==================================================
2026-01-14 14:15:44,982 - INFO -   [탐색 75] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:15:45,043 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:45,044 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:45,049 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:54,673 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:54,674 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:56,135 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:15:56,136 - INFO - ==================================================
2026-01-14 14:15:56,139 - INFO -   [탐색 76] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:15:56,186 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:56,186 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:56,191 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:04,740 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:04,743 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:05,627 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:16:05,629 - INFO - ==================================================
2026-01-14 14:16:05,637 - INFO -   [탐색 77] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:16:05,729 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:05,735 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:05,741 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:14,638 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:14,640 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:15,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:16:15,647 - INFO - ==================================================
2026-01-14 14:16:15,650 - INFO -   [탐색 78] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:16:15,694 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:15,695 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:15,698 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:24,626 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:24,628 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:25,649 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:16:25,653 - INFO - ==================================================
2026-01-14 14:16:25,655 - INFO -   [탐색 79] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:16:25,728 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:25,728 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:25,733 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:35,005 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:35,007 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:35,772 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:16:35,773 - INFO - ==================================================
2026-01-14 14:16:35,777 - INFO -   [탐색 80] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:16:36,393 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:36,394 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:36,399 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:45,916 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:45,918 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:46,737 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:16:46,738 - INFO - ==================================================
2026-01-14 14:16:46,743 - INFO -   [탐색 81] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:16:46,833 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:46,834 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:46,839 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:55,942 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:55,944 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:56,532 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:16:56,532 - INFO - ==================================================
2026-01-14 14:16:56,535 - INFO -   [탐색 82] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:16:56,580 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:56,581 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:56,585 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:05,855 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:05,857 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:06,509 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:17:06,510 - INFO - ==================================================
2026-01-14 14:17:06,513 - INFO -   [탐색 83] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:17:06,576 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:06,577 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:06,583 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:16,060 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:16,062 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:17,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:17:17,141 - INFO - ==================================================
2026-01-14 14:17:17,147 - INFO -   [탐색 84] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:17:17,209 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:17,209 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:17,213 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:25,285 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:25,287 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:26,615 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:17:26,615 - INFO - ==================================================
2026-01-14 14:17:26,618 - INFO -   [탐색 85] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:17:26,697 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:26,697 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:26,723 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:35,611 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:35,612 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:36,514 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:17:36,515 - INFO - ==================================================
2026-01-14 14:17:36,518 - INFO -   [탐색 86] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:17:36,672 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:36,675 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:36,680 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:45,398 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:45,400 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:46,443 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:17:46,443 - INFO - ==================================================
2026-01-14 14:17:46,445 - INFO -   [탐색 87] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:17:46,491 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:46,491 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:46,494 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:56,258 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:56,259 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:56,916 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:17:56,917 - INFO - ==================================================
2026-01-14 14:17:56,920 - INFO -   [탐색 88] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:17:57,012 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:57,013 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:57,059 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:06,294 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:06,296 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:07,174 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:18:07,175 - INFO - ==================================================
2026-01-14 14:18:07,179 - INFO -   [탐색 89] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:18:07,245 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:07,246 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:07,253 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:16,728 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:16,729 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:18,082 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:18:18,084 - INFO - ==================================================
2026-01-14 14:18:18,088 - INFO -   [탐색 90] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:18:18,149 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:18,150 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:18,155 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:27,144 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:27,146 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:28,075 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:18:28,075 - INFO - ==================================================
2026-01-14 14:18:28,078 - INFO -   [탐색 91] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:18:28,136 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:28,137 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:28,143 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:37,741 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:37,743 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:38,498 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:18:38,498 - INFO - ==================================================
2026-01-14 14:18:38,501 - INFO -   [탐색 92] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:18:38,562 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:38,563 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:38,568 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:48,315 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:48,316 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:49,102 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:18:49,104 - INFO - ==================================================
2026-01-14 14:18:49,111 - INFO -   [탐색 93] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:18:49,173 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:49,174 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:49,180 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:59,546 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:59,548 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:00,269 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:19:00,270 - INFO - ==================================================
2026-01-14 14:19:00,272 - INFO -   [탐색 94] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:19:00,329 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:19:00,330 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:19:00,335 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:09,810 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:09,812 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:10,702 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:19:10,703 - INFO - ==================================================
2026-01-14 14:19:10,707 - INFO -   [탐색 95] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:19:10,774 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:19:10,775 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:19:10,778 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:19,495 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:19,496 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:21,208 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:19:21,210 - INFO - ==================================================
2026-01-14 14:19:21,215 - INFO -   [탐색 96] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:19:21,275 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:19:21,276 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:19:21,281 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:29,792 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:29,796 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:30,646 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:19:30,648 - INFO - ==================================================
2026-01-14 14:19:30,651 - INFO -   [탐색 97] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:19:30,717 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:19:30,718 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:19:30,724 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:39,013 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:39,015 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:40,078 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:19:40,078 - INFO - ==================================================
2026-01-14 14:19:40,081 - INFO -   [탐색 98] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:19:40,128 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:19:40,128 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:19:40,132 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:48,776 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:48,778 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:50,104 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:19:50,105 - INFO - ==================================================
2026-01-14 14:19:50,109 - INFO -   [탐색 99] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:19:50,174 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:19:50,175 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:19:50,181 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:59,638 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:59,641 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:20:01,050 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90625)에 맞춰 변경되었습니다.
2026-01-14 14:20:01,051 - INFO - ==================================================
2026-01-14 14:20:01,054 - INFO -   [탐색 100] 희소도: 0.9062 -> 파라미터: 0.0316M (감소율: 96.68%)
2026-01-14 14:20:01,054 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9049 입니다.
2026-01-14 14:20:01,054 - INFO - ================================================================================
2026-01-14 14:20:01,058 - INFO - 계산된 Pruning 정보(희소도: 0.9049)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/pruning_info.yaml'에 저장했습니다.
2026-01-14 14:20:01,142 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 14:20:01,318 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:20:01,318 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:20:01,323 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:20:10,819 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:20:10,820 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:20:11,727 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 14:20:11,728 - INFO - ==================================================
2026-01-14 14:20:11,731 - INFO - ==================================================
2026-01-14 14:20:11,733 - INFO - 모델 파라미터 수:
2026-01-14 14:20:11,734 - INFO -   - 총 파라미터: 31,612 개
2026-01-14 14:20:11,735 - INFO -   - 학습 가능한 파라미터: 31,612 개
2026-01-14 14:20:11,878 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 14:20:12,043 - INFO - FLOPs가 0.5384 GFLOPs에서 0.0171 GFLOPs로 감소했습니다 (감소율: 96.83%).
2026-01-14 14:20:12,044 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 14:20:12,044 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:20:12,046 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 14:20:12,046 - INFO - ==================================================
2026-01-14 14:20:12,046 - INFO - train 모드를 시작합니다.
2026-01-14 14:20:12,046 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:20:12,046 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:20:12,047 - INFO - --------------------------------------------------
2026-01-14 14:20:12,050 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 14:20:22,726 - INFO - [Train] [11/90] | Loss: 0.6199 | Train Acc: 68.15%
2026-01-14 14:20:26,247 - INFO - [Valid] [11/90] | Loss: 0.6780 | Val Acc: 52.21%
2026-01-14 14:20:26,264 - INFO - [Metrics for 'abnormal'] | Precision: 0.4922 | Recall: 1.0000 | F1: 0.6597
2026-01-14 14:20:26,265 - INFO - [Metrics for 'normal'] | Precision: 1.0000 | Recall: 0.1099 | F1: 0.1980
2026-01-14 14:20:26,340 - INFO - [Best Model Saved] (val loss: 0.6780) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:20:26,341 - INFO - --------------------------------------------------
2026-01-14 14:20:26,344 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 14:20:36,281 - INFO - [Train] [12/90] | Loss: 0.5334 | Train Acc: 77.23%
2026-01-14 14:20:39,038 - INFO - [Valid] [12/90] | Loss: 0.5729 | Val Acc: 74.63%
2026-01-14 14:20:39,059 - INFO - [Metrics for 'abnormal'] | Precision: 0.7415 | Recall: 0.6943 | F1: 0.7171
2026-01-14 14:20:39,059 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.7912 | F1: 0.7701
2026-01-14 14:20:39,131 - INFO - [Best Model Saved] (val loss: 0.5729) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:20:39,132 - INFO - --------------------------------------------------
2026-01-14 14:20:39,135 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 14:20:47,684 - INFO - [Train] [13/90] | Loss: 0.5049 | Train Acc: 78.20%
2026-01-14 14:20:51,200 - INFO - [Valid] [13/90] | Loss: 0.5475 | Val Acc: 75.22%
2026-01-14 14:20:51,212 - INFO - [Metrics for 'abnormal'] | Precision: 0.7239 | Recall: 0.7516 | F1: 0.7375
2026-01-14 14:20:51,213 - INFO - [Metrics for 'normal'] | Precision: 0.7784 | Recall: 0.7527 | F1: 0.7654
2026-01-14 14:20:51,251 - INFO - [Best Model Saved] (val loss: 0.5475) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:20:51,252 - INFO - --------------------------------------------------
2026-01-14 14:20:51,255 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 14:21:00,752 - INFO - [Train] [14/90] | Loss: 0.4839 | Train Acc: 81.70%
2026-01-14 14:21:04,533 - INFO - [Valid] [14/90] | Loss: 0.5612 | Val Acc: 74.04%
2026-01-14 14:21:04,542 - INFO - [Metrics for 'abnormal'] | Precision: 0.6806 | Recall: 0.8280 | F1: 0.7471
2026-01-14 14:21:04,542 - INFO - [Metrics for 'normal'] | Precision: 0.8176 | Recall: 0.6648 | F1: 0.7333
2026-01-14 14:21:04,545 - INFO - --------------------------------------------------
2026-01-14 14:21:04,548 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 14:21:13,852 - INFO - [Train] [15/90] | Loss: 0.5043 | Train Acc: 80.58%
2026-01-14 14:21:16,815 - INFO - [Valid] [15/90] | Loss: 0.5820 | Val Acc: 71.68%
2026-01-14 14:21:16,828 - INFO - [Metrics for 'abnormal'] | Precision: 0.6473 | Recall: 0.8535 | F1: 0.7363
2026-01-14 14:21:16,828 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.5989 | F1: 0.6943
2026-01-14 14:21:16,835 - INFO - --------------------------------------------------
2026-01-14 14:21:16,839 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 14:21:25,344 - INFO - [Train] [16/90] | Loss: 0.4787 | Train Acc: 82.51%
2026-01-14 14:21:28,156 - INFO - [Valid] [16/90] | Loss: 0.5851 | Val Acc: 75.52%
2026-01-14 14:21:28,165 - INFO - [Metrics for 'abnormal'] | Precision: 0.8246 | Recall: 0.5987 | F1: 0.6937
2026-01-14 14:21:28,165 - INFO - [Metrics for 'normal'] | Precision: 0.7200 | Recall: 0.8901 | F1: 0.7961
2026-01-14 14:21:28,169 - INFO - --------------------------------------------------
2026-01-14 14:21:28,172 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 14:21:37,530 - INFO - [Train] [17/90] | Loss: 0.4660 | Train Acc: 82.66%
2026-01-14 14:21:40,511 - INFO - [Valid] [17/90] | Loss: 0.5632 | Val Acc: 76.99%
2026-01-14 14:21:40,525 - INFO - [Metrics for 'abnormal'] | Precision: 0.7068 | Recall: 0.8599 | F1: 0.7759
2026-01-14 14:21:40,528 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.6923 | F1: 0.7636
2026-01-14 14:21:40,533 - INFO - --------------------------------------------------
2026-01-14 14:21:40,536 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 14:21:50,495 - INFO - [Train] [18/90] | Loss: 0.4610 | Train Acc: 82.81%
2026-01-14 14:21:53,545 - INFO - [Valid] [18/90] | Loss: 0.5518 | Val Acc: 76.40%
2026-01-14 14:21:53,557 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.7134 | F1: 0.7368
2026-01-14 14:21:53,557 - INFO - [Metrics for 'normal'] | Precision: 0.7656 | Recall: 0.8077 | F1: 0.7861
2026-01-14 14:21:53,561 - INFO - --------------------------------------------------
2026-01-14 14:21:53,565 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 14:22:03,760 - INFO - [Train] [19/90] | Loss: 0.4561 | Train Acc: 83.33%
2026-01-14 14:22:07,023 - INFO - [Valid] [19/90] | Loss: 0.5600 | Val Acc: 75.22%
2026-01-14 14:22:07,036 - INFO - [Metrics for 'abnormal'] | Precision: 0.7062 | Recall: 0.7962 | F1: 0.7485
2026-01-14 14:22:07,037 - INFO - [Metrics for 'normal'] | Precision: 0.8025 | Recall: 0.7143 | F1: 0.7558
2026-01-14 14:22:07,042 - INFO - --------------------------------------------------
2026-01-14 14:22:07,045 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 14:22:17,377 - INFO - [Train] [20/90] | Loss: 0.4528 | Train Acc: 84.30%
2026-01-14 14:22:20,218 - INFO - [Valid] [20/90] | Loss: 0.5726 | Val Acc: 76.11%
2026-01-14 14:22:20,230 - INFO - [Metrics for 'abnormal'] | Precision: 0.6979 | Recall: 0.8535 | F1: 0.7679
2026-01-14 14:22:20,231 - INFO - [Metrics for 'normal'] | Precision: 0.8435 | Recall: 0.6813 | F1: 0.7538
2026-01-14 14:22:20,235 - INFO - --------------------------------------------------
2026-01-14 14:22:20,239 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 14:22:30,711 - INFO - [Train] [21/90] | Loss: 0.4513 | Train Acc: 83.93%
2026-01-14 14:22:32,979 - INFO - [Valid] [21/90] | Loss: 0.5615 | Val Acc: 77.29%
2026-01-14 14:22:32,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.7643 | F1: 0.7571
2026-01-14 14:22:32,996 - INFO - [Metrics for 'normal'] | Precision: 0.7933 | Recall: 0.7802 | F1: 0.7867
2026-01-14 14:22:33,010 - INFO - --------------------------------------------------
2026-01-14 14:22:33,017 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 14:22:43,400 - INFO - [Train] [22/90] | Loss: 0.4463 | Train Acc: 84.38%
2026-01-14 14:22:45,751 - INFO - [Valid] [22/90] | Loss: 0.6405 | Val Acc: 74.34%
2026-01-14 14:22:45,766 - INFO - [Metrics for 'abnormal'] | Precision: 0.6966 | Recall: 0.7898 | F1: 0.7403
2026-01-14 14:22:45,766 - INFO - [Metrics for 'normal'] | Precision: 0.7950 | Recall: 0.7033 | F1: 0.7464
2026-01-14 14:22:45,772 - INFO - --------------------------------------------------
2026-01-14 14:22:45,776 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 14:22:55,372 - INFO - [Train] [23/90] | Loss: 0.4438 | Train Acc: 84.45%
2026-01-14 14:22:57,765 - INFO - [Valid] [23/90] | Loss: 0.5643 | Val Acc: 75.22%
2026-01-14 14:22:57,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.7135 | Recall: 0.7771 | F1: 0.7439
2026-01-14 14:22:57,774 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.7308 | F1: 0.7600
2026-01-14 14:22:57,777 - INFO - --------------------------------------------------
2026-01-14 14:22:57,779 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 14:23:07,212 - INFO - [Train] [24/90] | Loss: 0.4369 | Train Acc: 84.82%
2026-01-14 14:23:10,342 - INFO - [Valid] [24/90] | Loss: 0.6510 | Val Acc: 74.34%
2026-01-14 14:23:10,355 - INFO - [Metrics for 'abnormal'] | Precision: 0.6768 | Recall: 0.8535 | F1: 0.7549
2026-01-14 14:23:10,355 - INFO - [Metrics for 'normal'] | Precision: 0.8369 | Recall: 0.6484 | F1: 0.7307
2026-01-14 14:23:10,360 - INFO - --------------------------------------------------
2026-01-14 14:23:10,364 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 14:23:20,327 - INFO - [Train] [25/90] | Loss: 0.4404 | Train Acc: 84.08%
2026-01-14 14:23:22,589 - INFO - [Valid] [25/90] | Loss: 0.5406 | Val Acc: 75.52%
2026-01-14 14:23:22,599 - INFO - [Metrics for 'abnormal'] | Precision: 0.7721 | Recall: 0.6688 | F1: 0.7167
2026-01-14 14:23:22,600 - INFO - [Metrics for 'normal'] | Precision: 0.7438 | Recall: 0.8297 | F1: 0.7844
2026-01-14 14:23:22,645 - INFO - [Best Model Saved] (val loss: 0.5406) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:23:22,646 - INFO - --------------------------------------------------
2026-01-14 14:23:22,648 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 14:23:32,863 - INFO - [Train] [26/90] | Loss: 0.4419 | Train Acc: 84.00%
2026-01-14 14:23:35,090 - INFO - [Valid] [26/90] | Loss: 0.5767 | Val Acc: 74.63%
2026-01-14 14:23:35,103 - INFO - [Metrics for 'abnormal'] | Precision: 0.8087 | Recall: 0.5924 | F1: 0.6838
2026-01-14 14:23:35,104 - INFO - [Metrics for 'normal'] | Precision: 0.7143 | Recall: 0.8791 | F1: 0.7882
2026-01-14 14:23:35,108 - INFO - --------------------------------------------------
2026-01-14 14:23:35,112 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 14:23:44,857 - INFO - [Train] [27/90] | Loss: 0.4413 | Train Acc: 83.48%
2026-01-14 14:23:48,065 - INFO - [Valid] [27/90] | Loss: 0.5699 | Val Acc: 73.75%
2026-01-14 14:23:48,076 - INFO - [Metrics for 'abnormal'] | Precision: 0.7125 | Recall: 0.7261 | F1: 0.7192
2026-01-14 14:23:48,077 - INFO - [Metrics for 'normal'] | Precision: 0.7598 | Recall: 0.7473 | F1: 0.7535
2026-01-14 14:23:48,081 - INFO - --------------------------------------------------
2026-01-14 14:23:48,084 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 14:23:58,198 - INFO - [Train] [28/90] | Loss: 0.4326 | Train Acc: 84.45%
2026-01-14 14:24:00,556 - INFO - [Valid] [28/90] | Loss: 0.5277 | Val Acc: 76.40%
2026-01-14 14:24:00,570 - INFO - [Metrics for 'abnormal'] | Precision: 0.7362 | Recall: 0.7643 | F1: 0.7500
2026-01-14 14:24:00,571 - INFO - [Metrics for 'normal'] | Precision: 0.7898 | Recall: 0.7637 | F1: 0.7765
2026-01-14 14:24:00,620 - INFO - [Best Model Saved] (val loss: 0.5277) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:24:00,620 - INFO - --------------------------------------------------
2026-01-14 14:24:00,623 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 14:24:09,627 - INFO - [Train] [29/90] | Loss: 0.4151 | Train Acc: 86.61%
2026-01-14 14:24:12,617 - INFO - [Valid] [29/90] | Loss: 0.5588 | Val Acc: 74.34%
2026-01-14 14:24:12,630 - INFO - [Metrics for 'abnormal'] | Precision: 0.7083 | Recall: 0.7580 | F1: 0.7323
2026-01-14 14:24:12,630 - INFO - [Metrics for 'normal'] | Precision: 0.7778 | Recall: 0.7308 | F1: 0.7535
2026-01-14 14:24:12,635 - INFO - --------------------------------------------------
2026-01-14 14:24:12,638 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 14:24:22,862 - INFO - [Train] [30/90] | Loss: 0.4139 | Train Acc: 86.31%
2026-01-14 14:24:25,369 - INFO - [Valid] [30/90] | Loss: 0.5390 | Val Acc: 76.40%
2026-01-14 14:24:25,381 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.6752 | F1: 0.7260
2026-01-14 14:24:25,382 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.8407 | F1: 0.7927
2026-01-14 14:24:25,387 - INFO - --------------------------------------------------
2026-01-14 14:24:25,391 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 14:24:33,279 - INFO - [Train] [31/90] | Loss: 0.4256 | Train Acc: 85.27%
2026-01-14 14:24:36,520 - INFO - [Valid] [31/90] | Loss: 0.5531 | Val Acc: 74.93%
2026-01-14 14:24:36,529 - INFO - [Metrics for 'abnormal'] | Precision: 0.7432 | Recall: 0.7006 | F1: 0.7213
2026-01-14 14:24:36,530 - INFO - [Metrics for 'normal'] | Precision: 0.7539 | Recall: 0.7912 | F1: 0.7721
2026-01-14 14:24:36,534 - INFO - --------------------------------------------------
2026-01-14 14:24:36,537 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 14:24:45,716 - INFO - [Train] [32/90] | Loss: 0.3951 | Train Acc: 87.35%
2026-01-14 14:24:48,857 - INFO - [Valid] [32/90] | Loss: 0.6004 | Val Acc: 74.93%
2026-01-14 14:24:48,869 - INFO - [Metrics for 'abnormal'] | Precision: 0.7143 | Recall: 0.7643 | F1: 0.7385
2026-01-14 14:24:48,870 - INFO - [Metrics for 'normal'] | Precision: 0.7836 | Recall: 0.7363 | F1: 0.7592
2026-01-14 14:24:48,878 - INFO - --------------------------------------------------
2026-01-14 14:24:48,882 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 14:24:58,334 - INFO - [Train] [33/90] | Loss: 0.4146 | Train Acc: 87.05%
2026-01-14 14:25:01,728 - INFO - [Valid] [33/90] | Loss: 0.5987 | Val Acc: 74.93%
2026-01-14 14:25:01,739 - INFO - [Metrics for 'abnormal'] | Precision: 0.7069 | Recall: 0.7834 | F1: 0.7432
2026-01-14 14:25:01,740 - INFO - [Metrics for 'normal'] | Precision: 0.7939 | Recall: 0.7198 | F1: 0.7550
2026-01-14 14:25:01,744 - INFO - --------------------------------------------------
2026-01-14 14:25:01,747 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 14:25:10,983 - INFO - [Train] [34/90] | Loss: 0.4053 | Train Acc: 87.05%
2026-01-14 14:25:13,957 - INFO - [Valid] [34/90] | Loss: 0.5636 | Val Acc: 75.52%
2026-01-14 14:25:13,994 - INFO - [Metrics for 'abnormal'] | Precision: 0.7033 | Recall: 0.8153 | F1: 0.7552
2026-01-14 14:25:13,994 - INFO - [Metrics for 'normal'] | Precision: 0.8153 | Recall: 0.7033 | F1: 0.7552
2026-01-14 14:25:13,998 - INFO - --------------------------------------------------
2026-01-14 14:25:14,001 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 14:25:22,474 - INFO - [Train] [35/90] | Loss: 0.3761 | Train Acc: 88.62%
2026-01-14 14:25:25,733 - INFO - [Valid] [35/90] | Loss: 0.6085 | Val Acc: 71.98%
2026-01-14 14:25:25,764 - INFO - [Metrics for 'abnormal'] | Precision: 0.6520 | Recall: 0.8471 | F1: 0.7368
2026-01-14 14:25:25,764 - INFO - [Metrics for 'normal'] | Precision: 0.8222 | Recall: 0.6099 | F1: 0.7003
2026-01-14 14:25:25,769 - INFO - --------------------------------------------------
2026-01-14 14:25:25,774 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 14:25:36,292 - INFO - [Train] [36/90] | Loss: 0.3888 | Train Acc: 87.65%
2026-01-14 14:25:38,915 - INFO - [Valid] [36/90] | Loss: 0.6157 | Val Acc: 71.39%
2026-01-14 14:25:38,930 - INFO - [Metrics for 'abnormal'] | Precision: 0.7344 | Recall: 0.5987 | F1: 0.6596
2026-01-14 14:25:38,931 - INFO - [Metrics for 'normal'] | Precision: 0.7014 | Recall: 0.8132 | F1: 0.7532
2026-01-14 14:25:38,936 - INFO - --------------------------------------------------
2026-01-14 14:25:38,940 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 14:25:49,004 - INFO - [Train] [37/90] | Loss: 0.3742 | Train Acc: 88.84%
2026-01-14 14:25:51,326 - INFO - [Valid] [37/90] | Loss: 0.6322 | Val Acc: 74.34%
2026-01-14 14:25:51,336 - INFO - [Metrics for 'abnormal'] | Precision: 0.6944 | Recall: 0.7962 | F1: 0.7418
2026-01-14 14:25:51,336 - INFO - [Metrics for 'normal'] | Precision: 0.7987 | Recall: 0.6978 | F1: 0.7449
2026-01-14 14:25:51,340 - INFO - --------------------------------------------------
2026-01-14 14:25:51,343 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 14:26:00,973 - INFO - [Train] [38/90] | Loss: 0.4001 | Train Acc: 86.31%
2026-01-14 14:26:03,793 - INFO - [Valid] [38/90] | Loss: 0.5692 | Val Acc: 76.40%
2026-01-14 14:26:03,807 - INFO - [Metrics for 'abnormal'] | Precision: 0.7251 | Recall: 0.7898 | F1: 0.7561
2026-01-14 14:26:03,808 - INFO - [Metrics for 'normal'] | Precision: 0.8036 | Recall: 0.7418 | F1: 0.7714
2026-01-14 14:26:03,813 - INFO - --------------------------------------------------
2026-01-14 14:26:03,818 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 14:26:14,220 - INFO - [Train] [39/90] | Loss: 0.3755 | Train Acc: 88.91%
2026-01-14 14:26:16,031 - INFO - [Valid] [39/90] | Loss: 0.5910 | Val Acc: 73.16%
2026-01-14 14:26:16,049 - INFO - [Metrics for 'abnormal'] | Precision: 0.7063 | Recall: 0.7197 | F1: 0.7129
2026-01-14 14:26:16,049 - INFO - [Metrics for 'normal'] | Precision: 0.7542 | Recall: 0.7418 | F1: 0.7479
2026-01-14 14:26:16,053 - INFO - --------------------------------------------------
2026-01-14 14:26:16,056 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 14:26:26,048 - INFO - [Train] [40/90] | Loss: 0.3896 | Train Acc: 87.95%
2026-01-14 14:26:28,303 - INFO - [Valid] [40/90] | Loss: 0.5770 | Val Acc: 76.11%
2026-01-14 14:26:28,315 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.7261 | F1: 0.7379
2026-01-14 14:26:28,316 - INFO - [Metrics for 'normal'] | Precision: 0.7701 | Recall: 0.7912 | F1: 0.7805
2026-01-14 14:26:28,320 - INFO - --------------------------------------------------
2026-01-14 14:26:28,324 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 14:26:38,398 - INFO - [Train] [41/90] | Loss: 0.3762 | Train Acc: 89.21%
2026-01-14 14:26:40,059 - INFO - [Valid] [41/90] | Loss: 0.5511 | Val Acc: 74.93%
2026-01-14 14:26:40,072 - INFO - [Metrics for 'abnormal'] | Precision: 0.7195 | Recall: 0.7516 | F1: 0.7352
2026-01-14 14:26:40,073 - INFO - [Metrics for 'normal'] | Precision: 0.7771 | Recall: 0.7473 | F1: 0.7619
2026-01-14 14:26:40,078 - INFO - --------------------------------------------------
2026-01-14 14:26:40,082 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 14:26:50,322 - INFO - [Train] [42/90] | Loss: 0.3661 | Train Acc: 90.03%
2026-01-14 14:26:52,354 - INFO - [Valid] [42/90] | Loss: 0.5591 | Val Acc: 73.45%
2026-01-14 14:26:52,369 - INFO - [Metrics for 'abnormal'] | Precision: 0.6754 | Recall: 0.8217 | F1: 0.7414
2026-01-14 14:26:52,369 - INFO - [Metrics for 'normal'] | Precision: 0.8108 | Recall: 0.6593 | F1: 0.7273
2026-01-14 14:26:52,373 - INFO - --------------------------------------------------
2026-01-14 14:26:52,375 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 14:27:03,162 - INFO - [Train] [43/90] | Loss: 0.3834 | Train Acc: 88.62%
2026-01-14 14:27:05,016 - INFO - [Valid] [43/90] | Loss: 0.5758 | Val Acc: 76.70%
2026-01-14 14:27:05,029 - INFO - [Metrics for 'abnormal'] | Precision: 0.7468 | Recall: 0.7516 | F1: 0.7492
2026-01-14 14:27:05,030 - INFO - [Metrics for 'normal'] | Precision: 0.7845 | Recall: 0.7802 | F1: 0.7824
2026-01-14 14:27:05,035 - INFO - --------------------------------------------------
2026-01-14 14:27:05,039 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 14:27:14,597 - INFO - [Train] [44/90] | Loss: 0.3676 | Train Acc: 89.36%
2026-01-14 14:27:16,943 - INFO - [Valid] [44/90] | Loss: 0.5639 | Val Acc: 75.81%
2026-01-14 14:27:16,955 - INFO - [Metrics for 'abnormal'] | Precision: 0.7586 | Recall: 0.7006 | F1: 0.7285
2026-01-14 14:27:16,955 - INFO - [Metrics for 'normal'] | Precision: 0.7577 | Recall: 0.8077 | F1: 0.7819
2026-01-14 14:27:16,959 - INFO - --------------------------------------------------
2026-01-14 14:27:16,962 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 14:27:27,205 - INFO - [Train] [45/90] | Loss: 0.3673 | Train Acc: 90.25%
2026-01-14 14:27:29,931 - INFO - [Valid] [45/90] | Loss: 0.6070 | Val Acc: 76.11%
2026-01-14 14:27:29,952 - INFO - [Metrics for 'abnormal'] | Precision: 0.8167 | Recall: 0.6242 | F1: 0.7076
2026-01-14 14:27:29,952 - INFO - [Metrics for 'normal'] | Precision: 0.7306 | Recall: 0.8791 | F1: 0.7980
2026-01-14 14:27:29,957 - INFO - --------------------------------------------------
2026-01-14 14:27:29,961 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 14:27:39,967 - INFO - [Train] [46/90] | Loss: 0.3611 | Train Acc: 91.29%
2026-01-14 14:27:43,426 - INFO - [Valid] [46/90] | Loss: 0.6358 | Val Acc: 75.52%
2026-01-14 14:27:43,436 - INFO - [Metrics for 'abnormal'] | Precision: 0.6832 | Recall: 0.8790 | F1: 0.7688
2026-01-14 14:27:43,437 - INFO - [Metrics for 'normal'] | Precision: 0.8613 | Recall: 0.6484 | F1: 0.7398
2026-01-14 14:27:43,441 - INFO - --------------------------------------------------
2026-01-14 14:27:43,444 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 14:27:52,209 - INFO - [Train] [47/90] | Loss: 0.3722 | Train Acc: 89.06%
2026-01-14 14:27:55,137 - INFO - [Valid] [47/90] | Loss: 0.6344 | Val Acc: 72.86%
2026-01-14 14:27:55,151 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.5796 | F1: 0.6642
2026-01-14 14:27:55,152 - INFO - [Metrics for 'normal'] | Precision: 0.7027 | Recall: 0.8571 | F1: 0.7723
2026-01-14 14:27:55,156 - INFO - --------------------------------------------------
2026-01-14 14:27:55,161 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 14:28:04,074 - INFO - [Train] [48/90] | Loss: 0.3606 | Train Acc: 89.81%
2026-01-14 14:28:06,783 - INFO - [Valid] [48/90] | Loss: 0.5555 | Val Acc: 76.11%
2026-01-14 14:28:06,796 - INFO - [Metrics for 'abnormal'] | Precision: 0.7262 | Recall: 0.7771 | F1: 0.7508
2026-01-14 14:28:06,797 - INFO - [Metrics for 'normal'] | Precision: 0.7953 | Recall: 0.7473 | F1: 0.7705
2026-01-14 14:28:06,802 - INFO - --------------------------------------------------
2026-01-14 14:28:06,806 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 14:28:17,988 - INFO - [Train] [49/90] | Loss: 0.3502 | Train Acc: 90.55%
2026-01-14 14:28:21,005 - INFO - [Valid] [49/90] | Loss: 0.6155 | Val Acc: 75.22%
2026-01-14 14:28:21,029 - INFO - [Metrics for 'abnormal'] | Precision: 0.7212 | Recall: 0.7580 | F1: 0.7391
2026-01-14 14:28:21,029 - INFO - [Metrics for 'normal'] | Precision: 0.7816 | Recall: 0.7473 | F1: 0.7640
2026-01-14 14:28:21,040 - INFO - --------------------------------------------------
2026-01-14 14:28:21,048 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 14:28:30,234 - INFO - [Train] [50/90] | Loss: 0.3531 | Train Acc: 90.62%
2026-01-14 14:28:32,627 - INFO - [Valid] [50/90] | Loss: 0.5885 | Val Acc: 76.11%
2026-01-14 14:28:32,645 - INFO - [Metrics for 'abnormal'] | Precision: 0.7405 | Recall: 0.7452 | F1: 0.7429
2026-01-14 14:28:32,645 - INFO - [Metrics for 'normal'] | Precision: 0.7790 | Recall: 0.7747 | F1: 0.7769
2026-01-14 14:28:32,650 - INFO - --------------------------------------------------
2026-01-14 14:28:32,655 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 14:28:41,901 - INFO - [Train] [51/90] | Loss: 0.3517 | Train Acc: 91.22%
2026-01-14 14:28:44,093 - INFO - [Valid] [51/90] | Loss: 0.6002 | Val Acc: 76.11%
2026-01-14 14:28:44,106 - INFO - [Metrics for 'abnormal'] | Precision: 0.7209 | Recall: 0.7898 | F1: 0.7538
2026-01-14 14:28:44,135 - INFO - [Metrics for 'normal'] | Precision: 0.8024 | Recall: 0.7363 | F1: 0.7679
2026-01-14 14:28:44,140 - INFO - --------------------------------------------------
2026-01-14 14:28:44,144 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 14:28:54,714 - INFO - [Train] [52/90] | Loss: 0.3477 | Train Acc: 90.85%
2026-01-14 14:28:57,554 - INFO - [Valid] [52/90] | Loss: 0.5683 | Val Acc: 76.40%
2026-01-14 14:28:57,566 - INFO - [Metrics for 'abnormal'] | Precision: 0.7655 | Recall: 0.7070 | F1: 0.7351
2026-01-14 14:28:57,567 - INFO - [Metrics for 'normal'] | Precision: 0.7629 | Recall: 0.8132 | F1: 0.7872
2026-01-14 14:28:57,572 - INFO - --------------------------------------------------
2026-01-14 14:28:57,576 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 14:29:09,545 - INFO - [Train] [53/90] | Loss: 0.3421 | Train Acc: 91.44%
2026-01-14 14:29:12,088 - INFO - [Valid] [53/90] | Loss: 0.5599 | Val Acc: 74.04%
2026-01-14 14:29:12,116 - INFO - [Metrics for 'abnormal'] | Precision: 0.7482 | Recall: 0.6624 | F1: 0.7027
2026-01-14 14:29:12,118 - INFO - [Metrics for 'normal'] | Precision: 0.7350 | Recall: 0.8077 | F1: 0.7696
2026-01-14 14:29:12,131 - INFO - --------------------------------------------------
2026-01-14 14:29:12,138 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 14:29:22,533 - INFO - [Train] [54/90] | Loss: 0.3566 | Train Acc: 90.70%
2026-01-14 14:29:26,433 - INFO - [Valid] [54/90] | Loss: 0.6094 | Val Acc: 75.52%
2026-01-14 14:29:26,489 - INFO - [Metrics for 'abnormal'] | Precision: 0.7534 | Recall: 0.7006 | F1: 0.7261
2026-01-14 14:29:26,489 - INFO - [Metrics for 'normal'] | Precision: 0.7565 | Recall: 0.8022 | F1: 0.7787
2026-01-14 14:29:26,493 - INFO - --------------------------------------------------
2026-01-14 14:29:26,495 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 14:29:35,179 - INFO - [Train] [55/90] | Loss: 0.3426 | Train Acc: 91.29%
2026-01-14 14:29:38,491 - INFO - [Valid] [55/90] | Loss: 0.5589 | Val Acc: 76.11%
2026-01-14 14:29:38,503 - INFO - [Metrics for 'abnormal'] | Precision: 0.7346 | Recall: 0.7580 | F1: 0.7461
2026-01-14 14:29:38,504 - INFO - [Metrics for 'normal'] | Precision: 0.7853 | Recall: 0.7637 | F1: 0.7744
2026-01-14 14:29:38,509 - INFO - --------------------------------------------------
2026-01-14 14:29:38,513 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 14:29:48,737 - INFO - [Train] [56/90] | Loss: 0.3421 | Train Acc: 92.04%
2026-01-14 14:29:52,263 - INFO - [Valid] [56/90] | Loss: 0.6214 | Val Acc: 76.40%
2026-01-14 14:29:52,274 - INFO - [Metrics for 'abnormal'] | Precision: 0.7516 | Recall: 0.7325 | F1: 0.7419
2026-01-14 14:29:52,275 - INFO - [Metrics for 'normal'] | Precision: 0.7742 | Recall: 0.7912 | F1: 0.7826
2026-01-14 14:29:52,279 - INFO - --------------------------------------------------
2026-01-14 14:29:52,282 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 14:30:03,150 - INFO - [Train] [57/90] | Loss: 0.3218 | Train Acc: 92.93%
2026-01-14 14:30:05,874 - INFO - [Valid] [57/90] | Loss: 0.6150 | Val Acc: 73.45%
2026-01-14 14:30:05,887 - INFO - [Metrics for 'abnormal'] | Precision: 0.6831 | Recall: 0.7962 | F1: 0.7353
2026-01-14 14:30:05,888 - INFO - [Metrics for 'normal'] | Precision: 0.7949 | Recall: 0.6813 | F1: 0.7337
2026-01-14 14:30:05,893 - INFO - --------------------------------------------------
2026-01-14 14:30:05,896 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 14:30:15,713 - INFO - [Train] [58/90] | Loss: 0.3372 | Train Acc: 91.96%
2026-01-14 14:30:17,468 - INFO - [Valid] [58/90] | Loss: 0.6024 | Val Acc: 74.93%
2026-01-14 14:30:17,478 - INFO - [Metrics for 'abnormal'] | Precision: 0.7432 | Recall: 0.7006 | F1: 0.7213
2026-01-14 14:30:17,479 - INFO - [Metrics for 'normal'] | Precision: 0.7539 | Recall: 0.7912 | F1: 0.7721
2026-01-14 14:30:17,483 - INFO - --------------------------------------------------
2026-01-14 14:30:17,486 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 14:30:27,963 - INFO - [Train] [59/90] | Loss: 0.3322 | Train Acc: 91.52%
2026-01-14 14:30:30,627 - INFO - [Valid] [59/90] | Loss: 0.5791 | Val Acc: 75.81%
2026-01-14 14:30:30,636 - INFO - [Metrics for 'abnormal'] | Precision: 0.7517 | Recall: 0.7134 | F1: 0.7320
2026-01-14 14:30:30,636 - INFO - [Metrics for 'normal'] | Precision: 0.7632 | Recall: 0.7967 | F1: 0.7796
2026-01-14 14:30:30,639 - INFO - --------------------------------------------------
2026-01-14 14:30:30,642 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 14:30:39,822 - INFO - [Train] [60/90] | Loss: 0.3171 | Train Acc: 94.27%
2026-01-14 14:30:42,049 - INFO - [Valid] [60/90] | Loss: 0.5883 | Val Acc: 77.29%
2026-01-14 14:30:42,067 - INFO - [Metrics for 'abnormal'] | Precision: 0.7151 | Recall: 0.8471 | F1: 0.7755
2026-01-14 14:30:42,069 - INFO - [Metrics for 'normal'] | Precision: 0.8431 | Recall: 0.7088 | F1: 0.7701
2026-01-14 14:30:42,072 - INFO - --------------------------------------------------
2026-01-14 14:30:42,075 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 14:30:51,992 - INFO - [Train] [61/90] | Loss: 0.3316 | Train Acc: 92.04%
2026-01-14 14:30:54,289 - INFO - [Valid] [61/90] | Loss: 0.6131 | Val Acc: 76.99%
2026-01-14 14:30:54,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.7548 | Recall: 0.7452 | F1: 0.7500
2026-01-14 14:30:54,304 - INFO - [Metrics for 'normal'] | Precision: 0.7826 | Recall: 0.7912 | F1: 0.7869
2026-01-14 14:30:54,309 - INFO - --------------------------------------------------
2026-01-14 14:30:54,312 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 14:31:03,842 - INFO - [Train] [62/90] | Loss: 0.3285 | Train Acc: 92.49%
2026-01-14 14:31:06,088 - INFO - [Valid] [62/90] | Loss: 0.5865 | Val Acc: 77.29%
2026-01-14 14:31:06,102 - INFO - [Metrics for 'abnormal'] | Precision: 0.7439 | Recall: 0.7771 | F1: 0.7601
2026-01-14 14:31:06,103 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7692 | F1: 0.7843
2026-01-14 14:31:06,117 - INFO - --------------------------------------------------
2026-01-14 14:31:06,125 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 14:31:15,725 - INFO - [Train] [63/90] | Loss: 0.3195 | Train Acc: 93.23%
2026-01-14 14:31:18,326 - INFO - [Valid] [63/90] | Loss: 0.6208 | Val Acc: 75.81%
2026-01-14 14:31:18,337 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.7389 | F1: 0.7389
2026-01-14 14:31:18,338 - INFO - [Metrics for 'normal'] | Precision: 0.7747 | Recall: 0.7747 | F1: 0.7747
2026-01-14 14:31:18,341 - INFO - --------------------------------------------------
2026-01-14 14:31:18,345 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 14:31:29,353 - INFO - [Train] [64/90] | Loss: 0.3203 | Train Acc: 92.93%
2026-01-14 14:31:32,209 - INFO - [Valid] [64/90] | Loss: 0.5719 | Val Acc: 75.81%
2026-01-14 14:31:32,223 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.7389 | F1: 0.7389
2026-01-14 14:31:32,223 - INFO - [Metrics for 'normal'] | Precision: 0.7747 | Recall: 0.7747 | F1: 0.7747
2026-01-14 14:31:32,228 - INFO - --------------------------------------------------
2026-01-14 14:31:32,231 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 14:31:43,107 - INFO - [Train] [65/90] | Loss: 0.3197 | Train Acc: 93.30%
2026-01-14 14:31:45,527 - INFO - [Valid] [65/90] | Loss: 0.6064 | Val Acc: 78.76%
2026-01-14 14:31:45,556 - INFO - [Metrics for 'abnormal'] | Precision: 0.7401 | Recall: 0.8344 | F1: 0.7844
2026-01-14 14:31:45,556 - INFO - [Metrics for 'normal'] | Precision: 0.8395 | Recall: 0.7473 | F1: 0.7907
2026-01-14 14:31:45,563 - INFO - --------------------------------------------------
2026-01-14 14:31:45,568 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 14:31:54,920 - INFO - [Train] [66/90] | Loss: 0.3041 | Train Acc: 93.97%
2026-01-14 14:31:57,808 - INFO - [Valid] [66/90] | Loss: 0.5879 | Val Acc: 78.17%
2026-01-14 14:31:57,816 - INFO - [Metrics for 'abnormal'] | Precision: 0.7219 | Recall: 0.8599 | F1: 0.7849
2026-01-14 14:31:57,817 - INFO - [Metrics for 'normal'] | Precision: 0.8553 | Recall: 0.7143 | F1: 0.7784
2026-01-14 14:31:57,820 - INFO - --------------------------------------------------
2026-01-14 14:31:57,822 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 14:32:07,025 - INFO - [Train] [67/90] | Loss: 0.3195 | Train Acc: 93.75%
2026-01-14 14:32:09,884 - INFO - [Valid] [67/90] | Loss: 0.6058 | Val Acc: 75.22%
2026-01-14 14:32:10,009 - INFO - [Metrics for 'abnormal'] | Precision: 0.7552 | Recall: 0.6879 | F1: 0.7200
2026-01-14 14:32:10,010 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.8077 | F1: 0.7778
2026-01-14 14:32:10,013 - INFO - --------------------------------------------------
2026-01-14 14:32:10,015 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 14:32:19,245 - INFO - [Train] [68/90] | Loss: 0.3223 | Train Acc: 92.93%
2026-01-14 14:32:22,823 - INFO - [Valid] [68/90] | Loss: 0.5739 | Val Acc: 76.99%
2026-01-14 14:32:22,835 - INFO - [Metrics for 'abnormal'] | Precision: 0.7548 | Recall: 0.7452 | F1: 0.7500
2026-01-14 14:32:22,836 - INFO - [Metrics for 'normal'] | Precision: 0.7826 | Recall: 0.7912 | F1: 0.7869
2026-01-14 14:32:22,840 - INFO - --------------------------------------------------
2026-01-14 14:32:22,843 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 14:32:32,222 - INFO - [Train] [69/90] | Loss: 0.2994 | Train Acc: 94.87%
2026-01-14 14:32:35,296 - INFO - [Valid] [69/90] | Loss: 0.5892 | Val Acc: 76.11%
2026-01-14 14:32:35,309 - INFO - [Metrics for 'abnormal'] | Precision: 0.7375 | Recall: 0.7516 | F1: 0.7445
2026-01-14 14:32:35,309 - INFO - [Metrics for 'normal'] | Precision: 0.7821 | Recall: 0.7692 | F1: 0.7756
2026-01-14 14:32:35,313 - INFO - --------------------------------------------------
2026-01-14 14:32:35,317 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 14:32:45,009 - INFO - [Train] [70/90] | Loss: 0.3215 | Train Acc: 92.63%
2026-01-14 14:32:49,540 - INFO - [Valid] [70/90] | Loss: 0.5710 | Val Acc: 77.88%
2026-01-14 14:32:49,548 - INFO - [Metrics for 'abnormal'] | Precision: 0.7330 | Recall: 0.8217 | F1: 0.7748
2026-01-14 14:32:49,549 - INFO - [Metrics for 'normal'] | Precision: 0.8282 | Recall: 0.7418 | F1: 0.7826
2026-01-14 14:32:49,552 - INFO - --------------------------------------------------
2026-01-14 14:32:49,554 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 14:32:56,334 - INFO - [Train] [71/90] | Loss: 0.3190 | Train Acc: 94.27%
2026-01-14 14:32:58,831 - INFO - [Valid] [71/90] | Loss: 0.6089 | Val Acc: 75.52%
2026-01-14 14:32:58,843 - INFO - [Metrics for 'abnormal'] | Precision: 0.7372 | Recall: 0.7325 | F1: 0.7348
2026-01-14 14:32:58,844 - INFO - [Metrics for 'normal'] | Precision: 0.7705 | Recall: 0.7747 | F1: 0.7726
2026-01-14 14:32:58,850 - INFO - --------------------------------------------------
2026-01-14 14:32:58,854 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 14:33:06,130 - INFO - [Train] [72/90] | Loss: 0.3226 | Train Acc: 92.71%
2026-01-14 14:33:08,556 - INFO - [Valid] [72/90] | Loss: 0.5981 | Val Acc: 76.70%
2026-01-14 14:33:08,590 - INFO - [Metrics for 'abnormal'] | Precision: 0.7468 | Recall: 0.7516 | F1: 0.7492
2026-01-14 14:33:08,591 - INFO - [Metrics for 'normal'] | Precision: 0.7845 | Recall: 0.7802 | F1: 0.7824
2026-01-14 14:33:08,598 - INFO - --------------------------------------------------
2026-01-14 14:33:08,602 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 14:33:17,028 - INFO - [Train] [73/90] | Loss: 0.2880 | Train Acc: 95.09%
2026-01-14 14:33:18,739 - INFO - [Valid] [73/90] | Loss: 0.5793 | Val Acc: 77.29%
2026-01-14 14:33:18,751 - INFO - [Metrics for 'abnormal'] | Precision: 0.7532 | Recall: 0.7580 | F1: 0.7556
2026-01-14 14:33:18,751 - INFO - [Metrics for 'normal'] | Precision: 0.7901 | Recall: 0.7857 | F1: 0.7879
2026-01-14 14:33:18,755 - INFO - --------------------------------------------------
2026-01-14 14:33:18,758 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 14:33:24,944 - INFO - [Train] [74/90] | Loss: 0.3154 | Train Acc: 93.15%
2026-01-14 14:33:27,014 - INFO - [Valid] [74/90] | Loss: 0.5985 | Val Acc: 76.99%
2026-01-14 14:33:27,025 - INFO - [Metrics for 'abnormal'] | Precision: 0.7423 | Recall: 0.7707 | F1: 0.7562
2026-01-14 14:33:27,025 - INFO - [Metrics for 'normal'] | Precision: 0.7955 | Recall: 0.7692 | F1: 0.7821
2026-01-14 14:33:27,029 - INFO - --------------------------------------------------
2026-01-14 14:33:27,032 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 14:33:33,008 - INFO - [Train] [75/90] | Loss: 0.3049 | Train Acc: 94.27%
2026-01-14 14:33:34,847 - INFO - [Valid] [75/90] | Loss: 0.5964 | Val Acc: 76.40%
2026-01-14 14:33:34,862 - INFO - [Metrics for 'abnormal'] | Precision: 0.7421 | Recall: 0.7516 | F1: 0.7468
2026-01-14 14:33:34,862 - INFO - [Metrics for 'normal'] | Precision: 0.7833 | Recall: 0.7747 | F1: 0.7790
2026-01-14 14:33:34,865 - INFO - --------------------------------------------------
2026-01-14 14:33:34,868 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 14:33:40,430 - INFO - [Train] [76/90] | Loss: 0.3113 | Train Acc: 93.45%
2026-01-14 14:33:42,083 - INFO - [Valid] [76/90] | Loss: 0.5878 | Val Acc: 77.29%
2026-01-14 14:33:42,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.7597 | Recall: 0.7452 | F1: 0.7524
2026-01-14 14:33:42,096 - INFO - [Metrics for 'normal'] | Precision: 0.7838 | Recall: 0.7967 | F1: 0.7902
2026-01-14 14:33:42,101 - INFO - --------------------------------------------------
2026-01-14 14:33:42,103 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 14:33:48,856 - INFO - [Train] [77/90] | Loss: 0.2999 | Train Acc: 94.27%
2026-01-14 14:33:50,461 - INFO - [Valid] [77/90] | Loss: 0.5841 | Val Acc: 77.88%
2026-01-14 14:33:50,470 - INFO - [Metrics for 'abnormal'] | Precision: 0.7470 | Recall: 0.7898 | F1: 0.7678
2026-01-14 14:33:50,470 - INFO - [Metrics for 'normal'] | Precision: 0.8092 | Recall: 0.7692 | F1: 0.7887
2026-01-14 14:33:50,473 - INFO - --------------------------------------------------
2026-01-14 14:33:50,475 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 14:33:55,623 - INFO - [Train] [78/90] | Loss: 0.3069 | Train Acc: 94.05%
2026-01-14 14:33:57,128 - INFO - [Valid] [78/90] | Loss: 0.5834 | Val Acc: 76.70%
2026-01-14 14:33:57,140 - INFO - [Metrics for 'abnormal'] | Precision: 0.7468 | Recall: 0.7516 | F1: 0.7492
2026-01-14 14:33:57,140 - INFO - [Metrics for 'normal'] | Precision: 0.7845 | Recall: 0.7802 | F1: 0.7824
2026-01-14 14:33:57,145 - INFO - --------------------------------------------------
2026-01-14 14:33:57,147 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 14:34:02,361 - INFO - [Train] [79/90] | Loss: 0.2914 | Train Acc: 94.94%
2026-01-14 14:34:03,908 - INFO - [Valid] [79/90] | Loss: 0.6248 | Val Acc: 76.11%
2026-01-14 14:34:03,920 - INFO - [Metrics for 'abnormal'] | Precision: 0.7405 | Recall: 0.7452 | F1: 0.7429
2026-01-14 14:34:03,920 - INFO - [Metrics for 'normal'] | Precision: 0.7790 | Recall: 0.7747 | F1: 0.7769
2026-01-14 14:34:03,925 - INFO - --------------------------------------------------
2026-01-14 14:34:03,929 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 14:34:09,100 - INFO - [Train] [80/90] | Loss: 0.2925 | Train Acc: 95.09%
2026-01-14 14:34:10,502 - INFO - [Valid] [80/90] | Loss: 0.6137 | Val Acc: 75.81%
2026-01-14 14:34:10,510 - INFO - [Metrics for 'abnormal'] | Precision: 0.7246 | Recall: 0.7707 | F1: 0.7469
2026-01-14 14:34:10,510 - INFO - [Metrics for 'normal'] | Precision: 0.7907 | Recall: 0.7473 | F1: 0.7684
2026-01-14 14:34:10,513 - INFO - --------------------------------------------------
2026-01-14 14:34:10,515 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 14:34:15,717 - INFO - [Train] [81/90] | Loss: 0.3032 | Train Acc: 94.05%
2026-01-14 14:34:17,058 - INFO - [Valid] [81/90] | Loss: 0.6053 | Val Acc: 77.29%
2026-01-14 14:34:17,066 - INFO - [Metrics for 'abnormal'] | Precision: 0.7326 | Recall: 0.8025 | F1: 0.7660
2026-01-14 14:34:17,066 - INFO - [Metrics for 'normal'] | Precision: 0.8144 | Recall: 0.7473 | F1: 0.7794
2026-01-14 14:34:17,069 - INFO - --------------------------------------------------
2026-01-14 14:34:17,071 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 14:34:22,339 - INFO - [Train] [82/90] | Loss: 0.3093 | Train Acc: 93.75%
2026-01-14 14:34:24,022 - INFO - [Valid] [82/90] | Loss: 0.6032 | Val Acc: 75.52%
2026-01-14 14:34:24,031 - INFO - [Metrics for 'abnormal'] | Precision: 0.7403 | Recall: 0.7261 | F1: 0.7331
2026-01-14 14:34:24,032 - INFO - [Metrics for 'normal'] | Precision: 0.7676 | Recall: 0.7802 | F1: 0.7738
2026-01-14 14:34:24,035 - INFO - --------------------------------------------------
2026-01-14 14:34:24,038 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 14:34:28,906 - INFO - [Train] [83/90] | Loss: 0.3162 | Train Acc: 93.38%
2026-01-14 14:34:30,264 - INFO - [Valid] [83/90] | Loss: 0.5933 | Val Acc: 76.99%
2026-01-14 14:34:30,273 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7580 | F1: 0.7532
2026-01-14 14:34:30,273 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.7802 | F1: 0.7845
2026-01-14 14:34:30,276 - INFO - --------------------------------------------------
2026-01-14 14:34:30,279 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 14:34:36,492 - INFO - [Train] [84/90] | Loss: 0.3044 | Train Acc: 93.82%
2026-01-14 14:34:38,322 - INFO - [Valid] [84/90] | Loss: 0.5900 | Val Acc: 75.81%
2026-01-14 14:34:38,330 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.7389 | F1: 0.7389
2026-01-14 14:34:38,330 - INFO - [Metrics for 'normal'] | Precision: 0.7747 | Recall: 0.7747 | F1: 0.7747
2026-01-14 14:34:38,333 - INFO - --------------------------------------------------
2026-01-14 14:34:38,335 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 14:34:42,166 - INFO - [Train] [85/90] | Loss: 0.2926 | Train Acc: 95.31%
2026-01-14 14:34:43,259 - INFO - [Valid] [85/90] | Loss: 0.6261 | Val Acc: 74.63%
2026-01-14 14:34:43,267 - INFO - [Metrics for 'abnormal'] | Precision: 0.7448 | Recall: 0.6879 | F1: 0.7152
2026-01-14 14:34:43,267 - INFO - [Metrics for 'normal'] | Precision: 0.7474 | Recall: 0.7967 | F1: 0.7713
2026-01-14 14:34:43,270 - INFO - --------------------------------------------------
2026-01-14 14:34:43,271 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 14:34:47,053 - INFO - [Train] [86/90] | Loss: 0.2893 | Train Acc: 94.64%
2026-01-14 14:34:48,130 - INFO - [Valid] [86/90] | Loss: 0.6091 | Val Acc: 76.11%
2026-01-14 14:34:48,138 - INFO - [Metrics for 'abnormal'] | Precision: 0.7375 | Recall: 0.7516 | F1: 0.7445
2026-01-14 14:34:48,138 - INFO - [Metrics for 'normal'] | Precision: 0.7821 | Recall: 0.7692 | F1: 0.7756
2026-01-14 14:34:48,141 - INFO - --------------------------------------------------
2026-01-14 14:34:48,143 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 14:34:51,852 - INFO - [Train] [87/90] | Loss: 0.2905 | Train Acc: 95.24%
2026-01-14 14:34:52,921 - INFO - [Valid] [87/90] | Loss: 0.6003 | Val Acc: 77.29%
2026-01-14 14:34:52,928 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.7643 | F1: 0.7571
2026-01-14 14:34:52,928 - INFO - [Metrics for 'normal'] | Precision: 0.7933 | Recall: 0.7802 | F1: 0.7867
2026-01-14 14:34:52,931 - INFO - --------------------------------------------------
2026-01-14 14:34:52,933 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 14:34:56,650 - INFO - [Train] [88/90] | Loss: 0.2945 | Train Acc: 95.46%
2026-01-14 14:34:57,742 - INFO - [Valid] [88/90] | Loss: 0.6099 | Val Acc: 76.70%
2026-01-14 14:34:57,749 - INFO - [Metrics for 'abnormal'] | Precision: 0.7407 | Recall: 0.7643 | F1: 0.7524
2026-01-14 14:34:57,749 - INFO - [Metrics for 'normal'] | Precision: 0.7910 | Recall: 0.7692 | F1: 0.7799
2026-01-14 14:34:57,752 - INFO - --------------------------------------------------
2026-01-14 14:34:57,754 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 14:35:01,444 - INFO - [Train] [89/90] | Loss: 0.2912 | Train Acc: 95.01%
2026-01-14 14:35:02,518 - INFO - [Valid] [89/90] | Loss: 0.6103 | Val Acc: 76.99%
2026-01-14 14:35:02,526 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7580 | F1: 0.7532
2026-01-14 14:35:02,526 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.7802 | F1: 0.7845
2026-01-14 14:35:02,529 - INFO - --------------------------------------------------
2026-01-14 14:35:02,530 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 14:35:06,267 - INFO - [Train] [90/90] | Loss: 0.2827 | Train Acc: 95.76%
2026-01-14 14:35:07,338 - INFO - [Valid] [90/90] | Loss: 0.6243 | Val Acc: 76.99%
2026-01-14 14:35:07,346 - INFO - [Metrics for 'abnormal'] | Precision: 0.7423 | Recall: 0.7707 | F1: 0.7562
2026-01-14 14:35:07,346 - INFO - [Metrics for 'normal'] | Precision: 0.7955 | Recall: 0.7692 | F1: 0.7821
2026-01-14 14:35:07,349 - INFO - ==================================================
2026-01-14 14:35:07,350 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 14:35:07,350 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 14:35:07,350 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:35:07,392 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 14:35:07,406 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 14:35:07,407 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:35:07,407 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:35:07,410 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:35:11,091 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:35:11,092 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:35:11,524 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 14:35:11,524 - INFO - ==================================================
2026-01-14 14:35:11,583 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/best_model.pth'
2026-01-14 14:35:11,583 - INFO - ==================================================
2026-01-14 14:35:11,583 - INFO - Test 모드를 시작합니다.
2026-01-14 14:35:11,682 - INFO - 연산량 (MACs): 0.0085 GMACs per sample
2026-01-14 14:35:11,683 - INFO - 연산량 (FLOPs): 0.0171 GFLOPs per sample
2026-01-14 14:35:11,683 - INFO - ==================================================
2026-01-14 14:35:11,683 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 14:35:12,843 - INFO - 샘플 당 평균 Forward Pass 시간: 7.08ms (std: 0.29ms), FPS: 141.36 (std: 4.48) (1개 샘플 x 100회 반복)
2026-01-14 14:35:12,844 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 38.17 MB
2026-01-14 14:35:12,844 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 14:35:14,660 - INFO - [Test] Loss: 0.4773 | Test Acc: 76.40%
2026-01-14 14:35:14,670 - INFO - [Metrics for 'abnormal'] | Precision: 0.7362 | Recall: 0.7643 | F1: 0.7500
2026-01-14 14:35:14,670 - INFO - [Metrics for 'normal'] | Precision: 0.7898 | Recall: 0.7637 | F1: 0.7765
2026-01-14 14:35:15,077 - INFO - ==================================================
2026-01-14 14:35:15,077 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/confusion_matrix_20260114_140030.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/confusion_matrix_20260114_140030.pdf'
2026-01-14 14:35:15,077 - INFO - ==================================================
2026-01-14 14:35:15,077 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 14:35:15,710 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/model_fp32_20260114_140030.onnx'에 저장되었습니다. (크기: 0.34 MB)
2026-01-14 14:35:16,026 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2520.25 MB (증가량: 1.61 MB)
2026-01-14 14:35:16,026 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 14:35:16,938 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 6.56ms (std: 0.05ms)
2026-01-14 14:35:16,938 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 152.45 FPS (std: 1.11) (1개 샘플 x 100회 반복)
2026-01-14 14:35:16,938 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2533.58 MB (순수 증가량: 8.06 MB)
2026-01-14 14:35:16,939 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2533.58 MB (전체 증가량: 14.94 MB)
2026-01-14 14:35:18,618 - INFO - [Test (ONNX)] | Test Acc (ONNX): 76.40%
2026-01-14 14:35:18,626 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7362 | Recall: 0.7643 | F1: 0.7500
2026-01-14 14:35:18,626 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.7898 | Recall: 0.7637 | F1: 0.7765
2026-01-14 14:35:18,966 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/val_acc.pdf'
2026-01-14 14:35:19,333 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/train_val_acc.pdf'
2026-01-14 14:35:19,646 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/F1_normal.pdf'
2026-01-14 14:35:20,005 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/val_loss.pdf'
2026-01-14 14:35:20,309 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/learning_rate.pdf'
2026-01-14 14:35:23,797 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_wanda_20260114_140030/graph_20260114_140030/compile.pdf'
