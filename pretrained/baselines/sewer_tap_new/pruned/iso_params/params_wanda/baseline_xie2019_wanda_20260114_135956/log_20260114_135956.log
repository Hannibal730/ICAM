2026-01-14 13:59:56,158 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/log_20260114_135956.log'에 저장됩니다.
2026-01-14 13:59:56,165 - INFO - ==================================================
2026-01-14 13:59:56,165 - INFO - config.yaml:
2026-01-14 13:59:56,165 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: xie2019
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.031371

2026-01-14 13:59:56,166 - INFO - ==================================================
2026-01-14 13:59:56,232 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:59:56,233 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:59:56,233 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:59:56,245 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:59:56,246 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:59:56,247 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:59:56,247 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:59:56,578 - INFO - ==================================================
2026-01-14 13:59:56,578 - INFO - 모델 파라미터 수:
2026-01-14 13:59:56,579 - INFO -   - 총 파라미터: 9,160,194 개
2026-01-14 13:59:56,579 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-01-14 13:59:56,579 - INFO - ================================================================================
2026-01-14 13:59:56,579 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:59:56,579 - INFO - ================================================================================
2026-01-14 13:59:56,579 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:59:56,579 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:59:56,579 - INFO - ==================================================
2026-01-14 13:59:56,579 - INFO - train 모드를 시작합니다.
2026-01-14 13:59:56,580 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:59:56,580 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:59:56,580 - INFO - --------------------------------------------------
2026-01-14 13:59:56,580 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 14:00:03,745 - INFO - [Train] [1/10] | Loss: 0.5882 | Train Acc: 74.48%
2026-01-14 14:00:06,380 - INFO - [Valid] [1/10] | Loss: 0.5796 | Val Acc: 74.63%
2026-01-14 14:00:06,412 - INFO - [Metrics for 'abnormal'] | Precision: 0.8989 | Recall: 0.5096 | F1: 0.6504
2026-01-14 14:00:06,412 - INFO - [Metrics for 'normal'] | Precision: 0.6920 | Recall: 0.9505 | F1: 0.8009
2026-01-14 14:00:06,499 - INFO - [Best Model Saved] (val loss: 0.5796) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:00:06,499 - INFO - --------------------------------------------------
2026-01-14 14:00:06,500 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 14:00:12,843 - INFO - [Train] [2/10] | Loss: 0.5912 | Train Acc: 77.98%
2026-01-14 14:00:14,496 - INFO - [Valid] [2/10] | Loss: 0.5603 | Val Acc: 74.63%
2026-01-14 14:00:14,513 - INFO - [Metrics for 'abnormal'] | Precision: 0.7261 | Recall: 0.7261 | F1: 0.7261
2026-01-14 14:00:14,513 - INFO - [Metrics for 'normal'] | Precision: 0.7637 | Recall: 0.7637 | F1: 0.7637
2026-01-14 14:00:14,598 - INFO - [Best Model Saved] (val loss: 0.5603) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:00:14,598 - INFO - --------------------------------------------------
2026-01-14 14:00:14,598 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 14:00:22,352 - INFO - [Train] [3/10] | Loss: 0.5237 | Train Acc: 79.84%
2026-01-14 14:00:24,616 - INFO - [Valid] [3/10] | Loss: 0.5369 | Val Acc: 77.29%
2026-01-14 14:00:24,628 - INFO - [Metrics for 'abnormal'] | Precision: 0.7273 | Recall: 0.8153 | F1: 0.7688
2026-01-14 14:00:24,628 - INFO - [Metrics for 'normal'] | Precision: 0.8221 | Recall: 0.7363 | F1: 0.7768
2026-01-14 14:00:24,726 - INFO - [Best Model Saved] (val loss: 0.5369) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:00:24,727 - INFO - --------------------------------------------------
2026-01-14 14:00:24,727 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 14:00:32,183 - INFO - [Train] [4/10] | Loss: 0.5037 | Train Acc: 80.88%
2026-01-14 14:00:34,760 - INFO - [Valid] [4/10] | Loss: 0.5596 | Val Acc: 75.52%
2026-01-14 14:00:34,772 - INFO - [Metrics for 'abnormal'] | Precision: 0.8190 | Recall: 0.6051 | F1: 0.6960
2026-01-14 14:00:34,772 - INFO - [Metrics for 'normal'] | Precision: 0.7220 | Recall: 0.8846 | F1: 0.7951
2026-01-14 14:00:34,776 - INFO - --------------------------------------------------
2026-01-14 14:00:34,777 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 14:00:42,729 - INFO - [Train] [5/10] | Loss: 0.4946 | Train Acc: 81.10%
2026-01-14 14:00:44,759 - INFO - [Valid] [5/10] | Loss: 0.5322 | Val Acc: 76.99%
2026-01-14 14:00:44,787 - INFO - [Metrics for 'abnormal'] | Precision: 0.7516 | Recall: 0.7516 | F1: 0.7516
2026-01-14 14:00:44,787 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.7857 | F1: 0.7857
2026-01-14 14:00:44,909 - INFO - [Best Model Saved] (val loss: 0.5322) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:00:44,911 - INFO - --------------------------------------------------
2026-01-14 14:00:44,912 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 14:00:54,007 - INFO - [Train] [6/10] | Loss: 0.4820 | Train Acc: 82.66%
2026-01-14 14:00:56,816 - INFO - [Valid] [6/10] | Loss: 0.5233 | Val Acc: 79.35%
2026-01-14 14:00:56,830 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 14:00:56,830 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 14:00:56,964 - INFO - [Best Model Saved] (val loss: 0.5233) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:00:56,967 - INFO - --------------------------------------------------
2026-01-14 14:00:56,968 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 14:01:06,612 - INFO - [Train] [7/10] | Loss: 0.4675 | Train Acc: 82.96%
2026-01-14 14:01:09,191 - INFO - [Valid] [7/10] | Loss: 0.5140 | Val Acc: 78.47%
2026-01-14 14:01:09,205 - INFO - [Metrics for 'abnormal'] | Precision: 0.7561 | Recall: 0.7898 | F1: 0.7726
2026-01-14 14:01:09,205 - INFO - [Metrics for 'normal'] | Precision: 0.8114 | Recall: 0.7802 | F1: 0.7955
2026-01-14 14:01:09,309 - INFO - [Best Model Saved] (val loss: 0.5140) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:01:09,310 - INFO - --------------------------------------------------
2026-01-14 14:01:09,311 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 14:01:18,847 - INFO - [Train] [8/10] | Loss: 0.4516 | Train Acc: 84.08%
2026-01-14 14:01:21,275 - INFO - [Valid] [8/10] | Loss: 0.5012 | Val Acc: 79.06%
2026-01-14 14:01:21,295 - INFO - [Metrics for 'abnormal'] | Precision: 0.7443 | Recall: 0.8344 | F1: 0.7868
2026-01-14 14:01:21,297 - INFO - [Metrics for 'normal'] | Precision: 0.8405 | Recall: 0.7527 | F1: 0.7942
2026-01-14 14:01:21,418 - INFO - [Best Model Saved] (val loss: 0.5012) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:01:21,419 - INFO - --------------------------------------------------
2026-01-14 14:01:21,419 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 14:01:30,893 - INFO - [Train] [9/10] | Loss: 0.4412 | Train Acc: 84.97%
2026-01-14 14:01:33,812 - INFO - [Valid] [9/10] | Loss: 0.5070 | Val Acc: 79.94%
2026-01-14 14:01:33,835 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-01-14 14:01:33,836 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-01-14 14:01:33,840 - INFO - --------------------------------------------------
2026-01-14 14:01:33,841 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 14:01:41,766 - INFO - [Train] [10/10] | Loss: 0.4394 | Train Acc: 84.67%
2026-01-14 14:01:44,476 - INFO - [Valid] [10/10] | Loss: 0.4975 | Val Acc: 79.94%
2026-01-14 14:01:44,505 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 14:01:44,505 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 14:01:44,648 - INFO - [Best Model Saved] (val loss: 0.4975) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:01:44,648 - INFO - ================================================================================
2026-01-14 14:01:44,648 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 14:01:44,648 - INFO - ================================================================================
2026-01-14 14:01:44,705 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'을(를) 불러왔습니다.
2026-01-14 14:01:44,706 - INFO - ================================================================================
2026-01-14 14:01:44,706 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 14:01:44,707 - INFO - 원본 모델 파라미터: 9.1602M
2026-01-14 14:01:44,715 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:44,715 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:44,716 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:53,665 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:54,467 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 14:01:54,467 - INFO - ==================================================
2026-01-14 14:01:54,468 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 2.3194M (감소율: 74.68%)
2026-01-14 14:01:54,473 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:54,473 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:54,474 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:04,125 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:04,760 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 14:02:04,761 - INFO - ==================================================
2026-01-14 14:02:04,761 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.5934M (감소율: 93.52%)
2026-01-14 14:02:04,765 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:04,766 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:04,766 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:13,855 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:14,665 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 14:02:14,665 - INFO - ==================================================
2026-01-14 14:02:14,667 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.1643M (감소율: 98.21%)
2026-01-14 14:02:14,683 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:14,685 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:14,685 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:23,550 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:24,323 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 14:02:24,324 - INFO - ==================================================
2026-01-14 14:02:24,326 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0474M (감소율: 99.48%)
2026-01-14 14:02:24,332 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:24,333 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:24,334 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:32,105 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:32,697 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 14:02:32,697 - INFO - ==================================================
2026-01-14 14:02:32,700 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0151M (감소율: 99.84%)
2026-01-14 14:02:32,707 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:32,708 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:32,708 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:41,555 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:42,356 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.94359375)에 맞춰 변경되었습니다.
2026-01-14 14:02:42,357 - INFO - ==================================================
2026-01-14 14:02:42,357 - INFO -   [탐색  6] 희소도: 0.9436 -> 파라미터: 0.0290M (감소율: 99.68%)
2026-01-14 14:02:42,362 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:42,363 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:42,363 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:51,177 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:52,510 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9358593749999999)에 맞춰 변경되었습니다.
2026-01-14 14:02:52,511 - INFO - ==================================================
2026-01-14 14:02:52,511 - INFO -   [탐색  7] 희소도: 0.9359 -> 파라미터: 0.0379M (감소율: 99.59%)
2026-01-14 14:02:52,516 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:52,517 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:52,518 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:01,232 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:02,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9397265625)에 맞춰 변경되었습니다.
2026-01-14 14:03:02,516 - INFO - ==================================================
2026-01-14 14:03:02,517 - INFO -   [탐색  8] 희소도: 0.9397 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:03:02,522 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:02,522 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:02,523 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:10,421 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:11,110 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93779296875)에 맞춰 변경되었습니다.
2026-01-14 14:03:11,110 - INFO - ==================================================
2026-01-14 14:03:11,111 - INFO -   [탐색  9] 희소도: 0.9378 -> 파라미터: 0.0321M (감소율: 99.65%)
2026-01-14 14:03:11,116 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:11,117 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:11,118 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:20,211 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:21,266 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 14:03:21,266 - INFO - ==================================================
2026-01-14 14:03:21,267 - INFO -   [탐색 10] 희소도: 0.9388 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:03:21,272 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:21,273 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:21,274 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:30,890 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:31,844 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9392431640625)에 맞춰 변경되었습니다.
2026-01-14 14:03:31,845 - INFO - ==================================================
2026-01-14 14:03:31,845 - INFO -   [탐색 11] 희소도: 0.9392 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:03:31,849 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:31,850 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:31,850 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:41,296 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:41,836 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93948486328125)에 맞춰 변경되었습니다.
2026-01-14 14:03:41,836 - INFO - ==================================================
2026-01-14 14:03:41,837 - INFO -   [탐색 12] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:03:41,840 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:41,841 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:41,841 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:50,338 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:51,276 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939364013671875)에 맞춰 변경되었습니다.
2026-01-14 14:03:51,276 - INFO - ==================================================
2026-01-14 14:03:51,277 - INFO -   [탐색 13] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:03:51,281 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:51,281 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:51,282 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:00,976 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:01,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394244384765625)에 맞춰 변경되었습니다.
2026-01-14 14:04:01,584 - INFO - ==================================================
2026-01-14 14:04:01,585 - INFO -   [탐색 14] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:04:01,589 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:01,589 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:01,590 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:11,617 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:12,257 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394546508789063)에 맞춰 변경되었습니다.
2026-01-14 14:04:12,258 - INFO - ==================================================
2026-01-14 14:04:12,260 - INFO -   [탐색 15] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:04:12,264 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:12,264 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:12,265 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:22,006 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:23,079 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394395446777344)에 맞춰 변경되었습니다.
2026-01-14 14:04:23,080 - INFO - ==================================================
2026-01-14 14:04:23,081 - INFO -   [탐색 16] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:04:23,086 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:23,087 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:23,088 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:31,999 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:32,538 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394470977783204)에 맞춰 변경되었습니다.
2026-01-14 14:04:32,539 - INFO - ==================================================
2026-01-14 14:04:32,539 - INFO -   [탐색 17] 희소도: 0.9394 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:04:32,543 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:32,543 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:32,544 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:41,324 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:42,066 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394508743286134)에 맞춰 변경되었습니다.
2026-01-14 14:04:42,067 - INFO - ==================================================
2026-01-14 14:04:42,068 - INFO -   [탐색 18] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:04:42,074 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:42,075 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:42,075 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:51,762 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:52,408 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394527626037599)에 맞춰 변경되었습니다.
2026-01-14 14:04:52,409 - INFO - ==================================================
2026-01-14 14:04:52,410 - INFO -   [탐색 19] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:04:52,415 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:52,415 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:52,415 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:02,120 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:02,625 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394537067413331)에 맞춰 변경되었습니다.
2026-01-14 14:05:02,625 - INFO - ==================================================
2026-01-14 14:05:02,625 - INFO -   [탐색 20] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:05:02,628 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:02,628 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:02,628 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:12,892 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:13,854 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394532346725465)에 맞춰 변경되었습니다.
2026-01-14 14:05:13,855 - INFO - ==================================================
2026-01-14 14:05:13,855 - INFO -   [탐색 21] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:05:13,860 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:13,860 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:13,861 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:23,546 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:24,652 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394529986381532)에 맞춰 변경되었습니다.
2026-01-14 14:05:24,653 - INFO - ==================================================
2026-01-14 14:05:24,653 - INFO -   [탐색 22] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:05:24,658 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:24,658 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:24,659 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:34,465 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:35,187 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531166553499)에 맞춰 변경되었습니다.
2026-01-14 14:05:35,187 - INFO - ==================================================
2026-01-14 14:05:35,189 - INFO -   [탐색 23] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:05:35,199 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:35,201 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:35,202 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:44,164 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:44,941 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531756639481)에 맞춰 변경되었습니다.
2026-01-14 14:05:44,942 - INFO - ==================================================
2026-01-14 14:05:44,943 - INFO -   [탐색 24] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:05:44,948 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:44,949 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:44,950 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:54,658 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:55,467 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453146159649)에 맞춰 변경되었습니다.
2026-01-14 14:05:55,468 - INFO - ==================================================
2026-01-14 14:05:55,469 - INFO -   [탐색 25] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:05:55,474 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:55,475 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:55,476 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:03,817 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:04,518 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531314074994)에 맞춰 변경되었습니다.
2026-01-14 14:06:04,518 - INFO - ==================================================
2026-01-14 14:06:04,519 - INFO -   [탐색 26] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:06:04,525 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:04,526 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:04,527 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:12,257 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:12,974 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531240314247)에 맞춰 변경되었습니다.
2026-01-14 14:06:12,975 - INFO - ==================================================
2026-01-14 14:06:12,976 - INFO -   [탐색 27] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:06:12,980 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:12,981 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:12,982 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:21,357 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:22,930 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453127719462)에 맞춰 변경되었습니다.
2026-01-14 14:06:22,930 - INFO - ==================================================
2026-01-14 14:06:22,931 - INFO -   [탐색 28] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:06:22,936 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:22,945 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:22,946 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:31,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:32,550 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531258754433)에 맞춰 변경되었습니다.
2026-01-14 14:06:32,550 - INFO - ==================================================
2026-01-14 14:06:32,551 - INFO -   [탐색 29] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:06:32,555 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:32,556 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:32,556 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:41,213 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:41,857 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249534339)에 맞춰 변경되었습니다.
2026-01-14 14:06:41,859 - INFO - ==================================================
2026-01-14 14:06:41,860 - INFO -   [탐색 30] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:06:41,867 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:41,867 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:41,868 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:50,072 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:50,698 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531254144386)에 맞춰 변경되었습니다.
2026-01-14 14:06:50,698 - INFO - ==================================================
2026-01-14 14:06:50,699 - INFO -   [탐색 31] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:06:50,703 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:50,703 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:50,704 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:58,971 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:59,806 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531251839362)에 맞춰 변경되었습니다.
2026-01-14 14:06:59,807 - INFO - ==================================================
2026-01-14 14:06:59,807 - INFO -   [탐색 32] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:06:59,816 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:59,816 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:59,816 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:08,439 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:09,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250686851)에 맞춰 변경되었습니다.
2026-01-14 14:07:09,951 - INFO - ==================================================
2026-01-14 14:07:09,952 - INFO -   [탐색 33] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:07:09,956 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:09,957 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:09,958 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:18,805 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:20,601 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250110595)에 맞춰 변경되었습니다.
2026-01-14 14:07:20,601 - INFO - ==================================================
2026-01-14 14:07:20,602 - INFO -   [탐색 34] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:07:20,606 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:20,607 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:20,607 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:29,637 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:30,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249822466)에 맞춰 변경되었습니다.
2026-01-14 14:07:30,493 - INFO - ==================================================
2026-01-14 14:07:30,494 - INFO -   [탐색 35] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:07:30,500 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:30,502 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:30,503 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:40,148 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:40,766 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249966531)에 맞춰 변경되었습니다.
2026-01-14 14:07:40,766 - INFO - ==================================================
2026-01-14 14:07:40,767 - INFO -   [탐색 36] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:07:40,772 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:40,772 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:40,773 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:49,975 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:50,818 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250038562)에 맞춰 변경되었습니다.
2026-01-14 14:07:50,819 - INFO - ==================================================
2026-01-14 14:07:50,819 - INFO -   [탐색 37] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:07:50,824 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:50,828 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:50,828 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:59,890 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:00,893 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250002547)에 맞춰 변경되었습니다.
2026-01-14 14:08:00,894 - INFO - ==================================================
2026-01-14 14:08:00,897 - INFO -   [탐색 38] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:08:00,904 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:00,904 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:00,905 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:09,216 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:09,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249984539)에 맞춰 변경되었습니다.
2026-01-14 14:08:09,863 - INFO - ==================================================
2026-01-14 14:08:09,864 - INFO -   [탐색 39] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:08:09,869 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:09,870 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:09,870 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:18,211 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:18,935 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249993543)에 맞춰 변경되었습니다.
2026-01-14 14:08:18,936 - INFO - ==================================================
2026-01-14 14:08:18,937 - INFO -   [탐색 40] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:08:18,941 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:18,941 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:18,942 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:27,152 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:28,370 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249998045)에 맞춰 변경되었습니다.
2026-01-14 14:08:28,370 - INFO - ==================================================
2026-01-14 14:08:28,371 - INFO -   [탐색 41] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:08:28,376 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:28,377 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:28,378 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:37,393 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:38,321 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000295)에 맞춰 변경되었습니다.
2026-01-14 14:08:38,322 - INFO - ==================================================
2026-01-14 14:08:38,322 - INFO -   [탐색 42] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:08:38,326 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:38,326 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:38,327 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:46,283 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:46,916 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453124999917)에 맞춰 변경되었습니다.
2026-01-14 14:08:46,917 - INFO - ==================================================
2026-01-14 14:08:46,917 - INFO -   [탐색 43] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:08:46,922 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:46,922 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:46,923 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:55,230 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:55,904 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999732)에 맞춰 변경되었습니다.
2026-01-14 14:08:55,904 - INFO - ==================================================
2026-01-14 14:08:55,904 - INFO -   [탐색 44] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:08:55,909 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:55,909 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:55,909 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:03,800 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:05,229 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000013)에 맞춰 변경되었습니다.
2026-01-14 14:09:05,231 - INFO - ==================================================
2026-01-14 14:09:05,231 - INFO -   [탐색 45] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:09:05,236 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:05,237 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:05,237 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:12,823 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:13,525 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999873)에 맞춰 변경되었습니다.
2026-01-14 14:09:13,526 - INFO - ==================================================
2026-01-14 14:09:13,527 - INFO -   [탐색 46] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:09:13,533 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:13,533 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:13,534 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:22,131 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:22,773 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999943)에 맞춰 변경되었습니다.
2026-01-14 14:09:22,774 - INFO - ==================================================
2026-01-14 14:09:22,775 - INFO -   [탐색 47] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:09:22,778 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:22,778 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:22,778 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:32,684 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:33,308 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999978)에 맞춰 변경되었습니다.
2026-01-14 14:09:33,309 - INFO - ==================================================
2026-01-14 14:09:33,309 - INFO -   [탐색 48] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:09:33,312 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:33,313 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:33,313 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:42,377 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:43,124 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531249999996)에 맞춰 변경되었습니다.
2026-01-14 14:09:43,125 - INFO - ==================================================
2026-01-14 14:09:43,125 - INFO -   [탐색 49] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:09:43,130 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:43,130 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:43,131 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:53,210 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:53,676 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000004)에 맞춰 변경되었습니다.
2026-01-14 14:09:53,676 - INFO - ==================================================
2026-01-14 14:09:53,676 - INFO -   [탐색 50] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:09:53,679 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:53,679 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:53,679 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:03,426 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:04,161 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:10:04,163 - INFO - ==================================================
2026-01-14 14:10:04,164 - INFO -   [탐색 51] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:10:04,169 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:04,169 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:04,170 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:14,425 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:15,182 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000002)에 맞춰 변경되었습니다.
2026-01-14 14:10:15,183 - INFO - ==================================================
2026-01-14 14:10:15,184 - INFO -   [탐색 52] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:10:15,188 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:15,189 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:15,189 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:24,368 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:25,196 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9394531250000001)에 맞춰 변경되었습니다.
2026-01-14 14:10:25,197 - INFO - ==================================================
2026-01-14 14:10:25,197 - INFO -   [탐색 53] 희소도: 0.9395 -> 파라미터: 0.0310M (감소율: 99.66%)
2026-01-14 14:10:25,202 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:25,202 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:25,203 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:33,990 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:34,666 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:10:34,667 - INFO - ==================================================
2026-01-14 14:10:34,668 - INFO -   [탐색 54] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:10:34,673 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:34,675 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:34,676 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:43,703 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:44,315 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:10:44,316 - INFO - ==================================================
2026-01-14 14:10:44,316 - INFO -   [탐색 55] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:10:44,321 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:44,321 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:44,321 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:53,930 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:54,616 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:10:54,617 - INFO - ==================================================
2026-01-14 14:10:54,618 - INFO -   [탐색 56] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:10:54,624 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:54,625 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:54,626 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:04,022 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:04,984 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:11:04,985 - INFO - ==================================================
2026-01-14 14:11:04,987 - INFO -   [탐색 57] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:11:05,007 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:05,008 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:05,009 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:13,683 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:15,164 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:11:15,165 - INFO - ==================================================
2026-01-14 14:11:15,165 - INFO -   [탐색 58] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:11:15,169 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:15,169 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:15,169 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:24,081 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:24,715 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:11:24,715 - INFO - ==================================================
2026-01-14 14:11:24,716 - INFO -   [탐색 59] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:11:24,720 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:24,721 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:24,721 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:33,726 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:34,431 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:11:34,431 - INFO - ==================================================
2026-01-14 14:11:34,432 - INFO -   [탐색 60] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:11:34,437 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:34,437 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:34,438 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:43,648 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:44,325 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:11:44,325 - INFO - ==================================================
2026-01-14 14:11:44,326 - INFO -   [탐색 61] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:11:44,331 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:44,331 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:44,332 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:53,927 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:54,468 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:11:54,468 - INFO - ==================================================
2026-01-14 14:11:54,468 - INFO -   [탐색 62] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:11:54,472 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:54,472 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:54,472 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:03,343 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:04,628 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:12:04,628 - INFO - ==================================================
2026-01-14 14:12:04,629 - INFO -   [탐색 63] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:12:04,635 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:04,636 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:04,636 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:13,733 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:14,576 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:12:14,576 - INFO - ==================================================
2026-01-14 14:12:14,577 - INFO -   [탐색 64] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:12:14,581 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:14,581 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:14,582 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:23,603 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:24,760 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:12:24,760 - INFO - ==================================================
2026-01-14 14:12:24,761 - INFO -   [탐색 65] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:12:24,767 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:24,767 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:24,768 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:33,400 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:34,255 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:12:34,255 - INFO - ==================================================
2026-01-14 14:12:34,256 - INFO -   [탐색 66] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:12:34,261 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:34,262 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:34,263 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:42,786 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:43,627 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:12:43,628 - INFO - ==================================================
2026-01-14 14:12:43,629 - INFO -   [탐색 67] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:12:43,634 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:43,635 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:43,636 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:52,092 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:53,579 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:12:53,580 - INFO - ==================================================
2026-01-14 14:12:53,581 - INFO -   [탐색 68] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:12:53,587 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:53,588 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:53,589 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:02,383 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:03,057 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:13:03,058 - INFO - ==================================================
2026-01-14 14:13:03,059 - INFO -   [탐색 69] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:13:03,064 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:03,064 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:03,065 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:12,380 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:13,017 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:13:13,018 - INFO - ==================================================
2026-01-14 14:13:13,018 - INFO -   [탐색 70] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:13:13,024 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:13,025 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:13,025 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:21,601 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:22,209 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:13:22,210 - INFO - ==================================================
2026-01-14 14:13:22,211 - INFO -   [탐색 71] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:13:22,216 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:22,216 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:22,217 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:30,451 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:31,361 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:13:31,362 - INFO - ==================================================
2026-01-14 14:13:31,362 - INFO -   [탐색 72] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:13:31,366 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:31,366 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:31,367 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:40,536 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:41,702 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:13:41,703 - INFO - ==================================================
2026-01-14 14:13:41,704 - INFO -   [탐색 73] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:13:41,710 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:41,710 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:41,711 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:50,761 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:51,459 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:13:51,460 - INFO - ==================================================
2026-01-14 14:13:51,460 - INFO -   [탐색 74] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:13:51,465 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:51,465 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:51,466 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:00,300 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:01,169 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:14:01,170 - INFO - ==================================================
2026-01-14 14:14:01,171 - INFO -   [탐색 75] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:14:01,176 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:01,176 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:01,177 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:09,887 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:10,473 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:14:10,473 - INFO - ==================================================
2026-01-14 14:14:10,474 - INFO -   [탐색 76] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:14:10,479 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:10,479 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:10,480 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:19,133 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:20,014 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:14:20,015 - INFO - ==================================================
2026-01-14 14:14:20,016 - INFO -   [탐색 77] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:14:20,021 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:20,021 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:20,022 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:29,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:29,846 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:14:29,847 - INFO - ==================================================
2026-01-14 14:14:29,847 - INFO -   [탐색 78] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:14:29,852 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:29,853 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:29,853 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:40,076 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:40,603 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:14:40,603 - INFO - ==================================================
2026-01-14 14:14:40,603 - INFO -   [탐색 79] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:14:40,606 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:40,607 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:40,607 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:49,672 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:50,283 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:14:50,284 - INFO - ==================================================
2026-01-14 14:14:50,284 - INFO -   [탐색 80] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:14:50,290 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:50,291 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:50,292 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:59,824 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:00,408 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:00,408 - INFO - ==================================================
2026-01-14 14:15:00,408 - INFO -   [탐색 81] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:00,413 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:00,413 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:00,413 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:09,073 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:10,304 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:10,305 - INFO - ==================================================
2026-01-14 14:15:10,305 - INFO -   [탐색 82] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:10,311 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:10,312 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:10,312 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:19,608 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:20,705 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:20,706 - INFO - ==================================================
2026-01-14 14:15:20,706 - INFO -   [탐색 83] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:20,720 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:20,720 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:20,721 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:29,082 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:30,379 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:30,380 - INFO - ==================================================
2026-01-14 14:15:30,380 - INFO -   [탐색 84] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:30,383 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:30,384 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:30,384 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:38,487 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:39,181 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:39,182 - INFO - ==================================================
2026-01-14 14:15:39,182 - INFO -   [탐색 85] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:39,187 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:39,187 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:39,188 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:47,108 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:48,088 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:48,089 - INFO - ==================================================
2026-01-14 14:15:48,089 - INFO -   [탐색 86] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:48,097 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:48,097 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:48,098 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:56,033 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:56,600 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:15:56,600 - INFO - ==================================================
2026-01-14 14:15:56,600 - INFO -   [탐색 87] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:15:56,605 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:56,606 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:56,607 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:05,791 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:06,503 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:16:06,503 - INFO - ==================================================
2026-01-14 14:16:06,504 - INFO -   [탐색 88] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:16:06,509 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:06,510 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:06,510 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:16,045 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:16,720 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:16:16,720 - INFO - ==================================================
2026-01-14 14:16:16,724 - INFO -   [탐색 89] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:16:16,729 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:16,729 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:16,730 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:25,517 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:26,966 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:16:26,971 - INFO - ==================================================
2026-01-14 14:16:26,971 - INFO -   [탐색 90] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:16:26,979 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:26,984 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:26,984 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:34,828 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:35,523 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:16:35,523 - INFO - ==================================================
2026-01-14 14:16:35,524 - INFO -   [탐색 91] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:16:35,529 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:35,530 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:35,531 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:45,387 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:46,379 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:16:46,380 - INFO - ==================================================
2026-01-14 14:16:46,381 - INFO -   [탐색 92] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:16:46,405 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:46,416 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:46,417 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:55,632 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:56,262 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:16:56,263 - INFO - ==================================================
2026-01-14 14:16:56,263 - INFO -   [탐색 93] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:16:56,268 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:56,269 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:56,269 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:05,396 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:07,211 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:17:07,212 - INFO - ==================================================
2026-01-14 14:17:07,213 - INFO -   [탐색 94] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:17:07,218 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:07,219 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:07,219 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:16,505 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:17,149 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:17:17,149 - INFO - ==================================================
2026-01-14 14:17:17,149 - INFO -   [탐색 95] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:17:17,154 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:17,154 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:17,155 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:25,370 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:26,256 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:17:26,256 - INFO - ==================================================
2026-01-14 14:17:26,257 - INFO -   [탐색 96] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:17:26,262 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:26,263 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:26,264 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:35,114 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:35,701 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:17:35,701 - INFO - ==================================================
2026-01-14 14:17:35,701 - INFO -   [탐색 97] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:17:35,706 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:35,706 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:35,707 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:44,317 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:45,334 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:17:45,335 - INFO - ==================================================
2026-01-14 14:17:45,336 - INFO -   [탐색 98] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:17:45,340 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:45,341 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:45,342 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:54,260 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:55,043 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:17:55,044 - INFO - ==================================================
2026-01-14 14:17:55,045 - INFO -   [탐색 99] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:17:55,050 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:55,050 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:55,051 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:03,461 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:04,282 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.939453125)에 맞춰 변경되었습니다.
2026-01-14 14:18:04,282 - INFO - ==================================================
2026-01-14 14:18:04,282 - INFO -   [탐색 100] 희소도: 0.9395 -> 파라미터: 0.0316M (감소율: 99.66%)
2026-01-14 14:18:04,283 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9388 입니다.
2026-01-14 14:18:04,283 - INFO - ================================================================================
2026-01-14 14:18:04,284 - INFO - 계산된 Pruning 정보(희소도: 0.9388)를 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/pruning_info.yaml'에 저장했습니다.
2026-01-14 14:18:04,291 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 14:18:04,320 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:04,321 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:04,321 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:12,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:13,871 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 14:18:13,875 - INFO - ==================================================
2026-01-14 14:18:13,875 - INFO - ==================================================
2026-01-14 14:18:13,875 - INFO - 모델 파라미터 수:
2026-01-14 14:18:13,875 - INFO -   - 총 파라미터: 31,591 개
2026-01-14 14:18:13,875 - INFO -   - 학습 가능한 파라미터: 31,591 개
2026-01-14 14:18:13,896 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 14:18:13,915 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1107 GFLOPs로 감소했습니다 (감소율: 96.14%).
2026-01-14 14:18:13,919 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 14:18:13,919 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:18:13,919 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 14:18:13,919 - INFO - ==================================================
2026-01-14 14:18:13,920 - INFO - train 모드를 시작합니다.
2026-01-14 14:18:13,920 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:18:13,920 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:18:13,920 - INFO - --------------------------------------------------
2026-01-14 14:18:13,920 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 14:18:21,989 - INFO - [Train] [11/90] | Loss: 0.5820 | Train Acc: 73.66%
2026-01-14 14:18:25,322 - INFO - [Valid] [11/90] | Loss: 0.5538 | Val Acc: 74.34%
2026-01-14 14:18:25,335 - INFO - [Metrics for 'abnormal'] | Precision: 0.7134 | Recall: 0.7452 | F1: 0.7290
2026-01-14 14:18:25,336 - INFO - [Metrics for 'normal'] | Precision: 0.7714 | Recall: 0.7418 | F1: 0.7563
2026-01-14 14:18:25,347 - INFO - [Best Model Saved] (val loss: 0.5538) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:18:25,347 - INFO - --------------------------------------------------
2026-01-14 14:18:25,348 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 14:18:34,718 - INFO - [Train] [12/90] | Loss: 0.5281 | Train Acc: 79.61%
2026-01-14 14:18:37,163 - INFO - [Valid] [12/90] | Loss: 0.5340 | Val Acc: 76.70%
2026-01-14 14:18:37,176 - INFO - [Metrics for 'abnormal'] | Precision: 0.7532 | Recall: 0.7389 | F1: 0.7460
2026-01-14 14:18:37,177 - INFO - [Metrics for 'normal'] | Precision: 0.7784 | Recall: 0.7912 | F1: 0.7847
2026-01-14 14:18:37,186 - INFO - [Best Model Saved] (val loss: 0.5340) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:18:37,187 - INFO - --------------------------------------------------
2026-01-14 14:18:37,187 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 14:18:47,132 - INFO - [Train] [13/90] | Loss: 0.5119 | Train Acc: 80.51%
2026-01-14 14:18:48,778 - INFO - [Valid] [13/90] | Loss: 0.5723 | Val Acc: 71.09%
2026-01-14 14:18:48,790 - INFO - [Metrics for 'abnormal'] | Precision: 0.6398 | Recall: 0.8599 | F1: 0.7337
2026-01-14 14:18:48,791 - INFO - [Metrics for 'normal'] | Precision: 0.8281 | Recall: 0.5824 | F1: 0.6839
2026-01-14 14:18:48,796 - INFO - --------------------------------------------------
2026-01-14 14:18:48,796 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 14:18:58,660 - INFO - [Train] [14/90] | Loss: 0.5046 | Train Acc: 79.69%
2026-01-14 14:19:00,281 - INFO - [Valid] [14/90] | Loss: 0.5272 | Val Acc: 76.70%
2026-01-14 14:19:00,289 - INFO - [Metrics for 'abnormal'] | Precision: 0.7600 | Recall: 0.7261 | F1: 0.7427
2026-01-14 14:19:00,289 - INFO - [Metrics for 'normal'] | Precision: 0.7725 | Recall: 0.8022 | F1: 0.7871
2026-01-14 14:19:00,295 - INFO - [Best Model Saved] (val loss: 0.5272) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:19:00,295 - INFO - --------------------------------------------------
2026-01-14 14:19:00,295 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 14:19:10,589 - INFO - [Train] [15/90] | Loss: 0.4948 | Train Acc: 82.22%
2026-01-14 14:19:13,286 - INFO - [Valid] [15/90] | Loss: 0.5249 | Val Acc: 76.40%
2026-01-14 14:19:13,295 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.7707 | F1: 0.7516
2026-01-14 14:19:13,295 - INFO - [Metrics for 'normal'] | Precision: 0.7931 | Recall: 0.7582 | F1: 0.7753
2026-01-14 14:19:13,302 - INFO - [Best Model Saved] (val loss: 0.5249) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:19:13,302 - INFO - --------------------------------------------------
2026-01-14 14:19:13,302 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 14:19:21,816 - INFO - [Train] [16/90] | Loss: 0.4945 | Train Acc: 82.22%
2026-01-14 14:19:23,870 - INFO - [Valid] [16/90] | Loss: 0.5188 | Val Acc: 78.76%
2026-01-14 14:19:23,901 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 14:19:23,903 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 14:19:23,919 - INFO - [Best Model Saved] (val loss: 0.5188) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:19:23,919 - INFO - --------------------------------------------------
2026-01-14 14:19:23,919 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 14:19:32,577 - INFO - [Train] [17/90] | Loss: 0.4881 | Train Acc: 83.33%
2026-01-14 14:19:34,514 - INFO - [Valid] [17/90] | Loss: 0.5220 | Val Acc: 75.81%
2026-01-14 14:19:34,526 - INFO - [Metrics for 'abnormal'] | Precision: 0.7389 | Recall: 0.7389 | F1: 0.7389
2026-01-14 14:19:34,527 - INFO - [Metrics for 'normal'] | Precision: 0.7747 | Recall: 0.7747 | F1: 0.7747
2026-01-14 14:19:34,532 - INFO - --------------------------------------------------
2026-01-14 14:19:34,533 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 14:19:43,801 - INFO - [Train] [18/90] | Loss: 0.4769 | Train Acc: 82.89%
2026-01-14 14:19:46,204 - INFO - [Valid] [18/90] | Loss: 0.5014 | Val Acc: 80.24%
2026-01-14 14:19:46,217 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 14:19:46,217 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 14:19:46,227 - INFO - [Best Model Saved] (val loss: 0.5014) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:19:46,228 - INFO - --------------------------------------------------
2026-01-14 14:19:46,229 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 14:19:55,538 - INFO - [Train] [19/90] | Loss: 0.4684 | Train Acc: 83.48%
2026-01-14 14:19:58,074 - INFO - [Valid] [19/90] | Loss: 0.5160 | Val Acc: 79.06%
2026-01-14 14:19:58,085 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 14:19:58,085 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 14:19:58,089 - INFO - --------------------------------------------------
2026-01-14 14:19:58,089 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 14:20:07,108 - INFO - [Train] [20/90] | Loss: 0.4717 | Train Acc: 83.56%
2026-01-14 14:20:09,716 - INFO - [Valid] [20/90] | Loss: 0.5162 | Val Acc: 79.35%
2026-01-14 14:20:09,741 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7389 | F1: 0.7682
2026-01-14 14:20:09,741 - INFO - [Metrics for 'normal'] | Precision: 0.7887 | Recall: 0.8407 | F1: 0.8138
2026-01-14 14:20:09,745 - INFO - --------------------------------------------------
2026-01-14 14:20:09,750 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 14:20:20,086 - INFO - [Train] [21/90] | Loss: 0.4763 | Train Acc: 83.93%
2026-01-14 14:20:22,166 - INFO - [Valid] [21/90] | Loss: 0.5007 | Val Acc: 79.65%
2026-01-14 14:20:22,175 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-01-14 14:20:22,176 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-01-14 14:20:22,183 - INFO - [Best Model Saved] (val loss: 0.5007) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:20:22,183 - INFO - --------------------------------------------------
2026-01-14 14:20:22,183 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 14:20:30,990 - INFO - [Train] [22/90] | Loss: 0.4703 | Train Acc: 84.30%
2026-01-14 14:20:33,636 - INFO - [Valid] [22/90] | Loss: 0.5245 | Val Acc: 77.58%
2026-01-14 14:20:33,649 - INFO - [Metrics for 'abnormal'] | Precision: 0.7120 | Recall: 0.8662 | F1: 0.7816
2026-01-14 14:20:33,651 - INFO - [Metrics for 'normal'] | Precision: 0.8581 | Recall: 0.6978 | F1: 0.7697
2026-01-14 14:20:33,656 - INFO - --------------------------------------------------
2026-01-14 14:20:33,657 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 14:20:42,472 - INFO - [Train] [23/90] | Loss: 0.4697 | Train Acc: 84.23%
2026-01-14 14:20:44,750 - INFO - [Valid] [23/90] | Loss: 0.5033 | Val Acc: 81.71%
2026-01-14 14:20:44,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.8105 | Recall: 0.7898 | F1: 0.8000
2026-01-14 14:20:44,775 - INFO - [Metrics for 'normal'] | Precision: 0.8226 | Recall: 0.8407 | F1: 0.8315
2026-01-14 14:20:44,779 - INFO - --------------------------------------------------
2026-01-14 14:20:44,781 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 14:20:53,974 - INFO - [Train] [24/90] | Loss: 0.4599 | Train Acc: 84.52%
2026-01-14 14:20:56,584 - INFO - [Valid] [24/90] | Loss: 0.5021 | Val Acc: 79.35%
2026-01-14 14:20:56,598 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8344 | F1: 0.7892
2026-01-14 14:20:56,599 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.7582 | F1: 0.7977
2026-01-14 14:20:56,605 - INFO - --------------------------------------------------
2026-01-14 14:20:56,606 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 14:21:04,905 - INFO - [Train] [25/90] | Loss: 0.4454 | Train Acc: 85.27%
2026-01-14 14:21:07,056 - INFO - [Valid] [25/90] | Loss: 0.5146 | Val Acc: 77.29%
2026-01-14 14:21:07,067 - INFO - [Metrics for 'abnormal'] | Precision: 0.7222 | Recall: 0.8280 | F1: 0.7715
2026-01-14 14:21:07,068 - INFO - [Metrics for 'normal'] | Precision: 0.8302 | Recall: 0.7253 | F1: 0.7742
2026-01-14 14:21:07,072 - INFO - --------------------------------------------------
2026-01-14 14:21:07,073 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 14:21:16,006 - INFO - [Train] [26/90] | Loss: 0.4526 | Train Acc: 84.82%
2026-01-14 14:21:19,117 - INFO - [Valid] [26/90] | Loss: 0.5095 | Val Acc: 82.30%
2026-01-14 14:21:19,128 - INFO - [Metrics for 'abnormal'] | Precision: 0.8089 | Recall: 0.8089 | F1: 0.8089
2026-01-14 14:21:19,129 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8352 | F1: 0.8352
2026-01-14 14:21:19,133 - INFO - --------------------------------------------------
2026-01-14 14:21:19,134 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 14:21:28,156 - INFO - [Train] [27/90] | Loss: 0.4531 | Train Acc: 84.45%
2026-01-14 14:21:30,675 - INFO - [Valid] [27/90] | Loss: 0.4825 | Val Acc: 82.89%
2026-01-14 14:21:30,687 - INFO - [Metrics for 'abnormal'] | Precision: 0.8367 | Recall: 0.7834 | F1: 0.8092
2026-01-14 14:21:30,687 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.8681 | F1: 0.8449
2026-01-14 14:21:30,698 - INFO - [Best Model Saved] (val loss: 0.4825) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:21:30,698 - INFO - --------------------------------------------------
2026-01-14 14:21:30,699 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 14:21:40,215 - INFO - [Train] [28/90] | Loss: 0.4518 | Train Acc: 84.90%
2026-01-14 14:21:42,702 - INFO - [Valid] [28/90] | Loss: 0.4880 | Val Acc: 81.12%
2026-01-14 14:21:42,731 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 14:21:42,735 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 14:21:42,742 - INFO - --------------------------------------------------
2026-01-14 14:21:42,746 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 14:21:51,161 - INFO - [Train] [29/90] | Loss: 0.4419 | Train Acc: 85.71%
2026-01-14 14:21:53,672 - INFO - [Valid] [29/90] | Loss: 0.4840 | Val Acc: 81.42%
2026-01-14 14:21:53,683 - INFO - [Metrics for 'abnormal'] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 14:21:53,683 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 14:21:53,688 - INFO - --------------------------------------------------
2026-01-14 14:21:53,689 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 14:22:02,430 - INFO - [Train] [30/90] | Loss: 0.4430 | Train Acc: 84.38%
2026-01-14 14:22:04,826 - INFO - [Valid] [30/90] | Loss: 0.4812 | Val Acc: 82.60%
2026-01-14 14:22:04,838 - INFO - [Metrics for 'abnormal'] | Precision: 0.8356 | Recall: 0.7771 | F1: 0.8053
2026-01-14 14:22:04,839 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8681 | F1: 0.8427
2026-01-14 14:22:04,846 - INFO - [Best Model Saved] (val loss: 0.4812) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:22:04,846 - INFO - --------------------------------------------------
2026-01-14 14:22:04,847 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 14:22:14,780 - INFO - [Train] [31/90] | Loss: 0.4411 | Train Acc: 84.97%
2026-01-14 14:22:17,216 - INFO - [Valid] [31/90] | Loss: 0.4780 | Val Acc: 82.60%
2026-01-14 14:22:17,228 - INFO - [Metrics for 'abnormal'] | Precision: 0.7917 | Recall: 0.8471 | F1: 0.8185
2026-01-14 14:22:17,229 - INFO - [Metrics for 'normal'] | Precision: 0.8596 | Recall: 0.8077 | F1: 0.8329
2026-01-14 14:22:17,236 - INFO - [Best Model Saved] (val loss: 0.4780) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:22:17,236 - INFO - --------------------------------------------------
2026-01-14 14:22:17,237 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 14:22:25,570 - INFO - [Train] [32/90] | Loss: 0.4387 | Train Acc: 85.71%
2026-01-14 14:22:28,704 - INFO - [Valid] [32/90] | Loss: 0.4895 | Val Acc: 80.24%
2026-01-14 14:22:28,718 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 14:22:28,722 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 14:22:28,727 - INFO - --------------------------------------------------
2026-01-14 14:22:28,731 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 14:22:36,091 - INFO - [Train] [33/90] | Loss: 0.4310 | Train Acc: 86.01%
2026-01-14 14:22:39,612 - INFO - [Valid] [33/90] | Loss: 0.4816 | Val Acc: 82.60%
2026-01-14 14:22:39,626 - INFO - [Metrics for 'abnormal'] | Precision: 0.8500 | Recall: 0.7580 | F1: 0.8013
2026-01-14 14:22:39,627 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.8846 | F1: 0.8451
2026-01-14 14:22:39,631 - INFO - --------------------------------------------------
2026-01-14 14:22:39,632 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 14:22:47,592 - INFO - [Train] [34/90] | Loss: 0.4417 | Train Acc: 84.60%
2026-01-14 14:22:50,852 - INFO - [Valid] [34/90] | Loss: 0.4723 | Val Acc: 81.71%
2026-01-14 14:22:50,877 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8471 | F1: 0.8110
2026-01-14 14:22:50,878 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.7912 | F1: 0.8229
2026-01-14 14:22:50,898 - INFO - [Best Model Saved] (val loss: 0.4723) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:22:50,898 - INFO - --------------------------------------------------
2026-01-14 14:22:50,898 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 14:23:00,973 - INFO - [Train] [35/90] | Loss: 0.4362 | Train Acc: 85.64%
2026-01-14 14:23:03,974 - INFO - [Valid] [35/90] | Loss: 0.4955 | Val Acc: 81.42%
2026-01-14 14:23:03,995 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-01-14 14:23:03,999 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-01-14 14:23:04,006 - INFO - --------------------------------------------------
2026-01-14 14:23:04,010 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 14:23:11,755 - INFO - [Train] [36/90] | Loss: 0.4206 | Train Acc: 87.87%
2026-01-14 14:23:15,323 - INFO - [Valid] [36/90] | Loss: 0.4850 | Val Acc: 81.42%
2026-01-14 14:23:15,336 - INFO - [Metrics for 'abnormal'] | Precision: 0.7901 | Recall: 0.8153 | F1: 0.8025
2026-01-14 14:23:15,337 - INFO - [Metrics for 'normal'] | Precision: 0.8362 | Recall: 0.8132 | F1: 0.8245
2026-01-14 14:23:15,360 - INFO - --------------------------------------------------
2026-01-14 14:23:15,362 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 14:23:22,988 - INFO - [Train] [37/90] | Loss: 0.4205 | Train Acc: 87.35%
2026-01-14 14:23:26,057 - INFO - [Valid] [37/90] | Loss: 0.4959 | Val Acc: 79.35%
2026-01-14 14:23:26,069 - INFO - [Metrics for 'abnormal'] | Precision: 0.7458 | Recall: 0.8408 | F1: 0.7904
2026-01-14 14:23:26,070 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.7527 | F1: 0.7965
2026-01-14 14:23:26,074 - INFO - --------------------------------------------------
2026-01-14 14:23:26,075 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 14:23:34,634 - INFO - [Train] [38/90] | Loss: 0.4231 | Train Acc: 86.16%
2026-01-14 14:23:37,341 - INFO - [Valid] [38/90] | Loss: 0.4898 | Val Acc: 80.24%
2026-01-14 14:23:37,354 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 14:23:37,355 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 14:23:37,360 - INFO - --------------------------------------------------
2026-01-14 14:23:37,360 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 14:23:46,755 - INFO - [Train] [39/90] | Loss: 0.4177 | Train Acc: 86.53%
2026-01-14 14:23:49,490 - INFO - [Valid] [39/90] | Loss: 0.4814 | Val Acc: 81.42%
2026-01-14 14:23:49,527 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 14:23:49,529 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 14:23:49,536 - INFO - --------------------------------------------------
2026-01-14 14:23:49,537 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 14:23:58,253 - INFO - [Train] [40/90] | Loss: 0.4196 | Train Acc: 87.43%
2026-01-14 14:24:00,743 - INFO - [Valid] [40/90] | Loss: 0.4799 | Val Acc: 81.12%
2026-01-14 14:24:00,756 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 14:24:00,756 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 14:24:00,761 - INFO - --------------------------------------------------
2026-01-14 14:24:00,762 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 14:24:09,200 - INFO - [Train] [41/90] | Loss: 0.4109 | Train Acc: 87.35%
2026-01-14 14:24:12,004 - INFO - [Valid] [41/90] | Loss: 0.5046 | Val Acc: 79.65%
2026-01-14 14:24:12,082 - INFO - [Metrics for 'abnormal'] | Precision: 0.7558 | Recall: 0.8280 | F1: 0.7903
2026-01-14 14:24:12,082 - INFO - [Metrics for 'normal'] | Precision: 0.8383 | Recall: 0.7692 | F1: 0.8023
2026-01-14 14:24:12,091 - INFO - --------------------------------------------------
2026-01-14 14:24:12,091 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 14:24:20,880 - INFO - [Train] [42/90] | Loss: 0.4169 | Train Acc: 86.68%
2026-01-14 14:24:23,596 - INFO - [Valid] [42/90] | Loss: 0.4829 | Val Acc: 80.24%
2026-01-14 14:24:23,607 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 14:24:23,607 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 14:24:23,612 - INFO - --------------------------------------------------
2026-01-14 14:24:23,612 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 14:24:32,739 - INFO - [Train] [43/90] | Loss: 0.4126 | Train Acc: 87.50%
2026-01-14 14:24:35,558 - INFO - [Valid] [43/90] | Loss: 0.4998 | Val Acc: 79.94%
2026-01-14 14:24:35,587 - INFO - [Metrics for 'abnormal'] | Precision: 0.7602 | Recall: 0.8280 | F1: 0.7927
2026-01-14 14:24:35,588 - INFO - [Metrics for 'normal'] | Precision: 0.8393 | Recall: 0.7747 | F1: 0.8057
2026-01-14 14:24:35,592 - INFO - --------------------------------------------------
2026-01-14 14:24:35,593 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 14:24:44,868 - INFO - [Train] [44/90] | Loss: 0.4028 | Train Acc: 88.69%
2026-01-14 14:24:47,384 - INFO - [Valid] [44/90] | Loss: 0.4744 | Val Acc: 81.71%
2026-01-14 14:24:47,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.8146 | Recall: 0.7834 | F1: 0.7987
2026-01-14 14:24:47,397 - INFO - [Metrics for 'normal'] | Precision: 0.8191 | Recall: 0.8462 | F1: 0.8324
2026-01-14 14:24:47,401 - INFO - --------------------------------------------------
2026-01-14 14:24:47,401 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 14:24:55,777 - INFO - [Train] [45/90] | Loss: 0.4145 | Train Acc: 86.83%
2026-01-14 14:24:58,275 - INFO - [Valid] [45/90] | Loss: 0.4761 | Val Acc: 79.94%
2026-01-14 14:24:58,290 - INFO - [Metrics for 'abnormal'] | Precision: 0.7543 | Recall: 0.8408 | F1: 0.7952
2026-01-14 14:24:58,291 - INFO - [Metrics for 'normal'] | Precision: 0.8476 | Recall: 0.7637 | F1: 0.8035
2026-01-14 14:24:58,296 - INFO - --------------------------------------------------
2026-01-14 14:24:58,297 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 14:25:06,554 - INFO - [Train] [46/90] | Loss: 0.4069 | Train Acc: 88.62%
2026-01-14 14:25:09,427 - INFO - [Valid] [46/90] | Loss: 0.4632 | Val Acc: 82.30%
2026-01-14 14:25:09,447 - INFO - [Metrics for 'abnormal'] | Precision: 0.8089 | Recall: 0.8089 | F1: 0.8089
2026-01-14 14:25:09,450 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8352 | F1: 0.8352
2026-01-14 14:25:09,469 - INFO - [Best Model Saved] (val loss: 0.4632) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:25:09,470 - INFO - --------------------------------------------------
2026-01-14 14:25:09,470 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 14:25:16,734 - INFO - [Train] [47/90] | Loss: 0.3988 | Train Acc: 88.69%
2026-01-14 14:25:19,428 - INFO - [Valid] [47/90] | Loss: 0.4657 | Val Acc: 81.12%
2026-01-14 14:25:19,455 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 14:25:19,459 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 14:25:19,466 - INFO - --------------------------------------------------
2026-01-14 14:25:19,468 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 14:25:28,259 - INFO - [Train] [48/90] | Loss: 0.3954 | Train Acc: 88.62%
2026-01-14 14:25:31,758 - INFO - [Valid] [48/90] | Loss: 0.4671 | Val Acc: 82.30%
2026-01-14 14:25:31,771 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 14:25:31,772 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 14:25:31,777 - INFO - --------------------------------------------------
2026-01-14 14:25:31,779 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 14:25:41,498 - INFO - [Train] [49/90] | Loss: 0.3948 | Train Acc: 87.95%
2026-01-14 14:25:43,924 - INFO - [Valid] [49/90] | Loss: 0.4825 | Val Acc: 80.24%
2026-01-14 14:25:43,951 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 14:25:43,955 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 14:25:43,959 - INFO - --------------------------------------------------
2026-01-14 14:25:43,963 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 14:25:52,847 - INFO - [Train] [50/90] | Loss: 0.3994 | Train Acc: 88.99%
2026-01-14 14:25:55,299 - INFO - [Valid] [50/90] | Loss: 0.4902 | Val Acc: 79.94%
2026-01-14 14:25:55,310 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8535 | F1: 0.7976
2026-01-14 14:25:55,310 - INFO - [Metrics for 'normal'] | Precision: 0.8562 | Recall: 0.7527 | F1: 0.8012
2026-01-14 14:25:55,314 - INFO - --------------------------------------------------
2026-01-14 14:25:55,315 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 14:26:03,547 - INFO - [Train] [51/90] | Loss: 0.3942 | Train Acc: 88.84%
2026-01-14 14:26:05,522 - INFO - [Valid] [51/90] | Loss: 0.4674 | Val Acc: 80.53%
2026-01-14 14:26:05,552 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-01-14 14:26:05,553 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-01-14 14:26:05,559 - INFO - --------------------------------------------------
2026-01-14 14:26:05,560 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 14:26:15,436 - INFO - [Train] [52/90] | Loss: 0.3858 | Train Acc: 89.43%
2026-01-14 14:26:17,616 - INFO - [Valid] [52/90] | Loss: 0.4646 | Val Acc: 81.71%
2026-01-14 14:26:17,668 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 14:26:17,672 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 14:26:17,696 - INFO - --------------------------------------------------
2026-01-14 14:26:17,697 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 14:26:27,721 - INFO - [Train] [53/90] | Loss: 0.3885 | Train Acc: 88.84%
2026-01-14 14:26:29,725 - INFO - [Valid] [53/90] | Loss: 0.4692 | Val Acc: 82.30%
2026-01-14 14:26:29,747 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8280 | F1: 0.8125
2026-01-14 14:26:29,752 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.8187 | F1: 0.8324
2026-01-14 14:26:29,756 - INFO - --------------------------------------------------
2026-01-14 14:26:29,760 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 14:26:39,061 - INFO - [Train] [54/90] | Loss: 0.3967 | Train Acc: 89.66%
2026-01-14 14:26:41,034 - INFO - [Valid] [54/90] | Loss: 0.4759 | Val Acc: 80.83%
2026-01-14 14:26:41,045 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-01-14 14:26:41,045 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-01-14 14:26:41,049 - INFO - --------------------------------------------------
2026-01-14 14:26:41,050 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 14:26:50,536 - INFO - [Train] [55/90] | Loss: 0.3806 | Train Acc: 89.58%
2026-01-14 14:26:52,504 - INFO - [Valid] [55/90] | Loss: 0.4642 | Val Acc: 82.60%
2026-01-14 14:26:52,516 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 14:26:52,517 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 14:26:52,521 - INFO - --------------------------------------------------
2026-01-14 14:26:52,521 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 14:27:02,483 - INFO - [Train] [56/90] | Loss: 0.3817 | Train Acc: 89.58%
2026-01-14 14:27:04,051 - INFO - [Valid] [56/90] | Loss: 0.4555 | Val Acc: 82.30%
2026-01-14 14:27:04,077 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 14:27:04,080 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 14:27:04,088 - INFO - [Best Model Saved] (val loss: 0.4555) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:27:04,088 - INFO - --------------------------------------------------
2026-01-14 14:27:04,088 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 14:27:13,863 - INFO - [Train] [57/90] | Loss: 0.3883 | Train Acc: 89.43%
2026-01-14 14:27:15,667 - INFO - [Valid] [57/90] | Loss: 0.4585 | Val Acc: 80.24%
2026-01-14 14:27:15,682 - INFO - [Metrics for 'abnormal'] | Precision: 0.7744 | Recall: 0.8089 | F1: 0.7913
2026-01-14 14:27:15,683 - INFO - [Metrics for 'normal'] | Precision: 0.8286 | Recall: 0.7967 | F1: 0.8123
2026-01-14 14:27:15,687 - INFO - --------------------------------------------------
2026-01-14 14:27:15,688 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 14:27:25,522 - INFO - [Train] [58/90] | Loss: 0.3879 | Train Acc: 89.73%
2026-01-14 14:27:27,610 - INFO - [Valid] [58/90] | Loss: 0.4732 | Val Acc: 80.53%
2026-01-14 14:27:27,655 - INFO - [Metrics for 'abnormal'] | Precision: 0.7630 | Recall: 0.8408 | F1: 0.8000
2026-01-14 14:27:27,656 - INFO - [Metrics for 'normal'] | Precision: 0.8494 | Recall: 0.7747 | F1: 0.8103
2026-01-14 14:27:27,659 - INFO - --------------------------------------------------
2026-01-14 14:27:27,659 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 14:27:36,450 - INFO - [Train] [59/90] | Loss: 0.3767 | Train Acc: 90.62%
2026-01-14 14:27:39,537 - INFO - [Valid] [59/90] | Loss: 0.4718 | Val Acc: 80.83%
2026-01-14 14:27:39,549 - INFO - [Metrics for 'abnormal'] | Precision: 0.7674 | Recall: 0.8408 | F1: 0.8024
2026-01-14 14:27:39,550 - INFO - [Metrics for 'normal'] | Precision: 0.8503 | Recall: 0.7802 | F1: 0.8138
2026-01-14 14:27:39,556 - INFO - --------------------------------------------------
2026-01-14 14:27:39,557 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 14:27:47,762 - INFO - [Train] [60/90] | Loss: 0.3778 | Train Acc: 89.51%
2026-01-14 14:27:50,431 - INFO - [Valid] [60/90] | Loss: 0.4568 | Val Acc: 81.71%
2026-01-14 14:27:50,444 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 14:27:50,445 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 14:27:50,450 - INFO - --------------------------------------------------
2026-01-14 14:27:50,451 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 14:27:58,765 - INFO - [Train] [61/90] | Loss: 0.3713 | Train Acc: 90.18%
2026-01-14 14:28:02,215 - INFO - [Valid] [61/90] | Loss: 0.4749 | Val Acc: 81.42%
2026-01-14 14:28:02,226 - INFO - [Metrics for 'abnormal'] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 14:28:02,227 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 14:28:02,230 - INFO - --------------------------------------------------
2026-01-14 14:28:02,231 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 14:28:10,825 - INFO - [Train] [62/90] | Loss: 0.3733 | Train Acc: 90.10%
2026-01-14 14:28:14,074 - INFO - [Valid] [62/90] | Loss: 0.4756 | Val Acc: 81.12%
2026-01-14 14:28:14,084 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 14:28:14,085 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 14:28:14,088 - INFO - --------------------------------------------------
2026-01-14 14:28:14,089 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 14:28:22,743 - INFO - [Train] [63/90] | Loss: 0.3789 | Train Acc: 90.03%
2026-01-14 14:28:25,473 - INFO - [Valid] [63/90] | Loss: 0.4680 | Val Acc: 81.12%
2026-01-14 14:28:25,486 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 14:28:25,487 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 14:28:25,492 - INFO - --------------------------------------------------
2026-01-14 14:28:25,493 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 14:28:33,057 - INFO - [Train] [64/90] | Loss: 0.3652 | Train Acc: 91.59%
2026-01-14 14:28:36,106 - INFO - [Valid] [64/90] | Loss: 0.4579 | Val Acc: 80.83%
2026-01-14 14:28:36,119 - INFO - [Metrics for 'abnormal'] | Precision: 0.7706 | Recall: 0.8344 | F1: 0.8012
2026-01-14 14:28:36,120 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.7857 | F1: 0.8148
2026-01-14 14:28:36,125 - INFO - --------------------------------------------------
2026-01-14 14:28:36,126 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 14:28:43,505 - INFO - [Train] [65/90] | Loss: 0.3678 | Train Acc: 91.22%
2026-01-14 14:28:46,376 - INFO - [Valid] [65/90] | Loss: 0.4707 | Val Acc: 81.42%
2026-01-14 14:28:46,400 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.8471 | F1: 0.8085
2026-01-14 14:28:46,405 - INFO - [Metrics for 'normal'] | Precision: 0.8563 | Recall: 0.7857 | F1: 0.8195
2026-01-14 14:28:46,410 - INFO - --------------------------------------------------
2026-01-14 14:28:46,410 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 14:28:55,479 - INFO - [Train] [66/90] | Loss: 0.3573 | Train Acc: 92.26%
2026-01-14 14:28:57,804 - INFO - [Valid] [66/90] | Loss: 0.4671 | Val Acc: 81.12%
2026-01-14 14:28:57,843 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 14:28:57,843 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 14:28:57,855 - INFO - --------------------------------------------------
2026-01-14 14:28:57,863 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 14:29:07,784 - INFO - [Train] [67/90] | Loss: 0.3690 | Train Acc: 90.85%
2026-01-14 14:29:10,383 - INFO - [Valid] [67/90] | Loss: 0.4614 | Val Acc: 80.24%
2026-01-14 14:29:10,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-01-14 14:29:10,397 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-01-14 14:29:10,402 - INFO - --------------------------------------------------
2026-01-14 14:29:10,405 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 14:29:20,333 - INFO - [Train] [68/90] | Loss: 0.3656 | Train Acc: 90.77%
2026-01-14 14:29:22,953 - INFO - [Valid] [68/90] | Loss: 0.4743 | Val Acc: 80.83%
2026-01-14 14:29:22,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7706 | Recall: 0.8344 | F1: 0.8012
2026-01-14 14:29:22,991 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.7857 | F1: 0.8148
2026-01-14 14:29:23,001 - INFO - --------------------------------------------------
2026-01-14 14:29:23,008 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 14:29:32,160 - INFO - [Train] [69/90] | Loss: 0.3580 | Train Acc: 91.74%
2026-01-14 14:29:35,266 - INFO - [Valid] [69/90] | Loss: 0.4651 | Val Acc: 80.24%
2026-01-14 14:29:35,289 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 14:29:35,293 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 14:29:35,305 - INFO - --------------------------------------------------
2026-01-14 14:29:35,306 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 14:29:44,911 - INFO - [Train] [70/90] | Loss: 0.3669 | Train Acc: 91.00%
2026-01-14 14:29:47,463 - INFO - [Valid] [70/90] | Loss: 0.4638 | Val Acc: 81.71%
2026-01-14 14:29:47,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 14:29:47,475 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 14:29:47,480 - INFO - --------------------------------------------------
2026-01-14 14:29:47,480 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 14:29:56,452 - INFO - [Train] [71/90] | Loss: 0.3597 | Train Acc: 91.67%
2026-01-14 14:30:00,299 - INFO - [Valid] [71/90] | Loss: 0.4683 | Val Acc: 80.24%
2026-01-14 14:30:00,323 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 14:30:00,324 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 14:30:00,345 - INFO - --------------------------------------------------
2026-01-14 14:30:00,346 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 14:30:08,862 - INFO - [Train] [72/90] | Loss: 0.3663 | Train Acc: 91.96%
2026-01-14 14:30:12,239 - INFO - [Valid] [72/90] | Loss: 0.4598 | Val Acc: 80.83%
2026-01-14 14:30:12,263 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 14:30:12,265 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 14:30:12,272 - INFO - --------------------------------------------------
2026-01-14 14:30:12,273 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 14:30:20,242 - INFO - [Train] [73/90] | Loss: 0.3633 | Train Acc: 92.11%
2026-01-14 14:30:23,980 - INFO - [Valid] [73/90] | Loss: 0.4588 | Val Acc: 81.12%
2026-01-14 14:30:23,994 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 14:30:23,995 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 14:30:24,002 - INFO - --------------------------------------------------
2026-01-14 14:30:24,003 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 14:30:31,885 - INFO - [Train] [74/90] | Loss: 0.3642 | Train Acc: 90.92%
2026-01-14 14:30:35,835 - INFO - [Valid] [74/90] | Loss: 0.4659 | Val Acc: 79.94%
2026-01-14 14:30:35,870 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-01-14 14:30:35,871 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-01-14 14:30:35,887 - INFO - --------------------------------------------------
2026-01-14 14:30:35,888 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 14:30:44,399 - INFO - [Train] [75/90] | Loss: 0.3611 | Train Acc: 91.37%
2026-01-14 14:30:47,344 - INFO - [Valid] [75/90] | Loss: 0.4674 | Val Acc: 79.94%
2026-01-14 14:30:47,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-01-14 14:30:47,372 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-01-14 14:30:47,384 - INFO - --------------------------------------------------
2026-01-14 14:30:47,386 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 14:30:55,587 - INFO - [Train] [76/90] | Loss: 0.3645 | Train Acc: 91.07%
2026-01-14 14:30:58,775 - INFO - [Valid] [76/90] | Loss: 0.4655 | Val Acc: 80.24%
2026-01-14 14:30:58,800 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 14:30:58,800 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 14:30:58,808 - INFO - --------------------------------------------------
2026-01-14 14:30:58,809 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 14:31:08,890 - INFO - [Train] [77/90] | Loss: 0.3545 | Train Acc: 91.22%
2026-01-14 14:31:12,734 - INFO - [Valid] [77/90] | Loss: 0.4661 | Val Acc: 79.94%
2026-01-14 14:31:12,757 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-01-14 14:31:12,759 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-01-14 14:31:12,767 - INFO - --------------------------------------------------
2026-01-14 14:31:12,770 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 14:31:21,391 - INFO - [Train] [78/90] | Loss: 0.3597 | Train Acc: 91.67%
2026-01-14 14:31:24,237 - INFO - [Valid] [78/90] | Loss: 0.4712 | Val Acc: 80.53%
2026-01-14 14:31:24,257 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 14:31:24,260 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 14:31:24,264 - INFO - --------------------------------------------------
2026-01-14 14:31:24,265 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 14:31:32,270 - INFO - [Train] [79/90] | Loss: 0.3500 | Train Acc: 92.11%
2026-01-14 14:31:35,452 - INFO - [Valid] [79/90] | Loss: 0.4774 | Val Acc: 80.83%
2026-01-14 14:31:35,466 - INFO - [Metrics for 'abnormal'] | Precision: 0.7706 | Recall: 0.8344 | F1: 0.8012
2026-01-14 14:31:35,466 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.7857 | F1: 0.8148
2026-01-14 14:31:35,470 - INFO - --------------------------------------------------
2026-01-14 14:31:35,471 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 14:31:43,496 - INFO - [Train] [80/90] | Loss: 0.3569 | Train Acc: 91.37%
2026-01-14 14:31:46,557 - INFO - [Valid] [80/90] | Loss: 0.4682 | Val Acc: 80.53%
2026-01-14 14:31:46,582 - INFO - [Metrics for 'abnormal'] | Precision: 0.7725 | Recall: 0.8217 | F1: 0.7963
2026-01-14 14:31:46,582 - INFO - [Metrics for 'normal'] | Precision: 0.8372 | Recall: 0.7912 | F1: 0.8136
2026-01-14 14:31:46,591 - INFO - --------------------------------------------------
2026-01-14 14:31:46,591 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 14:31:55,328 - INFO - [Train] [81/90] | Loss: 0.3504 | Train Acc: 91.52%
2026-01-14 14:31:58,260 - INFO - [Valid] [81/90] | Loss: 0.4646 | Val Acc: 80.53%
2026-01-14 14:31:58,275 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.8280 | F1: 0.7975
2026-01-14 14:31:58,276 - INFO - [Metrics for 'normal'] | Precision: 0.8412 | Recall: 0.7857 | F1: 0.8125
2026-01-14 14:31:58,281 - INFO - --------------------------------------------------
2026-01-14 14:31:58,282 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 14:32:07,565 - INFO - [Train] [82/90] | Loss: 0.3510 | Train Acc: 92.11%
2026-01-14 14:32:10,957 - INFO - [Valid] [82/90] | Loss: 0.4725 | Val Acc: 80.83%
2026-01-14 14:32:10,989 - INFO - [Metrics for 'abnormal'] | Precision: 0.7706 | Recall: 0.8344 | F1: 0.8012
2026-01-14 14:32:10,990 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.7857 | F1: 0.8148
2026-01-14 14:32:10,998 - INFO - --------------------------------------------------
2026-01-14 14:32:11,003 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 14:32:19,407 - INFO - [Train] [83/90] | Loss: 0.3504 | Train Acc: 92.41%
2026-01-14 14:32:22,509 - INFO - [Valid] [83/90] | Loss: 0.4687 | Val Acc: 80.24%
2026-01-14 14:32:22,520 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 14:32:22,521 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 14:32:22,525 - INFO - --------------------------------------------------
2026-01-14 14:32:22,526 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 14:32:30,951 - INFO - [Train] [84/90] | Loss: 0.3530 | Train Acc: 91.59%
2026-01-14 14:32:33,202 - INFO - [Valid] [84/90] | Loss: 0.4661 | Val Acc: 80.53%
2026-01-14 14:32:33,214 - INFO - [Metrics for 'abnormal'] | Precision: 0.7630 | Recall: 0.8408 | F1: 0.8000
2026-01-14 14:32:33,214 - INFO - [Metrics for 'normal'] | Precision: 0.8494 | Recall: 0.7747 | F1: 0.8103
2026-01-14 14:32:33,219 - INFO - --------------------------------------------------
2026-01-14 14:32:33,220 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 14:32:41,369 - INFO - [Train] [85/90] | Loss: 0.3539 | Train Acc: 92.04%
2026-01-14 14:32:44,577 - INFO - [Valid] [85/90] | Loss: 0.4660 | Val Acc: 80.83%
2026-01-14 14:32:44,613 - INFO - [Metrics for 'abnormal'] | Precision: 0.7674 | Recall: 0.8408 | F1: 0.8024
2026-01-14 14:32:44,613 - INFO - [Metrics for 'normal'] | Precision: 0.8503 | Recall: 0.7802 | F1: 0.8138
2026-01-14 14:32:44,631 - INFO - --------------------------------------------------
2026-01-14 14:32:44,635 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 14:32:53,673 - INFO - [Train] [86/90] | Loss: 0.3489 | Train Acc: 92.49%
2026-01-14 14:32:56,696 - INFO - [Valid] [86/90] | Loss: 0.4626 | Val Acc: 81.12%
2026-01-14 14:32:56,717 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 14:32:56,718 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 14:32:56,724 - INFO - --------------------------------------------------
2026-01-14 14:32:56,724 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 14:33:03,730 - INFO - [Train] [87/90] | Loss: 0.3535 | Train Acc: 92.04%
2026-01-14 14:33:05,865 - INFO - [Valid] [87/90] | Loss: 0.4688 | Val Acc: 81.12%
2026-01-14 14:33:05,878 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 14:33:05,878 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 14:33:05,883 - INFO - --------------------------------------------------
2026-01-14 14:33:05,883 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 14:33:13,086 - INFO - [Train] [88/90] | Loss: 0.3476 | Train Acc: 91.59%
2026-01-14 14:33:16,326 - INFO - [Valid] [88/90] | Loss: 0.4643 | Val Acc: 81.12%
2026-01-14 14:33:16,335 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 14:33:16,335 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 14:33:16,338 - INFO - --------------------------------------------------
2026-01-14 14:33:16,339 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 14:33:22,778 - INFO - [Train] [89/90] | Loss: 0.3472 | Train Acc: 91.15%
2026-01-14 14:33:24,412 - INFO - [Valid] [89/90] | Loss: 0.4712 | Val Acc: 81.12%
2026-01-14 14:33:24,424 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.8471 | F1: 0.8061
2026-01-14 14:33:24,425 - INFO - [Metrics for 'normal'] | Precision: 0.8554 | Recall: 0.7802 | F1: 0.8161
2026-01-14 14:33:24,429 - INFO - --------------------------------------------------
2026-01-14 14:33:24,431 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 14:33:30,202 - INFO - [Train] [90/90] | Loss: 0.3511 | Train Acc: 92.11%
2026-01-14 14:33:32,433 - INFO - [Valid] [90/90] | Loss: 0.4651 | Val Acc: 81.12%
2026-01-14 14:33:32,445 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.8471 | F1: 0.8061
2026-01-14 14:33:32,446 - INFO - [Metrics for 'normal'] | Precision: 0.8554 | Recall: 0.7802 | F1: 0.8161
2026-01-14 14:33:32,451 - INFO - ==================================================
2026-01-14 14:33:32,452 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 14:33:32,452 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 14:33:32,453 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:33:32,597 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 14:33:32,600 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:33:32,601 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:33:32,602 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:33:38,444 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:33:39,362 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.938759765625)에 맞춰 변경되었습니다.
2026-01-14 14:33:39,362 - INFO - ==================================================
2026-01-14 14:33:39,370 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/best_model.pth'
2026-01-14 14:33:39,371 - INFO - ==================================================
2026-01-14 14:33:39,371 - INFO - Test 모드를 시작합니다.
2026-01-14 14:33:39,529 - INFO - 연산량 (MACs): 0.0554 GMACs per sample
2026-01-14 14:33:39,535 - INFO - 연산량 (FLOPs): 0.1107 GFLOPs per sample
2026-01-14 14:33:39,535 - INFO - ==================================================
2026-01-14 14:33:39,535 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 14:33:40,024 - INFO - 샘플 당 평균 Forward Pass 시간: 0.37ms (std: 0.20ms), FPS: 3614.75 (std: 2306.57) (1개 샘플 x 100회 반복)
2026-01-14 14:33:40,025 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 158.92 MB
2026-01-14 14:33:40,025 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 14:33:42,572 - INFO - [Test] Loss: 0.3803 | Test Acc: 82.30%
2026-01-14 14:33:42,590 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 14:33:42,591 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 14:33:43,217 - INFO - ==================================================
2026-01-14 14:33:43,218 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/confusion_matrix_20260114_135956.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/confusion_matrix_20260114_135956.pdf'
2026-01-14 14:33:43,218 - INFO - ==================================================
2026-01-14 14:33:43,218 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 14:33:43,695 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/model_fp32_20260114_135956.onnx'에 저장되었습니다. (크기: 0.12 MB)
2026-01-14 14:33:44,205 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2385.80 MB (증가량: 6.89 MB)
2026-01-14 14:33:44,208 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 14:33:44,993 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 4.47ms (std: 5.22ms)
2026-01-14 14:33:44,994 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 467.92 FPS (std: 308.84) (1개 샘플 x 100회 반복)
2026-01-14 14:33:44,994 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2387.84 MB (순수 증가량: 2.04 MB)
2026-01-14 14:33:44,995 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2387.84 MB (전체 증가량: 8.93 MB)
2026-01-14 14:33:48,294 - INFO - [Test (ONNX)] | Test Acc (ONNX): 82.30%
2026-01-14 14:33:48,304 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 14:33:48,304 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 14:33:48,972 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/val_acc.pdf'
2026-01-14 14:33:49,515 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/train_val_acc.pdf'
2026-01-14 14:33:49,974 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/F1_normal.pdf'
2026-01-14 14:33:50,404 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/val_loss.pdf'
2026-01-14 14:33:50,733 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/learning_rate.pdf'
2026-01-14 14:33:55,731 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_135956/graph_20260114_135956/compile.pdf'
