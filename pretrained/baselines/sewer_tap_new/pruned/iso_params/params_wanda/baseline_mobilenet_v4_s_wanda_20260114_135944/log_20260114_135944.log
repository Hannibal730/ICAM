2026-01-14 13:59:44,831 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/log_20260114_135944.log'에 저장됩니다.
2026-01-14 13:59:44,840 - INFO - ==================================================
2026-01-14 13:59:44,840 - INFO - config.yaml:
2026-01-14 13:59:44,840 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobilenet_v4_s
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.031371

2026-01-14 13:59:44,840 - INFO - ==================================================
2026-01-14 13:59:44,900 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:59:44,900 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:59:44,900 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:59:44,908 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:59:44,909 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:59:44,909 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:59:44,909 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:59:45,159 - INFO - ==================================================
2026-01-14 13:59:45,159 - INFO - 모델 파라미터 수:
2026-01-14 13:59:45,159 - INFO -   - 총 파라미터: 2,495,586 개
2026-01-14 13:59:45,159 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-01-14 13:59:45,159 - INFO - ================================================================================
2026-01-14 13:59:45,159 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:59:45,159 - INFO - ================================================================================
2026-01-14 13:59:45,159 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:59:45,161 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:59:45,161 - INFO - ==================================================
2026-01-14 13:59:45,161 - INFO - train 모드를 시작합니다.
2026-01-14 13:59:45,161 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:59:45,162 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:59:45,162 - INFO - --------------------------------------------------
2026-01-14 13:59:45,163 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:59:51,596 - INFO - [Train] [1/10] | Loss: 3.0948 | Train Acc: 64.58%
2026-01-14 13:59:54,201 - INFO - [Valid] [1/10] | Loss: 1.2014 | Val Acc: 61.95%
2026-01-14 13:59:54,217 - INFO - [Metrics for 'abnormal'] | Precision: 0.9118 | Recall: 0.1975 | F1: 0.3246
2026-01-14 13:59:54,218 - INFO - [Metrics for 'normal'] | Precision: 0.5869 | Recall: 0.9835 | F1: 0.7351
2026-01-14 13:59:54,256 - INFO - [Best Model Saved] (val loss: 1.2014) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 13:59:54,256 - INFO - --------------------------------------------------
2026-01-14 13:59:54,258 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:59:59,894 - INFO - [Train] [2/10] | Loss: 0.7260 | Train Acc: 71.21%
2026-01-14 14:00:01,623 - INFO - [Valid] [2/10] | Loss: 0.9875 | Val Acc: 67.55%
2026-01-14 14:00:01,637 - INFO - [Metrics for 'abnormal'] | Precision: 0.6911 | Recall: 0.5414 | F1: 0.6071
2026-01-14 14:00:01,638 - INFO - [Metrics for 'normal'] | Precision: 0.6667 | Recall: 0.7912 | F1: 0.7236
2026-01-14 14:00:01,698 - INFO - [Best Model Saved] (val loss: 0.9875) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:00:01,699 - INFO - --------------------------------------------------
2026-01-14 14:00:01,702 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 14:00:07,298 - INFO - [Train] [3/10] | Loss: 0.6979 | Train Acc: 69.49%
2026-01-14 14:00:09,604 - INFO - [Valid] [3/10] | Loss: 0.8612 | Val Acc: 69.03%
2026-01-14 14:00:09,618 - INFO - [Metrics for 'abnormal'] | Precision: 0.7549 | Recall: 0.4904 | F1: 0.5946
2026-01-14 14:00:09,618 - INFO - [Metrics for 'normal'] | Precision: 0.6624 | Recall: 0.8626 | F1: 0.7494
2026-01-14 14:00:09,676 - INFO - [Best Model Saved] (val loss: 0.8612) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:00:09,677 - INFO - --------------------------------------------------
2026-01-14 14:00:09,679 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 14:00:15,849 - INFO - [Train] [4/10] | Loss: 0.5955 | Train Acc: 75.30%
2026-01-14 14:00:18,497 - INFO - [Valid] [4/10] | Loss: 1.4526 | Val Acc: 50.44%
2026-01-14 14:00:18,510 - INFO - [Metrics for 'abnormal'] | Precision: 0.4791 | Recall: 0.8025 | F1: 0.6000
2026-01-14 14:00:18,511 - INFO - [Metrics for 'normal'] | Precision: 0.5921 | Recall: 0.2473 | F1: 0.3488
2026-01-14 14:00:18,515 - INFO - --------------------------------------------------
2026-01-14 14:00:18,518 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 14:00:26,015 - INFO - [Train] [5/10] | Loss: 0.5979 | Train Acc: 76.64%
2026-01-14 14:00:29,115 - INFO - [Valid] [5/10] | Loss: 0.6600 | Val Acc: 74.93%
2026-01-14 14:00:29,125 - INFO - [Metrics for 'abnormal'] | Precision: 0.7045 | Recall: 0.7898 | F1: 0.7447
2026-01-14 14:00:29,125 - INFO - [Metrics for 'normal'] | Precision: 0.7975 | Recall: 0.7143 | F1: 0.7536
2026-01-14 14:00:29,173 - INFO - [Best Model Saved] (val loss: 0.6600) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:00:29,173 - INFO - --------------------------------------------------
2026-01-14 14:00:29,175 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 14:00:36,966 - INFO - [Train] [6/10] | Loss: 0.5420 | Train Acc: 78.87%
2026-01-14 14:00:41,125 - INFO - [Valid] [6/10] | Loss: 0.6048 | Val Acc: 74.93%
2026-01-14 14:00:41,152 - INFO - [Metrics for 'abnormal'] | Precision: 0.6782 | Recall: 0.8726 | F1: 0.7632
2026-01-14 14:00:41,152 - INFO - [Metrics for 'normal'] | Precision: 0.8540 | Recall: 0.6429 | F1: 0.7335
2026-01-14 14:00:41,253 - INFO - [Best Model Saved] (val loss: 0.6048) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:00:41,253 - INFO - --------------------------------------------------
2026-01-14 14:00:41,255 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 14:00:48,419 - INFO - [Train] [7/10] | Loss: 0.5320 | Train Acc: 79.17%
2026-01-14 14:00:51,815 - INFO - [Valid] [7/10] | Loss: 0.5658 | Val Acc: 75.81%
2026-01-14 14:00:51,824 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.6688 | F1: 0.7192
2026-01-14 14:00:51,825 - INFO - [Metrics for 'normal'] | Precision: 0.7451 | Recall: 0.8352 | F1: 0.7876
2026-01-14 14:00:51,881 - INFO - [Best Model Saved] (val loss: 0.5658) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:00:51,881 - INFO - --------------------------------------------------
2026-01-14 14:00:51,883 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 14:00:59,648 - INFO - [Train] [8/10] | Loss: 0.4855 | Train Acc: 82.44%
2026-01-14 14:01:01,840 - INFO - [Valid] [8/10] | Loss: 0.5841 | Val Acc: 76.40%
2026-01-14 14:01:01,852 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.7006 | F1: 0.7333
2026-01-14 14:01:01,852 - INFO - [Metrics for 'normal'] | Precision: 0.7602 | Recall: 0.8187 | F1: 0.7884
2026-01-14 14:01:01,856 - INFO - --------------------------------------------------
2026-01-14 14:01:01,859 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 14:01:11,281 - INFO - [Train] [9/10] | Loss: 0.4596 | Train Acc: 83.78%
2026-01-14 14:01:13,997 - INFO - [Valid] [9/10] | Loss: 0.5588 | Val Acc: 77.88%
2026-01-14 14:01:14,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.8254 | Recall: 0.6624 | F1: 0.7350
2026-01-14 14:01:14,009 - INFO - [Metrics for 'normal'] | Precision: 0.7512 | Recall: 0.8791 | F1: 0.8101
2026-01-14 14:01:14,086 - INFO - [Best Model Saved] (val loss: 0.5588) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:01:14,087 - INFO - --------------------------------------------------
2026-01-14 14:01:14,089 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 14:01:23,663 - INFO - [Train] [10/10] | Loss: 0.4536 | Train Acc: 82.89%
2026-01-14 14:01:26,416 - INFO - [Valid] [10/10] | Loss: 0.5230 | Val Acc: 79.06%
2026-01-14 14:01:26,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.7529 | Recall: 0.8153 | F1: 0.7829
2026-01-14 14:01:26,430 - INFO - [Metrics for 'normal'] | Precision: 0.8284 | Recall: 0.7692 | F1: 0.7977
2026-01-14 14:01:26,569 - INFO - [Best Model Saved] (val loss: 0.5230) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:01:26,570 - INFO - ================================================================================
2026-01-14 14:01:26,570 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 14:01:26,570 - INFO - ================================================================================
2026-01-14 14:01:26,752 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'을(를) 불러왔습니다.
2026-01-14 14:01:26,753 - INFO - ================================================================================
2026-01-14 14:01:26,753 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 14:01:26,755 - INFO - 원본 모델 파라미터: 2.4956M
2026-01-14 14:01:26,838 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:26,839 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:26,842 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:35,490 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:36,358 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 14:01:36,359 - INFO - ==================================================
2026-01-14 14:01:36,362 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 0.6554M (감소율: 73.74%)
2026-01-14 14:01:36,555 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:36,556 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:36,559 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:46,421 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:46,644 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 14:01:46,646 - INFO - ==================================================
2026-01-14 14:01:46,650 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.1807M (감소율: 92.76%)
2026-01-14 14:01:46,704 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:46,704 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:46,707 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:54,701 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:54,855 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 14:01:54,856 - INFO - ==================================================
2026-01-14 14:01:54,859 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0548M (감소율: 97.80%)
2026-01-14 14:01:54,914 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:54,915 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:54,919 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:05,307 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:05,490 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 14:02:05,491 - INFO - ==================================================
2026-01-14 14:02:05,493 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0186M (감소율: 99.25%)
2026-01-14 14:02:05,543 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:05,543 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:05,547 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:14,891 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:15,122 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 14:02:15,123 - INFO - ==================================================
2026-01-14 14:02:15,126 - INFO -   [탐색  5] 희소도: 0.8972 -> 파라미터: 0.0343M (감소율: 98.63%)
2026-01-14 14:02:15,185 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:15,186 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:15,190 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:24,853 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:25,445 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 14:02:25,445 - INFO - ==================================================
2026-01-14 14:02:25,451 - INFO -   [탐색  6] 희소도: 0.9127 -> 파라미터: 0.0259M (감소율: 98.96%)
2026-01-14 14:02:25,567 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:25,567 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:25,576 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:33,700 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:34,472 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.904921875)에 맞춰 변경되었습니다.
2026-01-14 14:02:34,473 - INFO - ==================================================
2026-01-14 14:02:34,477 - INFO -   [탐색  7] 희소도: 0.9049 -> 파라미터: 0.0304M (감소율: 98.78%)
2026-01-14 14:02:34,558 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:34,559 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:34,678 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:44,458 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:44,646 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9010546875000001)에 맞춰 변경되었습니다.
2026-01-14 14:02:44,646 - INFO - ==================================================
2026-01-14 14:02:44,648 - INFO -   [탐색  8] 희소도: 0.9011 -> 파라미터: 0.0317M (감소율: 98.73%)
2026-01-14 14:02:44,687 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:44,688 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:44,690 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:54,901 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:55,088 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9029882812500001)에 맞춰 변경되었습니다.
2026-01-14 14:02:55,089 - INFO - ==================================================
2026-01-14 14:02:55,092 - INFO -   [탐색  9] 희소도: 0.9030 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:02:55,143 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:55,144 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:55,148 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:04,786 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:05,100 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9020214843750001)에 맞춰 변경되었습니다.
2026-01-14 14:03:05,100 - INFO - ==================================================
2026-01-14 14:03:05,105 - INFO -   [탐색 10] 희소도: 0.9020 -> 파라미터: 0.0316M (감소율: 98.73%)
2026-01-14 14:03:05,154 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:05,155 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:05,159 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:15,695 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:15,878 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 14:03:15,879 - INFO - ==================================================
2026-01-14 14:03:15,882 - INFO -   [탐색 11] 희소도: 0.9025 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:03:15,936 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:15,937 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:15,941 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:25,171 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:25,376 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90226318359375)에 맞춰 변경되었습니다.
2026-01-14 14:03:25,378 - INFO - ==================================================
2026-01-14 14:03:25,381 - INFO -   [탐색 12] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:03:25,428 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:25,429 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:25,432 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:35,579 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:35,870 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902384033203125)에 맞춰 변경되었습니다.
2026-01-14 14:03:35,871 - INFO - ==================================================
2026-01-14 14:03:35,873 - INFO -   [탐색 13] 희소도: 0.9024 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:03:35,973 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:35,974 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:35,977 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:45,057 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:45,424 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023236083984375)에 맞춰 변경되었습니다.
2026-01-14 14:03:45,425 - INFO - ==================================================
2026-01-14 14:03:45,500 - INFO -   [탐색 14] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:03:45,611 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:45,611 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:45,614 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:54,536 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:54,696 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023538208007813)에 맞춰 변경되었습니다.
2026-01-14 14:03:54,698 - INFO - ==================================================
2026-01-14 14:03:54,700 - INFO -   [탐색 15] 희소도: 0.9024 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:03:54,878 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:54,879 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:54,883 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:02,823 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:03,070 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023387145996093)에 맞춰 변경되었습니다.
2026-01-14 14:04:03,071 - INFO - ==================================================
2026-01-14 14:04:03,073 - INFO -   [탐색 16] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:04:03,180 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:03,180 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:03,192 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:12,601 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:12,768 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023462677001953)에 맞춰 변경되었습니다.
2026-01-14 14:04:12,769 - INFO - ==================================================
2026-01-14 14:04:12,771 - INFO -   [탐색 17] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:04:12,815 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:12,816 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:12,819 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:22,447 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:22,626 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023424911499023)에 맞춰 변경되었습니다.
2026-01-14 14:04:22,626 - INFO - ==================================================
2026-01-14 14:04:22,628 - INFO -   [탐색 18] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:04:22,698 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:22,698 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:22,703 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:31,957 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:32,413 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023443794250487)에 맞춰 변경되었습니다.
2026-01-14 14:04:32,414 - INFO - ==================================================
2026-01-14 14:04:32,417 - INFO -   [탐색 19] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:04:32,464 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:32,464 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:32,467 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:40,912 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:41,127 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023434352874755)에 맞춰 변경되었습니다.
2026-01-14 14:04:41,127 - INFO - ==================================================
2026-01-14 14:04:41,130 - INFO -   [탐색 20] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:04:41,242 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:41,242 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:41,244 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:51,965 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:52,175 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023439073562621)에 맞춰 변경되었습니다.
2026-01-14 14:04:52,176 - INFO - ==================================================
2026-01-14 14:04:52,178 - INFO -   [탐색 21] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:04:52,218 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:52,218 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:52,222 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:02,485 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:02,677 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023436713218689)에 맞춰 변경되었습니다.
2026-01-14 14:05:02,677 - INFO - ==================================================
2026-01-14 14:05:02,679 - INFO -   [탐색 22] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:05:02,727 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:02,727 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:02,731 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:12,778 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:12,913 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437893390656)에 맞춰 변경되었습니다.
2026-01-14 14:05:12,914 - INFO - ==================================================
2026-01-14 14:05:12,916 - INFO -   [탐색 23] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:05:12,955 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:12,955 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:12,957 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:22,942 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:23,126 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437303304672)에 맞춰 변경되었습니다.
2026-01-14 14:05:23,126 - INFO - ==================================================
2026-01-14 14:05:23,128 - INFO -   [탐색 24] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:05:23,160 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:23,161 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:23,163 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:32,795 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:32,975 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437598347663)에 맞춰 변경되었습니다.
2026-01-14 14:05:32,975 - INFO - ==================================================
2026-01-14 14:05:32,978 - INFO -   [탐색 25] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:05:33,037 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:33,038 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:33,041 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:42,008 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:42,126 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437450826168)에 맞춰 변경되었습니다.
2026-01-14 14:05:42,126 - INFO - ==================================================
2026-01-14 14:05:42,128 - INFO -   [탐색 26] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:05:42,171 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:42,172 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:42,175 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:51,528 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:51,665 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437524586916)에 맞춰 변경되었습니다.
2026-01-14 14:05:51,666 - INFO - ==================================================
2026-01-14 14:05:51,668 - INFO -   [탐색 27] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:05:51,715 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:51,715 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:51,719 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:00,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:00,817 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437487706543)에 맞춰 변경되었습니다.
2026-01-14 14:06:00,818 - INFO - ==================================================
2026-01-14 14:06:00,829 - INFO -   [탐색 28] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:06:00,929 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:00,929 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:00,933 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:09,511 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:09,756 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343750614673)에 맞춰 변경되었습니다.
2026-01-14 14:06:09,756 - INFO - ==================================================
2026-01-14 14:06:09,758 - INFO -   [탐색 29] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:06:09,801 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:09,801 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:09,804 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:18,187 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:18,386 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437496926636)에 맞춰 변경되었습니다.
2026-01-14 14:06:18,387 - INFO - ==================================================
2026-01-14 14:06:18,390 - INFO -   [탐색 30] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:06:18,455 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:18,456 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:18,460 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:27,561 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:28,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437501536683)에 맞춰 변경되었습니다.
2026-01-14 14:06:28,060 - INFO - ==================================================
2026-01-14 14:06:28,064 - INFO -   [탐색 31] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:06:28,113 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:28,114 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:28,118 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:38,155 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:38,284 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499231659)에 맞춰 변경되었습니다.
2026-01-14 14:06:38,285 - INFO - ==================================================
2026-01-14 14:06:38,288 - INFO -   [탐색 32] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:06:38,324 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:38,325 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:38,327 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:47,532 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:47,800 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343750038417)에 맞춰 변경되었습니다.
2026-01-14 14:06:47,801 - INFO - ==================================================
2026-01-14 14:06:47,803 - INFO -   [탐색 33] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:06:47,861 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:47,862 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:47,865 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:56,683 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:57,358 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499807915)에 맞춰 변경되었습니다.
2026-01-14 14:06:57,360 - INFO - ==================================================
2026-01-14 14:06:57,363 - INFO -   [탐색 34] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:06:57,425 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:57,425 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:57,430 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:05,673 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:06,026 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500096043)에 맞춰 변경되었습니다.
2026-01-14 14:07:06,027 - INFO - ==================================================
2026-01-14 14:07:06,030 - INFO -   [탐색 35] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:07:06,074 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:06,074 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:06,078 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:15,128 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:15,318 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499951978)에 맞춰 변경되었습니다.
2026-01-14 14:07:15,364 - INFO - ==================================================
2026-01-14 14:07:15,411 - INFO -   [탐색 36] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:07:15,622 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:15,623 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:15,625 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:23,887 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:24,043 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500024011)에 맞춰 변경되었습니다.
2026-01-14 14:07:24,044 - INFO - ==================================================
2026-01-14 14:07:24,047 - INFO -   [탐색 37] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:07:24,095 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:24,095 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:24,100 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:33,421 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:33,536 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499987994)에 맞춰 변경되었습니다.
2026-01-14 14:07:33,537 - INFO - ==================================================
2026-01-14 14:07:33,539 - INFO -   [탐색 38] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:07:33,587 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:33,588 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:33,590 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:42,719 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:42,969 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500006002)에 맞춰 변경되었습니다.
2026-01-14 14:07:42,972 - INFO - ==================================================
2026-01-14 14:07:42,975 - INFO -   [탐색 39] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:07:43,178 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:43,179 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:43,183 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:52,190 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:52,512 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499996998)에 맞춰 변경되었습니다.
2026-01-14 14:07:52,513 - INFO - ==================================================
2026-01-14 14:07:52,516 - INFO -   [탐색 40] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:07:52,605 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:52,605 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:52,611 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:01,744 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:01,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375000015)에 맞춰 변경되었습니다.
2026-01-14 14:08:01,862 - INFO - ==================================================
2026-01-14 14:08:01,864 - INFO -   [탐색 41] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:08:02,444 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:02,446 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:02,449 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:10,879 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:11,371 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.902343749999925)에 맞춰 변경되었습니다.
2026-01-14 14:08:11,372 - INFO - ==================================================
2026-01-14 14:08:11,376 - INFO -   [탐색 42] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:08:11,428 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:11,429 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:11,433 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:20,551 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:20,790 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000375)에 맞춰 변경되었습니다.
2026-01-14 14:08:20,791 - INFO - ==================================================
2026-01-14 14:08:20,794 - INFO -   [탐색 43] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:08:20,961 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:20,961 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:20,964 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:30,164 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:30,362 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999812)에 맞춰 변경되었습니다.
2026-01-14 14:08:30,363 - INFO - ==================================================
2026-01-14 14:08:30,366 - INFO -   [탐색 44] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:08:30,422 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:30,423 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:30,426 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:39,636 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:39,787 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000093)에 맞춰 변경되었습니다.
2026-01-14 14:08:39,788 - INFO - ==================================================
2026-01-14 14:08:39,790 - INFO -   [탐색 45] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:08:39,848 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:39,849 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:39,852 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:49,591 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:50,021 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999953)에 맞춰 변경되었습니다.
2026-01-14 14:08:50,021 - INFO - ==================================================
2026-01-14 14:08:50,027 - INFO -   [탐색 46] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:08:50,070 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:50,070 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:50,073 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:59,222 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:59,410 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000023)에 맞춰 변경되었습니다.
2026-01-14 14:08:59,410 - INFO - ==================================================
2026-01-14 14:08:59,413 - INFO -   [탐색 47] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:08:59,480 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:59,481 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:59,488 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:08,765 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:08,915 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999989)에 맞춰 변경되었습니다.
2026-01-14 14:09:08,916 - INFO - ==================================================
2026-01-14 14:09:08,920 - INFO -   [탐색 48] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:09:08,980 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:08,981 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:08,985 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:17,850 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:18,094 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000007)에 맞춰 변경되었습니다.
2026-01-14 14:09:18,094 - INFO - ==================================================
2026-01-14 14:09:18,097 - INFO -   [탐색 49] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:09:18,153 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:18,153 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:18,157 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:27,589 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:27,735 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437499999998)에 맞춰 변경되었습니다.
2026-01-14 14:09:27,736 - INFO - ==================================================
2026-01-14 14:09:27,739 - INFO -   [탐색 50] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:09:27,784 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:27,785 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:27,789 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:35,175 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:35,335 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000002)에 맞춰 변경되었습니다.
2026-01-14 14:09:35,336 - INFO - ==================================================
2026-01-14 14:09:35,339 - INFO -   [탐색 51] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:09:35,386 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:35,387 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:35,390 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:43,682 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:43,811 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:09:43,811 - INFO - ==================================================
2026-01-14 14:09:43,814 - INFO -   [탐색 52] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:09:43,867 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:43,868 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:43,871 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:53,965 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:54,477 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9023437500000001)에 맞춰 변경되었습니다.
2026-01-14 14:09:54,478 - INFO - ==================================================
2026-01-14 14:09:54,482 - INFO -   [탐색 53] 희소도: 0.9023 -> 파라미터: 0.0312M (감소율: 98.75%)
2026-01-14 14:09:54,586 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:54,587 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:54,591 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:04,409 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:04,741 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:04,741 - INFO - ==================================================
2026-01-14 14:10:04,743 - INFO -   [탐색 54] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:04,795 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:04,796 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:04,800 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:14,199 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:14,291 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:14,291 - INFO - ==================================================
2026-01-14 14:10:14,293 - INFO -   [탐색 55] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:14,421 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:14,421 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:14,426 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:23,989 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:24,137 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:24,137 - INFO - ==================================================
2026-01-14 14:10:24,139 - INFO -   [탐색 56] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:24,169 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:24,169 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:24,171 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:33,012 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:33,202 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:33,202 - INFO - ==================================================
2026-01-14 14:10:33,205 - INFO -   [탐색 57] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:33,266 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:33,266 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:33,270 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:41,864 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:42,106 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:42,107 - INFO - ==================================================
2026-01-14 14:10:42,111 - INFO -   [탐색 58] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:42,171 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:42,172 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:42,177 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:50,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:50,733 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:50,733 - INFO - ==================================================
2026-01-14 14:10:50,736 - INFO -   [탐색 59] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:50,807 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:50,829 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:50,832 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:58,247 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:58,454 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:10:58,457 - INFO - ==================================================
2026-01-14 14:10:58,459 - INFO -   [탐색 60] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:10:58,510 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:58,511 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:58,516 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:05,979 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:06,265 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:11:06,266 - INFO - ==================================================
2026-01-14 14:11:06,269 - INFO -   [탐색 61] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:11:06,337 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:06,337 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:06,342 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:15,962 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:16,127 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:11:16,127 - INFO - ==================================================
2026-01-14 14:11:16,129 - INFO -   [탐색 62] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:11:16,167 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:16,168 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:16,171 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:25,010 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:25,194 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:11:25,195 - INFO - ==================================================
2026-01-14 14:11:25,198 - INFO -   [탐색 63] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:11:25,247 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:25,248 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:25,252 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:34,256 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:34,386 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:11:34,387 - INFO - ==================================================
2026-01-14 14:11:34,389 - INFO -   [탐색 64] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:11:34,426 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:34,426 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:34,429 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:43,773 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:44,386 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:11:44,386 - INFO - ==================================================
2026-01-14 14:11:44,395 - INFO -   [탐색 65] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:11:44,493 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:44,494 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:44,498 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:53,908 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:54,096 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:11:54,097 - INFO - ==================================================
2026-01-14 14:11:54,100 - INFO -   [탐색 66] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:11:54,152 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:54,153 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:54,157 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:03,609 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:03,762 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:12:03,763 - INFO - ==================================================
2026-01-14 14:12:03,766 - INFO -   [탐색 67] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:12:03,829 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:03,829 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:03,834 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:13,598 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:13,845 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:12:13,846 - INFO - ==================================================
2026-01-14 14:12:13,849 - INFO -   [탐색 68] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:12:13,902 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:13,903 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:13,906 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:23,509 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:24,132 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:12:24,133 - INFO - ==================================================
2026-01-14 14:12:24,137 - INFO -   [탐색 69] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:12:24,206 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:24,206 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:24,209 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:32,881 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:32,997 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:12:32,998 - INFO - ==================================================
2026-01-14 14:12:33,000 - INFO -   [탐색 70] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:12:33,042 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:33,042 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:33,045 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:41,772 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:42,117 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:12:42,118 - INFO - ==================================================
2026-01-14 14:12:42,121 - INFO -   [탐색 71] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:12:42,186 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:42,186 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:42,189 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:51,168 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:51,290 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:12:51,290 - INFO - ==================================================
2026-01-14 14:12:51,293 - INFO -   [탐색 72] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:12:51,334 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:51,335 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:51,338 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:00,794 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:01,320 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:01,330 - INFO - ==================================================
2026-01-14 14:13:01,341 - INFO -   [탐색 73] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:01,538 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:01,544 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:01,553 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:10,751 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:10,923 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:10,923 - INFO - ==================================================
2026-01-14 14:13:10,926 - INFO -   [탐색 74] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:10,992 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:11,000 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:11,004 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:19,323 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:20,367 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:20,368 - INFO - ==================================================
2026-01-14 14:13:20,372 - INFO -   [탐색 75] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:20,690 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:20,691 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:20,697 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:29,084 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:29,219 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:29,220 - INFO - ==================================================
2026-01-14 14:13:29,222 - INFO -   [탐색 76] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:29,275 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:29,276 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:29,280 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:38,682 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:38,897 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:38,899 - INFO - ==================================================
2026-01-14 14:13:38,903 - INFO -   [탐색 77] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:38,964 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:38,964 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:38,967 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:47,841 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:47,989 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:47,989 - INFO - ==================================================
2026-01-14 14:13:47,992 - INFO -   [탐색 78] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:48,053 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:48,054 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:48,057 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:56,859 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:57,163 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:13:57,164 - INFO - ==================================================
2026-01-14 14:13:57,166 - INFO -   [탐색 79] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:13:57,208 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:57,208 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:57,211 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:06,944 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:07,197 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:14:07,198 - INFO - ==================================================
2026-01-14 14:14:07,201 - INFO -   [탐색 80] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:14:07,255 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:07,255 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:07,260 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:15,360 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:15,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:14:15,568 - INFO - ==================================================
2026-01-14 14:14:15,571 - INFO -   [탐색 81] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:14:15,624 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:15,625 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:15,628 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:23,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:23,530 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:14:23,531 - INFO - ==================================================
2026-01-14 14:14:23,533 - INFO -   [탐색 82] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:14:23,638 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:23,639 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:23,735 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:32,776 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:32,983 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:14:32,984 - INFO - ==================================================
2026-01-14 14:14:32,987 - INFO -   [탐색 83] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:14:33,034 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:33,035 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:33,038 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:41,352 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:41,644 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:14:41,644 - INFO - ==================================================
2026-01-14 14:14:41,647 - INFO -   [탐색 84] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:14:41,774 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:41,775 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:41,781 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:50,549 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:50,721 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:14:50,722 - INFO - ==================================================
2026-01-14 14:14:50,725 - INFO -   [탐색 85] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:14:50,783 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:50,784 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:50,788 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:01,158 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:01,645 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:01,645 - INFO - ==================================================
2026-01-14 14:15:01,649 - INFO -   [탐색 86] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:01,701 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:01,702 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:01,706 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:11,704 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:11,814 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:11,815 - INFO - ==================================================
2026-01-14 14:15:11,817 - INFO -   [탐색 87] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:11,855 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:11,855 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:11,858 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:21,653 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:21,823 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:21,824 - INFO - ==================================================
2026-01-14 14:15:21,826 - INFO -   [탐색 88] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:21,884 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:21,884 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:21,888 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:31,456 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:31,622 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:31,622 - INFO - ==================================================
2026-01-14 14:15:31,625 - INFO -   [탐색 89] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:31,665 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:31,666 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:31,669 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:39,918 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:40,243 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:40,243 - INFO - ==================================================
2026-01-14 14:15:40,249 - INFO -   [탐색 90] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:40,358 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:40,358 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:40,367 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:48,580 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:48,769 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:48,769 - INFO - ==================================================
2026-01-14 14:15:48,772 - INFO -   [탐색 91] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:48,831 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:48,832 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:48,836 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:57,412 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:57,566 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:15:57,566 - INFO - ==================================================
2026-01-14 14:15:57,569 - INFO -   [탐색 92] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:15:57,628 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:57,629 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:57,632 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:06,102 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:06,316 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:16:06,317 - INFO - ==================================================
2026-01-14 14:16:06,319 - INFO -   [탐색 93] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:16:06,368 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:06,370 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:06,374 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:15,120 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:15,279 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:16:15,280 - INFO - ==================================================
2026-01-14 14:16:15,283 - INFO -   [탐색 94] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:16:15,342 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:15,344 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:15,348 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:24,205 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:24,402 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:16:24,403 - INFO - ==================================================
2026-01-14 14:16:24,406 - INFO -   [탐색 95] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:16:24,478 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:24,479 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:24,482 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:34,190 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:34,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:16:34,355 - INFO - ==================================================
2026-01-14 14:16:34,357 - INFO -   [탐색 96] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:16:34,409 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:34,410 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:34,414 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:43,688 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:44,137 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:16:44,138 - INFO - ==================================================
2026-01-14 14:16:44,141 - INFO -   [탐색 97] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:16:44,201 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:44,202 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:44,207 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:52,148 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:52,799 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:16:52,800 - INFO - ==================================================
2026-01-14 14:16:52,804 - INFO -   [탐색 98] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:16:52,924 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:52,925 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:52,928 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:01,203 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:01,466 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:17:01,467 - INFO - ==================================================
2026-01-14 14:17:01,469 - INFO -   [탐색 99] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:17:01,563 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:01,563 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:01,568 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:09,738 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:09,866 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.90234375)에 맞춰 변경되었습니다.
2026-01-14 14:17:09,867 - INFO - ==================================================
2026-01-14 14:17:09,869 - INFO -   [탐색 100] 희소도: 0.9023 -> 파라미터: 0.0315M (감소율: 98.74%)
2026-01-14 14:17:09,870 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9025 입니다.
2026-01-14 14:17:09,870 - INFO - ================================================================================
2026-01-14 14:17:09,875 - INFO - 계산된 Pruning 정보(희소도: 0.9025)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/pruning_info.yaml'에 저장했습니다.
2026-01-14 14:17:09,935 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 14:17:10,139 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:10,140 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:10,143 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:17,545 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:17,828 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 14:17:17,829 - INFO - ==================================================
2026-01-14 14:17:17,831 - INFO - ==================================================
2026-01-14 14:17:17,832 - INFO - 모델 파라미터 수:
2026-01-14 14:17:17,832 - INFO -   - 총 파라미터: 31,233 개
2026-01-14 14:17:17,832 - INFO -   - 학습 가능한 파라미터: 31,233 개
2026-01-14 14:17:17,930 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 14:17:18,047 - INFO - FLOPs가 0.3853 GFLOPs에서 0.0077 GFLOPs로 감소했습니다 (감소율: 97.99%).
2026-01-14 14:17:18,047 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 14:17:18,047 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:17:18,049 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 14:17:18,049 - INFO - ==================================================
2026-01-14 14:17:18,049 - INFO - train 모드를 시작합니다.
2026-01-14 14:17:18,050 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:17:18,050 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:17:18,050 - INFO - --------------------------------------------------
2026-01-14 14:17:18,052 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 14:17:26,605 - INFO - [Train] [11/90] | Loss: 0.7453 | Train Acc: 63.62%
2026-01-14 14:17:29,952 - INFO - [Valid] [11/90] | Loss: 0.6090 | Val Acc: 69.32%
2026-01-14 14:17:29,973 - INFO - [Metrics for 'abnormal'] | Precision: 0.6568 | Recall: 0.7070 | F1: 0.6810
2026-01-14 14:17:29,977 - INFO - [Metrics for 'normal'] | Precision: 0.7294 | Recall: 0.6813 | F1: 0.7045
2026-01-14 14:17:30,052 - INFO - [Best Model Saved] (val loss: 0.6090) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:17:30,053 - INFO - --------------------------------------------------
2026-01-14 14:17:30,056 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 14:17:38,725 - INFO - [Train] [12/90] | Loss: 0.6230 | Train Acc: 66.67%
2026-01-14 14:17:42,841 - INFO - [Valid] [12/90] | Loss: 0.6440 | Val Acc: 65.49%
2026-01-14 14:17:42,850 - INFO - [Metrics for 'abnormal'] | Precision: 0.6923 | Recall: 0.4586 | F1: 0.5517
2026-01-14 14:17:42,851 - INFO - [Metrics for 'normal'] | Precision: 0.6383 | Recall: 0.8242 | F1: 0.7194
2026-01-14 14:17:42,854 - INFO - --------------------------------------------------
2026-01-14 14:17:42,857 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 14:17:51,141 - INFO - [Train] [13/90] | Loss: 0.6176 | Train Acc: 67.49%
2026-01-14 14:17:54,224 - INFO - [Valid] [13/90] | Loss: 0.6751 | Val Acc: 59.59%
2026-01-14 14:17:54,247 - INFO - [Metrics for 'abnormal'] | Precision: 0.5403 | Recall: 0.8535 | F1: 0.6617
2026-01-14 14:17:54,249 - INFO - [Metrics for 'normal'] | Precision: 0.7473 | Recall: 0.3736 | F1: 0.4982
2026-01-14 14:17:54,254 - INFO - --------------------------------------------------
2026-01-14 14:17:54,257 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 14:18:03,024 - INFO - [Train] [14/90] | Loss: 0.5989 | Train Acc: 69.35%
2026-01-14 14:18:05,585 - INFO - [Valid] [14/90] | Loss: 0.6212 | Val Acc: 69.62%
2026-01-14 14:18:05,596 - INFO - [Metrics for 'abnormal'] | Precision: 0.6901 | Recall: 0.6242 | F1: 0.6555
2026-01-14 14:18:05,596 - INFO - [Metrics for 'normal'] | Precision: 0.7005 | Recall: 0.7582 | F1: 0.7282
2026-01-14 14:18:05,600 - INFO - --------------------------------------------------
2026-01-14 14:18:05,603 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 14:18:13,592 - INFO - [Train] [15/90] | Loss: 0.5972 | Train Acc: 70.68%
2026-01-14 14:18:15,805 - INFO - [Valid] [15/90] | Loss: 0.6317 | Val Acc: 70.21%
2026-01-14 14:18:15,818 - INFO - [Metrics for 'abnormal'] | Precision: 0.6591 | Recall: 0.7389 | F1: 0.6967
2026-01-14 14:18:15,819 - INFO - [Metrics for 'normal'] | Precision: 0.7485 | Recall: 0.6703 | F1: 0.7072
2026-01-14 14:18:15,824 - INFO - --------------------------------------------------
2026-01-14 14:18:15,827 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 14:18:25,101 - INFO - [Train] [16/90] | Loss: 0.6091 | Train Acc: 70.46%
2026-01-14 14:18:27,456 - INFO - [Valid] [16/90] | Loss: 0.5794 | Val Acc: 70.80%
2026-01-14 14:18:27,466 - INFO - [Metrics for 'abnormal'] | Precision: 0.7042 | Recall: 0.6369 | F1: 0.6689
2026-01-14 14:18:27,466 - INFO - [Metrics for 'normal'] | Precision: 0.7107 | Recall: 0.7692 | F1: 0.7388
2026-01-14 14:18:27,505 - INFO - [Best Model Saved] (val loss: 0.5794) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:18:27,505 - INFO - --------------------------------------------------
2026-01-14 14:18:27,507 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 14:18:36,798 - INFO - [Train] [17/90] | Loss: 0.5784 | Train Acc: 74.11%
2026-01-14 14:18:38,610 - INFO - [Valid] [17/90] | Loss: 0.5933 | Val Acc: 68.14%
2026-01-14 14:18:38,620 - INFO - [Metrics for 'abnormal'] | Precision: 0.6184 | Recall: 0.8153 | F1: 0.7033
2026-01-14 14:18:38,620 - INFO - [Metrics for 'normal'] | Precision: 0.7803 | Recall: 0.5659 | F1: 0.6561
2026-01-14 14:18:38,624 - INFO - --------------------------------------------------
2026-01-14 14:18:38,626 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 14:18:47,924 - INFO - [Train] [18/90] | Loss: 0.5657 | Train Acc: 72.47%
2026-01-14 14:18:49,637 - INFO - [Valid] [18/90] | Loss: 0.5750 | Val Acc: 71.98%
2026-01-14 14:18:49,657 - INFO - [Metrics for 'abnormal'] | Precision: 0.7039 | Recall: 0.6815 | F1: 0.6926
2026-01-14 14:18:49,658 - INFO - [Metrics for 'normal'] | Precision: 0.7326 | Recall: 0.7527 | F1: 0.7425
2026-01-14 14:18:49,705 - INFO - [Best Model Saved] (val loss: 0.5750) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:18:49,705 - INFO - --------------------------------------------------
2026-01-14 14:18:49,707 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 14:18:59,360 - INFO - [Train] [19/90] | Loss: 0.5593 | Train Acc: 73.44%
2026-01-14 14:19:01,738 - INFO - [Valid] [19/90] | Loss: 0.5755 | Val Acc: 75.52%
2026-01-14 14:19:01,765 - INFO - [Metrics for 'abnormal'] | Precision: 0.7284 | Recall: 0.7516 | F1: 0.7398
2026-01-14 14:19:01,765 - INFO - [Metrics for 'normal'] | Precision: 0.7797 | Recall: 0.7582 | F1: 0.7688
2026-01-14 14:19:01,770 - INFO - --------------------------------------------------
2026-01-14 14:19:01,856 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 14:19:11,288 - INFO - [Train] [20/90] | Loss: 0.5453 | Train Acc: 75.00%
2026-01-14 14:19:14,552 - INFO - [Valid] [20/90] | Loss: 0.5900 | Val Acc: 71.98%
2026-01-14 14:19:14,658 - INFO - [Metrics for 'abnormal'] | Precision: 0.7313 | Recall: 0.6242 | F1: 0.6735
2026-01-14 14:19:14,681 - INFO - [Metrics for 'normal'] | Precision: 0.7122 | Recall: 0.8022 | F1: 0.7545
2026-01-14 14:19:14,685 - INFO - --------------------------------------------------
2026-01-14 14:19:14,688 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 14:19:23,272 - INFO - [Train] [21/90] | Loss: 0.5365 | Train Acc: 77.98%
2026-01-14 14:19:25,578 - INFO - [Valid] [21/90] | Loss: 0.5557 | Val Acc: 76.40%
2026-01-14 14:19:25,591 - INFO - [Metrics for 'abnormal'] | Precision: 0.7081 | Recall: 0.8344 | F1: 0.7661
2026-01-14 14:19:25,591 - INFO - [Metrics for 'normal'] | Precision: 0.8312 | Recall: 0.7033 | F1: 0.7619
2026-01-14 14:19:25,635 - INFO - [Best Model Saved] (val loss: 0.5557) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:19:25,636 - INFO - --------------------------------------------------
2026-01-14 14:19:25,638 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 14:19:34,610 - INFO - [Train] [22/90] | Loss: 0.5441 | Train Acc: 77.75%
2026-01-14 14:19:37,046 - INFO - [Valid] [22/90] | Loss: 0.5761 | Val Acc: 76.40%
2026-01-14 14:19:37,058 - INFO - [Metrics for 'abnormal'] | Precision: 0.7225 | Recall: 0.7962 | F1: 0.7576
2026-01-14 14:19:37,058 - INFO - [Metrics for 'normal'] | Precision: 0.8072 | Recall: 0.7363 | F1: 0.7701
2026-01-14 14:19:37,063 - INFO - --------------------------------------------------
2026-01-14 14:19:37,066 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 14:19:46,446 - INFO - [Train] [23/90] | Loss: 0.5211 | Train Acc: 77.98%
2026-01-14 14:19:49,694 - INFO - [Valid] [23/90] | Loss: 0.5693 | Val Acc: 74.34%
2026-01-14 14:19:49,706 - INFO - [Metrics for 'abnormal'] | Precision: 0.7059 | Recall: 0.7643 | F1: 0.7339
2026-01-14 14:19:49,706 - INFO - [Metrics for 'normal'] | Precision: 0.7811 | Recall: 0.7253 | F1: 0.7521
2026-01-14 14:19:49,711 - INFO - --------------------------------------------------
2026-01-14 14:19:49,713 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 14:19:59,070 - INFO - [Train] [24/90] | Loss: 0.5230 | Train Acc: 78.94%
2026-01-14 14:20:01,037 - INFO - [Valid] [24/90] | Loss: 0.5202 | Val Acc: 78.76%
2026-01-14 14:20:01,047 - INFO - [Metrics for 'abnormal'] | Precision: 0.7545 | Recall: 0.8025 | F1: 0.7778
2026-01-14 14:20:01,048 - INFO - [Metrics for 'normal'] | Precision: 0.8198 | Recall: 0.7747 | F1: 0.7966
2026-01-14 14:20:01,081 - INFO - [Best Model Saved] (val loss: 0.5202) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:20:01,082 - INFO - --------------------------------------------------
2026-01-14 14:20:01,083 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 14:20:10,756 - INFO - [Train] [25/90] | Loss: 0.5111 | Train Acc: 78.72%
2026-01-14 14:20:13,109 - INFO - [Valid] [25/90] | Loss: 0.5496 | Val Acc: 79.35%
2026-01-14 14:20:13,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-01-14 14:20:13,147 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-01-14 14:20:13,150 - INFO - --------------------------------------------------
2026-01-14 14:20:13,163 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 14:20:22,635 - INFO - [Train] [26/90] | Loss: 0.5231 | Train Acc: 78.35%
2026-01-14 14:20:25,494 - INFO - [Valid] [26/90] | Loss: 0.5229 | Val Acc: 77.88%
2026-01-14 14:20:25,503 - INFO - [Metrics for 'abnormal'] | Precision: 0.7384 | Recall: 0.8089 | F1: 0.7720
2026-01-14 14:20:25,504 - INFO - [Metrics for 'normal'] | Precision: 0.8204 | Recall: 0.7527 | F1: 0.7851
2026-01-14 14:20:25,508 - INFO - --------------------------------------------------
2026-01-14 14:20:25,512 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 14:20:35,079 - INFO - [Train] [27/90] | Loss: 0.4984 | Train Acc: 79.76%
2026-01-14 14:20:37,772 - INFO - [Valid] [27/90] | Loss: 0.5755 | Val Acc: 79.06%
2026-01-14 14:20:37,784 - INFO - [Metrics for 'abnormal'] | Precision: 0.7722 | Recall: 0.7771 | F1: 0.7746
2026-01-14 14:20:37,785 - INFO - [Metrics for 'normal'] | Precision: 0.8066 | Recall: 0.8022 | F1: 0.8044
2026-01-14 14:20:37,789 - INFO - --------------------------------------------------
2026-01-14 14:20:37,793 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 14:20:47,765 - INFO - [Train] [28/90] | Loss: 0.4994 | Train Acc: 80.58%
2026-01-14 14:20:50,854 - INFO - [Valid] [28/90] | Loss: 0.5434 | Val Acc: 76.11%
2026-01-14 14:20:50,867 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.6624 | F1: 0.7197
2026-01-14 14:20:50,868 - INFO - [Metrics for 'normal'] | Precision: 0.7440 | Recall: 0.8462 | F1: 0.7918
2026-01-14 14:20:50,873 - INFO - --------------------------------------------------
2026-01-14 14:20:50,876 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 14:20:59,255 - INFO - [Train] [29/90] | Loss: 0.4901 | Train Acc: 81.55%
2026-01-14 14:21:01,985 - INFO - [Valid] [29/90] | Loss: 0.5314 | Val Acc: 81.42%
2026-01-14 14:21:01,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.7701 | Recall: 0.8535 | F1: 0.8097
2026-01-14 14:21:01,997 - INFO - [Metrics for 'normal'] | Precision: 0.8606 | Recall: 0.7802 | F1: 0.8184
2026-01-14 14:21:02,001 - INFO - --------------------------------------------------
2026-01-14 14:21:02,004 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 14:21:10,712 - INFO - [Train] [30/90] | Loss: 0.4792 | Train Acc: 82.07%
2026-01-14 14:21:13,930 - INFO - [Valid] [30/90] | Loss: 0.5484 | Val Acc: 78.17%
2026-01-14 14:21:13,945 - INFO - [Metrics for 'abnormal'] | Precision: 0.7823 | Recall: 0.7325 | F1: 0.7566
2026-01-14 14:21:13,945 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.8242 | F1: 0.8021
2026-01-14 14:21:13,955 - INFO - --------------------------------------------------
2026-01-14 14:21:13,960 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 14:21:23,073 - INFO - [Train] [31/90] | Loss: 0.4792 | Train Acc: 80.73%
2026-01-14 14:21:26,330 - INFO - [Valid] [31/90] | Loss: 0.5177 | Val Acc: 80.24%
2026-01-14 14:21:26,356 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-01-14 14:21:26,356 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-01-14 14:21:26,429 - INFO - [Best Model Saved] (val loss: 0.5177) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:21:26,430 - INFO - --------------------------------------------------
2026-01-14 14:21:26,433 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 14:21:34,303 - INFO - [Train] [32/90] | Loss: 0.4742 | Train Acc: 83.11%
2026-01-14 14:21:37,111 - INFO - [Valid] [32/90] | Loss: 0.5461 | Val Acc: 79.35%
2026-01-14 14:21:37,149 - INFO - [Metrics for 'abnormal'] | Precision: 0.7544 | Recall: 0.8217 | F1: 0.7866
2026-01-14 14:21:37,150 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7692 | F1: 0.8000
2026-01-14 14:21:37,155 - INFO - --------------------------------------------------
2026-01-14 14:21:37,158 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 14:21:45,450 - INFO - [Train] [33/90] | Loss: 0.4725 | Train Acc: 83.85%
2026-01-14 14:21:49,513 - INFO - [Valid] [33/90] | Loss: 0.5568 | Val Acc: 80.24%
2026-01-14 14:21:49,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 14:21:49,523 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 14:21:49,527 - INFO - --------------------------------------------------
2026-01-14 14:21:49,529 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 14:21:58,291 - INFO - [Train] [34/90] | Loss: 0.4815 | Train Acc: 82.14%
2026-01-14 14:22:01,537 - INFO - [Valid] [34/90] | Loss: 0.5448 | Val Acc: 80.24%
2026-01-14 14:22:01,547 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 14:22:01,548 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 14:22:01,552 - INFO - --------------------------------------------------
2026-01-14 14:22:01,554 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 14:22:09,597 - INFO - [Train] [35/90] | Loss: 0.4565 | Train Acc: 83.04%
2026-01-14 14:22:12,586 - INFO - [Valid] [35/90] | Loss: 0.5861 | Val Acc: 78.17%
2026-01-14 14:22:12,605 - INFO - [Metrics for 'abnormal'] | Precision: 0.7823 | Recall: 0.7325 | F1: 0.7566
2026-01-14 14:22:12,606 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.8242 | F1: 0.8021
2026-01-14 14:22:12,619 - INFO - --------------------------------------------------
2026-01-14 14:22:12,630 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 14:22:21,051 - INFO - [Train] [36/90] | Loss: 0.5043 | Train Acc: 79.46%
2026-01-14 14:22:24,252 - INFO - [Valid] [36/90] | Loss: 0.5228 | Val Acc: 78.47%
2026-01-14 14:22:24,271 - INFO - [Metrics for 'abnormal'] | Precision: 0.7471 | Recall: 0.8089 | F1: 0.7768
2026-01-14 14:22:24,271 - INFO - [Metrics for 'normal'] | Precision: 0.8225 | Recall: 0.7637 | F1: 0.7920
2026-01-14 14:22:24,278 - INFO - --------------------------------------------------
2026-01-14 14:22:24,282 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 14:22:32,943 - INFO - [Train] [37/90] | Loss: 0.4799 | Train Acc: 82.29%
2026-01-14 14:22:35,757 - INFO - [Valid] [37/90] | Loss: 0.5132 | Val Acc: 78.76%
2026-01-14 14:22:35,771 - INFO - [Metrics for 'abnormal'] | Precision: 0.7891 | Recall: 0.7389 | F1: 0.7632
2026-01-14 14:22:35,774 - INFO - [Metrics for 'normal'] | Precision: 0.7865 | Recall: 0.8297 | F1: 0.8075
2026-01-14 14:22:35,820 - INFO - [Best Model Saved] (val loss: 0.5132) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:22:35,821 - INFO - --------------------------------------------------
2026-01-14 14:22:35,823 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 14:22:44,645 - INFO - [Train] [38/90] | Loss: 0.4641 | Train Acc: 82.81%
2026-01-14 14:22:47,002 - INFO - [Valid] [38/90] | Loss: 0.5309 | Val Acc: 79.35%
2026-01-14 14:22:47,012 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-01-14 14:22:47,012 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-01-14 14:22:47,016 - INFO - --------------------------------------------------
2026-01-14 14:22:47,018 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 14:22:55,588 - INFO - [Train] [39/90] | Loss: 0.4618 | Train Acc: 82.51%
2026-01-14 14:22:58,149 - INFO - [Valid] [39/90] | Loss: 0.5674 | Val Acc: 78.17%
2026-01-14 14:22:58,160 - INFO - [Metrics for 'abnormal'] | Precision: 0.7578 | Recall: 0.7771 | F1: 0.7673
2026-01-14 14:22:58,161 - INFO - [Metrics for 'normal'] | Precision: 0.8034 | Recall: 0.7857 | F1: 0.7944
2026-01-14 14:22:58,165 - INFO - --------------------------------------------------
2026-01-14 14:22:58,168 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 14:23:06,795 - INFO - [Train] [40/90] | Loss: 0.4601 | Train Acc: 83.26%
2026-01-14 14:23:09,160 - INFO - [Valid] [40/90] | Loss: 0.5134 | Val Acc: 80.83%
2026-01-14 14:23:09,174 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 14:23:09,175 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 14:23:09,180 - INFO - --------------------------------------------------
2026-01-14 14:23:09,183 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 14:23:18,767 - INFO - [Train] [41/90] | Loss: 0.4509 | Train Acc: 84.90%
2026-01-14 14:23:21,480 - INFO - [Valid] [41/90] | Loss: 0.5228 | Val Acc: 79.94%
2026-01-14 14:23:21,492 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8471 | F1: 0.7964
2026-01-14 14:23:21,493 - INFO - [Metrics for 'normal'] | Precision: 0.8519 | Recall: 0.7582 | F1: 0.8023
2026-01-14 14:23:21,497 - INFO - --------------------------------------------------
2026-01-14 14:23:21,500 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 14:23:30,720 - INFO - [Train] [42/90] | Loss: 0.4411 | Train Acc: 84.60%
2026-01-14 14:23:32,908 - INFO - [Valid] [42/90] | Loss: 0.5249 | Val Acc: 81.12%
2026-01-14 14:23:32,934 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 14:23:32,937 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 14:23:32,946 - INFO - --------------------------------------------------
2026-01-14 14:23:32,952 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 14:23:41,935 - INFO - [Train] [43/90] | Loss: 0.4372 | Train Acc: 85.19%
2026-01-14 14:23:45,072 - INFO - [Valid] [43/90] | Loss: 0.5274 | Val Acc: 78.17%
2026-01-14 14:23:45,085 - INFO - [Metrics for 'abnormal'] | Precision: 0.7943 | Recall: 0.7134 | F1: 0.7517
2026-01-14 14:23:45,086 - INFO - [Metrics for 'normal'] | Precision: 0.7727 | Recall: 0.8407 | F1: 0.8053
2026-01-14 14:23:45,091 - INFO - --------------------------------------------------
2026-01-14 14:23:45,094 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 14:23:54,008 - INFO - [Train] [44/90] | Loss: 0.4449 | Train Acc: 85.27%
2026-01-14 14:23:57,174 - INFO - [Valid] [44/90] | Loss: 0.5181 | Val Acc: 78.47%
2026-01-14 14:23:57,193 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.7580 | F1: 0.7653
2026-01-14 14:23:57,193 - INFO - [Metrics for 'normal'] | Precision: 0.7946 | Recall: 0.8077 | F1: 0.8011
2026-01-14 14:23:57,197 - INFO - --------------------------------------------------
2026-01-14 14:23:57,199 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 14:24:06,619 - INFO - [Train] [45/90] | Loss: 0.4374 | Train Acc: 84.38%
2026-01-14 14:24:09,023 - INFO - [Valid] [45/90] | Loss: 0.5488 | Val Acc: 78.76%
2026-01-14 14:24:09,037 - INFO - [Metrics for 'abnormal'] | Precision: 0.7972 | Recall: 0.7261 | F1: 0.7600
2026-01-14 14:24:09,037 - INFO - [Metrics for 'normal'] | Precision: 0.7806 | Recall: 0.8407 | F1: 0.8095
2026-01-14 14:24:09,041 - INFO - --------------------------------------------------
2026-01-14 14:24:09,043 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 14:24:17,983 - INFO - [Train] [46/90] | Loss: 0.4325 | Train Acc: 84.60%
2026-01-14 14:24:20,687 - INFO - [Valid] [46/90] | Loss: 0.5715 | Val Acc: 78.76%
2026-01-14 14:24:20,698 - INFO - [Metrics for 'abnormal'] | Precision: 0.7457 | Recall: 0.8217 | F1: 0.7818
2026-01-14 14:24:20,698 - INFO - [Metrics for 'normal'] | Precision: 0.8313 | Recall: 0.7582 | F1: 0.7931
2026-01-14 14:24:20,702 - INFO - --------------------------------------------------
2026-01-14 14:24:20,704 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 14:24:29,644 - INFO - [Train] [47/90] | Loss: 0.4427 | Train Acc: 84.82%
2026-01-14 14:24:32,460 - INFO - [Valid] [47/90] | Loss: 0.5216 | Val Acc: 80.24%
2026-01-14 14:24:32,471 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-01-14 14:24:32,471 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-01-14 14:24:32,476 - INFO - --------------------------------------------------
2026-01-14 14:24:32,478 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 14:24:40,817 - INFO - [Train] [48/90] | Loss: 0.4328 | Train Acc: 85.19%
2026-01-14 14:24:43,874 - INFO - [Valid] [48/90] | Loss: 0.5298 | Val Acc: 80.24%
2026-01-14 14:24:43,885 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-01-14 14:24:43,886 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-01-14 14:24:43,890 - INFO - --------------------------------------------------
2026-01-14 14:24:43,893 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 14:24:52,330 - INFO - [Train] [49/90] | Loss: 0.4151 | Train Acc: 87.35%
2026-01-14 14:24:55,604 - INFO - [Valid] [49/90] | Loss: 0.5412 | Val Acc: 78.76%
2026-01-14 14:24:55,616 - INFO - [Metrics for 'abnormal'] | Precision: 0.7515 | Recall: 0.8089 | F1: 0.7791
2026-01-14 14:24:55,617 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.7692 | F1: 0.7955
2026-01-14 14:24:55,621 - INFO - --------------------------------------------------
2026-01-14 14:24:55,625 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 14:25:04,722 - INFO - [Train] [50/90] | Loss: 0.4260 | Train Acc: 86.09%
2026-01-14 14:25:07,216 - INFO - [Valid] [50/90] | Loss: 0.5376 | Val Acc: 77.88%
2026-01-14 14:25:07,232 - INFO - [Metrics for 'abnormal'] | Precision: 0.7662 | Recall: 0.7516 | F1: 0.7588
2026-01-14 14:25:07,233 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8022 | F1: 0.7956
2026-01-14 14:25:07,241 - INFO - --------------------------------------------------
2026-01-14 14:25:07,245 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 14:25:16,344 - INFO - [Train] [51/90] | Loss: 0.4237 | Train Acc: 86.24%
2026-01-14 14:25:18,993 - INFO - [Valid] [51/90] | Loss: 0.5257 | Val Acc: 80.24%
2026-01-14 14:25:19,002 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-01-14 14:25:19,003 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-01-14 14:25:19,007 - INFO - --------------------------------------------------
2026-01-14 14:25:19,009 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 14:25:28,966 - INFO - [Train] [52/90] | Loss: 0.4204 | Train Acc: 85.86%
2026-01-14 14:25:31,493 - INFO - [Valid] [52/90] | Loss: 0.5349 | Val Acc: 79.94%
2026-01-14 14:25:31,506 - INFO - [Metrics for 'abnormal'] | Precision: 0.7602 | Recall: 0.8280 | F1: 0.7927
2026-01-14 14:25:31,507 - INFO - [Metrics for 'normal'] | Precision: 0.8393 | Recall: 0.7747 | F1: 0.8057
2026-01-14 14:25:31,511 - INFO - --------------------------------------------------
2026-01-14 14:25:31,514 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 14:25:40,825 - INFO - [Train] [53/90] | Loss: 0.4180 | Train Acc: 86.24%
2026-01-14 14:25:43,006 - INFO - [Valid] [53/90] | Loss: 0.5483 | Val Acc: 76.40%
2026-01-14 14:25:43,015 - INFO - [Metrics for 'abnormal'] | Precision: 0.7037 | Recall: 0.8471 | F1: 0.7688
2026-01-14 14:25:43,016 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.6923 | F1: 0.7590
2026-01-14 14:25:43,019 - INFO - --------------------------------------------------
2026-01-14 14:25:43,021 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 14:25:52,324 - INFO - [Train] [54/90] | Loss: 0.4092 | Train Acc: 87.28%
2026-01-14 14:25:54,768 - INFO - [Valid] [54/90] | Loss: 0.5413 | Val Acc: 78.76%
2026-01-14 14:25:54,777 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-01-14 14:25:54,778 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-01-14 14:25:54,781 - INFO - --------------------------------------------------
2026-01-14 14:25:54,784 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 14:26:03,852 - INFO - [Train] [55/90] | Loss: 0.4103 | Train Acc: 87.35%
2026-01-14 14:26:06,663 - INFO - [Valid] [55/90] | Loss: 0.5049 | Val Acc: 77.58%
2026-01-14 14:26:06,675 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.7643 | F1: 0.7595
2026-01-14 14:26:06,676 - INFO - [Metrics for 'normal'] | Precision: 0.7944 | Recall: 0.7857 | F1: 0.7901
2026-01-14 14:26:06,790 - INFO - [Best Model Saved] (val loss: 0.5049) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:26:06,790 - INFO - --------------------------------------------------
2026-01-14 14:26:06,793 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 14:26:16,332 - INFO - [Train] [56/90] | Loss: 0.3988 | Train Acc: 87.35%
2026-01-14 14:26:18,976 - INFO - [Valid] [56/90] | Loss: 0.5483 | Val Acc: 78.76%
2026-01-14 14:26:18,986 - INFO - [Metrics for 'abnormal'] | Precision: 0.7576 | Recall: 0.7962 | F1: 0.7764
2026-01-14 14:26:18,986 - INFO - [Metrics for 'normal'] | Precision: 0.8161 | Recall: 0.7802 | F1: 0.7978
2026-01-14 14:26:18,990 - INFO - --------------------------------------------------
2026-01-14 14:26:18,992 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 14:26:27,633 - INFO - [Train] [57/90] | Loss: 0.4011 | Train Acc: 87.80%
2026-01-14 14:26:29,808 - INFO - [Valid] [57/90] | Loss: 0.5043 | Val Acc: 78.76%
2026-01-14 14:26:29,824 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 14:26:29,824 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 14:26:29,893 - INFO - [Best Model Saved] (val loss: 0.5043) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:26:29,894 - INFO - --------------------------------------------------
2026-01-14 14:26:29,896 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 14:26:39,281 - INFO - [Train] [58/90] | Loss: 0.3852 | Train Acc: 89.36%
2026-01-14 14:26:41,458 - INFO - [Valid] [58/90] | Loss: 0.5235 | Val Acc: 78.76%
2026-01-14 14:26:41,472 - INFO - [Metrics for 'abnormal'] | Precision: 0.7931 | Recall: 0.7325 | F1: 0.7616
2026-01-14 14:26:41,473 - INFO - [Metrics for 'normal'] | Precision: 0.7835 | Recall: 0.8352 | F1: 0.8085
2026-01-14 14:26:41,478 - INFO - --------------------------------------------------
2026-01-14 14:26:41,480 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 14:26:51,034 - INFO - [Train] [59/90] | Loss: 0.4028 | Train Acc: 87.80%
2026-01-14 14:26:53,016 - INFO - [Valid] [59/90] | Loss: 0.5318 | Val Acc: 79.65%
2026-01-14 14:26:53,029 - INFO - [Metrics for 'abnormal'] | Precision: 0.7785 | Recall: 0.7834 | F1: 0.7810
2026-01-14 14:26:53,029 - INFO - [Metrics for 'normal'] | Precision: 0.8122 | Recall: 0.8077 | F1: 0.8099
2026-01-14 14:26:53,034 - INFO - --------------------------------------------------
2026-01-14 14:26:53,037 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 14:27:02,998 - INFO - [Train] [60/90] | Loss: 0.4074 | Train Acc: 87.20%
2026-01-14 14:27:04,882 - INFO - [Valid] [60/90] | Loss: 0.5274 | Val Acc: 80.53%
2026-01-14 14:27:04,920 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 14:27:04,922 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 14:27:04,932 - INFO - --------------------------------------------------
2026-01-14 14:27:04,935 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 14:27:14,164 - INFO - [Train] [61/90] | Loss: 0.4134 | Train Acc: 86.38%
2026-01-14 14:27:16,008 - INFO - [Valid] [61/90] | Loss: 0.5149 | Val Acc: 77.88%
2026-01-14 14:27:16,017 - INFO - [Metrics for 'abnormal'] | Precision: 0.7595 | Recall: 0.7643 | F1: 0.7619
2026-01-14 14:27:16,018 - INFO - [Metrics for 'normal'] | Precision: 0.7956 | Recall: 0.7912 | F1: 0.7934
2026-01-14 14:27:16,021 - INFO - --------------------------------------------------
2026-01-14 14:27:16,024 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 14:27:25,398 - INFO - [Train] [62/90] | Loss: 0.3907 | Train Acc: 88.24%
2026-01-14 14:27:27,358 - INFO - [Valid] [62/90] | Loss: 0.5235 | Val Acc: 79.94%
2026-01-14 14:27:27,369 - INFO - [Metrics for 'abnormal'] | Precision: 0.8069 | Recall: 0.7452 | F1: 0.7748
2026-01-14 14:27:27,370 - INFO - [Metrics for 'normal'] | Precision: 0.7938 | Recall: 0.8462 | F1: 0.8191
2026-01-14 14:27:27,375 - INFO - --------------------------------------------------
2026-01-14 14:27:27,377 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 14:27:36,616 - INFO - [Train] [63/90] | Loss: 0.3721 | Train Acc: 89.81%
2026-01-14 14:27:39,041 - INFO - [Valid] [63/90] | Loss: 0.5092 | Val Acc: 79.35%
2026-01-14 14:27:39,053 - INFO - [Metrics for 'abnormal'] | Precision: 0.7736 | Recall: 0.7834 | F1: 0.7785
2026-01-14 14:27:39,053 - INFO - [Metrics for 'normal'] | Precision: 0.8111 | Recall: 0.8022 | F1: 0.8066
2026-01-14 14:27:39,058 - INFO - --------------------------------------------------
2026-01-14 14:27:39,060 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 14:27:48,013 - INFO - [Train] [64/90] | Loss: 0.3846 | Train Acc: 87.95%
2026-01-14 14:27:50,863 - INFO - [Valid] [64/90] | Loss: 0.5107 | Val Acc: 79.06%
2026-01-14 14:27:50,874 - INFO - [Metrics for 'abnormal'] | Precision: 0.7654 | Recall: 0.7898 | F1: 0.7774
2026-01-14 14:27:50,874 - INFO - [Metrics for 'normal'] | Precision: 0.8136 | Recall: 0.7912 | F1: 0.8022
2026-01-14 14:27:50,878 - INFO - --------------------------------------------------
2026-01-14 14:27:50,880 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 14:27:59,810 - INFO - [Train] [65/90] | Loss: 0.3659 | Train Acc: 90.10%
2026-01-14 14:28:02,453 - INFO - [Valid] [65/90] | Loss: 0.5145 | Val Acc: 79.65%
2026-01-14 14:28:02,463 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-01-14 14:28:02,464 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-01-14 14:28:02,468 - INFO - --------------------------------------------------
2026-01-14 14:28:02,471 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 14:28:10,925 - INFO - [Train] [66/90] | Loss: 0.3648 | Train Acc: 90.18%
2026-01-14 14:28:14,239 - INFO - [Valid] [66/90] | Loss: 0.5212 | Val Acc: 79.65%
2026-01-14 14:28:14,250 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-01-14 14:28:14,251 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-01-14 14:28:14,255 - INFO - --------------------------------------------------
2026-01-14 14:28:14,258 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 14:28:22,698 - INFO - [Train] [67/90] | Loss: 0.3960 | Train Acc: 88.47%
2026-01-14 14:28:25,581 - INFO - [Valid] [67/90] | Loss: 0.5124 | Val Acc: 80.24%
2026-01-14 14:28:25,592 - INFO - [Metrics for 'abnormal'] | Precision: 0.7922 | Recall: 0.7771 | F1: 0.7846
2026-01-14 14:28:25,593 - INFO - [Metrics for 'normal'] | Precision: 0.8108 | Recall: 0.8242 | F1: 0.8174
2026-01-14 14:28:25,598 - INFO - --------------------------------------------------
2026-01-14 14:28:25,601 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 14:28:34,315 - INFO - [Train] [68/90] | Loss: 0.3674 | Train Acc: 89.66%
2026-01-14 14:28:37,306 - INFO - [Valid] [68/90] | Loss: 0.5481 | Val Acc: 80.83%
2026-01-14 14:28:37,334 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 14:28:37,352 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 14:28:37,357 - INFO - --------------------------------------------------
2026-01-14 14:28:37,360 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 14:28:45,084 - INFO - [Train] [69/90] | Loss: 0.3662 | Train Acc: 89.29%
2026-01-14 14:28:48,161 - INFO - [Valid] [69/90] | Loss: 0.5270 | Val Acc: 78.47%
2026-01-14 14:28:48,172 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7134 | F1: 0.7542
2026-01-14 14:28:48,173 - INFO - [Metrics for 'normal'] | Precision: 0.7739 | Recall: 0.8462 | F1: 0.8084
2026-01-14 14:28:48,177 - INFO - --------------------------------------------------
2026-01-14 14:28:48,180 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 14:28:57,122 - INFO - [Train] [70/90] | Loss: 0.3618 | Train Acc: 90.33%
2026-01-14 14:29:00,504 - INFO - [Valid] [70/90] | Loss: 0.5885 | Val Acc: 77.29%
2026-01-14 14:29:00,517 - INFO - [Metrics for 'abnormal'] | Precision: 0.7174 | Recall: 0.8408 | F1: 0.7742
2026-01-14 14:29:00,518 - INFO - [Metrics for 'normal'] | Precision: 0.8387 | Recall: 0.7143 | F1: 0.7715
2026-01-14 14:29:00,522 - INFO - --------------------------------------------------
2026-01-14 14:29:00,526 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 14:29:08,957 - INFO - [Train] [71/90] | Loss: 0.3715 | Train Acc: 89.51%
2026-01-14 14:29:11,250 - INFO - [Valid] [71/90] | Loss: 0.5355 | Val Acc: 78.76%
2026-01-14 14:29:11,262 - INFO - [Metrics for 'abnormal'] | Precision: 0.7815 | Recall: 0.7516 | F1: 0.7662
2026-01-14 14:29:11,262 - INFO - [Metrics for 'normal'] | Precision: 0.7926 | Recall: 0.8187 | F1: 0.8054
2026-01-14 14:29:11,266 - INFO - --------------------------------------------------
2026-01-14 14:29:11,269 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 14:29:20,197 - INFO - [Train] [72/90] | Loss: 0.3649 | Train Acc: 90.10%
2026-01-14 14:29:22,713 - INFO - [Valid] [72/90] | Loss: 0.5610 | Val Acc: 82.30%
2026-01-14 14:29:22,725 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8662 | F1: 0.8193
2026-01-14 14:29:22,725 - INFO - [Metrics for 'normal'] | Precision: 0.8720 | Recall: 0.7857 | F1: 0.8266
2026-01-14 14:29:22,730 - INFO - --------------------------------------------------
2026-01-14 14:29:22,733 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 14:29:31,920 - INFO - [Train] [73/90] | Loss: 0.3604 | Train Acc: 89.73%
2026-01-14 14:29:34,471 - INFO - [Valid] [73/90] | Loss: 0.5522 | Val Acc: 79.35%
2026-01-14 14:29:34,483 - INFO - [Metrics for 'abnormal'] | Precision: 0.7636 | Recall: 0.8025 | F1: 0.7826
2026-01-14 14:29:34,484 - INFO - [Metrics for 'normal'] | Precision: 0.8218 | Recall: 0.7857 | F1: 0.8034
2026-01-14 14:29:34,488 - INFO - --------------------------------------------------
2026-01-14 14:29:34,491 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 14:29:43,752 - INFO - [Train] [74/90] | Loss: 0.3549 | Train Acc: 90.92%
2026-01-14 14:29:46,505 - INFO - [Valid] [74/90] | Loss: 0.5515 | Val Acc: 80.24%
2026-01-14 14:29:46,515 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-01-14 14:29:46,515 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-01-14 14:29:46,520 - INFO - --------------------------------------------------
2026-01-14 14:29:46,523 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 14:29:55,621 - INFO - [Train] [75/90] | Loss: 0.3643 | Train Acc: 89.73%
2026-01-14 14:29:57,946 - INFO - [Valid] [75/90] | Loss: 0.5411 | Val Acc: 79.35%
2026-01-14 14:29:57,960 - INFO - [Metrics for 'abnormal'] | Precision: 0.8042 | Recall: 0.7325 | F1: 0.7667
2026-01-14 14:29:57,961 - INFO - [Metrics for 'normal'] | Precision: 0.7857 | Recall: 0.8462 | F1: 0.8148
2026-01-14 14:29:57,965 - INFO - --------------------------------------------------
2026-01-14 14:29:57,968 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 14:30:06,389 - INFO - [Train] [76/90] | Loss: 0.3670 | Train Acc: 90.70%
2026-01-14 14:30:08,436 - INFO - [Valid] [76/90] | Loss: 0.5380 | Val Acc: 79.94%
2026-01-14 14:30:08,448 - INFO - [Metrics for 'abnormal'] | Precision: 0.7947 | Recall: 0.7643 | F1: 0.7792
2026-01-14 14:30:08,448 - INFO - [Metrics for 'normal'] | Precision: 0.8032 | Recall: 0.8297 | F1: 0.8162
2026-01-14 14:30:08,452 - INFO - --------------------------------------------------
2026-01-14 14:30:08,454 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 14:30:18,190 - INFO - [Train] [77/90] | Loss: 0.3474 | Train Acc: 91.07%
2026-01-14 14:30:20,910 - INFO - [Valid] [77/90] | Loss: 0.5332 | Val Acc: 80.53%
2026-01-14 14:30:20,922 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-01-14 14:30:20,923 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-01-14 14:30:20,927 - INFO - --------------------------------------------------
2026-01-14 14:30:20,930 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 14:30:29,724 - INFO - [Train] [78/90] | Loss: 0.3611 | Train Acc: 90.70%
2026-01-14 14:30:31,926 - INFO - [Valid] [78/90] | Loss: 0.5492 | Val Acc: 78.76%
2026-01-14 14:30:31,938 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-01-14 14:30:31,938 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-01-14 14:30:31,943 - INFO - --------------------------------------------------
2026-01-14 14:30:31,945 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 14:30:41,145 - INFO - [Train] [79/90] | Loss: 0.3496 | Train Acc: 91.07%
2026-01-14 14:30:43,900 - INFO - [Valid] [79/90] | Loss: 0.5455 | Val Acc: 79.65%
2026-01-14 14:30:43,918 - INFO - [Metrics for 'abnormal'] | Precision: 0.8014 | Recall: 0.7452 | F1: 0.7723
2026-01-14 14:30:43,919 - INFO - [Metrics for 'normal'] | Precision: 0.7927 | Recall: 0.8407 | F1: 0.8160
2026-01-14 14:30:43,924 - INFO - --------------------------------------------------
2026-01-14 14:30:43,937 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 14:30:53,435 - INFO - [Train] [80/90] | Loss: 0.3484 | Train Acc: 91.37%
2026-01-14 14:30:55,611 - INFO - [Valid] [80/90] | Loss: 0.5438 | Val Acc: 79.06%
2026-01-14 14:30:55,637 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 14:30:55,639 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 14:30:55,642 - INFO - --------------------------------------------------
2026-01-14 14:30:55,645 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 14:31:05,197 - INFO - [Train] [81/90] | Loss: 0.3511 | Train Acc: 90.92%
2026-01-14 14:31:07,974 - INFO - [Valid] [81/90] | Loss: 0.5475 | Val Acc: 79.35%
2026-01-14 14:31:07,986 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.7580 | F1: 0.7727
2026-01-14 14:31:07,987 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8242 | F1: 0.8108
2026-01-14 14:31:07,991 - INFO - --------------------------------------------------
2026-01-14 14:31:07,994 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 14:31:16,085 - INFO - [Train] [82/90] | Loss: 0.3606 | Train Acc: 90.70%
2026-01-14 14:31:18,686 - INFO - [Valid] [82/90] | Loss: 0.5339 | Val Acc: 78.47%
2026-01-14 14:31:18,698 - INFO - [Metrics for 'abnormal'] | Precision: 0.7530 | Recall: 0.7962 | F1: 0.7740
2026-01-14 14:31:18,699 - INFO - [Metrics for 'normal'] | Precision: 0.8150 | Recall: 0.7747 | F1: 0.7944
2026-01-14 14:31:18,702 - INFO - --------------------------------------------------
2026-01-14 14:31:18,706 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 14:31:28,630 - INFO - [Train] [83/90] | Loss: 0.3480 | Train Acc: 91.07%
2026-01-14 14:31:31,531 - INFO - [Valid] [83/90] | Loss: 0.5475 | Val Acc: 79.65%
2026-01-14 14:31:31,543 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-01-14 14:31:31,543 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-01-14 14:31:31,547 - INFO - --------------------------------------------------
2026-01-14 14:31:31,549 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 14:31:42,005 - INFO - [Train] [84/90] | Loss: 0.3341 | Train Acc: 91.74%
2026-01-14 14:31:43,983 - INFO - [Valid] [84/90] | Loss: 0.5539 | Val Acc: 78.17%
2026-01-14 14:31:43,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.7677 | Recall: 0.7580 | F1: 0.7628
2026-01-14 14:31:43,997 - INFO - [Metrics for 'normal'] | Precision: 0.7935 | Recall: 0.8022 | F1: 0.7978
2026-01-14 14:31:44,001 - INFO - --------------------------------------------------
2026-01-14 14:31:44,005 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 14:31:52,937 - INFO - [Train] [85/90] | Loss: 0.3392 | Train Acc: 90.70%
2026-01-14 14:31:55,420 - INFO - [Valid] [85/90] | Loss: 0.5518 | Val Acc: 79.65%
2026-01-14 14:31:55,432 - INFO - [Metrics for 'abnormal'] | Precision: 0.7821 | Recall: 0.7771 | F1: 0.7796
2026-01-14 14:31:55,432 - INFO - [Metrics for 'normal'] | Precision: 0.8087 | Recall: 0.8132 | F1: 0.8110
2026-01-14 14:31:55,435 - INFO - --------------------------------------------------
2026-01-14 14:31:55,437 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 14:32:05,136 - INFO - [Train] [86/90] | Loss: 0.3434 | Train Acc: 91.07%
2026-01-14 14:32:07,522 - INFO - [Valid] [86/90] | Loss: 0.5715 | Val Acc: 78.17%
2026-01-14 14:32:07,544 - INFO - [Metrics for 'abnormal'] | Precision: 0.7902 | Recall: 0.7197 | F1: 0.7533
2026-01-14 14:32:07,546 - INFO - [Metrics for 'normal'] | Precision: 0.7755 | Recall: 0.8352 | F1: 0.8042
2026-01-14 14:32:07,554 - INFO - --------------------------------------------------
2026-01-14 14:32:07,558 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 14:32:16,890 - INFO - [Train] [87/90] | Loss: 0.3411 | Train Acc: 91.96%
2026-01-14 14:32:19,052 - INFO - [Valid] [87/90] | Loss: 0.5363 | Val Acc: 80.53%
2026-01-14 14:32:19,071 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-01-14 14:32:19,071 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-01-14 14:32:19,078 - INFO - --------------------------------------------------
2026-01-14 14:32:19,081 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 14:32:28,081 - INFO - [Train] [88/90] | Loss: 0.3422 | Train Acc: 91.67%
2026-01-14 14:32:30,479 - INFO - [Valid] [88/90] | Loss: 0.5540 | Val Acc: 79.06%
2026-01-14 14:32:30,493 - INFO - [Metrics for 'abnormal'] | Precision: 0.7945 | Recall: 0.7389 | F1: 0.7657
2026-01-14 14:32:30,493 - INFO - [Metrics for 'normal'] | Precision: 0.7876 | Recall: 0.8352 | F1: 0.8107
2026-01-14 14:32:30,498 - INFO - --------------------------------------------------
2026-01-14 14:32:30,501 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 14:32:39,187 - INFO - [Train] [89/90] | Loss: 0.3330 | Train Acc: 91.82%
2026-01-14 14:32:41,503 - INFO - [Valid] [89/90] | Loss: 0.5612 | Val Acc: 78.47%
2026-01-14 14:32:41,514 - INFO - [Metrics for 'abnormal'] | Precision: 0.8134 | Recall: 0.6943 | F1: 0.7491
2026-01-14 14:32:41,515 - INFO - [Metrics for 'normal'] | Precision: 0.7659 | Recall: 0.8626 | F1: 0.8114
2026-01-14 14:32:41,519 - INFO - --------------------------------------------------
2026-01-14 14:32:41,521 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 14:32:51,274 - INFO - [Train] [90/90] | Loss: 0.3436 | Train Acc: 90.92%
2026-01-14 14:32:53,472 - INFO - [Valid] [90/90] | Loss: 0.5561 | Val Acc: 78.47%
2026-01-14 14:32:53,483 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.7580 | F1: 0.7653
2026-01-14 14:32:53,484 - INFO - [Metrics for 'normal'] | Precision: 0.7946 | Recall: 0.8077 | F1: 0.8011
2026-01-14 14:32:53,489 - INFO - ==================================================
2026-01-14 14:32:53,490 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 14:32:53,490 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 14:32:53,490 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:32:53,697 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 14:32:53,699 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:32:53,700 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:32:53,703 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:33:00,555 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:33:00,716 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9025048828125001)에 맞춰 변경되었습니다.
2026-01-14 14:33:00,719 - INFO - ==================================================
2026-01-14 14:33:00,946 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/best_model.pth'
2026-01-14 14:33:00,948 - INFO - ==================================================
2026-01-14 14:33:00,949 - INFO - Test 모드를 시작합니다.
2026-01-14 14:33:01,424 - INFO - 연산량 (MACs): 0.0039 GMACs per sample
2026-01-14 14:33:01,425 - INFO - 연산량 (FLOPs): 0.0077 GFLOPs per sample
2026-01-14 14:33:01,425 - INFO - ==================================================
2026-01-14 14:33:01,425 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 14:33:02,790 - INFO - 샘플 당 평균 Forward Pass 시간: 6.92ms (std: 3.16ms), FPS: 169.28 (std: 60.57) (1개 샘플 x 100회 반복)
2026-01-14 14:33:02,790 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 57.83 MB
2026-01-14 14:33:02,791 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 14:33:06,490 - INFO - [Test] Loss: 0.4351 | Test Acc: 78.76%
2026-01-14 14:33:06,522 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 14:33:06,539 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 14:33:07,367 - INFO - ==================================================
2026-01-14 14:33:07,368 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/confusion_matrix_20260114_135944.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/confusion_matrix_20260114_135944.pdf'
2026-01-14 14:33:07,368 - INFO - ==================================================
2026-01-14 14:33:07,369 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 14:33:12,264 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/model_fp32_20260114_135944.onnx'에 저장되었습니다. (크기: 0.14 MB)
2026-01-14 14:33:12,627 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2601.05 MB (증가량: 6.57 MB)
2026-01-14 14:33:12,627 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 14:33:13,525 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 3.35ms (std: 4.62ms)
2026-01-14 14:33:13,525 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 559.23 FPS (std: 245.85) (1개 샘플 x 100회 반복)
2026-01-14 14:33:13,526 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2603.11 MB (순수 증가량: 2.06 MB)
2026-01-14 14:33:13,526 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2603.11 MB (전체 증가량: 8.63 MB)
2026-01-14 14:33:16,539 - INFO - [Test (ONNX)] | Test Acc (ONNX): 78.76%
2026-01-14 14:33:16,549 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 14:33:16,549 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 14:33:17,408 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/val_acc.pdf'
2026-01-14 14:33:18,241 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/train_val_acc.pdf'
2026-01-14 14:33:18,689 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/F1_normal.pdf'
2026-01-14 14:33:19,101 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/val_loss.pdf'
2026-01-14 14:33:19,567 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/learning_rate.pdf'
2026-01-14 14:33:24,651 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_wanda_20260114_135944/graph_20260114_135944/compile.pdf'
