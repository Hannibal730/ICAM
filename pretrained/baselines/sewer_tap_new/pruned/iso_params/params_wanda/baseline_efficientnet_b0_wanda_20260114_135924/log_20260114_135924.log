2026-01-14 13:59:24,077 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/log_20260114_135924.log'에 저장됩니다.
2026-01-14 13:59:24,084 - INFO - ==================================================
2026-01-14 13:59:24,084 - INFO - config.yaml:
2026-01-14 13:59:24,084 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: efficientnet_b0
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.031371

2026-01-14 13:59:24,084 - INFO - ==================================================
2026-01-14 13:59:24,296 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 13:59:24,296 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 13:59:24,297 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 13:59:24,312 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 13:59:24,312 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 13:59:24,313 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 13:59:24,313 - INFO - Baseline 모델 'efficientnet_b0'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:59:24,618 - INFO - ==================================================
2026-01-14 13:59:24,618 - INFO - 모델 파라미터 수:
2026-01-14 13:59:24,618 - INFO -   - 총 파라미터: 4,010,110 개
2026-01-14 13:59:24,619 - INFO -   - 학습 가능한 파라미터: 4,010,110 개
2026-01-14 13:59:24,619 - INFO - ================================================================================
2026-01-14 13:59:24,619 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 13:59:24,619 - INFO - ================================================================================
2026-01-14 13:59:24,619 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 13:59:24,623 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 13:59:24,626 - INFO - ==================================================
2026-01-14 13:59:24,626 - INFO - train 모드를 시작합니다.
2026-01-14 13:59:24,626 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 13:59:24,626 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 13:59:24,626 - INFO - --------------------------------------------------
2026-01-14 13:59:24,628 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 13:59:30,325 - INFO - [Train] [1/10] | Loss: 0.5889 | Train Acc: 72.77%
2026-01-14 13:59:32,509 - INFO - [Valid] [1/10] | Loss: 0.5952 | Val Acc: 75.52%
2026-01-14 13:59:32,521 - INFO - [Metrics for 'abnormal'] | Precision: 0.8700 | Recall: 0.5541 | F1: 0.6770
2026-01-14 13:59:32,521 - INFO - [Metrics for 'normal'] | Precision: 0.7071 | Recall: 0.9286 | F1: 0.8029
2026-01-14 13:59:32,567 - INFO - [Best Model Saved] (val loss: 0.5952) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 13:59:32,568 - INFO - --------------------------------------------------
2026-01-14 13:59:32,569 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 13:59:37,228 - INFO - [Train] [2/10] | Loss: 0.5284 | Train Acc: 79.17%
2026-01-14 13:59:38,534 - INFO - [Valid] [2/10] | Loss: 0.5904 | Val Acc: 76.99%
2026-01-14 13:59:38,545 - INFO - [Metrics for 'abnormal'] | Precision: 0.8762 | Recall: 0.5860 | F1: 0.7023
2026-01-14 13:59:38,545 - INFO - [Metrics for 'normal'] | Precision: 0.7222 | Recall: 0.9286 | F1: 0.8125
2026-01-14 13:59:38,612 - INFO - [Best Model Saved] (val loss: 0.5904) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 13:59:38,612 - INFO - --------------------------------------------------
2026-01-14 13:59:38,614 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 13:59:43,466 - INFO - [Train] [3/10] | Loss: 0.5064 | Train Acc: 81.03%
2026-01-14 13:59:44,802 - INFO - [Valid] [3/10] | Loss: 0.5188 | Val Acc: 79.65%
2026-01-14 13:59:44,811 - INFO - [Metrics for 'abnormal'] | Precision: 0.8284 | Recall: 0.7070 | F1: 0.7629
2026-01-14 13:59:44,811 - INFO - [Metrics for 'normal'] | Precision: 0.7756 | Recall: 0.8736 | F1: 0.8217
2026-01-14 13:59:44,863 - INFO - [Best Model Saved] (val loss: 0.5188) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 13:59:44,863 - INFO - --------------------------------------------------
2026-01-14 13:59:44,865 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 13:59:49,810 - INFO - [Train] [4/10] | Loss: 0.4789 | Train Acc: 82.22%
2026-01-14 13:59:51,359 - INFO - [Valid] [4/10] | Loss: 0.4986 | Val Acc: 81.12%
2026-01-14 13:59:51,405 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 13:59:51,405 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 13:59:51,462 - INFO - [Best Model Saved] (val loss: 0.4986) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 13:59:51,462 - INFO - --------------------------------------------------
2026-01-14 13:59:51,464 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 13:59:56,523 - INFO - [Train] [5/10] | Loss: 0.4479 | Train Acc: 85.27%
2026-01-14 13:59:58,203 - INFO - [Valid] [5/10] | Loss: 0.5198 | Val Acc: 82.01%
2026-01-14 13:59:58,217 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-01-14 13:59:58,217 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-01-14 13:59:58,222 - INFO - --------------------------------------------------
2026-01-14 13:59:58,225 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 14:00:04,034 - INFO - [Train] [6/10] | Loss: 0.4307 | Train Acc: 85.27%
2026-01-14 14:00:05,556 - INFO - [Valid] [6/10] | Loss: 0.5691 | Val Acc: 79.06%
2026-01-14 14:00:05,569 - INFO - [Metrics for 'abnormal'] | Precision: 0.7654 | Recall: 0.7898 | F1: 0.7774
2026-01-14 14:00:05,569 - INFO - [Metrics for 'normal'] | Precision: 0.8136 | Recall: 0.7912 | F1: 0.8022
2026-01-14 14:00:05,574 - INFO - --------------------------------------------------
2026-01-14 14:00:05,576 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 14:00:11,719 - INFO - [Train] [7/10] | Loss: 0.4010 | Train Acc: 88.76%
2026-01-14 14:00:13,357 - INFO - [Valid] [7/10] | Loss: 0.4950 | Val Acc: 82.01%
2026-01-14 14:00:13,378 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 14:00:13,386 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 14:00:13,465 - INFO - [Best Model Saved] (val loss: 0.4950) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:00:13,466 - INFO - --------------------------------------------------
2026-01-14 14:00:13,468 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 14:00:20,905 - INFO - [Train] [8/10] | Loss: 0.3774 | Train Acc: 88.84%
2026-01-14 14:00:23,040 - INFO - [Valid] [8/10] | Loss: 0.4937 | Val Acc: 82.60%
2026-01-14 14:00:23,058 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 14:00:23,059 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 14:00:23,173 - INFO - [Best Model Saved] (val loss: 0.4937) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:00:23,173 - INFO - --------------------------------------------------
2026-01-14 14:00:23,175 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 14:00:30,454 - INFO - [Train] [9/10] | Loss: 0.3254 | Train Acc: 92.71%
2026-01-14 14:00:32,920 - INFO - [Valid] [9/10] | Loss: 0.5092 | Val Acc: 82.30%
2026-01-14 14:00:32,992 - INFO - [Metrics for 'abnormal'] | Precision: 0.7939 | Recall: 0.8344 | F1: 0.8137
2026-01-14 14:00:32,992 - INFO - [Metrics for 'normal'] | Precision: 0.8506 | Recall: 0.8132 | F1: 0.8315
2026-01-14 14:00:32,996 - INFO - --------------------------------------------------
2026-01-14 14:00:33,000 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 14:00:41,582 - INFO - [Train] [10/10] | Loss: 0.3070 | Train Acc: 94.49%
2026-01-14 14:00:43,645 - INFO - [Valid] [10/10] | Loss: 0.5292 | Val Acc: 80.53%
2026-01-14 14:00:43,657 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.7580 | F1: 0.7829
2026-01-14 14:00:43,658 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8462 | F1: 0.8235
2026-01-14 14:00:43,663 - INFO - ================================================================================
2026-01-14 14:00:43,664 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 14:00:43,665 - INFO - ================================================================================
2026-01-14 14:00:43,827 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'을(를) 불러왔습니다.
2026-01-14 14:00:43,828 - INFO - ================================================================================
2026-01-14 14:00:43,828 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 14:00:43,830 - INFO - 원본 모델 파라미터: 4.0101M
2026-01-14 14:00:43,959 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:00:43,960 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:00:43,965 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:00:52,462 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:00:53,116 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 14:00:53,116 - INFO - ==================================================
2026-01-14 14:00:53,119 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.0721M (감소율: 73.26%)
2026-01-14 14:00:53,172 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:00:53,172 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:00:53,176 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:01,331 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:01,677 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 14:01:01,678 - INFO - ==================================================
2026-01-14 14:01:01,681 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.3065M (감소율: 92.36%)
2026-01-14 14:01:01,769 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:01,772 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:01,776 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:09,897 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:10,247 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 14:01:10,248 - INFO - ==================================================
2026-01-14 14:01:10,250 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.0963M (감소율: 97.60%)
2026-01-14 14:01:10,308 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:10,309 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:10,314 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:19,113 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:19,422 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 14:01:19,423 - INFO - ==================================================
2026-01-14 14:01:19,426 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.0360M (감소율: 99.10%)
2026-01-14 14:01:19,493 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:19,494 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:19,499 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:28,483 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:29,314 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 14:01:29,315 - INFO - ==================================================
2026-01-14 14:01:29,318 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0183M (감소율: 99.54%)
2026-01-14 14:01:29,375 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:29,375 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:29,379 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:37,620 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:38,513 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.94359375)에 맞춰 변경되었습니다.
2026-01-14 14:01:38,514 - INFO - ==================================================
2026-01-14 14:01:38,517 - INFO -   [탐색  6] 희소도: 0.9436 -> 파라미터: 0.0247M (감소율: 99.38%)
2026-01-14 14:01:38,580 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:38,581 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:38,587 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:47,160 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:47,450 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9358593749999999)에 맞춰 변경되었습니다.
2026-01-14 14:01:47,451 - INFO - ==================================================
2026-01-14 14:01:47,454 - INFO -   [탐색  7] 희소도: 0.9359 -> 파라미터: 0.0306M (감소율: 99.24%)
2026-01-14 14:01:47,512 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:47,513 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:47,518 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:01:55,017 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:01:55,618 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9319921874999999)에 맞춰 변경되었습니다.
2026-01-14 14:01:55,619 - INFO - ==================================================
2026-01-14 14:01:55,621 - INFO -   [탐색  8] 희소도: 0.9320 -> 파라미터: 0.0332M (감소율: 99.17%)
2026-01-14 14:01:55,671 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:01:55,672 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:01:55,676 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:04,662 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:04,928 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9339257812499999)에 맞춰 변경되었습니다.
2026-01-14 14:02:04,928 - INFO - ==================================================
2026-01-14 14:02:04,931 - INFO -   [탐색  9] 희소도: 0.9339 -> 파라미터: 0.0317M (감소율: 99.21%)
2026-01-14 14:02:04,984 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:04,985 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:04,990 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:12,648 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:13,139 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9348925781249999)에 맞춰 변경되었습니다.
2026-01-14 14:02:13,140 - INFO - ==================================================
2026-01-14 14:02:13,143 - INFO -   [탐색 10] 희소도: 0.9349 -> 파라미터: 0.0311M (감소율: 99.22%)
2026-01-14 14:02:13,232 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:13,233 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:13,293 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:20,993 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:21,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 14:02:21,308 - INFO - ==================================================
2026-01-14 14:02:21,311 - INFO -   [탐색 11] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:02:21,374 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:21,375 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:21,381 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:29,759 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:30,699 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9341674804687499)에 맞춰 변경되었습니다.
2026-01-14 14:02:30,700 - INFO - ==================================================
2026-01-14 14:02:30,708 - INFO -   [탐색 12] 희소도: 0.9342 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:02:30,776 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:30,777 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:30,788 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:38,914 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:39,506 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9342883300781248)에 맞춰 변경되었습니다.
2026-01-14 14:02:39,507 - INFO - ==================================================
2026-01-14 14:02:39,511 - INFO -   [탐색 13] 희소도: 0.9343 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:02:39,594 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:39,596 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:39,601 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:48,191 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:49,050 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343487548828124)에 맞춰 변경되었습니다.
2026-01-14 14:02:49,051 - INFO - ==================================================
2026-01-14 14:02:49,053 - INFO -   [탐색 14] 희소도: 0.9343 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:02:49,163 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:49,163 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:49,167 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:56,696 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:56,991 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343789672851561)에 맞춰 변경되었습니다.
2026-01-14 14:02:56,992 - INFO - ==================================================
2026-01-14 14:02:56,995 - INFO -   [탐색 15] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:02:57,055 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:57,056 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:57,061 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:06,592 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:07,024 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343638610839843)에 맞춰 변경되었습니다.
2026-01-14 14:03:07,025 - INFO - ==================================================
2026-01-14 14:03:07,029 - INFO -   [탐색 16] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:03:07,086 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:07,087 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:07,092 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:16,344 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:16,865 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343714141845703)에 맞춰 변경되었습니다.
2026-01-14 14:03:16,865 - INFO - ==================================================
2026-01-14 14:03:16,868 - INFO -   [탐색 17] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:03:16,957 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:16,958 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:16,961 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:24,440 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:24,761 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343751907348632)에 맞춰 변경되었습니다.
2026-01-14 14:03:24,766 - INFO - ==================================================
2026-01-14 14:03:24,773 - INFO -   [탐색 18] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:03:24,856 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:24,857 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:24,860 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:33,337 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:33,712 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343733024597167)에 맞춰 변경되었습니다.
2026-01-14 14:03:33,712 - INFO - ==================================================
2026-01-14 14:03:33,722 - INFO -   [탐색 19] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:03:33,818 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:33,818 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:33,825 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:43,054 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:43,726 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.93437424659729)에 맞춰 변경되었습니다.
2026-01-14 14:03:43,727 - INFO - ==================================================
2026-01-14 14:03:43,733 - INFO -   [탐색 20] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:03:43,799 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:43,800 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:43,805 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:52,715 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:53,105 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343747186660766)에 맞춰 변경되었습니다.
2026-01-14 14:03:53,105 - INFO - ==================================================
2026-01-14 14:03:53,109 - INFO -   [탐색 21] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:03:53,168 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:53,169 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:53,173 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:01,962 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:02,265 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749547004698)에 맞춰 변경되었습니다.
2026-01-14 14:04:02,265 - INFO - ==================================================
2026-01-14 14:04:02,269 - INFO -   [탐색 22] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:04:02,385 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:02,387 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:02,390 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:10,983 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:11,211 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750727176665)에 맞춰 변경되었습니다.
2026-01-14 14:04:11,212 - INFO - ==================================================
2026-01-14 14:04:11,214 - INFO -   [탐색 23] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:04:11,258 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:11,259 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:11,261 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:19,944 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:20,303 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750137090682)에 맞춰 변경되었습니다.
2026-01-14 14:04:20,304 - INFO - ==================================================
2026-01-14 14:04:20,307 - INFO -   [탐색 24] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:04:20,362 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:20,363 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:20,367 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:28,406 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:28,872 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934374984204769)에 맞춰 변경되었습니다.
2026-01-14 14:04:28,873 - INFO - ==================================================
2026-01-14 14:04:28,876 - INFO -   [탐색 25] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:04:28,938 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:28,938 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:28,943 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:37,050 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:37,433 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749989569186)에 맞춰 변경되었습니다.
2026-01-14 14:04:37,434 - INFO - ==================================================
2026-01-14 14:04:37,437 - INFO -   [탐색 26] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:04:37,493 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:37,495 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:37,499 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:45,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:46,318 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750063329934)에 맞춰 변경되었습니다.
2026-01-14 14:04:46,318 - INFO - ==================================================
2026-01-14 14:04:46,322 - INFO -   [탐색 27] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:04:46,880 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:46,881 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:46,886 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:55,149 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:55,594 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375002644956)에 맞춰 변경되었습니다.
2026-01-14 14:04:55,595 - INFO - ==================================================
2026-01-14 14:04:55,600 - INFO -   [탐색 28] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:04:55,657 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:55,658 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:55,663 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:04,121 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:04,419 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750008009373)에 맞춰 변경되었습니다.
2026-01-14 14:05:04,419 - INFO - ==================================================
2026-01-14 14:05:04,422 - INFO -   [탐색 29] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:05:04,480 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:04,483 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:04,486 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:13,048 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:13,248 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749998789279)에 맞춰 변경되었습니다.
2026-01-14 14:05:13,248 - INFO - ==================================================
2026-01-14 14:05:13,251 - INFO -   [탐색 30] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:05:13,304 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:13,304 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:13,307 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:23,177 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:23,389 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750003399326)에 맞춰 변경되었습니다.
2026-01-14 14:05:23,389 - INFO - ==================================================
2026-01-14 14:05:23,391 - INFO -   [탐색 31] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:05:23,437 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:23,437 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:23,441 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:32,718 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:32,977 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750001094302)에 맞춰 변경되었습니다.
2026-01-14 14:05:32,977 - INFO - ==================================================
2026-01-14 14:05:32,979 - INFO -   [탐색 32] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:05:33,024 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:33,024 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:33,027 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:41,951 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:42,350 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999941791)에 맞춰 변경되었습니다.
2026-01-14 14:05:42,351 - INFO - ==================================================
2026-01-14 14:05:42,354 - INFO -   [탐색 33] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:05:42,414 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:42,415 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:42,420 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:51,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:51,842 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000518046)에 맞춰 변경되었습니다.
2026-01-14 14:05:51,842 - INFO - ==================================================
2026-01-14 14:05:51,848 - INFO -   [탐색 34] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:05:51,922 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:51,924 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:51,929 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:59,922 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:00,936 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000229918)에 맞춰 변경되었습니다.
2026-01-14 14:06:00,937 - INFO - ==================================================
2026-01-14 14:06:00,940 - INFO -   [탐색 35] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:06:01,020 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:01,021 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:01,027 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:09,963 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:10,290 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000085854)에 맞춰 변경되었습니다.
2026-01-14 14:06:10,290 - INFO - ==================================================
2026-01-14 14:06:10,293 - INFO -   [탐색 36] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:06:10,353 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:10,354 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:10,359 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:18,404 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:18,799 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000013822)에 맞춰 변경되었습니다.
2026-01-14 14:06:18,800 - INFO - ==================================================
2026-01-14 14:06:18,803 - INFO -   [탐색 37] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:06:18,863 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:18,864 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:18,868 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:28,370 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:28,793 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999977806)에 맞춰 변경되었습니다.
2026-01-14 14:06:28,793 - INFO - ==================================================
2026-01-14 14:06:28,795 - INFO -   [탐색 38] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:06:28,852 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:28,852 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:28,857 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:37,852 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:38,159 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999995814)에 맞춰 변경되었습니다.
2026-01-14 14:06:38,159 - INFO - ==================================================
2026-01-14 14:06:38,162 - INFO -   [탐색 39] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:06:38,211 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:38,212 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:38,215 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:46,351 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:47,020 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000004818)에 맞춰 변경되었습니다.
2026-01-14 14:06:47,021 - INFO - ==================================================
2026-01-14 14:06:47,024 - INFO -   [탐색 40] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:06:47,087 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:47,087 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:47,091 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:54,486 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:54,993 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000316)에 맞춰 변경되었습니다.
2026-01-14 14:06:54,994 - INFO - ==================================================
2026-01-14 14:06:54,996 - INFO -   [탐색 41] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:06:55,042 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:55,042 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:55,046 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:04,145 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:04,518 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999998066)에 맞춰 변경되었습니다.
2026-01-14 14:07:04,521 - INFO - ==================================================
2026-01-14 14:07:04,526 - INFO -   [탐색 42] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:07:04,593 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:04,593 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:04,597 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:13,408 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:14,065 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999191)에 맞춰 변경되었습니다.
2026-01-14 14:07:14,066 - INFO - ==================================================
2026-01-14 14:07:14,070 - INFO -   [탐색 43] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:07:14,125 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:14,126 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:14,131 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:22,743 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:23,146 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999753)에 맞춰 변경되었습니다.
2026-01-14 14:07:23,147 - INFO - ==================================================
2026-01-14 14:07:23,149 - INFO -   [탐색 44] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:07:23,286 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:23,286 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:23,297 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:32,216 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:32,714 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000035)에 맞춰 변경되었습니다.
2026-01-14 14:07:32,714 - INFO - ==================================================
2026-01-14 14:07:32,718 - INFO -   [탐색 45] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:07:32,777 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:32,778 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:32,782 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:41,075 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:41,637 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999894)에 맞춰 변경되었습니다.
2026-01-14 14:07:41,637 - INFO - ==================================================
2026-01-14 14:07:41,640 - INFO -   [탐색 46] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:07:41,689 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:41,690 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:41,694 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:50,134 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:50,529 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343749999999964)에 맞춰 변경되었습니다.
2026-01-14 14:07:50,529 - INFO - ==================================================
2026-01-14 14:07:50,531 - INFO -   [탐색 47] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:07:50,568 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:50,568 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:50,571 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:58,981 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:59,627 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:07:59,627 - INFO - ==================================================
2026-01-14 14:07:59,630 - INFO -   [탐색 48] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:07:59,689 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:59,689 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:59,693 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:08,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:08,850 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000017)에 맞춰 변경되었습니다.
2026-01-14 14:08:08,851 - INFO - ==================================================
2026-01-14 14:08:08,861 - INFO -   [탐색 49] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:08:08,993 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:08,993 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:08,999 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:17,844 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:18,460 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000008)에 맞춰 변경되었습니다.
2026-01-14 14:08:18,461 - INFO - ==================================================
2026-01-14 14:08:18,465 - INFO -   [탐색 50] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:08:18,528 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:18,528 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:18,533 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:26,297 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:26,754 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000004)에 맞춰 변경되었습니다.
2026-01-14 14:08:26,755 - INFO - ==================================================
2026-01-14 14:08:26,758 - INFO -   [탐색 51] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:08:26,816 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:26,816 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:26,821 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:35,533 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:36,371 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000002)에 맞춰 변경되었습니다.
2026-01-14 14:08:36,371 - INFO - ==================================================
2026-01-14 14:08:36,374 - INFO -   [탐색 52] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:08:36,430 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:36,430 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:36,435 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:46,871 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:47,300 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9343750000000001)에 맞춰 변경되었습니다.
2026-01-14 14:08:47,300 - INFO - ==================================================
2026-01-14 14:08:47,303 - INFO -   [탐색 53] 희소도: 0.9344 -> 파라미터: 0.0313M (감소율: 99.22%)
2026-01-14 14:08:47,418 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:47,418 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:47,423 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:55,774 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:56,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:08:56,177 - INFO - ==================================================
2026-01-14 14:08:56,180 - INFO -   [탐색 54] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:08:56,228 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:56,229 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:56,232 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:04,974 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:05,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:09:05,586 - INFO - ==================================================
2026-01-14 14:09:05,588 - INFO -   [탐색 55] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:09:05,714 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:05,714 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:05,721 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:13,951 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:14,281 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:09:14,282 - INFO - ==================================================
2026-01-14 14:09:14,285 - INFO -   [탐색 56] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:09:14,429 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:14,433 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:14,440 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:23,423 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:23,755 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:09:23,758 - INFO - ==================================================
2026-01-14 14:09:23,766 - INFO -   [탐색 57] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:09:23,839 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:23,840 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:23,843 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:33,113 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:34,117 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:09:34,117 - INFO - ==================================================
2026-01-14 14:09:34,127 - INFO -   [탐색 58] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:09:34,248 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:34,248 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:34,255 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:43,693 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:43,981 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:09:43,982 - INFO - ==================================================
2026-01-14 14:09:43,985 - INFO -   [탐색 59] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:09:44,038 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:44,038 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:44,044 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:53,467 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:53,784 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:09:53,785 - INFO - ==================================================
2026-01-14 14:09:53,788 - INFO -   [탐색 60] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:09:53,884 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:53,885 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:53,890 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:03,686 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:03,896 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:10:03,896 - INFO - ==================================================
2026-01-14 14:10:03,899 - INFO -   [탐색 61] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:10:03,957 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:03,958 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:03,960 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:13,690 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:13,913 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:10:13,914 - INFO - ==================================================
2026-01-14 14:10:13,916 - INFO -   [탐색 62] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:10:13,958 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:13,958 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:13,960 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:24,035 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:24,227 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:10:24,227 - INFO - ==================================================
2026-01-14 14:10:24,229 - INFO -   [탐색 63] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:10:24,273 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:24,273 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:24,276 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:33,586 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:33,888 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:10:33,888 - INFO - ==================================================
2026-01-14 14:10:33,890 - INFO -   [탐색 64] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:10:33,928 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:33,928 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:33,931 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:43,330 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:43,825 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:10:43,826 - INFO - ==================================================
2026-01-14 14:10:43,830 - INFO -   [탐색 65] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:10:43,872 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:43,873 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:43,876 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:52,670 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:53,031 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:10:53,031 - INFO - ==================================================
2026-01-14 14:10:53,034 - INFO -   [탐색 66] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:10:53,125 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:53,126 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:53,130 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:03,116 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:03,464 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:11:03,465 - INFO - ==================================================
2026-01-14 14:11:03,467 - INFO -   [탐색 67] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:11:03,525 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:03,525 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:03,530 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:12,253 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:12,639 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:11:12,640 - INFO - ==================================================
2026-01-14 14:11:12,643 - INFO -   [탐색 68] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:11:12,700 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:12,701 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:12,706 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:22,174 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:22,674 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:11:22,675 - INFO - ==================================================
2026-01-14 14:11:22,678 - INFO -   [탐색 69] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:11:22,741 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:22,742 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:22,747 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:31,483 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:31,770 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:11:31,772 - INFO - ==================================================
2026-01-14 14:11:31,775 - INFO -   [탐색 70] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:11:31,834 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:31,835 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:31,839 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:40,938 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:41,450 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:11:41,451 - INFO - ==================================================
2026-01-14 14:11:41,454 - INFO -   [탐색 71] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:11:41,655 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:41,655 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:41,704 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:49,814 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:50,123 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:11:50,124 - INFO - ==================================================
2026-01-14 14:11:50,126 - INFO -   [탐색 72] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:11:50,178 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:50,179 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:50,184 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:59,095 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:00,484 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:00,484 - INFO - ==================================================
2026-01-14 14:12:00,489 - INFO -   [탐색 73] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:00,551 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:00,552 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:00,557 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:08,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:09,245 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:09,246 - INFO - ==================================================
2026-01-14 14:12:09,252 - INFO -   [탐색 74] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:09,358 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:09,359 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:09,363 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:17,231 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:17,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:17,796 - INFO - ==================================================
2026-01-14 14:12:17,799 - INFO -   [탐색 75] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:17,856 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:17,856 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:17,861 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:27,206 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:27,556 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:27,557 - INFO - ==================================================
2026-01-14 14:12:27,559 - INFO -   [탐색 76] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:27,670 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:27,671 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:27,675 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:36,427 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:36,755 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:36,756 - INFO - ==================================================
2026-01-14 14:12:36,759 - INFO -   [탐색 77] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:36,824 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:36,825 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:36,829 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:45,838 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:46,127 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:46,128 - INFO - ==================================================
2026-01-14 14:12:46,130 - INFO -   [탐색 78] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:46,186 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:46,187 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:46,191 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:55,670 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:55,991 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:12:55,993 - INFO - ==================================================
2026-01-14 14:12:55,996 - INFO -   [탐색 79] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:12:56,057 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:56,058 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:56,063 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:04,681 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:05,445 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:13:05,446 - INFO - ==================================================
2026-01-14 14:13:05,454 - INFO -   [탐색 80] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:13:05,546 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:05,546 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:05,550 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:14,692 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:15,121 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:13:15,122 - INFO - ==================================================
2026-01-14 14:13:15,125 - INFO -   [탐색 81] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:13:15,220 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:15,220 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:15,224 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:24,191 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:24,598 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:13:24,599 - INFO - ==================================================
2026-01-14 14:13:24,602 - INFO -   [탐색 82] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:13:24,694 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:24,694 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:24,699 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:33,573 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:33,896 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:13:33,897 - INFO - ==================================================
2026-01-14 14:13:33,900 - INFO -   [탐색 83] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:13:33,964 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:33,965 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:33,969 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:42,115 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:42,761 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:13:42,761 - INFO - ==================================================
2026-01-14 14:13:42,767 - INFO -   [탐색 84] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:13:42,831 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:42,831 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:42,835 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:51,437 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:51,729 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:13:51,732 - INFO - ==================================================
2026-01-14 14:13:51,736 - INFO -   [탐색 85] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:13:51,935 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:51,936 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:51,940 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:01,053 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:01,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:14:01,444 - INFO - ==================================================
2026-01-14 14:14:01,556 - INFO -   [탐색 86] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:14:01,637 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:01,638 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:01,642 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:09,919 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:10,229 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:14:10,230 - INFO - ==================================================
2026-01-14 14:14:10,235 - INFO -   [탐색 87] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:14:10,616 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:10,616 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:10,620 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:20,472 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:20,806 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:14:20,807 - INFO - ==================================================
2026-01-14 14:14:20,813 - INFO -   [탐색 88] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:14:20,870 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:20,871 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:20,875 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:30,161 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:30,680 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:14:30,680 - INFO - ==================================================
2026-01-14 14:14:30,689 - INFO -   [탐색 89] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:14:30,757 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:30,759 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:30,764 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:40,031 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:40,435 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:14:40,435 - INFO - ==================================================
2026-01-14 14:14:40,438 - INFO -   [탐색 90] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:14:40,482 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:40,482 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:40,485 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:49,786 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:50,097 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:14:50,098 - INFO - ==================================================
2026-01-14 14:14:50,102 - INFO -   [탐색 91] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:14:50,164 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:50,164 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:50,167 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:59,962 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:00,286 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:00,287 - INFO - ==================================================
2026-01-14 14:15:00,289 - INFO -   [탐색 92] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:00,330 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:00,330 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:00,332 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:09,190 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:09,517 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:09,518 - INFO - ==================================================
2026-01-14 14:15:09,521 - INFO -   [탐색 93] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:09,563 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:09,564 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:09,567 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:18,529 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:18,932 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:18,932 - INFO - ==================================================
2026-01-14 14:15:18,935 - INFO -   [탐색 94] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:19,064 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:19,064 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:19,069 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:27,563 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:28,315 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:28,316 - INFO - ==================================================
2026-01-14 14:15:28,319 - INFO -   [탐색 95] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:28,373 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:28,374 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:28,377 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:36,451 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:36,956 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:36,957 - INFO - ==================================================
2026-01-14 14:15:36,960 - INFO -   [탐색 96] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:37,018 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:37,019 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:37,023 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:45,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:46,195 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:46,196 - INFO - ==================================================
2026-01-14 14:15:46,199 - INFO -   [탐색 97] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:46,248 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:46,249 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:46,253 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:55,463 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:55,845 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:15:55,845 - INFO - ==================================================
2026-01-14 14:15:55,848 - INFO -   [탐색 98] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:15:55,906 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:55,906 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:55,910 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:03,845 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:04,369 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:16:04,371 - INFO - ==================================================
2026-01-14 14:16:04,374 - INFO -   [탐색 99] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:16:04,433 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:04,434 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:04,439 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:13,300 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:14,009 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.934375)에 맞춰 변경되었습니다.
2026-01-14 14:16:14,010 - INFO - ==================================================
2026-01-14 14:16:14,014 - INFO -   [탐색 100] 희소도: 0.9344 -> 파라미터: 0.0315M (감소율: 99.22%)
2026-01-14 14:16:14,015 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9344 입니다.
2026-01-14 14:16:14,015 - INFO - ================================================================================
2026-01-14 14:16:14,024 - INFO - 계산된 Pruning 정보(희소도: 0.9344)를 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/pruning_info.yaml'에 저장했습니다.
2026-01-14 14:16:14,100 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 14:16:14,315 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:14,316 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:14,320 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:22,705 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:23,230 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 14:16:23,231 - INFO - ==================================================
2026-01-14 14:16:23,234 - INFO - ==================================================
2026-01-14 14:16:23,234 - INFO - 모델 파라미터 수:
2026-01-14 14:16:23,235 - INFO -   - 총 파라미터: 31,288 개
2026-01-14 14:16:23,235 - INFO -   - 학습 가능한 파라미터: 31,288 개
2026-01-14 14:16:23,363 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 14:16:23,509 - INFO - FLOPs가 0.8277 GFLOPs에서 0.0120 GFLOPs로 감소했습니다 (감소율: 98.55%).
2026-01-14 14:16:23,510 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 14:16:23,510 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:16:23,513 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 14:16:23,513 - INFO - ==================================================
2026-01-14 14:16:23,514 - INFO - train 모드를 시작합니다.
2026-01-14 14:16:23,515 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:16:23,515 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:16:23,516 - INFO - --------------------------------------------------
2026-01-14 14:16:23,519 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 14:16:32,380 - INFO - [Train] [11/90] | Loss: 0.6232 | Train Acc: 70.83%
2026-01-14 14:16:35,029 - INFO - [Valid] [11/90] | Loss: 0.5457 | Val Acc: 76.40%
2026-01-14 14:16:35,042 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.6752 | F1: 0.7260
2026-01-14 14:16:35,042 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.8407 | F1: 0.7927
2026-01-14 14:16:35,095 - INFO - [Best Model Saved] (val loss: 0.5457) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:16:35,096 - INFO - --------------------------------------------------
2026-01-14 14:16:35,101 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 14:16:45,254 - INFO - [Train] [12/90] | Loss: 0.5460 | Train Acc: 76.34%
2026-01-14 14:16:47,869 - INFO - [Valid] [12/90] | Loss: 0.5187 | Val Acc: 78.47%
2026-01-14 14:16:47,882 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.7580 | F1: 0.7653
2026-01-14 14:16:47,883 - INFO - [Metrics for 'normal'] | Precision: 0.7946 | Recall: 0.8077 | F1: 0.8011
2026-01-14 14:16:48,009 - INFO - [Best Model Saved] (val loss: 0.5187) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:16:48,010 - INFO - --------------------------------------------------
2026-01-14 14:16:48,013 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 14:16:56,338 - INFO - [Train] [13/90] | Loss: 0.5234 | Train Acc: 78.87%
2026-01-14 14:17:00,041 - INFO - [Valid] [13/90] | Loss: 0.5234 | Val Acc: 80.24%
2026-01-14 14:17:00,056 - INFO - [Metrics for 'abnormal'] | Precision: 0.8169 | Recall: 0.7389 | F1: 0.7759
2026-01-14 14:17:00,057 - INFO - [Metrics for 'normal'] | Precision: 0.7919 | Recall: 0.8571 | F1: 0.8232
2026-01-14 14:17:00,061 - INFO - --------------------------------------------------
2026-01-14 14:17:00,065 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 14:17:09,292 - INFO - [Train] [14/90] | Loss: 0.5124 | Train Acc: 79.76%
2026-01-14 14:17:12,050 - INFO - [Valid] [14/90] | Loss: 0.5225 | Val Acc: 80.24%
2026-01-14 14:17:12,073 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 14:17:12,073 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 14:17:12,083 - INFO - --------------------------------------------------
2026-01-14 14:17:12,089 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 14:17:20,055 - INFO - [Train] [15/90] | Loss: 0.5028 | Train Acc: 80.95%
2026-01-14 14:17:23,998 - INFO - [Valid] [15/90] | Loss: 0.5034 | Val Acc: 80.53%
2026-01-14 14:17:24,040 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-01-14 14:17:24,042 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-01-14 14:17:24,394 - INFO - [Best Model Saved] (val loss: 0.5034) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:17:24,395 - INFO - --------------------------------------------------
2026-01-14 14:17:24,397 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 14:17:33,413 - INFO - [Train] [16/90] | Loss: 0.4914 | Train Acc: 80.73%
2026-01-14 14:17:35,515 - INFO - [Valid] [16/90] | Loss: 0.5037 | Val Acc: 79.94%
2026-01-14 14:17:35,528 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 14:17:35,529 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 14:17:35,533 - INFO - --------------------------------------------------
2026-01-14 14:17:35,537 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 14:17:44,516 - INFO - [Train] [17/90] | Loss: 0.4809 | Train Acc: 82.44%
2026-01-14 14:17:46,862 - INFO - [Valid] [17/90] | Loss: 0.4927 | Val Acc: 82.89%
2026-01-14 14:17:46,884 - INFO - [Metrics for 'abnormal'] | Precision: 0.8367 | Recall: 0.7834 | F1: 0.8092
2026-01-14 14:17:46,884 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.8681 | F1: 0.8449
2026-01-14 14:17:46,964 - INFO - [Best Model Saved] (val loss: 0.4927) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:17:46,969 - INFO - --------------------------------------------------
2026-01-14 14:17:46,971 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 14:17:56,347 - INFO - [Train] [18/90] | Loss: 0.4833 | Train Acc: 81.47%
2026-01-14 14:17:59,579 - INFO - [Valid] [18/90] | Loss: 0.5034 | Val Acc: 79.35%
2026-01-14 14:17:59,592 - INFO - [Metrics for 'abnormal'] | Precision: 0.8222 | Recall: 0.7070 | F1: 0.7603
2026-01-14 14:17:59,593 - INFO - [Metrics for 'normal'] | Precision: 0.7745 | Recall: 0.8681 | F1: 0.8187
2026-01-14 14:17:59,599 - INFO - --------------------------------------------------
2026-01-14 14:17:59,603 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 14:18:08,996 - INFO - [Train] [19/90] | Loss: 0.4761 | Train Acc: 81.62%
2026-01-14 14:18:12,819 - INFO - [Valid] [19/90] | Loss: 0.5229 | Val Acc: 77.88%
2026-01-14 14:18:12,831 - INFO - [Metrics for 'abnormal'] | Precision: 0.7531 | Recall: 0.7771 | F1: 0.7649
2026-01-14 14:18:12,832 - INFO - [Metrics for 'normal'] | Precision: 0.8023 | Recall: 0.7802 | F1: 0.7911
2026-01-14 14:18:12,868 - INFO - --------------------------------------------------
2026-01-14 14:18:12,871 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 14:18:21,812 - INFO - [Train] [20/90] | Loss: 0.4709 | Train Acc: 81.77%
2026-01-14 14:18:24,775 - INFO - [Valid] [20/90] | Loss: 0.5184 | Val Acc: 79.65%
2026-01-14 14:18:24,857 - INFO - [Metrics for 'abnormal'] | Precision: 0.7973 | Recall: 0.7516 | F1: 0.7738
2026-01-14 14:18:24,857 - INFO - [Metrics for 'normal'] | Precision: 0.7958 | Recall: 0.8352 | F1: 0.8150
2026-01-14 14:18:24,861 - INFO - --------------------------------------------------
2026-01-14 14:18:24,864 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 14:18:34,233 - INFO - [Train] [21/90] | Loss: 0.4636 | Train Acc: 82.37%
2026-01-14 14:18:36,843 - INFO - [Valid] [21/90] | Loss: 0.5114 | Val Acc: 79.06%
2026-01-14 14:18:36,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 14:18:36,854 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 14:18:36,859 - INFO - --------------------------------------------------
2026-01-14 14:18:36,862 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 14:18:46,775 - INFO - [Train] [22/90] | Loss: 0.4724 | Train Acc: 83.11%
2026-01-14 14:18:48,508 - INFO - [Valid] [22/90] | Loss: 0.5014 | Val Acc: 80.24%
2026-01-14 14:18:48,518 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 14:18:48,519 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 14:18:48,523 - INFO - --------------------------------------------------
2026-01-14 14:18:48,525 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 14:18:58,562 - INFO - [Train] [23/90] | Loss: 0.4587 | Train Acc: 82.81%
2026-01-14 14:19:00,277 - INFO - [Valid] [23/90] | Loss: 0.5156 | Val Acc: 81.12%
2026-01-14 14:19:00,289 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.8471 | F1: 0.8061
2026-01-14 14:19:00,289 - INFO - [Metrics for 'normal'] | Precision: 0.8554 | Recall: 0.7802 | F1: 0.8161
2026-01-14 14:19:00,293 - INFO - --------------------------------------------------
2026-01-14 14:19:00,295 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 14:19:10,109 - INFO - [Train] [24/90] | Loss: 0.4513 | Train Acc: 84.08%
2026-01-14 14:19:12,170 - INFO - [Valid] [24/90] | Loss: 0.5503 | Val Acc: 78.17%
2026-01-14 14:19:12,192 - INFO - [Metrics for 'abnormal'] | Precision: 0.7546 | Recall: 0.7834 | F1: 0.7688
2026-01-14 14:19:12,195 - INFO - [Metrics for 'normal'] | Precision: 0.8068 | Recall: 0.7802 | F1: 0.7933
2026-01-14 14:19:12,203 - INFO - --------------------------------------------------
2026-01-14 14:19:12,209 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 14:19:21,140 - INFO - [Train] [25/90] | Loss: 0.4469 | Train Acc: 84.38%
2026-01-14 14:19:23,420 - INFO - [Valid] [25/90] | Loss: 0.5156 | Val Acc: 78.76%
2026-01-14 14:19:23,477 - INFO - [Metrics for 'abnormal'] | Precision: 0.7545 | Recall: 0.8025 | F1: 0.7778
2026-01-14 14:19:23,477 - INFO - [Metrics for 'normal'] | Precision: 0.8198 | Recall: 0.7747 | F1: 0.7966
2026-01-14 14:19:23,481 - INFO - --------------------------------------------------
2026-01-14 14:19:23,485 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 14:19:32,731 - INFO - [Train] [26/90] | Loss: 0.4379 | Train Acc: 84.08%
2026-01-14 14:19:34,832 - INFO - [Valid] [26/90] | Loss: 0.5001 | Val Acc: 78.76%
2026-01-14 14:19:34,851 - INFO - [Metrics for 'abnormal'] | Precision: 0.7931 | Recall: 0.7325 | F1: 0.7616
2026-01-14 14:19:34,857 - INFO - [Metrics for 'normal'] | Precision: 0.7835 | Recall: 0.8352 | F1: 0.8085
2026-01-14 14:19:34,870 - INFO - --------------------------------------------------
2026-01-14 14:19:34,879 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 14:19:44,748 - INFO - [Train] [27/90] | Loss: 0.4427 | Train Acc: 85.34%
2026-01-14 14:19:46,914 - INFO - [Valid] [27/90] | Loss: 0.4878 | Val Acc: 81.12%
2026-01-14 14:19:46,927 - INFO - [Metrics for 'abnormal'] | Precision: 0.7657 | Recall: 0.8535 | F1: 0.8072
2026-01-14 14:19:46,927 - INFO - [Metrics for 'normal'] | Precision: 0.8598 | Recall: 0.7747 | F1: 0.8150
2026-01-14 14:19:46,979 - INFO - [Best Model Saved] (val loss: 0.4878) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:19:46,980 - INFO - --------------------------------------------------
2026-01-14 14:19:46,983 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 14:19:56,869 - INFO - [Train] [28/90] | Loss: 0.4436 | Train Acc: 84.52%
2026-01-14 14:19:58,915 - INFO - [Valid] [28/90] | Loss: 0.5169 | Val Acc: 79.06%
2026-01-14 14:19:58,927 - INFO - [Metrics for 'abnormal'] | Precision: 0.7905 | Recall: 0.7452 | F1: 0.7672
2026-01-14 14:19:58,927 - INFO - [Metrics for 'normal'] | Precision: 0.7906 | Recall: 0.8297 | F1: 0.8097
2026-01-14 14:19:58,931 - INFO - --------------------------------------------------
2026-01-14 14:19:58,934 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 14:20:09,460 - INFO - [Train] [29/90] | Loss: 0.4330 | Train Acc: 84.97%
2026-01-14 14:20:11,336 - INFO - [Valid] [29/90] | Loss: 0.5318 | Val Acc: 77.88%
2026-01-14 14:20:11,356 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.7389 | F1: 0.7557
2026-01-14 14:20:11,362 - INFO - [Metrics for 'normal'] | Precision: 0.7831 | Recall: 0.8132 | F1: 0.7978
2026-01-14 14:20:11,367 - INFO - --------------------------------------------------
2026-01-14 14:20:11,372 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 14:20:21,062 - INFO - [Train] [30/90] | Loss: 0.4278 | Train Acc: 84.82%
2026-01-14 14:20:23,056 - INFO - [Valid] [30/90] | Loss: 0.5069 | Val Acc: 78.76%
2026-01-14 14:20:23,067 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 14:20:23,068 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 14:20:23,072 - INFO - --------------------------------------------------
2026-01-14 14:20:23,075 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 14:20:32,060 - INFO - [Train] [31/90] | Loss: 0.4056 | Train Acc: 87.20%
2026-01-14 14:20:34,412 - INFO - [Valid] [31/90] | Loss: 0.5068 | Val Acc: 80.83%
2026-01-14 14:20:34,426 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 14:20:34,427 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 14:20:34,430 - INFO - --------------------------------------------------
2026-01-14 14:20:34,432 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 14:20:44,233 - INFO - [Train] [32/90] | Loss: 0.4254 | Train Acc: 86.16%
2026-01-14 14:20:46,968 - INFO - [Valid] [32/90] | Loss: 0.4741 | Val Acc: 83.48%
2026-01-14 14:20:46,981 - INFO - [Metrics for 'abnormal'] | Precision: 0.8024 | Recall: 0.8535 | F1: 0.8272
2026-01-14 14:20:46,981 - INFO - [Metrics for 'normal'] | Precision: 0.8663 | Recall: 0.8187 | F1: 0.8418
2026-01-14 14:20:47,032 - INFO - [Best Model Saved] (val loss: 0.4741) -> 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:20:47,033 - INFO - --------------------------------------------------
2026-01-14 14:20:47,036 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 14:20:55,272 - INFO - [Train] [33/90] | Loss: 0.4197 | Train Acc: 86.24%
2026-01-14 14:20:58,345 - INFO - [Valid] [33/90] | Loss: 0.5156 | Val Acc: 79.94%
2026-01-14 14:20:58,361 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-01-14 14:20:58,361 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-01-14 14:20:58,368 - INFO - --------------------------------------------------
2026-01-14 14:20:58,373 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 14:21:07,331 - INFO - [Train] [34/90] | Loss: 0.4092 | Train Acc: 86.46%
2026-01-14 14:21:10,485 - INFO - [Valid] [34/90] | Loss: 0.5282 | Val Acc: 79.94%
2026-01-14 14:21:10,517 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-01-14 14:21:10,519 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-01-14 14:21:10,527 - INFO - --------------------------------------------------
2026-01-14 14:21:10,533 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 14:21:19,616 - INFO - [Train] [35/90] | Loss: 0.3978 | Train Acc: 88.32%
2026-01-14 14:21:22,684 - INFO - [Valid] [35/90] | Loss: 0.5238 | Val Acc: 79.94%
2026-01-14 14:21:22,698 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-01-14 14:21:22,698 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-01-14 14:21:22,704 - INFO - --------------------------------------------------
2026-01-14 14:21:22,707 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 14:21:31,323 - INFO - [Train] [36/90] | Loss: 0.4080 | Train Acc: 86.61%
2026-01-14 14:21:34,071 - INFO - [Valid] [36/90] | Loss: 0.5245 | Val Acc: 80.24%
2026-01-14 14:21:34,090 - INFO - [Metrics for 'abnormal'] | Precision: 0.7812 | Recall: 0.7962 | F1: 0.7886
2026-01-14 14:21:34,090 - INFO - [Metrics for 'normal'] | Precision: 0.8212 | Recall: 0.8077 | F1: 0.8144
2026-01-14 14:21:34,096 - INFO - --------------------------------------------------
2026-01-14 14:21:34,099 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 14:21:42,556 - INFO - [Train] [37/90] | Loss: 0.4022 | Train Acc: 87.72%
2026-01-14 14:21:45,158 - INFO - [Valid] [37/90] | Loss: 0.5498 | Val Acc: 78.76%
2026-01-14 14:21:45,171 - INFO - [Metrics for 'abnormal'] | Precision: 0.7815 | Recall: 0.7516 | F1: 0.7662
2026-01-14 14:21:45,172 - INFO - [Metrics for 'normal'] | Precision: 0.7926 | Recall: 0.8187 | F1: 0.8054
2026-01-14 14:21:45,176 - INFO - --------------------------------------------------
2026-01-14 14:21:45,179 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 14:21:54,525 - INFO - [Train] [38/90] | Loss: 0.3999 | Train Acc: 88.10%
2026-01-14 14:21:57,702 - INFO - [Valid] [38/90] | Loss: 0.5262 | Val Acc: 81.12%
2026-01-14 14:21:57,738 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 14:21:57,739 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 14:21:57,745 - INFO - --------------------------------------------------
2026-01-14 14:21:57,755 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 14:22:07,587 - INFO - [Train] [39/90] | Loss: 0.3785 | Train Acc: 88.47%
2026-01-14 14:22:11,161 - INFO - [Valid] [39/90] | Loss: 0.5393 | Val Acc: 79.65%
2026-01-14 14:22:11,189 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-01-14 14:22:11,189 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-01-14 14:22:11,219 - INFO - --------------------------------------------------
2026-01-14 14:22:11,222 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 14:22:19,478 - INFO - [Train] [40/90] | Loss: 0.3992 | Train Acc: 87.28%
2026-01-14 14:22:21,873 - INFO - [Valid] [40/90] | Loss: 0.4986 | Val Acc: 81.12%
2026-01-14 14:22:21,899 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 14:22:21,900 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 14:22:21,909 - INFO - --------------------------------------------------
2026-01-14 14:22:21,915 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 14:22:31,884 - INFO - [Train] [41/90] | Loss: 0.3900 | Train Acc: 88.39%
2026-01-14 14:22:34,676 - INFO - [Valid] [41/90] | Loss: 0.5301 | Val Acc: 78.47%
2026-01-14 14:22:34,687 - INFO - [Metrics for 'abnormal'] | Precision: 0.7360 | Recall: 0.8344 | F1: 0.7821
2026-01-14 14:22:34,688 - INFO - [Metrics for 'normal'] | Precision: 0.8385 | Recall: 0.7418 | F1: 0.7872
2026-01-14 14:22:34,692 - INFO - --------------------------------------------------
2026-01-14 14:22:34,696 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 14:22:44,022 - INFO - [Train] [42/90] | Loss: 0.3830 | Train Acc: 88.84%
2026-01-14 14:22:46,674 - INFO - [Valid] [42/90] | Loss: 0.5455 | Val Acc: 77.88%
2026-01-14 14:22:46,687 - INFO - [Metrics for 'abnormal'] | Precision: 0.7562 | Recall: 0.7707 | F1: 0.7634
2026-01-14 14:22:46,687 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.7857 | F1: 0.7922
2026-01-14 14:22:46,692 - INFO - --------------------------------------------------
2026-01-14 14:22:46,695 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 14:22:55,495 - INFO - [Train] [43/90] | Loss: 0.3821 | Train Acc: 89.43%
2026-01-14 14:22:57,818 - INFO - [Valid] [43/90] | Loss: 0.5385 | Val Acc: 80.53%
2026-01-14 14:22:57,830 - INFO - [Metrics for 'abnormal'] | Precision: 0.7433 | Recall: 0.8854 | F1: 0.8081
2026-01-14 14:22:57,831 - INFO - [Metrics for 'normal'] | Precision: 0.8816 | Recall: 0.7363 | F1: 0.8024
2026-01-14 14:22:57,834 - INFO - --------------------------------------------------
2026-01-14 14:22:57,837 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 14:23:05,994 - INFO - [Train] [44/90] | Loss: 0.3818 | Train Acc: 88.39%
2026-01-14 14:23:08,348 - INFO - [Valid] [44/90] | Loss: 0.5410 | Val Acc: 79.94%
2026-01-14 14:23:08,360 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 14:23:08,361 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 14:23:08,365 - INFO - --------------------------------------------------
2026-01-14 14:23:08,368 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 14:23:17,475 - INFO - [Train] [45/90] | Loss: 0.3761 | Train Acc: 89.51%
2026-01-14 14:23:21,040 - INFO - [Valid] [45/90] | Loss: 0.5502 | Val Acc: 81.12%
2026-01-14 14:23:21,170 - INFO - [Metrics for 'abnormal'] | Precision: 0.8121 | Recall: 0.7707 | F1: 0.7908
2026-01-14 14:23:21,171 - INFO - [Metrics for 'normal'] | Precision: 0.8105 | Recall: 0.8462 | F1: 0.8280
2026-01-14 14:23:21,174 - INFO - --------------------------------------------------
2026-01-14 14:23:21,178 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 14:23:30,884 - INFO - [Train] [46/90] | Loss: 0.3692 | Train Acc: 90.03%
2026-01-14 14:23:33,519 - INFO - [Valid] [46/90] | Loss: 0.5476 | Val Acc: 79.06%
2026-01-14 14:23:33,535 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-01-14 14:23:33,537 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-01-14 14:23:33,542 - INFO - --------------------------------------------------
2026-01-14 14:23:33,545 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 14:23:42,837 - INFO - [Train] [47/90] | Loss: 0.3678 | Train Acc: 90.85%
2026-01-14 14:23:46,015 - INFO - [Valid] [47/90] | Loss: 0.5482 | Val Acc: 81.12%
2026-01-14 14:23:46,028 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 14:23:46,028 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 14:23:46,258 - INFO - --------------------------------------------------
2026-01-14 14:23:46,260 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 14:23:55,677 - INFO - [Train] [48/90] | Loss: 0.3676 | Train Acc: 90.18%
2026-01-14 14:23:58,226 - INFO - [Valid] [48/90] | Loss: 0.5382 | Val Acc: 80.24%
2026-01-14 14:23:58,239 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-01-14 14:23:58,239 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-01-14 14:23:58,243 - INFO - --------------------------------------------------
2026-01-14 14:23:58,245 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 14:24:07,949 - INFO - [Train] [49/90] | Loss: 0.3600 | Train Acc: 91.00%
2026-01-14 14:24:10,311 - INFO - [Valid] [49/90] | Loss: 0.5342 | Val Acc: 82.60%
2026-01-14 14:24:10,322 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.8025 | F1: 0.8103
2026-01-14 14:24:10,322 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8462 | F1: 0.8392
2026-01-14 14:24:10,326 - INFO - --------------------------------------------------
2026-01-14 14:24:10,329 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 14:24:19,322 - INFO - [Train] [50/90] | Loss: 0.3543 | Train Acc: 91.00%
2026-01-14 14:24:21,793 - INFO - [Valid] [50/90] | Loss: 0.5417 | Val Acc: 79.94%
2026-01-14 14:24:21,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8535 | F1: 0.7976
2026-01-14 14:24:21,809 - INFO - [Metrics for 'normal'] | Precision: 0.8562 | Recall: 0.7527 | F1: 0.8012
2026-01-14 14:24:21,813 - INFO - --------------------------------------------------
2026-01-14 14:24:21,816 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 14:24:31,161 - INFO - [Train] [51/90] | Loss: 0.3381 | Train Acc: 91.67%
2026-01-14 14:24:33,357 - INFO - [Valid] [51/90] | Loss: 0.5245 | Val Acc: 82.30%
2026-01-14 14:24:33,375 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8662 | F1: 0.8193
2026-01-14 14:24:33,376 - INFO - [Metrics for 'normal'] | Precision: 0.8720 | Recall: 0.7857 | F1: 0.8266
2026-01-14 14:24:33,384 - INFO - --------------------------------------------------
2026-01-14 14:24:33,387 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 14:24:42,796 - INFO - [Train] [52/90] | Loss: 0.3417 | Train Acc: 91.59%
2026-01-14 14:24:45,060 - INFO - [Valid] [52/90] | Loss: 0.5202 | Val Acc: 83.78%
2026-01-14 14:24:45,106 - INFO - [Metrics for 'abnormal'] | Precision: 0.8110 | Recall: 0.8471 | F1: 0.8287
2026-01-14 14:24:45,106 - INFO - [Metrics for 'normal'] | Precision: 0.8629 | Recall: 0.8297 | F1: 0.8459
2026-01-14 14:24:45,112 - INFO - --------------------------------------------------
2026-01-14 14:24:45,115 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 14:24:54,253 - INFO - [Train] [53/90] | Loss: 0.3678 | Train Acc: 89.43%
2026-01-14 14:24:56,956 - INFO - [Valid] [53/90] | Loss: 0.5376 | Val Acc: 81.12%
2026-01-14 14:24:56,975 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-01-14 14:24:56,977 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-01-14 14:24:56,984 - INFO - --------------------------------------------------
2026-01-14 14:24:56,988 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 14:25:05,809 - INFO - [Train] [54/90] | Loss: 0.3539 | Train Acc: 91.52%
2026-01-14 14:25:08,045 - INFO - [Valid] [54/90] | Loss: 0.5112 | Val Acc: 82.01%
2026-01-14 14:25:08,058 - INFO - [Metrics for 'abnormal'] | Precision: 0.8077 | Recall: 0.8025 | F1: 0.8051
2026-01-14 14:25:08,059 - INFO - [Metrics for 'normal'] | Precision: 0.8306 | Recall: 0.8352 | F1: 0.8329
2026-01-14 14:25:08,064 - INFO - --------------------------------------------------
2026-01-14 14:25:08,067 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 14:25:16,422 - INFO - [Train] [55/90] | Loss: 0.3469 | Train Acc: 90.55%
2026-01-14 14:25:18,976 - INFO - [Valid] [55/90] | Loss: 0.5270 | Val Acc: 84.37%
2026-01-14 14:25:18,989 - INFO - [Metrics for 'abnormal'] | Precision: 0.8133 | Recall: 0.8599 | F1: 0.8359
2026-01-14 14:25:18,989 - INFO - [Metrics for 'normal'] | Precision: 0.8728 | Recall: 0.8297 | F1: 0.8507
2026-01-14 14:25:18,994 - INFO - --------------------------------------------------
2026-01-14 14:25:18,997 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 14:25:28,103 - INFO - [Train] [56/90] | Loss: 0.3268 | Train Acc: 93.01%
2026-01-14 14:25:30,218 - INFO - [Valid] [56/90] | Loss: 0.5240 | Val Acc: 82.30%
2026-01-14 14:25:30,229 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8662 | F1: 0.8193
2026-01-14 14:25:30,230 - INFO - [Metrics for 'normal'] | Precision: 0.8720 | Recall: 0.7857 | F1: 0.8266
2026-01-14 14:25:30,235 - INFO - --------------------------------------------------
2026-01-14 14:25:30,238 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 14:25:40,135 - INFO - [Train] [57/90] | Loss: 0.3216 | Train Acc: 93.82%
2026-01-14 14:25:42,155 - INFO - [Valid] [57/90] | Loss: 0.5637 | Val Acc: 80.24%
2026-01-14 14:25:42,180 - INFO - [Metrics for 'abnormal'] | Precision: 0.7528 | Recall: 0.8535 | F1: 0.8000
2026-01-14 14:25:42,180 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.7582 | F1: 0.8047
2026-01-14 14:25:42,190 - INFO - --------------------------------------------------
2026-01-14 14:25:42,196 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 14:25:51,847 - INFO - [Train] [58/90] | Loss: 0.3383 | Train Acc: 91.59%
2026-01-14 14:25:54,070 - INFO - [Valid] [58/90] | Loss: 0.5459 | Val Acc: 82.01%
2026-01-14 14:25:54,102 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-01-14 14:25:54,110 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-01-14 14:25:54,116 - INFO - --------------------------------------------------
2026-01-14 14:25:54,121 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 14:26:03,351 - INFO - [Train] [59/90] | Loss: 0.3188 | Train Acc: 93.45%
2026-01-14 14:26:05,573 - INFO - [Valid] [59/90] | Loss: 0.5601 | Val Acc: 81.12%
2026-01-14 14:26:05,587 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 14:26:05,588 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 14:26:05,593 - INFO - --------------------------------------------------
2026-01-14 14:26:05,597 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 14:26:14,749 - INFO - [Train] [60/90] | Loss: 0.3087 | Train Acc: 93.90%
2026-01-14 14:26:16,854 - INFO - [Valid] [60/90] | Loss: 0.5315 | Val Acc: 80.24%
2026-01-14 14:26:16,864 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 14:26:16,865 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 14:26:16,868 - INFO - --------------------------------------------------
2026-01-14 14:26:16,870 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 14:26:26,908 - INFO - [Train] [61/90] | Loss: 0.3123 | Train Acc: 93.68%
2026-01-14 14:26:28,734 - INFO - [Valid] [61/90] | Loss: 0.5559 | Val Acc: 81.12%
2026-01-14 14:26:28,750 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 14:26:28,751 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 14:26:28,758 - INFO - --------------------------------------------------
2026-01-14 14:26:28,761 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 14:26:39,350 - INFO - [Train] [62/90] | Loss: 0.2975 | Train Acc: 94.72%
2026-01-14 14:26:41,288 - INFO - [Valid] [62/90] | Loss: 0.5454 | Val Acc: 81.12%
2026-01-14 14:26:41,298 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 14:26:41,299 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 14:26:41,310 - INFO - --------------------------------------------------
2026-01-14 14:26:41,313 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 14:26:51,482 - INFO - [Train] [63/90] | Loss: 0.3095 | Train Acc: 93.90%
2026-01-14 14:26:54,353 - INFO - [Valid] [63/90] | Loss: 0.5325 | Val Acc: 79.06%
2026-01-14 14:26:54,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7722 | Recall: 0.7771 | F1: 0.7746
2026-01-14 14:26:54,376 - INFO - [Metrics for 'normal'] | Precision: 0.8066 | Recall: 0.8022 | F1: 0.8044
2026-01-14 14:26:54,384 - INFO - --------------------------------------------------
2026-01-14 14:26:54,388 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 14:27:03,665 - INFO - [Train] [64/90] | Loss: 0.3047 | Train Acc: 94.57%
2026-01-14 14:27:05,758 - INFO - [Valid] [64/90] | Loss: 0.5614 | Val Acc: 80.24%
2026-01-14 14:27:05,770 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 14:27:05,771 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 14:27:05,776 - INFO - --------------------------------------------------
2026-01-14 14:27:05,779 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 14:27:15,602 - INFO - [Train] [65/90] | Loss: 0.3052 | Train Acc: 94.87%
2026-01-14 14:27:17,992 - INFO - [Valid] [65/90] | Loss: 0.5256 | Val Acc: 81.12%
2026-01-14 14:27:18,004 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 14:27:18,005 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 14:27:18,009 - INFO - --------------------------------------------------
2026-01-14 14:27:18,012 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 14:27:28,172 - INFO - [Train] [66/90] | Loss: 0.3156 | Train Acc: 93.38%
2026-01-14 14:27:31,312 - INFO - [Valid] [66/90] | Loss: 0.5446 | Val Acc: 83.19%
2026-01-14 14:27:31,374 - INFO - [Metrics for 'abnormal'] | Precision: 0.8205 | Recall: 0.8153 | F1: 0.8179
2026-01-14 14:27:31,377 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.8462 | F1: 0.8438
2026-01-14 14:27:31,386 - INFO - --------------------------------------------------
2026-01-14 14:27:31,392 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 14:27:41,865 - INFO - [Train] [67/90] | Loss: 0.2918 | Train Acc: 94.87%
2026-01-14 14:27:44,789 - INFO - [Valid] [67/90] | Loss: 0.5703 | Val Acc: 82.01%
2026-01-14 14:27:44,809 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-01-14 14:27:44,810 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-01-14 14:27:44,820 - INFO - --------------------------------------------------
2026-01-14 14:27:44,827 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 14:27:53,608 - INFO - [Train] [68/90] | Loss: 0.2990 | Train Acc: 94.94%
2026-01-14 14:27:56,883 - INFO - [Valid] [68/90] | Loss: 0.5691 | Val Acc: 79.94%
2026-01-14 14:27:56,894 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 14:27:56,895 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 14:27:56,898 - INFO - --------------------------------------------------
2026-01-14 14:27:56,900 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 14:28:06,204 - INFO - [Train] [69/90] | Loss: 0.2898 | Train Acc: 94.94%
2026-01-14 14:28:09,451 - INFO - [Valid] [69/90] | Loss: 0.5449 | Val Acc: 82.60%
2026-01-14 14:28:09,464 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-01-14 14:28:09,465 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-01-14 14:28:09,470 - INFO - --------------------------------------------------
2026-01-14 14:28:09,473 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 14:28:17,941 - INFO - [Train] [70/90] | Loss: 0.2839 | Train Acc: 95.83%
2026-01-14 14:28:20,288 - INFO - [Valid] [70/90] | Loss: 0.5443 | Val Acc: 83.19%
2026-01-14 14:28:20,310 - INFO - [Metrics for 'abnormal'] | Precision: 0.8205 | Recall: 0.8153 | F1: 0.8179
2026-01-14 14:28:20,311 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.8462 | F1: 0.8438
2026-01-14 14:28:20,316 - INFO - --------------------------------------------------
2026-01-14 14:28:20,320 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 14:28:29,316 - INFO - [Train] [71/90] | Loss: 0.2866 | Train Acc: 95.46%
2026-01-14 14:28:32,284 - INFO - [Valid] [71/90] | Loss: 0.5574 | Val Acc: 81.71%
2026-01-14 14:28:32,295 - INFO - [Metrics for 'abnormal'] | Precision: 0.8065 | Recall: 0.7962 | F1: 0.8013
2026-01-14 14:28:32,296 - INFO - [Metrics for 'normal'] | Precision: 0.8261 | Recall: 0.8352 | F1: 0.8306
2026-01-14 14:28:32,301 - INFO - --------------------------------------------------
2026-01-14 14:28:32,304 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 14:28:40,501 - INFO - [Train] [72/90] | Loss: 0.2844 | Train Acc: 95.91%
2026-01-14 14:28:42,870 - INFO - [Valid] [72/90] | Loss: 0.5477 | Val Acc: 81.12%
2026-01-14 14:28:42,881 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 14:28:42,881 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 14:28:42,884 - INFO - --------------------------------------------------
2026-01-14 14:28:42,887 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 14:28:52,541 - INFO - [Train] [73/90] | Loss: 0.2803 | Train Acc: 96.21%
2026-01-14 14:28:54,761 - INFO - [Valid] [73/90] | Loss: 0.5409 | Val Acc: 83.48%
2026-01-14 14:28:54,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.8217 | Recall: 0.8217 | F1: 0.8217
2026-01-14 14:28:54,774 - INFO - [Metrics for 'normal'] | Precision: 0.8462 | Recall: 0.8462 | F1: 0.8462
2026-01-14 14:28:54,780 - INFO - --------------------------------------------------
2026-01-14 14:28:54,783 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 14:29:05,369 - INFO - [Train] [74/90] | Loss: 0.2839 | Train Acc: 95.24%
2026-01-14 14:29:07,647 - INFO - [Valid] [74/90] | Loss: 0.5510 | Val Acc: 83.19%
2026-01-14 14:29:07,659 - INFO - [Metrics for 'abnormal'] | Precision: 0.8012 | Recall: 0.8471 | F1: 0.8235
2026-01-14 14:29:07,660 - INFO - [Metrics for 'normal'] | Precision: 0.8613 | Recall: 0.8187 | F1: 0.8394
2026-01-14 14:29:07,664 - INFO - --------------------------------------------------
2026-01-14 14:29:07,667 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 14:29:17,684 - INFO - [Train] [75/90] | Loss: 0.2752 | Train Acc: 96.65%
2026-01-14 14:29:20,219 - INFO - [Valid] [75/90] | Loss: 0.5429 | Val Acc: 83.78%
2026-01-14 14:29:20,230 - INFO - [Metrics for 'abnormal'] | Precision: 0.8355 | Recall: 0.8089 | F1: 0.8220
2026-01-14 14:29:20,230 - INFO - [Metrics for 'normal'] | Precision: 0.8396 | Recall: 0.8626 | F1: 0.8509
2026-01-14 14:29:20,234 - INFO - --------------------------------------------------
2026-01-14 14:29:20,237 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 14:29:29,438 - INFO - [Train] [76/90] | Loss: 0.2811 | Train Acc: 95.46%
2026-01-14 14:29:32,441 - INFO - [Valid] [76/90] | Loss: 0.5434 | Val Acc: 83.19%
2026-01-14 14:29:32,505 - INFO - [Metrics for 'abnormal'] | Precision: 0.8289 | Recall: 0.8025 | F1: 0.8155
2026-01-14 14:29:32,507 - INFO - [Metrics for 'normal'] | Precision: 0.8342 | Recall: 0.8571 | F1: 0.8455
2026-01-14 14:29:32,510 - INFO - --------------------------------------------------
2026-01-14 14:29:32,520 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 14:29:42,166 - INFO - [Train] [77/90] | Loss: 0.2797 | Train Acc: 96.13%
2026-01-14 14:29:44,362 - INFO - [Valid] [77/90] | Loss: 0.5343 | Val Acc: 82.30%
2026-01-14 14:29:44,374 - INFO - [Metrics for 'abnormal'] | Precision: 0.8089 | Recall: 0.8089 | F1: 0.8089
2026-01-14 14:29:44,375 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8352 | F1: 0.8352
2026-01-14 14:29:44,379 - INFO - --------------------------------------------------
2026-01-14 14:29:44,383 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 14:29:54,061 - INFO - [Train] [78/90] | Loss: 0.2663 | Train Acc: 96.73%
2026-01-14 14:29:56,525 - INFO - [Valid] [78/90] | Loss: 0.5555 | Val Acc: 80.53%
2026-01-14 14:29:56,541 - INFO - [Metrics for 'abnormal'] | Precision: 0.7630 | Recall: 0.8408 | F1: 0.8000
2026-01-14 14:29:56,542 - INFO - [Metrics for 'normal'] | Precision: 0.8494 | Recall: 0.7747 | F1: 0.8103
2026-01-14 14:29:56,548 - INFO - --------------------------------------------------
2026-01-14 14:29:56,551 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 14:30:06,067 - INFO - [Train] [79/90] | Loss: 0.2767 | Train Acc: 96.50%
2026-01-14 14:30:08,302 - INFO - [Valid] [79/90] | Loss: 0.5443 | Val Acc: 82.30%
2026-01-14 14:30:08,324 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 14:30:08,328 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 14:30:08,337 - INFO - --------------------------------------------------
2026-01-14 14:30:08,343 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 14:30:17,271 - INFO - [Train] [80/90] | Loss: 0.2771 | Train Acc: 96.50%
2026-01-14 14:30:19,971 - INFO - [Valid] [80/90] | Loss: 0.5436 | Val Acc: 82.30%
2026-01-14 14:30:19,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 14:30:19,985 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 14:30:19,990 - INFO - --------------------------------------------------
2026-01-14 14:30:19,993 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 14:30:29,429 - INFO - [Train] [81/90] | Loss: 0.2696 | Train Acc: 96.28%
2026-01-14 14:30:31,949 - INFO - [Valid] [81/90] | Loss: 0.5517 | Val Acc: 81.42%
2026-01-14 14:30:31,961 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-01-14 14:30:31,962 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-01-14 14:30:31,967 - INFO - --------------------------------------------------
2026-01-14 14:30:31,969 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 14:30:41,137 - INFO - [Train] [82/90] | Loss: 0.2682 | Train Acc: 96.43%
2026-01-14 14:30:43,482 - INFO - [Valid] [82/90] | Loss: 0.5607 | Val Acc: 81.71%
2026-01-14 14:30:43,494 - INFO - [Metrics for 'abnormal'] | Precision: 0.8146 | Recall: 0.7834 | F1: 0.7987
2026-01-14 14:30:43,495 - INFO - [Metrics for 'normal'] | Precision: 0.8191 | Recall: 0.8462 | F1: 0.8324
2026-01-14 14:30:43,499 - INFO - --------------------------------------------------
2026-01-14 14:30:43,502 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 14:30:52,445 - INFO - [Train] [83/90] | Loss: 0.2808 | Train Acc: 95.68%
2026-01-14 14:30:54,502 - INFO - [Valid] [83/90] | Loss: 0.5529 | Val Acc: 80.53%
2026-01-14 14:30:54,515 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-01-14 14:30:54,516 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-01-14 14:30:54,520 - INFO - --------------------------------------------------
2026-01-14 14:30:54,522 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 14:31:03,550 - INFO - [Train] [84/90] | Loss: 0.2623 | Train Acc: 97.17%
2026-01-14 14:31:05,787 - INFO - [Valid] [84/90] | Loss: 0.5636 | Val Acc: 81.42%
2026-01-14 14:31:05,798 - INFO - [Metrics for 'abnormal'] | Precision: 0.7798 | Recall: 0.8344 | F1: 0.8062
2026-01-14 14:31:05,799 - INFO - [Metrics for 'normal'] | Precision: 0.8480 | Recall: 0.7967 | F1: 0.8215
2026-01-14 14:31:05,803 - INFO - --------------------------------------------------
2026-01-14 14:31:05,806 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 14:31:15,304 - INFO - [Train] [85/90] | Loss: 0.2648 | Train Acc: 97.10%
2026-01-14 14:31:18,210 - INFO - [Valid] [85/90] | Loss: 0.5622 | Val Acc: 82.30%
2026-01-14 14:31:18,221 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 14:31:18,221 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 14:31:18,225 - INFO - --------------------------------------------------
2026-01-14 14:31:18,230 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 14:31:28,003 - INFO - [Train] [86/90] | Loss: 0.2677 | Train Acc: 96.65%
2026-01-14 14:31:30,387 - INFO - [Valid] [86/90] | Loss: 0.5465 | Val Acc: 81.71%
2026-01-14 14:31:30,399 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 14:31:30,401 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 14:31:30,404 - INFO - --------------------------------------------------
2026-01-14 14:31:30,406 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 14:31:41,010 - INFO - [Train] [87/90] | Loss: 0.2572 | Train Acc: 97.40%
2026-01-14 14:31:43,397 - INFO - [Valid] [87/90] | Loss: 0.5522 | Val Acc: 82.89%
2026-01-14 14:31:43,411 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 14:31:43,414 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 14:31:43,423 - INFO - --------------------------------------------------
2026-01-14 14:31:43,425 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 14:31:52,742 - INFO - [Train] [88/90] | Loss: 0.2629 | Train Acc: 96.88%
2026-01-14 14:31:54,714 - INFO - [Valid] [88/90] | Loss: 0.5534 | Val Acc: 83.78%
2026-01-14 14:31:54,723 - INFO - [Metrics for 'abnormal'] | Precision: 0.8269 | Recall: 0.8217 | F1: 0.8243
2026-01-14 14:31:54,724 - INFO - [Metrics for 'normal'] | Precision: 0.8470 | Recall: 0.8516 | F1: 0.8493
2026-01-14 14:31:54,727 - INFO - --------------------------------------------------
2026-01-14 14:31:54,730 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 14:32:03,702 - INFO - [Train] [89/90] | Loss: 0.2645 | Train Acc: 96.95%
2026-01-14 14:32:05,999 - INFO - [Valid] [89/90] | Loss: 0.5587 | Val Acc: 82.30%
2026-01-14 14:32:06,022 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-01-14 14:32:06,023 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-01-14 14:32:06,027 - INFO - --------------------------------------------------
2026-01-14 14:32:06,031 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 14:32:16,193 - INFO - [Train] [90/90] | Loss: 0.2649 | Train Acc: 96.80%
2026-01-14 14:32:18,590 - INFO - [Valid] [90/90] | Loss: 0.5645 | Val Acc: 82.01%
2026-01-14 14:32:18,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.8038 | Recall: 0.8089 | F1: 0.8063
2026-01-14 14:32:18,601 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8297 | F1: 0.8320
2026-01-14 14:32:18,605 - INFO - ==================================================
2026-01-14 14:32:18,606 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 14:32:18,606 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 14:32:18,606 - INFO - Baseline 모델 'efficientnet_b0'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:32:18,779 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 14:32:18,781 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:32:18,781 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:32:18,785 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:32:27,720 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:32:28,174 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9344091796874999)에 맞춰 변경되었습니다.
2026-01-14 14:32:28,176 - INFO - ==================================================
2026-01-14 14:32:28,335 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/best_model.pth'
2026-01-14 14:32:28,336 - INFO - ==================================================
2026-01-14 14:32:28,336 - INFO - Test 모드를 시작합니다.
2026-01-14 14:32:28,766 - INFO - 연산량 (MACs): 0.0060 GMACs per sample
2026-01-14 14:32:28,767 - INFO - 연산량 (FLOPs): 0.0120 GFLOPs per sample
2026-01-14 14:32:28,768 - INFO - ==================================================
2026-01-14 14:32:28,768 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 14:32:30,703 - INFO - 샘플 당 평균 Forward Pass 시간: 10.13ms (std: 3.91ms), FPS: 108.36 (std: 26.78) (1개 샘플 x 100회 반복)
2026-01-14 14:32:30,705 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 80.42 MB
2026-01-14 14:32:30,705 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 14:32:35,133 - INFO - [Test] Loss: 0.4084 | Test Acc: 83.48%
2026-01-14 14:32:35,167 - INFO - [Metrics for 'abnormal'] | Precision: 0.8024 | Recall: 0.8535 | F1: 0.8272
2026-01-14 14:32:35,167 - INFO - [Metrics for 'normal'] | Precision: 0.8663 | Recall: 0.8187 | F1: 0.8418
2026-01-14 14:32:35,986 - INFO - ==================================================
2026-01-14 14:32:35,989 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/confusion_matrix_20260114_135924.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/confusion_matrix_20260114_135924.pdf'
2026-01-14 14:32:35,989 - INFO - ==================================================
2026-01-14 14:32:35,989 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 14:32:41,369 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/model_fp32_20260114_135924.onnx'에 저장되었습니다. (크기: 0.18 MB)
2026-01-14 14:32:42,277 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2506.53 MB (증가량: 6.95 MB)
2026-01-14 14:32:42,277 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 14:32:44,063 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 11.74ms (std: 12.52ms)
2026-01-14 14:32:44,063 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 138.93 FPS (std: 72.02) (1개 샘플 x 100회 반복)
2026-01-14 14:32:44,063 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2508.57 MB (순수 증가량: 2.04 MB)
2026-01-14 14:32:44,064 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2508.57 MB (전체 증가량: 8.99 MB)
2026-01-14 14:32:49,223 - INFO - [Test (ONNX)] | Test Acc (ONNX): 83.48%
2026-01-14 14:32:49,247 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8024 | Recall: 0.8535 | F1: 0.8272
2026-01-14 14:32:49,247 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8663 | Recall: 0.8187 | F1: 0.8418
2026-01-14 14:32:50,264 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/val_acc.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/val_acc.pdf'
2026-01-14 14:32:51,170 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/train_val_acc.pdf'
2026-01-14 14:32:51,659 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/F1_normal.pdf'
2026-01-14 14:32:52,374 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/val_loss.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/val_loss.pdf'
2026-01-14 14:32:52,908 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/learning_rate.pdf'
2026-01-14 14:33:01,728 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/compile.png' and 'log/Sewer-TAPNEW/baseline_efficientnet_b0_wanda_20260114_135924/graph_20260114_135924/compile.pdf'
