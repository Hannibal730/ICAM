2026-01-14 14:00:14,452 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/log_20260114_140014.log'에 저장됩니다.
2026-01-14 14:00:14,459 - INFO - ==================================================
2026-01-14 14:00:14,459 - INFO - config.yaml:
2026-01-14 14:00:14,460 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: deit_tiny
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_params_target: 0.031371

2026-01-14 14:00:14,461 - INFO - ==================================================
2026-01-14 14:00:14,527 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 14:00:14,528 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 14:00:14,528 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 14:00:14,541 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 14:00:14,542 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 14:00:14,542 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 14:00:14,543 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:00:20,557 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 14:00:20,571 - INFO - ==================================================
2026-01-14 14:00:20,571 - INFO - 모델 파라미터 수:
2026-01-14 14:00:20,571 - INFO -   - 총 파라미터: 5,524,802 개
2026-01-14 14:00:20,571 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-01-14 14:00:20,571 - INFO - ================================================================================
2026-01-14 14:00:20,571 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 14:00:20,571 - INFO - ================================================================================
2026-01-14 14:00:20,571 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:00:20,582 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 14:00:20,582 - INFO - ==================================================
2026-01-14 14:00:20,582 - INFO - train 모드를 시작합니다.
2026-01-14 14:00:20,582 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:00:20,583 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:00:20,583 - INFO - --------------------------------------------------
2026-01-14 14:00:20,584 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 14:00:29,848 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-01-14 14:00:33,276 - INFO - [Valid] [1/10] | Loss: 0.6723 | Val Acc: 59.88%
2026-01-14 14:00:33,314 - INFO - [Metrics for 'abnormal'] | Precision: 0.5484 | Recall: 0.7580 | F1: 0.6364
2026-01-14 14:00:33,318 - INFO - [Metrics for 'normal'] | Precision: 0.6885 | Recall: 0.4615 | F1: 0.5526
2026-01-14 14:00:33,395 - INFO - [Best Model Saved] (val loss: 0.6723) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:00:33,397 - INFO - --------------------------------------------------
2026-01-14 14:00:33,399 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 14:00:43,092 - INFO - [Train] [2/10] | Loss: 0.6456 | Train Acc: 65.18%
2026-01-14 14:00:45,840 - INFO - [Valid] [2/10] | Loss: 0.6476 | Val Acc: 63.72%
2026-01-14 14:00:45,865 - INFO - [Metrics for 'abnormal'] | Precision: 0.7297 | Recall: 0.3439 | F1: 0.4675
2026-01-14 14:00:45,870 - INFO - [Metrics for 'normal'] | Precision: 0.6113 | Recall: 0.8901 | F1: 0.7248
2026-01-14 14:00:45,987 - INFO - [Best Model Saved] (val loss: 0.6476) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:00:45,988 - INFO - --------------------------------------------------
2026-01-14 14:00:45,990 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 14:00:55,237 - INFO - [Train] [3/10] | Loss: 0.5969 | Train Acc: 70.24%
2026-01-14 14:00:57,741 - INFO - [Valid] [3/10] | Loss: 0.5721 | Val Acc: 73.75%
2026-01-14 14:00:57,752 - INFO - [Metrics for 'abnormal'] | Precision: 0.7394 | Recall: 0.6688 | F1: 0.7023
2026-01-14 14:00:57,753 - INFO - [Metrics for 'normal'] | Precision: 0.7360 | Recall: 0.7967 | F1: 0.7652
2026-01-14 14:00:57,822 - INFO - [Best Model Saved] (val loss: 0.5721) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:00:57,823 - INFO - --------------------------------------------------
2026-01-14 14:00:57,825 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 14:01:07,248 - INFO - [Train] [4/10] | Loss: 0.5593 | Train Acc: 76.34%
2026-01-14 14:01:09,784 - INFO - [Valid] [4/10] | Loss: 0.5522 | Val Acc: 76.70%
2026-01-14 14:01:09,806 - INFO - [Metrics for 'abnormal'] | Precision: 0.8197 | Recall: 0.6369 | F1: 0.7168
2026-01-14 14:01:09,808 - INFO - [Metrics for 'normal'] | Precision: 0.7373 | Recall: 0.8791 | F1: 0.8020
2026-01-14 14:01:09,872 - INFO - [Best Model Saved] (val loss: 0.5522) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:01:09,873 - INFO - --------------------------------------------------
2026-01-14 14:01:09,875 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 14:01:19,310 - INFO - [Train] [5/10] | Loss: 0.5317 | Train Acc: 77.98%
2026-01-14 14:01:22,360 - INFO - [Valid] [5/10] | Loss: 0.5848 | Val Acc: 73.75%
2026-01-14 14:01:22,374 - INFO - [Metrics for 'abnormal'] | Precision: 0.7024 | Recall: 0.7516 | F1: 0.7262
2026-01-14 14:01:22,374 - INFO - [Metrics for 'normal'] | Precision: 0.7719 | Recall: 0.7253 | F1: 0.7479
2026-01-14 14:01:22,379 - INFO - --------------------------------------------------
2026-01-14 14:01:22,381 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 14:01:30,854 - INFO - [Train] [6/10] | Loss: 0.5470 | Train Acc: 76.49%
2026-01-14 14:01:34,005 - INFO - [Valid] [6/10] | Loss: 0.5642 | Val Acc: 73.45%
2026-01-14 14:01:34,015 - INFO - [Metrics for 'abnormal'] | Precision: 0.6736 | Recall: 0.8280 | F1: 0.7429
2026-01-14 14:01:34,015 - INFO - [Metrics for 'normal'] | Precision: 0.8151 | Recall: 0.6538 | F1: 0.7256
2026-01-14 14:01:34,019 - INFO - --------------------------------------------------
2026-01-14 14:01:34,021 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 14:01:43,936 - INFO - [Train] [7/10] | Loss: 0.5059 | Train Acc: 78.72%
2026-01-14 14:01:46,631 - INFO - [Valid] [7/10] | Loss: 0.5455 | Val Acc: 74.93%
2026-01-14 14:01:46,640 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.5924 | F1: 0.6863
2026-01-14 14:01:46,641 - INFO - [Metrics for 'normal'] | Precision: 0.7156 | Recall: 0.8846 | F1: 0.7912
2026-01-14 14:01:46,701 - INFO - [Best Model Saved] (val loss: 0.5455) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:01:46,701 - INFO - --------------------------------------------------
2026-01-14 14:01:46,703 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 14:01:54,600 - INFO - [Train] [8/10] | Loss: 0.4936 | Train Acc: 80.80%
2026-01-14 14:01:57,458 - INFO - [Valid] [8/10] | Loss: 0.5257 | Val Acc: 77.88%
2026-01-14 14:01:57,480 - INFO - [Metrics for 'abnormal'] | Precision: 0.7929 | Recall: 0.7070 | F1: 0.7475
2026-01-14 14:01:57,485 - INFO - [Metrics for 'normal'] | Precision: 0.7688 | Recall: 0.8407 | F1: 0.8031
2026-01-14 14:01:57,593 - INFO - [Best Model Saved] (val loss: 0.5257) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:01:57,595 - INFO - --------------------------------------------------
2026-01-14 14:01:57,597 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 14:02:06,755 - INFO - [Train] [9/10] | Loss: 0.4926 | Train Acc: 79.91%
2026-01-14 14:02:11,045 - INFO - [Valid] [9/10] | Loss: 0.5325 | Val Acc: 76.99%
2026-01-14 14:02:11,057 - INFO - [Metrics for 'abnormal'] | Precision: 0.8211 | Recall: 0.6433 | F1: 0.7214
2026-01-14 14:02:11,058 - INFO - [Metrics for 'normal'] | Precision: 0.7407 | Recall: 0.8791 | F1: 0.8040
2026-01-14 14:02:11,062 - INFO - --------------------------------------------------
2026-01-14 14:02:11,065 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 14:02:19,605 - INFO - [Train] [10/10] | Loss: 0.4859 | Train Acc: 80.13%
2026-01-14 14:02:23,034 - INFO - [Valid] [10/10] | Loss: 0.5384 | Val Acc: 76.40%
2026-01-14 14:02:23,046 - INFO - [Metrics for 'abnormal'] | Precision: 0.7484 | Recall: 0.7389 | F1: 0.7436
2026-01-14 14:02:23,047 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.7857 | F1: 0.7814
2026-01-14 14:02:23,053 - INFO - ================================================================================
2026-01-14 14:02:23,054 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 14:02:23,055 - INFO - ================================================================================
2026-01-14 14:02:23,129 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'을(를) 불러왔습니다.
2026-01-14 14:02:23,130 - INFO - ================================================================================
2026-01-14 14:02:23,131 - INFO - 목표 파라미터 수 (0.0314M)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 14:02:23,132 - INFO - 원본 모델 파라미터: 5.5248M
2026-01-14 14:02:23,213 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:23,217 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:23,224 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:32,225 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:32,226 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:02:32,816 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 14:02:32,817 - INFO - ==================================================
2026-01-14 14:02:32,818 - INFO -   [탐색  1] 희소도: 0.4950 -> 파라미터: 1.8881M (감소율: 65.83%)
2026-01-14 14:02:32,850 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:32,851 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:32,854 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:42,695 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:42,696 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:02:43,335 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 14:02:43,336 - INFO - ==================================================
2026-01-14 14:02:43,339 - INFO -   [탐색  2] 희소도: 0.7425 -> 파라미터: 0.7436M (감소율: 86.54%)
2026-01-14 14:02:43,396 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:43,397 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:43,432 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:02:52,564 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:02:52,565 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:02:53,150 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 14:02:53,150 - INFO - ==================================================
2026-01-14 14:02:53,152 - INFO -   [탐색  3] 희소도: 0.8662 -> 파라미터: 0.3258M (감소율: 94.10%)
2026-01-14 14:02:53,672 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:02:53,673 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:02:53,677 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:03,129 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:03,130 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:03,590 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 14:03:03,591 - INFO - ==================================================
2026-01-14 14:03:03,593 - INFO -   [탐색  4] 희소도: 0.9281 -> 파라미터: 0.1581M (감소율: 97.14%)
2026-01-14 14:03:03,640 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:03,643 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:03,645 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:13,230 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:13,232 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:13,935 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9590624999999999)에 맞춰 변경되었습니다.
2026-01-14 14:03:13,936 - INFO - ==================================================
2026-01-14 14:03:13,938 - INFO -   [탐색  5] 희소도: 0.9591 -> 파라미터: 0.0843M (감소율: 98.47%)
2026-01-14 14:03:13,976 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:13,976 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:13,979 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:23,833 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:23,834 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:24,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.97453125)에 맞춰 변경되었습니다.
2026-01-14 14:03:24,348 - INFO - ==================================================
2026-01-14 14:03:24,349 - INFO -   [탐색  6] 희소도: 0.9745 -> 파라미터: 0.0500M (감소율: 99.09%)
2026-01-14 14:03:24,380 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:24,380 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:24,383 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:33,207 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:33,208 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:33,708 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9822656249999999)에 맞춰 변경되었습니다.
2026-01-14 14:03:33,709 - INFO - ==================================================
2026-01-14 14:03:33,711 - INFO -   [탐색  7] 희소도: 0.9823 -> 파라미터: 0.0388M (감소율: 99.30%)
2026-01-14 14:03:33,746 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:33,746 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:33,749 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:42,342 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:42,343 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:43,687 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9861328125)에 맞춰 변경되었습니다.
2026-01-14 14:03:43,687 - INFO - ==================================================
2026-01-14 14:03:43,689 - INFO -   [탐색  8] 희소도: 0.9861 -> 파라미터: 0.0280M (감소율: 99.49%)
2026-01-14 14:03:43,723 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:43,723 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:43,726 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:03:53,714 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:03:53,716 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:03:54,388 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9841992187499999)에 맞춰 변경되었습니다.
2026-01-14 14:03:54,389 - INFO - ==================================================
2026-01-14 14:03:54,391 - INFO -   [탐색  9] 희소도: 0.9842 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:03:54,425 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:03:54,426 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:03:54,433 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:03,028 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:03,030 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:03,794 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 14:04:03,795 - INFO - ==================================================
2026-01-14 14:04:03,798 - INFO -   [탐색 10] 희소도: 0.9852 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:04:03,927 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:03,928 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:03,932 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:12,463 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:12,466 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:13,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9846826171874999)에 맞춰 변경되었습니다.
2026-01-14 14:04:13,671 - INFO - ==================================================
2026-01-14 14:04:13,673 - INFO -   [탐색 11] 희소도: 0.9847 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:04:13,739 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:13,740 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:13,744 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:23,547 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:23,548 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:24,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9844409179687499)에 맞춰 변경되었습니다.
2026-01-14 14:04:24,238 - INFO - ==================================================
2026-01-14 14:04:24,240 - INFO -   [탐색 12] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:04:24,311 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:24,311 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:24,314 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:32,986 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:32,991 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:34,044 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843200683593749)에 맞춰 변경되었습니다.
2026-01-14 14:04:34,044 - INFO - ==================================================
2026-01-14 14:04:34,047 - INFO -   [탐색 13] 희소도: 0.9843 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:04:34,079 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:34,080 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:34,083 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:43,783 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:43,785 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:44,538 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843804931640624)에 맞춰 변경되었습니다.
2026-01-14 14:04:44,538 - INFO - ==================================================
2026-01-14 14:04:44,540 - INFO -   [탐색 14] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:04:44,574 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:44,575 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:44,578 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:04:52,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:04:52,471 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:04:53,205 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843502807617186)에 맞춰 변경되었습니다.
2026-01-14 14:04:53,205 - INFO - ==================================================
2026-01-14 14:04:53,207 - INFO -   [탐색 15] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:04:53,241 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:04:53,241 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:04:53,244 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:02,758 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:02,759 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:03,289 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843653869628906)에 맞춰 변경되었습니다.
2026-01-14 14:05:03,289 - INFO - ==================================================
2026-01-14 14:05:03,291 - INFO -   [탐색 16] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:05:03,325 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:03,325 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:03,329 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:12,755 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:12,756 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:13,210 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843729400634764)에 맞춰 변경되었습니다.
2026-01-14 14:05:13,211 - INFO - ==================================================
2026-01-14 14:05:13,212 - INFO -   [탐색 17] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:05:13,233 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:13,233 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:13,234 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:23,675 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:23,676 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:24,565 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843767166137694)에 맞춰 변경되었습니다.
2026-01-14 14:05:24,566 - INFO - ==================================================
2026-01-14 14:05:24,568 - INFO -   [탐색 18] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:05:24,603 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:24,604 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:24,607 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:34,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:34,317 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:34,876 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843748283386229)에 맞춰 변경되었습니다.
2026-01-14 14:05:34,876 - INFO - ==================================================
2026-01-14 14:05:34,878 - INFO -   [탐색 19] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:05:34,914 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:34,915 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:34,919 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:44,613 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:44,615 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:45,180 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843757724761961)에 맞춰 변경되었습니다.
2026-01-14 14:05:45,180 - INFO - ==================================================
2026-01-14 14:05:45,182 - INFO -   [탐색 20] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:05:45,267 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:45,267 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:45,271 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:05:54,703 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:05:54,704 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:05:55,359 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843753004074095)에 맞춰 변경되었습니다.
2026-01-14 14:05:55,359 - INFO - ==================================================
2026-01-14 14:05:55,361 - INFO -   [탐색 21] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:05:55,385 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:05:55,385 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:05:55,387 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:04,318 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:04,320 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:05,030 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750643730163)에 맞춰 변경되었습니다.
2026-01-14 14:06:05,030 - INFO - ==================================================
2026-01-14 14:06:05,032 - INFO -   [탐색 22] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:06:05,066 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:05,067 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:05,070 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:14,120 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:14,125 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:15,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749463558196)에 맞춰 변경되었습니다.
2026-01-14 14:06:15,307 - INFO - ==================================================
2026-01-14 14:06:15,309 - INFO -   [탐색 23] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:06:15,342 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:15,344 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:15,347 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:23,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:23,653 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:24,367 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750053644179)에 맞춰 변경되었습니다.
2026-01-14 14:06:24,367 - INFO - ==================================================
2026-01-14 14:06:24,369 - INFO -   [탐색 24] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:06:24,405 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:24,406 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:24,409 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:32,476 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:32,477 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:33,185 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749758601188)에 맞춰 변경되었습니다.
2026-01-14 14:06:33,193 - INFO - ==================================================
2026-01-14 14:06:33,196 - INFO -   [탐색 25] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:06:33,245 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:33,246 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:33,250 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:41,857 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:41,859 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:42,873 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749906122683)에 맞춰 변경되었습니다.
2026-01-14 14:06:42,874 - INFO - ==================================================
2026-01-14 14:06:42,875 - INFO -   [탐색 26] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:06:42,939 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:42,942 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:42,946 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:06:52,724 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:06:52,728 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:06:54,374 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749979883432)에 맞춰 변경되었습니다.
2026-01-14 14:06:54,375 - INFO - ==================================================
2026-01-14 14:06:54,379 - INFO -   [탐색 27] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:06:54,412 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:06:54,413 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:06:54,417 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:04,030 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:04,031 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:04,636 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750016763806)에 맞춰 변경되었습니다.
2026-01-14 14:07:04,637 - INFO - ==================================================
2026-01-14 14:07:04,639 - INFO -   [탐색 28] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:07:04,670 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:04,670 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:04,674 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:13,941 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:13,942 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:14,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749998323619)에 맞춰 변경되었습니다.
2026-01-14 14:07:14,492 - INFO - ==================================================
2026-01-14 14:07:14,494 - INFO -   [탐색 29] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:07:14,529 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:14,530 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:14,533 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:23,442 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:23,443 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:24,428 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750007543712)에 맞춰 변경되었습니다.
2026-01-14 14:07:24,429 - INFO - ==================================================
2026-01-14 14:07:24,431 - INFO -   [탐색 30] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:07:24,463 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:24,464 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:24,467 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:33,393 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:33,394 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:33,988 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750002933666)에 맞춰 변경되었습니다.
2026-01-14 14:07:33,988 - INFO - ==================================================
2026-01-14 14:07:33,990 - INFO -   [탐색 31] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:07:34,024 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:34,025 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:34,028 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:42,904 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:42,906 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:44,230 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000628642)에 맞춰 변경되었습니다.
2026-01-14 14:07:44,230 - INFO - ==================================================
2026-01-14 14:07:44,232 - INFO -   [탐색 32] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:07:44,262 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:44,263 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:44,267 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:07:52,535 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:07:52,536 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:07:53,377 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984374999947613)에 맞춰 변경되었습니다.
2026-01-14 14:07:53,381 - INFO - ==================================================
2026-01-14 14:07:53,384 - INFO -   [탐색 33] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:07:53,417 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:07:53,418 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:07:53,422 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:02,761 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:02,763 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:03,806 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000052386)에 맞춰 변경되었습니다.
2026-01-14 14:08:03,807 - INFO - ==================================================
2026-01-14 14:08:03,809 - INFO -   [탐색 34] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:08:03,841 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:03,842 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:03,845 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:12,748 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:12,752 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:13,230 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999764257)에 맞춰 변경되었습니다.
2026-01-14 14:08:13,231 - INFO - ==================================================
2026-01-14 14:08:13,233 - INFO -   [탐색 35] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:08:13,266 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:13,267 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:13,270 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:21,002 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:21,003 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:21,780 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999908322)에 맞춰 변경되었습니다.
2026-01-14 14:08:21,783 - INFO - ==================================================
2026-01-14 14:08:21,785 - INFO -   [탐색 36] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:08:21,855 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:21,858 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:21,864 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:29,834 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:29,869 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:30,952 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999980353)에 맞춰 변경되었습니다.
2026-01-14 14:08:30,953 - INFO - ==================================================
2026-01-14 14:08:30,956 - INFO -   [탐색 37] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:08:30,990 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:30,991 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:30,994 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:39,777 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:39,779 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:40,315 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000016369)에 맞춰 변경되었습니다.
2026-01-14 14:08:40,316 - INFO - ==================================================
2026-01-14 14:08:40,318 - INFO -   [탐색 38] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:08:40,366 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:40,367 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:40,370 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:49,602 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:49,606 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:08:50,184 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999998361)에 맞춰 변경되었습니다.
2026-01-14 14:08:50,185 - INFO - ==================================================
2026-01-14 14:08:50,187 - INFO -   [탐색 39] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:08:50,221 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:08:50,221 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:08:50,225 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:08:59,414 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:08:59,416 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:00,435 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000007365)에 맞춰 변경되었습니다.
2026-01-14 14:09:00,435 - INFO - ==================================================
2026-01-14 14:09:00,443 - INFO -   [탐색 40] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:09:00,504 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:00,506 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:00,520 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:11,983 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:11,985 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:12,516 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000002863)에 맞춰 변경되었습니다.
2026-01-14 14:09:12,517 - INFO - ==================================================
2026-01-14 14:09:12,519 - INFO -   [탐색 41] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:09:12,563 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:12,563 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:12,566 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:21,908 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:21,909 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:22,745 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000613)에 맞춰 변경되었습니다.
2026-01-14 14:09:22,746 - INFO - ==================================================
2026-01-14 14:09:22,749 - INFO -   [탐색 42] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:09:22,784 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:22,784 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:22,787 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:32,983 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:32,983 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:33,588 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999487)에 맞춰 변경되었습니다.
2026-01-14 14:09:33,588 - INFO - ==================================================
2026-01-14 14:09:33,590 - INFO -   [탐색 43] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:09:33,629 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:33,630 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:33,633 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:43,127 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:43,128 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:43,634 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375000000005)에 맞춰 변경되었습니다.
2026-01-14 14:09:43,635 - INFO - ==================================================
2026-01-14 14:09:43,636 - INFO -   [탐색 44] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:09:43,671 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:43,672 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:43,675 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:09:53,742 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:09:53,743 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:09:54,171 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999769)에 맞춰 변경되었습니다.
2026-01-14 14:09:54,171 - INFO - ==================================================
2026-01-14 14:09:54,177 - INFO -   [탐색 45] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:09:54,230 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:09:54,234 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:09:54,236 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:03,676 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:03,677 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:04,017 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999909)에 맞춰 변경되었습니다.
2026-01-14 14:10:04,017 - INFO - ==================================================
2026-01-14 14:10:04,019 - INFO -   [탐색 46] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:10:04,044 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:04,044 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:04,047 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:13,999 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:14,000 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:14,809 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984374999999998)에 맞춰 변경되었습니다.
2026-01-14 14:10:14,810 - INFO - ==================================================
2026-01-14 14:10:14,813 - INFO -   [탐색 47] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:10:14,839 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:14,839 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:14,842 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:24,554 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:24,555 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:25,197 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000016)에 맞춰 변경되었습니다.
2026-01-14 14:10:25,197 - INFO - ==================================================
2026-01-14 14:10:25,199 - INFO -   [탐색 48] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:10:25,245 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:25,246 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:25,249 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:34,740 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:34,742 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:35,509 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843749999999998)에 맞춰 변경되었습니다.
2026-01-14 14:10:35,509 - INFO - ==================================================
2026-01-14 14:10:35,511 - INFO -   [탐색 49] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:10:35,566 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:35,566 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:35,569 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:44,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:44,315 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:45,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000007)에 맞춰 변경되었습니다.
2026-01-14 14:10:45,268 - INFO - ==================================================
2026-01-14 14:10:45,273 - INFO -   [탐색 50] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:10:45,339 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:45,343 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:45,346 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:10:54,355 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:10:54,357 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:10:55,838 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000002)에 맞춰 변경되었습니다.
2026-01-14 14:10:55,842 - INFO - ==================================================
2026-01-14 14:10:55,845 - INFO -   [탐색 51] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:10:55,918 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:10:55,919 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:10:55,923 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:05,810 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:05,811 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:06,671 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:11:06,671 - INFO - ==================================================
2026-01-14 14:11:06,673 - INFO -   [탐색 52] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:11:06,736 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:06,740 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:06,744 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:16,598 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:16,599 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:17,183 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9843750000000001)에 맞춰 변경되었습니다.
2026-01-14 14:11:17,185 - INFO - ==================================================
2026-01-14 14:11:17,187 - INFO -   [탐색 53] 희소도: 0.9844 -> 파라미터: 0.0281M (감소율: 99.49%)
2026-01-14 14:11:17,222 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:17,223 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:17,226 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:27,653 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:27,658 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:28,635 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:11:28,636 - INFO - ==================================================
2026-01-14 14:11:28,638 - INFO -   [탐색 54] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:11:28,672 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:28,672 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:28,675 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:37,691 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:37,693 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:38,479 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:11:38,479 - INFO - ==================================================
2026-01-14 14:11:38,484 - INFO -   [탐색 55] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:11:38,552 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:38,552 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:38,559 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:46,645 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:46,646 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:47,934 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:11:47,934 - INFO - ==================================================
2026-01-14 14:11:47,937 - INFO -   [탐색 56] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:11:47,970 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:47,971 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:47,974 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:11:56,703 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:11:56,708 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:11:57,646 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:11:57,650 - INFO - ==================================================
2026-01-14 14:11:57,652 - INFO -   [탐색 57] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:11:57,721 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:11:57,721 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:11:57,727 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:06,361 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:06,367 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:07,173 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:12:07,174 - INFO - ==================================================
2026-01-14 14:12:07,176 - INFO -   [탐색 58] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:12:07,210 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:07,211 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:07,214 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:16,034 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:16,037 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:16,527 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:12:16,528 - INFO - ==================================================
2026-01-14 14:12:16,531 - INFO -   [탐색 59] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:12:16,563 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:16,564 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:16,567 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:26,254 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:26,257 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:26,765 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:12:26,765 - INFO - ==================================================
2026-01-14 14:12:26,767 - INFO -   [탐색 60] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:12:26,791 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:26,792 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:26,794 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:36,203 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:36,207 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:37,146 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:12:37,150 - INFO - ==================================================
2026-01-14 14:12:37,152 - INFO -   [탐색 61] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:12:37,198 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:37,199 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:37,203 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:46,138 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:46,139 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:46,688 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:12:46,689 - INFO - ==================================================
2026-01-14 14:12:46,691 - INFO -   [탐색 62] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:12:46,722 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:46,723 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:46,725 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:12:56,495 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:12:56,497 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:12:57,370 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:12:57,371 - INFO - ==================================================
2026-01-14 14:12:57,374 - INFO -   [탐색 63] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:12:57,412 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:12:57,413 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:12:57,418 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:05,889 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:05,890 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:06,533 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:13:06,535 - INFO - ==================================================
2026-01-14 14:13:06,538 - INFO -   [탐색 64] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:13:06,582 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:06,583 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:06,590 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:15,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:15,463 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:16,641 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:13:16,643 - INFO - ==================================================
2026-01-14 14:13:16,645 - INFO -   [탐색 65] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:13:16,677 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:16,678 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:16,681 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:25,506 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:25,507 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:26,718 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:13:26,722 - INFO - ==================================================
2026-01-14 14:13:26,724 - INFO -   [탐색 66] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:13:26,799 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:26,799 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:26,803 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:35,778 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:35,781 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:36,353 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:13:36,353 - INFO - ==================================================
2026-01-14 14:13:36,356 - INFO -   [탐색 67] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:13:36,436 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:36,437 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:36,440 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:45,124 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:45,131 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:45,915 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:13:45,919 - INFO - ==================================================
2026-01-14 14:13:45,921 - INFO -   [탐색 68] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:13:45,994 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:45,994 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:46,001 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:13:53,596 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:13:53,600 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:13:54,228 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:13:54,228 - INFO - ==================================================
2026-01-14 14:13:54,231 - INFO -   [탐색 69] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:13:54,312 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:13:54,315 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:13:54,322 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:02,544 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:02,546 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:03,439 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:14:03,439 - INFO - ==================================================
2026-01-14 14:14:03,441 - INFO -   [탐색 70] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:14:03,964 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:03,966 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:03,970 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:12,344 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:12,346 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:13,612 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:14:13,616 - INFO - ==================================================
2026-01-14 14:14:13,627 - INFO -   [탐색 71] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:14:13,662 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:13,663 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:13,666 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:23,442 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:23,444 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:24,012 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:14:24,013 - INFO - ==================================================
2026-01-14 14:14:24,017 - INFO -   [탐색 72] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:14:24,055 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:24,056 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:24,059 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:32,754 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:32,755 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:33,725 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:14:33,726 - INFO - ==================================================
2026-01-14 14:14:33,729 - INFO -   [탐색 73] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:14:33,766 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:33,767 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:33,771 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:42,732 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:42,734 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:43,476 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:14:43,477 - INFO - ==================================================
2026-01-14 14:14:43,481 - INFO -   [탐색 74] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:14:43,518 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:43,519 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:43,522 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:14:53,375 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:14:53,376 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:14:54,363 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:14:54,364 - INFO - ==================================================
2026-01-14 14:14:54,370 - INFO -   [탐색 75] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:14:54,421 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:14:54,425 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:14:54,427 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:02,755 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:02,757 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:03,350 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:15:03,351 - INFO - ==================================================
2026-01-14 14:15:03,354 - INFO -   [탐색 76] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:15:03,387 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:03,387 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:03,391 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:11,943 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:11,944 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:13,006 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:15:13,008 - INFO - ==================================================
2026-01-14 14:15:13,010 - INFO -   [탐색 77] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:15:13,060 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:13,060 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:13,068 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:22,798 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:22,799 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:23,513 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:15:23,513 - INFO - ==================================================
2026-01-14 14:15:23,516 - INFO -   [탐색 78] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:15:23,551 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:23,552 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:23,555 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:32,487 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:32,488 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:33,053 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:15:33,054 - INFO - ==================================================
2026-01-14 14:15:33,057 - INFO -   [탐색 79] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:15:33,092 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:33,093 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:33,096 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:41,952 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:41,953 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:42,952 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:15:42,952 - INFO - ==================================================
2026-01-14 14:15:42,955 - INFO -   [탐색 80] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:15:43,031 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:43,032 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:43,038 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:15:52,377 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:15:52,383 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:15:53,041 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:15:53,042 - INFO - ==================================================
2026-01-14 14:15:53,045 - INFO -   [탐색 81] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:15:53,083 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:15:53,084 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:15:53,088 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:03,069 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:03,071 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:03,564 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:16:03,565 - INFO - ==================================================
2026-01-14 14:16:03,567 - INFO -   [탐색 82] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:16:03,603 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:03,603 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:03,607 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:12,469 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:12,470 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:13,231 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:16:13,231 - INFO - ==================================================
2026-01-14 14:16:13,235 - INFO -   [탐색 83] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:16:13,273 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:13,273 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:13,277 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:22,164 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:22,166 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:22,879 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:16:22,880 - INFO - ==================================================
2026-01-14 14:16:22,882 - INFO -   [탐색 84] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:16:22,905 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:22,906 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:22,909 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:30,551 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:30,553 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:31,954 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:16:31,954 - INFO - ==================================================
2026-01-14 14:16:31,956 - INFO -   [탐색 85] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:16:31,990 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:31,990 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:31,993 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:42,036 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:42,096 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:42,765 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:16:42,765 - INFO - ==================================================
2026-01-14 14:16:42,766 - INFO -   [탐색 86] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:16:42,797 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:42,797 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:42,800 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:16:51,253 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:16:51,254 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:16:52,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:16:52,047 - INFO - ==================================================
2026-01-14 14:16:52,049 - INFO -   [탐색 87] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:16:52,078 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:16:52,082 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:16:52,085 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:00,276 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:00,277 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:01,091 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:01,092 - INFO - ==================================================
2026-01-14 14:17:01,094 - INFO -   [탐색 88] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:01,128 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:01,129 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:01,133 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:09,447 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:09,449 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:09,907 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:09,908 - INFO - ==================================================
2026-01-14 14:17:09,909 - INFO -   [탐색 89] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:09,949 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:09,950 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:09,953 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:18,577 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:18,583 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:19,613 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:19,614 - INFO - ==================================================
2026-01-14 14:17:19,620 - INFO -   [탐색 90] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:19,692 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:19,692 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:19,698 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:27,896 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:27,898 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:28,479 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:28,480 - INFO - ==================================================
2026-01-14 14:17:28,481 - INFO -   [탐색 91] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:28,544 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:28,545 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:28,548 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:37,265 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:37,267 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:37,965 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:37,969 - INFO - ==================================================
2026-01-14 14:17:37,972 - INFO -   [탐색 92] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:38,005 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:38,005 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:38,009 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:46,283 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:46,285 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:46,891 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:46,891 - INFO - ==================================================
2026-01-14 14:17:46,894 - INFO -   [탐색 93] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:46,929 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:46,930 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:46,933 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:17:55,902 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:17:55,903 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:17:56,800 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:17:56,800 - INFO - ==================================================
2026-01-14 14:17:56,803 - INFO -   [탐색 94] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:17:56,894 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:17:56,901 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:17:56,907 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:06,522 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:06,527 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:07,268 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:18:07,269 - INFO - ==================================================
2026-01-14 14:18:07,271 - INFO -   [탐색 95] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:18:07,329 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:07,330 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:07,333 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:17,174 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:17,179 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:17,727 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:18:17,728 - INFO - ==================================================
2026-01-14 14:18:17,740 - INFO -   [탐색 96] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:18:17,784 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:17,785 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:17,787 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:27,039 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:27,041 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:27,601 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:18:27,602 - INFO - ==================================================
2026-01-14 14:18:27,604 - INFO -   [탐색 97] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:18:27,690 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:27,690 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:27,693 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:37,534 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:37,535 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:38,092 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:18:38,092 - INFO - ==================================================
2026-01-14 14:18:38,094 - INFO -   [탐색 98] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:18:38,119 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:38,119 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:38,122 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:47,732 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:47,734 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:48,569 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:18:48,570 - INFO - ==================================================
2026-01-14 14:18:48,571 - INFO -   [탐색 99] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:18:48,601 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:48,601 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:48,603 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:18:58,775 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:18:58,776 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:18:59,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.984375)에 맞춰 변경되었습니다.
2026-01-14 14:18:59,355 - INFO - ==================================================
2026-01-14 14:18:59,356 - INFO -   [탐색 100] 희소도: 0.9844 -> 파라미터: 0.0387M (감소율: 99.30%)
2026-01-14 14:18:59,357 - INFO - 탐색 완료. 목표 파라미터 수(0.0314M)에 가장 근접한 최적 희소도는 0.9852 입니다.
2026-01-14 14:18:59,357 - INFO - ================================================================================
2026-01-14 14:18:59,360 - INFO - 계산된 Pruning 정보(희소도: 0.9852)를 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/pruning_info.yaml'에 저장했습니다.
2026-01-14 14:18:59,402 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 14:18:59,502 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:18:59,502 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:18:59,505 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:19:09,820 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:19:09,822 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:19:10,397 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 14:19:10,397 - INFO - ==================================================
2026-01-14 14:19:10,400 - INFO - ==================================================
2026-01-14 14:19:10,401 - INFO - 모델 파라미터 수:
2026-01-14 14:19:10,401 - INFO -   - 총 파라미터: 28,092 개
2026-01-14 14:19:10,402 - INFO -   - 학습 가능한 파라미터: 28,092 개
2026-01-14 14:19:10,443 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 14:19:10,539 - INFO - FLOPs가 2.1493 GFLOPs에서 0.0081 GFLOPs로 감소했습니다 (감소율: 99.62%).
2026-01-14 14:19:10,540 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 14:19:10,541 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 14:19:10,543 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 14:19:10,544 - INFO - ==================================================
2026-01-14 14:19:10,544 - INFO - train 모드를 시작합니다.
2026-01-14 14:19:10,545 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 14:19:10,545 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 14:19:10,547 - INFO - --------------------------------------------------
2026-01-14 14:19:10,550 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 14:19:19,620 - INFO - [Train] [11/90] | Loss: 0.6763 | Train Acc: 66.29%
2026-01-14 14:19:21,812 - INFO - [Valid] [11/90] | Loss: 0.6685 | Val Acc: 63.72%
2026-01-14 14:19:21,825 - INFO - [Metrics for 'abnormal'] | Precision: 0.5787 | Recall: 0.7962 | F1: 0.6702
2026-01-14 14:19:21,826 - INFO - [Metrics for 'normal'] | Precision: 0.7398 | Recall: 0.5000 | F1: 0.5967
2026-01-14 14:19:21,854 - INFO - [Best Model Saved] (val loss: 0.6685) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:19:21,855 - INFO - --------------------------------------------------
2026-01-14 14:19:21,857 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 14:19:30,664 - INFO - [Train] [12/90] | Loss: 0.6574 | Train Acc: 66.22%
2026-01-14 14:19:33,656 - INFO - [Valid] [12/90] | Loss: 0.6798 | Val Acc: 60.18%
2026-01-14 14:19:33,670 - INFO - [Metrics for 'abnormal'] | Precision: 0.7200 | Recall: 0.2293 | F1: 0.3478
2026-01-14 14:19:33,671 - INFO - [Metrics for 'normal'] | Precision: 0.5813 | Recall: 0.9231 | F1: 0.7134
2026-01-14 14:19:33,679 - INFO - --------------------------------------------------
2026-01-14 14:19:33,682 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 14:19:43,446 - INFO - [Train] [13/90] | Loss: 0.6474 | Train Acc: 66.74%
2026-01-14 14:19:45,842 - INFO - [Valid] [13/90] | Loss: 0.6634 | Val Acc: 61.65%
2026-01-14 14:19:45,851 - INFO - [Metrics for 'abnormal'] | Precision: 0.5521 | Recall: 0.9108 | F1: 0.6875
2026-01-14 14:19:45,852 - INFO - [Metrics for 'normal'] | Precision: 0.8250 | Recall: 0.3626 | F1: 0.5038
2026-01-14 14:19:45,876 - INFO - [Best Model Saved] (val loss: 0.6634) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:19:45,877 - INFO - --------------------------------------------------
2026-01-14 14:19:45,878 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 14:19:55,405 - INFO - [Train] [14/90] | Loss: 0.6399 | Train Acc: 67.34%
2026-01-14 14:19:58,863 - INFO - [Valid] [14/90] | Loss: 0.6807 | Val Acc: 62.83%
2026-01-14 14:19:58,874 - INFO - [Metrics for 'abnormal'] | Precision: 0.6962 | Recall: 0.3503 | F1: 0.4661
2026-01-14 14:19:58,874 - INFO - [Metrics for 'normal'] | Precision: 0.6077 | Recall: 0.8681 | F1: 0.7149
2026-01-14 14:19:58,879 - INFO - --------------------------------------------------
2026-01-14 14:19:58,881 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 14:20:08,931 - INFO - [Train] [15/90] | Loss: 0.6541 | Train Acc: 66.22%
2026-01-14 14:20:11,080 - INFO - [Valid] [15/90] | Loss: 0.6645 | Val Acc: 64.01%
2026-01-14 14:20:11,090 - INFO - [Metrics for 'abnormal'] | Precision: 0.6667 | Recall: 0.4459 | F1: 0.5344
2026-01-14 14:20:11,091 - INFO - [Metrics for 'normal'] | Precision: 0.6282 | Recall: 0.8077 | F1: 0.7067
2026-01-14 14:20:11,095 - INFO - --------------------------------------------------
2026-01-14 14:20:11,098 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 14:20:20,153 - INFO - [Train] [16/90] | Loss: 0.6535 | Train Acc: 65.70%
2026-01-14 14:20:22,384 - INFO - [Valid] [16/90] | Loss: 0.6764 | Val Acc: 60.77%
2026-01-14 14:20:22,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.6765 | Recall: 0.2930 | F1: 0.4089
2026-01-14 14:20:22,396 - INFO - [Metrics for 'normal'] | Precision: 0.5904 | Recall: 0.8791 | F1: 0.7064
2026-01-14 14:20:22,400 - INFO - --------------------------------------------------
2026-01-14 14:20:22,403 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 14:20:31,910 - INFO - [Train] [17/90] | Loss: 0.6565 | Train Acc: 64.73%
2026-01-14 14:20:34,443 - INFO - [Valid] [17/90] | Loss: 0.6892 | Val Acc: 57.23%
2026-01-14 14:20:34,455 - INFO - [Metrics for 'abnormal'] | Precision: 0.7308 | Recall: 0.1210 | F1: 0.2077
2026-01-14 14:20:34,456 - INFO - [Metrics for 'normal'] | Precision: 0.5591 | Recall: 0.9615 | F1: 0.7071
2026-01-14 14:20:34,460 - INFO - --------------------------------------------------
2026-01-14 14:20:34,462 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 14:20:43,288 - INFO - [Train] [18/90] | Loss: 0.6460 | Train Acc: 67.19%
2026-01-14 14:20:46,122 - INFO - [Valid] [18/90] | Loss: 0.6649 | Val Acc: 63.72%
2026-01-14 14:20:46,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.6000 | Recall: 0.6497 | F1: 0.6239
2026-01-14 14:20:46,143 - INFO - [Metrics for 'normal'] | Precision: 0.6746 | Recall: 0.6264 | F1: 0.6496
2026-01-14 14:20:46,148 - INFO - --------------------------------------------------
2026-01-14 14:20:46,150 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 14:20:54,945 - INFO - [Train] [19/90] | Loss: 0.6476 | Train Acc: 66.82%
2026-01-14 14:20:57,692 - INFO - [Valid] [19/90] | Loss: 0.6601 | Val Acc: 64.31%
2026-01-14 14:20:57,704 - INFO - [Metrics for 'abnormal'] | Precision: 0.6047 | Recall: 0.6624 | F1: 0.6322
2026-01-14 14:20:57,705 - INFO - [Metrics for 'normal'] | Precision: 0.6826 | Recall: 0.6264 | F1: 0.6533
2026-01-14 14:20:57,737 - INFO - [Best Model Saved] (val loss: 0.6601) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:20:57,738 - INFO - --------------------------------------------------
2026-01-14 14:20:57,740 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 14:21:06,638 - INFO - [Train] [20/90] | Loss: 0.6456 | Train Acc: 66.96%
2026-01-14 14:21:09,517 - INFO - [Valid] [20/90] | Loss: 0.6667 | Val Acc: 62.54%
2026-01-14 14:21:09,529 - INFO - [Metrics for 'abnormal'] | Precision: 0.5721 | Recall: 0.7580 | F1: 0.6521
2026-01-14 14:21:09,529 - INFO - [Metrics for 'normal'] | Precision: 0.7099 | Recall: 0.5110 | F1: 0.5942
2026-01-14 14:21:09,533 - INFO - --------------------------------------------------
2026-01-14 14:21:09,536 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 14:21:17,931 - INFO - [Train] [21/90] | Loss: 0.6369 | Train Acc: 68.08%
2026-01-14 14:21:20,630 - INFO - [Valid] [21/90] | Loss: 0.6638 | Val Acc: 62.83%
2026-01-14 14:21:20,685 - INFO - [Metrics for 'abnormal'] | Precision: 0.5708 | Recall: 0.7962 | F1: 0.6649
2026-01-14 14:21:20,685 - INFO - [Metrics for 'normal'] | Precision: 0.7333 | Recall: 0.4835 | F1: 0.5828
2026-01-14 14:21:20,689 - INFO - --------------------------------------------------
2026-01-14 14:21:20,700 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 14:21:29,270 - INFO - [Train] [22/90] | Loss: 0.6340 | Train Acc: 68.30%
2026-01-14 14:21:32,019 - INFO - [Valid] [22/90] | Loss: 0.6627 | Val Acc: 62.83%
2026-01-14 14:21:32,043 - INFO - [Metrics for 'abnormal'] | Precision: 0.5708 | Recall: 0.7962 | F1: 0.6649
2026-01-14 14:21:32,043 - INFO - [Metrics for 'normal'] | Precision: 0.7333 | Recall: 0.4835 | F1: 0.5828
2026-01-14 14:21:32,048 - INFO - --------------------------------------------------
2026-01-14 14:21:32,050 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 14:21:42,087 - INFO - [Train] [23/90] | Loss: 0.6295 | Train Acc: 68.23%
2026-01-14 14:21:44,975 - INFO - [Valid] [23/90] | Loss: 0.6567 | Val Acc: 62.24%
2026-01-14 14:21:44,988 - INFO - [Metrics for 'abnormal'] | Precision: 0.5564 | Recall: 0.9108 | F1: 0.6908
2026-01-14 14:21:44,989 - INFO - [Metrics for 'normal'] | Precision: 0.8293 | Recall: 0.3736 | F1: 0.5152
2026-01-14 14:21:45,020 - INFO - [Best Model Saved] (val loss: 0.6567) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:21:45,021 - INFO - --------------------------------------------------
2026-01-14 14:21:45,023 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 14:21:53,691 - INFO - [Train] [24/90] | Loss: 0.6188 | Train Acc: 68.75%
2026-01-14 14:21:56,542 - INFO - [Valid] [24/90] | Loss: 0.6526 | Val Acc: 62.24%
2026-01-14 14:21:56,567 - INFO - [Metrics for 'abnormal'] | Precision: 0.5564 | Recall: 0.9108 | F1: 0.6908
2026-01-14 14:21:56,570 - INFO - [Metrics for 'normal'] | Precision: 0.8293 | Recall: 0.3736 | F1: 0.5152
2026-01-14 14:21:56,642 - INFO - [Best Model Saved] (val loss: 0.6526) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:21:56,643 - INFO - --------------------------------------------------
2026-01-14 14:21:56,656 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 14:22:05,367 - INFO - [Train] [25/90] | Loss: 0.6201 | Train Acc: 67.56%
2026-01-14 14:22:07,905 - INFO - [Valid] [25/90] | Loss: 0.6523 | Val Acc: 61.65%
2026-01-14 14:22:07,943 - INFO - [Metrics for 'abnormal'] | Precision: 0.5517 | Recall: 0.9172 | F1: 0.6890
2026-01-14 14:22:07,946 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.3571 | F1: 0.5000
2026-01-14 14:22:07,999 - INFO - [Best Model Saved] (val loss: 0.6523) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:22:07,999 - INFO - --------------------------------------------------
2026-01-14 14:22:08,004 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 14:22:17,252 - INFO - [Train] [26/90] | Loss: 0.6095 | Train Acc: 68.45%
2026-01-14 14:22:19,870 - INFO - [Valid] [26/90] | Loss: 0.6522 | Val Acc: 61.65%
2026-01-14 14:22:19,915 - INFO - [Metrics for 'abnormal'] | Precision: 0.5517 | Recall: 0.9172 | F1: 0.6890
2026-01-14 14:22:19,915 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.3571 | F1: 0.5000
2026-01-14 14:22:19,969 - INFO - [Best Model Saved] (val loss: 0.6522) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:22:19,970 - INFO - --------------------------------------------------
2026-01-14 14:22:19,972 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 14:22:29,431 - INFO - [Train] [27/90] | Loss: 0.6350 | Train Acc: 68.15%
2026-01-14 14:22:32,042 - INFO - [Valid] [27/90] | Loss: 0.6880 | Val Acc: 61.36%
2026-01-14 14:22:32,072 - INFO - [Metrics for 'abnormal'] | Precision: 0.5619 | Recall: 0.7516 | F1: 0.6431
2026-01-14 14:22:32,072 - INFO - [Metrics for 'normal'] | Precision: 0.6977 | Recall: 0.4945 | F1: 0.5788
2026-01-14 14:22:32,091 - INFO - --------------------------------------------------
2026-01-14 14:22:32,095 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 14:22:40,176 - INFO - [Train] [28/90] | Loss: 0.6498 | Train Acc: 66.52%
2026-01-14 14:22:42,904 - INFO - [Valid] [28/90] | Loss: 0.6805 | Val Acc: 61.36%
2026-01-14 14:22:42,916 - INFO - [Metrics for 'abnormal'] | Precision: 0.5619 | Recall: 0.7516 | F1: 0.6431
2026-01-14 14:22:42,917 - INFO - [Metrics for 'normal'] | Precision: 0.6977 | Recall: 0.4945 | F1: 0.5788
2026-01-14 14:22:42,922 - INFO - --------------------------------------------------
2026-01-14 14:22:42,925 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 14:22:52,348 - INFO - [Train] [29/90] | Loss: 0.6371 | Train Acc: 67.86%
2026-01-14 14:22:55,024 - INFO - [Valid] [29/90] | Loss: 0.6815 | Val Acc: 60.77%
2026-01-14 14:22:55,035 - INFO - [Metrics for 'abnormal'] | Precision: 0.5550 | Recall: 0.7707 | F1: 0.6453
2026-01-14 14:22:55,036 - INFO - [Metrics for 'normal'] | Precision: 0.7025 | Recall: 0.4670 | F1: 0.5611
2026-01-14 14:22:55,040 - INFO - --------------------------------------------------
2026-01-14 14:22:55,042 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 14:23:02,958 - INFO - [Train] [30/90] | Loss: 0.6231 | Train Acc: 69.64%
2026-01-14 14:23:05,989 - INFO - [Valid] [30/90] | Loss: 0.6856 | Val Acc: 60.77%
2026-01-14 14:23:06,000 - INFO - [Metrics for 'abnormal'] | Precision: 0.5550 | Recall: 0.7707 | F1: 0.6453
2026-01-14 14:23:06,003 - INFO - [Metrics for 'normal'] | Precision: 0.7025 | Recall: 0.4670 | F1: 0.5611
2026-01-14 14:23:06,012 - INFO - --------------------------------------------------
2026-01-14 14:23:06,014 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 14:23:14,925 - INFO - [Train] [31/90] | Loss: 0.6346 | Train Acc: 68.08%
2026-01-14 14:23:17,118 - INFO - [Valid] [31/90] | Loss: 0.6831 | Val Acc: 60.47%
2026-01-14 14:23:17,129 - INFO - [Metrics for 'abnormal'] | Precision: 0.5507 | Recall: 0.7962 | F1: 0.6510
2026-01-14 14:23:17,130 - INFO - [Metrics for 'normal'] | Precision: 0.7143 | Recall: 0.4396 | F1: 0.5442
2026-01-14 14:23:17,134 - INFO - --------------------------------------------------
2026-01-14 14:23:17,136 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 14:23:25,678 - INFO - [Train] [32/90] | Loss: 0.6279 | Train Acc: 68.60%
2026-01-14 14:23:29,083 - INFO - [Valid] [32/90] | Loss: 0.6838 | Val Acc: 60.47%
2026-01-14 14:23:29,211 - INFO - [Metrics for 'abnormal'] | Precision: 0.5507 | Recall: 0.7962 | F1: 0.6510
2026-01-14 14:23:29,211 - INFO - [Metrics for 'normal'] | Precision: 0.7143 | Recall: 0.4396 | F1: 0.5442
2026-01-14 14:23:29,219 - INFO - --------------------------------------------------
2026-01-14 14:23:29,224 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 14:23:37,392 - INFO - [Train] [33/90] | Loss: 0.6286 | Train Acc: 68.60%
2026-01-14 14:23:40,995 - INFO - [Valid] [33/90] | Loss: 0.6883 | Val Acc: 59.88%
2026-01-14 14:23:41,019 - INFO - [Metrics for 'abnormal'] | Precision: 0.5459 | Recall: 0.7962 | F1: 0.6477
2026-01-14 14:23:41,019 - INFO - [Metrics for 'normal'] | Precision: 0.7091 | Recall: 0.4286 | F1: 0.5342
2026-01-14 14:23:41,023 - INFO - --------------------------------------------------
2026-01-14 14:23:41,026 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 14:23:49,849 - INFO - [Train] [34/90] | Loss: 0.6312 | Train Acc: 68.30%
2026-01-14 14:23:52,880 - INFO - [Valid] [34/90] | Loss: 0.6857 | Val Acc: 60.18%
2026-01-14 14:23:52,911 - INFO - [Metrics for 'abnormal'] | Precision: 0.5482 | Recall: 0.7962 | F1: 0.6494
2026-01-14 14:23:52,914 - INFO - [Metrics for 'normal'] | Precision: 0.7117 | Recall: 0.4341 | F1: 0.5392
2026-01-14 14:23:52,921 - INFO - --------------------------------------------------
2026-01-14 14:23:52,927 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 14:24:01,135 - INFO - [Train] [35/90] | Loss: 0.6239 | Train Acc: 69.27%
2026-01-14 14:24:05,198 - INFO - [Valid] [35/90] | Loss: 0.6866 | Val Acc: 60.18%
2026-01-14 14:24:05,221 - INFO - [Metrics for 'abnormal'] | Precision: 0.5482 | Recall: 0.7962 | F1: 0.6494
2026-01-14 14:24:05,223 - INFO - [Metrics for 'normal'] | Precision: 0.7117 | Recall: 0.4341 | F1: 0.5392
2026-01-14 14:24:05,234 - INFO - --------------------------------------------------
2026-01-14 14:24:05,240 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 14:24:13,886 - INFO - [Train] [36/90] | Loss: 0.6426 | Train Acc: 66.52%
2026-01-14 14:24:17,118 - INFO - [Valid] [36/90] | Loss: 0.6839 | Val Acc: 60.18%
2026-01-14 14:24:17,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.5482 | Recall: 0.7962 | F1: 0.6494
2026-01-14 14:24:17,144 - INFO - [Metrics for 'normal'] | Precision: 0.7117 | Recall: 0.4341 | F1: 0.5392
2026-01-14 14:24:17,156 - INFO - --------------------------------------------------
2026-01-14 14:24:17,158 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 14:24:25,560 - INFO - [Train] [37/90] | Loss: 0.6400 | Train Acc: 67.11%
2026-01-14 14:24:29,301 - INFO - [Valid] [37/90] | Loss: 0.6859 | Val Acc: 59.29%
2026-01-14 14:24:29,325 - INFO - [Metrics for 'abnormal'] | Precision: 0.5404 | Recall: 0.8089 | F1: 0.6480
2026-01-14 14:24:29,325 - INFO - [Metrics for 'normal'] | Precision: 0.7115 | Recall: 0.4066 | F1: 0.5175
2026-01-14 14:24:29,330 - INFO - --------------------------------------------------
2026-01-14 14:24:29,333 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 14:24:37,912 - INFO - [Train] [38/90] | Loss: 0.6252 | Train Acc: 68.08%
2026-01-14 14:24:41,023 - INFO - [Valid] [38/90] | Loss: 0.6661 | Val Acc: 60.47%
2026-01-14 14:24:41,035 - INFO - [Metrics for 'abnormal'] | Precision: 0.5462 | Recall: 0.8662 | F1: 0.6700
2026-01-14 14:24:41,036 - INFO - [Metrics for 'normal'] | Precision: 0.7667 | Recall: 0.3791 | F1: 0.5074
2026-01-14 14:24:41,040 - INFO - --------------------------------------------------
2026-01-14 14:24:41,043 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 14:24:49,286 - INFO - [Train] [39/90] | Loss: 0.7089 | Train Acc: 58.48%
2026-01-14 14:24:52,614 - INFO - [Valid] [39/90] | Loss: 0.7297 | Val Acc: 53.98%
2026-01-14 14:24:52,635 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:24:52,635 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:24:52,643 - INFO - --------------------------------------------------
2026-01-14 14:24:52,645 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 14:25:01,612 - INFO - [Train] [40/90] | Loss: 0.7110 | Train Acc: 51.64%
2026-01-14 14:25:04,438 - INFO - [Valid] [40/90] | Loss: 0.6940 | Val Acc: 53.98%
2026-01-14 14:25:04,452 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:25:04,453 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:25:04,458 - INFO - --------------------------------------------------
2026-01-14 14:25:04,461 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 14:25:13,077 - INFO - [Train] [41/90] | Loss: 0.6947 | Train Acc: 51.79%
2026-01-14 14:25:16,158 - INFO - [Valid] [41/90] | Loss: 0.6914 | Val Acc: 53.98%
2026-01-14 14:25:16,170 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:25:16,170 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:25:16,175 - INFO - --------------------------------------------------
2026-01-14 14:25:16,177 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 14:25:25,802 - INFO - [Train] [42/90] | Loss: 0.6926 | Train Acc: 52.08%
2026-01-14 14:25:28,658 - INFO - [Valid] [42/90] | Loss: 0.6914 | Val Acc: 53.98%
2026-01-14 14:25:28,669 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:25:28,669 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:25:28,673 - INFO - --------------------------------------------------
2026-01-14 14:25:28,676 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 14:25:38,527 - INFO - [Train] [43/90] | Loss: 0.6926 | Train Acc: 51.93%
2026-01-14 14:25:41,747 - INFO - [Valid] [43/90] | Loss: 0.6916 | Val Acc: 53.98%
2026-01-14 14:25:41,763 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:25:41,763 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:25:41,767 - INFO - --------------------------------------------------
2026-01-14 14:25:41,770 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 14:25:51,055 - INFO - [Train] [44/90] | Loss: 0.6926 | Train Acc: 51.79%
2026-01-14 14:25:52,941 - INFO - [Valid] [44/90] | Loss: 0.6917 | Val Acc: 53.98%
2026-01-14 14:25:52,953 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:25:52,954 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:25:52,958 - INFO - --------------------------------------------------
2026-01-14 14:25:52,961 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 14:26:01,699 - INFO - [Train] [45/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 14:26:04,020 - INFO - [Valid] [45/90] | Loss: 0.6918 | Val Acc: 53.98%
2026-01-14 14:26:04,054 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:26:04,054 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:26:04,066 - INFO - --------------------------------------------------
2026-01-14 14:26:04,089 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 14:26:14,251 - INFO - [Train] [46/90] | Loss: 0.6926 | Train Acc: 52.01%
2026-01-14 14:26:16,306 - INFO - [Valid] [46/90] | Loss: 0.6916 | Val Acc: 53.98%
2026-01-14 14:26:16,315 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:26:16,315 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:26:16,319 - INFO - --------------------------------------------------
2026-01-14 14:26:16,320 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 14:26:26,140 - INFO - [Train] [47/90] | Loss: 0.6927 | Train Acc: 51.79%
2026-01-14 14:26:28,667 - INFO - [Valid] [47/90] | Loss: 0.6916 | Val Acc: 53.98%
2026-01-14 14:26:28,677 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:26:28,677 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:26:28,680 - INFO - --------------------------------------------------
2026-01-14 14:26:28,682 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 14:26:39,353 - INFO - [Train] [48/90] | Loss: 0.6926 | Train Acc: 51.79%
2026-01-14 14:26:41,753 - INFO - [Valid] [48/90] | Loss: 0.6917 | Val Acc: 53.98%
2026-01-14 14:26:41,765 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:26:41,766 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:26:41,771 - INFO - --------------------------------------------------
2026-01-14 14:26:41,773 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 14:26:51,235 - INFO - [Train] [49/90] | Loss: 0.6924 | Train Acc: 51.93%
2026-01-14 14:26:53,266 - INFO - [Valid] [49/90] | Loss: 0.6917 | Val Acc: 53.98%
2026-01-14 14:26:53,279 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:26:53,279 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:26:53,282 - INFO - --------------------------------------------------
2026-01-14 14:26:53,284 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 14:27:04,241 - INFO - [Train] [50/90] | Loss: 0.6923 | Train Acc: 52.08%
2026-01-14 14:27:06,545 - INFO - [Valid] [50/90] | Loss: 0.6917 | Val Acc: 53.98%
2026-01-14 14:27:06,569 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:27:06,572 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:27:06,583 - INFO - --------------------------------------------------
2026-01-14 14:27:06,589 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 14:27:15,612 - INFO - [Train] [51/90] | Loss: 0.6923 | Train Acc: 52.08%
2026-01-14 14:27:18,347 - INFO - [Valid] [51/90] | Loss: 0.6915 | Val Acc: 53.98%
2026-01-14 14:27:18,373 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:27:18,374 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:27:18,384 - INFO - --------------------------------------------------
2026-01-14 14:27:18,390 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 14:27:28,142 - INFO - [Train] [52/90] | Loss: 0.6921 | Train Acc: 52.16%
2026-01-14 14:27:31,119 - INFO - [Valid] [52/90] | Loss: 0.6916 | Val Acc: 53.98%
2026-01-14 14:27:31,139 - INFO - [Metrics for 'abnormal'] | Precision: 1.0000 | Recall: 0.0064 | F1: 0.0127
2026-01-14 14:27:31,141 - INFO - [Metrics for 'normal'] | Precision: 0.5385 | Recall: 1.0000 | F1: 0.7000
2026-01-14 14:27:31,149 - INFO - --------------------------------------------------
2026-01-14 14:27:31,156 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 14:27:40,621 - INFO - [Train] [53/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 14:27:43,506 - INFO - [Valid] [53/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 14:27:43,531 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:27:43,531 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:27:43,535 - INFO - --------------------------------------------------
2026-01-14 14:27:43,539 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 14:27:51,509 - INFO - [Train] [54/90] | Loss: 0.6931 | Train Acc: 51.26%
2026-01-14 14:27:54,449 - INFO - [Valid] [54/90] | Loss: 0.6920 | Val Acc: 53.69%
2026-01-14 14:27:54,473 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:27:54,473 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:27:54,481 - INFO - --------------------------------------------------
2026-01-14 14:27:54,485 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 14:28:03,792 - INFO - [Train] [55/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 14:28:06,227 - INFO - [Valid] [55/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:28:06,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:28:06,246 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:28:06,252 - INFO - --------------------------------------------------
2026-01-14 14:28:06,256 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 14:28:14,978 - INFO - [Train] [56/90] | Loss: 0.6930 | Train Acc: 51.19%
2026-01-14 14:28:18,042 - INFO - [Valid] [56/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:28:18,066 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:28:18,066 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:28:18,074 - INFO - --------------------------------------------------
2026-01-14 14:28:18,080 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 14:28:27,321 - INFO - [Train] [57/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 14:28:30,122 - INFO - [Valid] [57/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:28:30,181 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:28:30,181 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:28:30,187 - INFO - --------------------------------------------------
2026-01-14 14:28:30,189 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 14:28:38,554 - INFO - [Train] [58/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 14:28:42,331 - INFO - [Valid] [58/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:28:42,343 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:28:42,343 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:28:42,348 - INFO - --------------------------------------------------
2026-01-14 14:28:42,351 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 14:28:51,703 - INFO - [Train] [59/90] | Loss: 0.6930 | Train Acc: 51.19%
2026-01-14 14:28:54,105 - INFO - [Valid] [59/90] | Loss: 0.6924 | Val Acc: 53.69%
2026-01-14 14:28:54,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:28:54,115 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:28:54,119 - INFO - --------------------------------------------------
2026-01-14 14:28:54,121 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 14:29:04,225 - INFO - [Train] [60/90] | Loss: 0.6929 | Train Acc: 51.64%
2026-01-14 14:29:07,210 - INFO - [Valid] [60/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:29:07,218 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:29:07,218 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:29:07,221 - INFO - --------------------------------------------------
2026-01-14 14:29:07,222 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 14:29:16,587 - INFO - [Train] [61/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 14:29:19,615 - INFO - [Valid] [61/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:29:19,626 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:29:19,627 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:29:19,631 - INFO - --------------------------------------------------
2026-01-14 14:29:19,633 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 14:29:28,733 - INFO - [Train] [62/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 14:29:31,881 - INFO - [Valid] [62/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:29:31,891 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:29:31,892 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:29:31,895 - INFO - --------------------------------------------------
2026-01-14 14:29:31,897 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 14:29:41,503 - INFO - [Train] [63/90] | Loss: 0.6930 | Train Acc: 51.26%
2026-01-14 14:29:43,910 - INFO - [Valid] [63/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:29:43,921 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:29:43,922 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:29:43,926 - INFO - --------------------------------------------------
2026-01-14 14:29:43,928 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 14:29:52,526 - INFO - [Train] [64/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 14:29:55,339 - INFO - [Valid] [64/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 14:29:55,351 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:29:55,351 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:29:55,355 - INFO - --------------------------------------------------
2026-01-14 14:29:55,357 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 14:30:05,286 - INFO - [Train] [65/90] | Loss: 0.6929 | Train Acc: 51.56%
2026-01-14 14:30:08,138 - INFO - [Valid] [65/90] | Loss: 0.6923 | Val Acc: 53.69%
2026-01-14 14:30:08,148 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:30:08,149 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:30:08,152 - INFO - --------------------------------------------------
2026-01-14 14:30:08,154 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 14:30:16,999 - INFO - [Train] [66/90] | Loss: 0.6930 | Train Acc: 51.34%
2026-01-14 14:30:19,273 - INFO - [Valid] [66/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:30:19,286 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:30:19,287 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:30:19,291 - INFO - --------------------------------------------------
2026-01-14 14:30:19,295 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 14:30:28,516 - INFO - [Train] [67/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 14:30:30,976 - INFO - [Valid] [67/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:30:30,988 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:30:30,989 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:30:30,994 - INFO - --------------------------------------------------
2026-01-14 14:30:30,997 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 14:30:40,458 - INFO - [Train] [68/90] | Loss: 0.6928 | Train Acc: 51.64%
2026-01-14 14:30:42,780 - INFO - [Valid] [68/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:30:42,803 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:30:42,804 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:30:42,810 - INFO - --------------------------------------------------
2026-01-14 14:30:42,814 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 14:30:51,620 - INFO - [Train] [69/90] | Loss: 0.6930 | Train Acc: 51.41%
2026-01-14 14:30:53,938 - INFO - [Valid] [69/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:30:53,952 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:30:53,953 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:30:53,958 - INFO - --------------------------------------------------
2026-01-14 14:30:53,960 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 14:31:03,271 - INFO - [Train] [70/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 14:31:05,771 - INFO - [Valid] [70/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:31:05,782 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:31:05,782 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:31:05,787 - INFO - --------------------------------------------------
2026-01-14 14:31:05,789 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 14:31:14,346 - INFO - [Train] [71/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 14:31:16,695 - INFO - [Valid] [71/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:31:16,717 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:31:16,720 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:31:16,725 - INFO - --------------------------------------------------
2026-01-14 14:31:16,731 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 14:31:26,377 - INFO - [Train] [72/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 14:31:28,963 - INFO - [Valid] [72/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:31:28,985 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:31:28,985 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:31:28,996 - INFO - --------------------------------------------------
2026-01-14 14:31:28,998 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 14:31:38,316 - INFO - [Train] [73/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 14:31:41,140 - INFO - [Valid] [73/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:31:41,153 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:31:41,153 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:31:41,159 - INFO - --------------------------------------------------
2026-01-14 14:31:41,163 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 14:31:50,517 - INFO - [Train] [74/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 14:31:53,208 - INFO - [Valid] [74/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:31:53,221 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:31:53,224 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:31:53,228 - INFO - --------------------------------------------------
2026-01-14 14:31:53,231 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 14:32:03,041 - INFO - [Train] [75/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 14:32:05,251 - INFO - [Valid] [75/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:32:05,263 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:32:05,263 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:32:05,267 - INFO - --------------------------------------------------
2026-01-14 14:32:05,269 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 14:32:14,794 - INFO - [Train] [76/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 14:32:17,013 - INFO - [Valid] [76/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:32:17,032 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:32:17,033 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:32:17,038 - INFO - --------------------------------------------------
2026-01-14 14:32:17,043 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 14:32:26,511 - INFO - [Train] [77/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 14:32:28,879 - INFO - [Valid] [77/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:32:28,893 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:32:28,893 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:32:28,898 - INFO - --------------------------------------------------
2026-01-14 14:32:28,902 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 14:32:38,290 - INFO - [Train] [78/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 14:32:41,039 - INFO - [Valid] [78/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:32:41,051 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:32:41,051 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:32:41,055 - INFO - --------------------------------------------------
2026-01-14 14:32:41,057 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 14:32:51,747 - INFO - [Train] [79/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 14:32:53,719 - INFO - [Valid] [79/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:32:53,733 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:32:53,735 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:32:53,740 - INFO - --------------------------------------------------
2026-01-14 14:32:53,743 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 14:33:01,844 - INFO - [Train] [80/90] | Loss: 0.6928 | Train Acc: 51.41%
2026-01-14 14:33:03,675 - INFO - [Valid] [80/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:33:03,688 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:03,688 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:03,692 - INFO - --------------------------------------------------
2026-01-14 14:33:03,695 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 14:33:10,483 - INFO - [Train] [81/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 14:33:12,325 - INFO - [Valid] [81/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:33:12,333 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:12,333 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:12,336 - INFO - --------------------------------------------------
2026-01-14 14:33:12,338 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 14:33:19,526 - INFO - [Train] [82/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 14:33:21,424 - INFO - [Valid] [82/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:33:21,441 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:21,446 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:21,451 - INFO - --------------------------------------------------
2026-01-14 14:33:21,454 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 14:33:27,476 - INFO - [Train] [83/90] | Loss: 0.6929 | Train Acc: 51.26%
2026-01-14 14:33:29,426 - INFO - [Valid] [83/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:33:29,437 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:29,437 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:29,441 - INFO - --------------------------------------------------
2026-01-14 14:33:29,443 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 14:33:35,383 - INFO - [Train] [84/90] | Loss: 0.6928 | Train Acc: 51.56%
2026-01-14 14:33:37,255 - INFO - [Valid] [84/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:33:37,269 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:37,269 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:37,273 - INFO - --------------------------------------------------
2026-01-14 14:33:37,276 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 14:33:43,083 - INFO - [Train] [85/90] | Loss: 0.6929 | Train Acc: 51.49%
2026-01-14 14:33:44,890 - INFO - [Valid] [85/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:33:44,912 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:44,912 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:44,922 - INFO - --------------------------------------------------
2026-01-14 14:33:44,924 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 14:33:51,103 - INFO - [Train] [86/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 14:33:52,670 - INFO - [Valid] [86/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:33:52,682 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:52,682 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:52,686 - INFO - --------------------------------------------------
2026-01-14 14:33:52,688 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 14:33:57,526 - INFO - [Train] [87/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 14:33:59,028 - INFO - [Valid] [87/90] | Loss: 0.6922 | Val Acc: 53.69%
2026-01-14 14:33:59,040 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:33:59,041 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:33:59,045 - INFO - --------------------------------------------------
2026-01-14 14:33:59,047 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 14:34:03,758 - INFO - [Train] [88/90] | Loss: 0.6928 | Train Acc: 51.49%
2026-01-14 14:34:05,213 - INFO - [Valid] [88/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:34:05,223 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:34:05,223 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:34:05,227 - INFO - --------------------------------------------------
2026-01-14 14:34:05,229 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 14:34:10,515 - INFO - [Train] [89/90] | Loss: 0.6929 | Train Acc: 51.34%
2026-01-14 14:34:12,003 - INFO - [Valid] [89/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:34:12,016 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:34:12,017 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:34:12,021 - INFO - --------------------------------------------------
2026-01-14 14:34:12,024 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 14:34:17,159 - INFO - [Train] [90/90] | Loss: 0.6929 | Train Acc: 51.41%
2026-01-14 14:34:18,727 - INFO - [Valid] [90/90] | Loss: 0.6921 | Val Acc: 53.69%
2026-01-14 14:34:18,736 - INFO - [Metrics for 'abnormal'] | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000
2026-01-14 14:34:18,737 - INFO - [Metrics for 'normal'] | Precision: 0.5369 | Recall: 1.0000 | F1: 0.6987
2026-01-14 14:34:18,742 - INFO - ==================================================
2026-01-14 14:34:18,742 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 14:34:18,743 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 14:34:18,743 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 14:34:20,375 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 14:34:20,377 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 14:34:20,379 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 14:34:20,380 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 14:34:20,384 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 14:34:25,363 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 14:34:25,364 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 14:34:25,880 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.985166015625)에 맞춰 변경되었습니다.
2026-01-14 14:34:25,880 - INFO - ==================================================
2026-01-14 14:34:25,942 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/best_model.pth'
2026-01-14 14:34:25,943 - INFO - ==================================================
2026-01-14 14:34:25,943 - INFO - Test 모드를 시작합니다.
2026-01-14 14:34:26,099 - INFO - 연산량 (MACs): 0.0040 GMACs per sample
2026-01-14 14:34:26,100 - INFO - 연산량 (FLOPs): 0.0081 GFLOPs per sample
2026-01-14 14:34:26,101 - INFO - ==================================================
2026-01-14 14:34:26,101 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 14:34:27,380 - INFO - 샘플 당 평균 Forward Pass 시간: 6.52ms (std: 1.60ms), FPS: 162.72 (std: 40.08) (1개 샘플 x 100회 반복)
2026-01-14 14:34:27,380 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 104.15 MB
2026-01-14 14:34:27,380 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 14:34:29,798 - INFO - [Test] Loss: 0.6402 | Test Acc: 61.65%
2026-01-14 14:34:29,813 - INFO - [Metrics for 'abnormal'] | Precision: 0.5517 | Recall: 0.9172 | F1: 0.6890
2026-01-14 14:34:29,813 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.3571 | F1: 0.5000
2026-01-14 14:34:30,333 - INFO - ==================================================
2026-01-14 14:34:30,334 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/confusion_matrix_20260114_140014.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/confusion_matrix_20260114_140014.pdf'
2026-01-14 14:34:30,334 - INFO - ==================================================
2026-01-14 14:34:30,334 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 14:34:32,102 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/model_fp32_20260114_140014.onnx'에 저장되었습니다. (크기: 0.24 MB)
2026-01-14 14:34:32,524 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2319.04 MB (증가량: 7.07 MB)
2026-01-14 14:34:32,524 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 14:34:34,721 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 17.87ms (std: 18.95ms)
2026-01-14 14:34:34,724 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 77.79 FPS (std: 28.45) (1개 샘플 x 100회 반복)
2026-01-14 14:34:34,724 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2321.54 MB (순수 증가량: 2.50 MB)
2026-01-14 14:34:34,724 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2321.54 MB (전체 증가량: 9.57 MB)
2026-01-14 14:34:38,290 - INFO - [Test (ONNX)] | Test Acc (ONNX): 61.65%
2026-01-14 14:34:38,299 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.5517 | Recall: 0.9172 | F1: 0.6890
2026-01-14 14:34:38,300 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8333 | Recall: 0.3571 | F1: 0.5000
2026-01-14 14:34:38,680 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/val_acc.pdf'
2026-01-14 14:34:39,084 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/train_val_acc.pdf'
2026-01-14 14:34:39,431 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/F1_normal.pdf'
2026-01-14 14:34:39,799 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/val_loss.pdf'
2026-01-14 14:34:40,110 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/learning_rate.pdf'
2026-01-14 14:34:43,586 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_140014/graph_20260114_140014/compile.pdf'
