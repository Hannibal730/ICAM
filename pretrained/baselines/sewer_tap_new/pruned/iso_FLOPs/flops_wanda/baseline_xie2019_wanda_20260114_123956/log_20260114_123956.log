2026-01-14 12:39:56,001 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/log_20260114_123956.log'에 저장됩니다.
2026-01-14 12:39:56,008 - INFO - ==================================================
2026-01-14 12:39:56,008 - INFO - config.yaml:
2026-01-14 12:39:56,008 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: xie2019
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_flops_target: 0.1829

2026-01-14 12:39:56,009 - INFO - ==================================================
2026-01-14 12:39:56,086 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 12:39:56,087 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 12:39:56,087 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 12:39:56,102 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 12:39:56,103 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 12:39:56,103 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 12:39:56,104 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:39:56,424 - INFO - ==================================================
2026-01-14 12:39:56,424 - INFO - 모델 파라미터 수:
2026-01-14 12:39:56,424 - INFO -   - 총 파라미터: 9,160,194 개
2026-01-14 12:39:56,424 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-01-14 12:39:56,424 - INFO - ================================================================================
2026-01-14 12:39:56,425 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 12:39:56,425 - INFO - ================================================================================
2026-01-14 12:39:56,425 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:39:56,425 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 12:39:56,425 - INFO - ==================================================
2026-01-14 12:39:56,426 - INFO - train 모드를 시작합니다.
2026-01-14 12:39:56,426 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:39:56,426 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:39:56,426 - INFO - --------------------------------------------------
2026-01-14 12:39:56,427 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 12:40:04,337 - INFO - [Train] [1/10] | Loss: 0.5919 | Train Acc: 74.40%
2026-01-14 12:40:07,413 - INFO - [Valid] [1/10] | Loss: 0.6090 | Val Acc: 75.52%
2026-01-14 12:40:07,426 - INFO - [Metrics for 'abnormal'] | Precision: 0.8627 | Recall: 0.5605 | F1: 0.6795
2026-01-14 12:40:07,426 - INFO - [Metrics for 'normal'] | Precision: 0.7089 | Recall: 0.9231 | F1: 0.8019
2026-01-14 12:40:07,505 - INFO - [Best Model Saved] (val loss: 0.6090) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:40:07,505 - INFO - --------------------------------------------------
2026-01-14 12:40:07,506 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 12:40:14,704 - INFO - [Train] [2/10] | Loss: 0.5287 | Train Acc: 79.61%
2026-01-14 12:40:16,994 - INFO - [Valid] [2/10] | Loss: 0.7138 | Val Acc: 50.44%
2026-01-14 12:40:17,005 - INFO - [Metrics for 'abnormal'] | Precision: 0.4817 | Recall: 0.9236 | F1: 0.6332
2026-01-14 12:40:17,006 - INFO - [Metrics for 'normal'] | Precision: 0.6842 | Recall: 0.1429 | F1: 0.2364
2026-01-14 12:40:17,010 - INFO - --------------------------------------------------
2026-01-14 12:40:17,010 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 12:40:25,359 - INFO - [Train] [3/10] | Loss: 0.5194 | Train Acc: 80.06%
2026-01-14 12:40:28,166 - INFO - [Valid] [3/10] | Loss: 0.5404 | Val Acc: 75.52%
2026-01-14 12:40:28,189 - INFO - [Metrics for 'abnormal'] | Precision: 0.7056 | Recall: 0.8089 | F1: 0.7537
2026-01-14 12:40:28,189 - INFO - [Metrics for 'normal'] | Precision: 0.8113 | Recall: 0.7088 | F1: 0.7566
2026-01-14 12:40:28,355 - INFO - [Best Model Saved] (val loss: 0.5404) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:40:28,356 - INFO - --------------------------------------------------
2026-01-14 12:40:28,356 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 12:40:38,160 - INFO - [Train] [4/10] | Loss: 0.5015 | Train Acc: 80.95%
2026-01-14 12:40:40,827 - INFO - [Valid] [4/10] | Loss: 0.5544 | Val Acc: 75.81%
2026-01-14 12:40:40,852 - INFO - [Metrics for 'abnormal'] | Precision: 0.8151 | Recall: 0.6178 | F1: 0.7029
2026-01-14 12:40:40,852 - INFO - [Metrics for 'normal'] | Precision: 0.7273 | Recall: 0.8791 | F1: 0.7960
2026-01-14 12:40:40,871 - INFO - --------------------------------------------------
2026-01-14 12:40:40,871 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 12:40:51,493 - INFO - [Train] [5/10] | Loss: 0.4864 | Train Acc: 80.43%
2026-01-14 12:40:53,757 - INFO - [Valid] [5/10] | Loss: 0.5151 | Val Acc: 78.47%
2026-01-14 12:40:53,768 - INFO - [Metrics for 'abnormal'] | Precision: 0.7800 | Recall: 0.7452 | F1: 0.7622
2026-01-14 12:40:53,769 - INFO - [Metrics for 'normal'] | Precision: 0.7884 | Recall: 0.8187 | F1: 0.8032
2026-01-14 12:40:53,865 - INFO - [Best Model Saved] (val loss: 0.5151) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:40:53,866 - INFO - --------------------------------------------------
2026-01-14 12:40:53,867 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 12:41:04,142 - INFO - [Train] [6/10] | Loss: 0.4817 | Train Acc: 83.56%
2026-01-14 12:41:06,429 - INFO - [Valid] [6/10] | Loss: 0.5003 | Val Acc: 81.71%
2026-01-14 12:41:06,443 - INFO - [Metrics for 'abnormal'] | Precision: 0.8231 | Recall: 0.7707 | F1: 0.7961
2026-01-14 12:41:06,443 - INFO - [Metrics for 'normal'] | Precision: 0.8125 | Recall: 0.8571 | F1: 0.8342
2026-01-14 12:41:06,534 - INFO - [Best Model Saved] (val loss: 0.5003) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:41:06,534 - INFO - --------------------------------------------------
2026-01-14 12:41:06,535 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 12:41:15,533 - INFO - [Train] [7/10] | Loss: 0.4565 | Train Acc: 84.30%
2026-01-14 12:41:18,223 - INFO - [Valid] [7/10] | Loss: 0.5103 | Val Acc: 77.88%
2026-01-14 12:41:18,234 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.7834 | F1: 0.7664
2026-01-14 12:41:18,235 - INFO - [Metrics for 'normal'] | Precision: 0.8057 | Recall: 0.7747 | F1: 0.7899
2026-01-14 12:41:18,239 - INFO - --------------------------------------------------
2026-01-14 12:41:18,239 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 12:41:28,568 - INFO - [Train] [8/10] | Loss: 0.4458 | Train Acc: 84.52%
2026-01-14 12:41:31,466 - INFO - [Valid] [8/10] | Loss: 0.5031 | Val Acc: 79.94%
2026-01-14 12:41:31,480 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 12:41:31,481 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 12:41:31,486 - INFO - --------------------------------------------------
2026-01-14 12:41:31,487 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 12:41:42,163 - INFO - [Train] [9/10] | Loss: 0.4283 | Train Acc: 85.86%
2026-01-14 12:41:44,853 - INFO - [Valid] [9/10] | Loss: 0.5000 | Val Acc: 79.65%
2026-01-14 12:41:44,863 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-01-14 12:41:44,863 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-01-14 12:41:44,949 - INFO - [Best Model Saved] (val loss: 0.5000) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:41:44,949 - INFO - --------------------------------------------------
2026-01-14 12:41:44,950 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 12:41:54,261 - INFO - [Train] [10/10] | Loss: 0.4239 | Train Acc: 85.94%
2026-01-14 12:41:57,691 - INFO - [Valid] [10/10] | Loss: 0.4958 | Val Acc: 79.94%
2026-01-14 12:41:57,718 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-01-14 12:41:57,718 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-01-14 12:41:57,858 - INFO - [Best Model Saved] (val loss: 0.4958) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:41:57,860 - INFO - ================================================================================
2026-01-14 12:41:57,860 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 12:41:57,860 - INFO - ================================================================================
2026-01-14 12:41:57,974 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'을(를) 불러왔습니다.
2026-01-14 12:41:57,976 - INFO - ================================================================================
2026-01-14 12:41:57,980 - INFO - 목표 FLOPs (0.1829 GFLOPs)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 12:41:58,072 - INFO - 원본 모델 FLOPs: 2.8696 GFLOPs
2026-01-14 12:41:58,081 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:41:58,081 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:41:58,081 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:06,348 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:08,218 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 12:42:08,219 - INFO - ==================================================
2026-01-14 12:42:08,237 - INFO -   [탐색  1] 희소도: 0.4950 -> FLOPs: 1.3003 GFLOPs (감소율: 54.69%)
2026-01-14 12:42:08,254 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:08,254 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:08,254 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:17,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:19,135 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 12:42:19,135 - INFO - ==================================================
2026-01-14 12:42:19,155 - INFO -   [탐색  2] 희소도: 0.7425 -> FLOPs: 0.6166 GFLOPs (감소율: 78.51%)
2026-01-14 12:42:19,163 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:19,163 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:19,164 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:28,663 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:29,789 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 12:42:29,790 - INFO - ==================================================
2026-01-14 12:42:29,806 - INFO -   [탐색  3] 희소도: 0.8662 -> FLOPs: 0.3005 GFLOPs (감소율: 89.53%)
2026-01-14 12:42:29,818 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:29,820 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:29,821 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:39,695 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:40,559 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 12:42:40,560 - INFO - ==================================================
2026-01-14 12:42:40,572 - INFO -   [탐색  4] 희소도: 0.9281 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:42:40,578 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:40,578 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:40,579 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:48,714 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:49,463 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 12:42:49,464 - INFO - ==================================================
2026-01-14 12:42:49,472 - INFO -   [탐색  5] 희소도: 0.8972 -> FLOPs: 0.2238 GFLOPs (감소율: 92.20%)
2026-01-14 12:42:49,478 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:49,478 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:49,479 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:57,057 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:57,748 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 12:42:57,748 - INFO - ==================================================
2026-01-14 12:42:57,757 - INFO -   [탐색  6] 희소도: 0.9127 -> FLOPs: 0.1858 GFLOPs (감소율: 93.52%)
2026-01-14 12:42:57,763 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:57,763 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:57,764 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:07,627 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:08,730 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.920390625)에 맞춰 변경되었습니다.
2026-01-14 12:43:08,731 - INFO - ==================================================
2026-01-14 12:43:08,773 - INFO -   [탐색  7] 희소도: 0.9204 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:43:08,778 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:08,779 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:08,779 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:17,133 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:18,424 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9242578125)에 맞춰 변경되었습니다.
2026-01-14 12:43:18,425 - INFO - ==================================================
2026-01-14 12:43:18,430 - INFO -   [탐색  8] 희소도: 0.9243 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:43:18,436 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:18,437 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:18,438 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:27,979 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:29,171 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.92232421875)에 맞춰 변경되었습니다.
2026-01-14 12:43:29,172 - INFO - ==================================================
2026-01-14 12:43:29,178 - INFO -   [탐색  9] 희소도: 0.9223 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:43:29,183 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:29,184 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:29,185 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:38,025 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:39,091 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921357421875)에 맞춰 변경되었습니다.
2026-01-14 12:43:39,091 - INFO - ==================================================
2026-01-14 12:43:39,095 - INFO -   [탐색 10] 희소도: 0.9214 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:43:39,099 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:39,099 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:39,100 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:48,413 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:49,796 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218408203125)에 맞춰 변경되었습니다.
2026-01-14 12:43:49,796 - INFO - ==================================================
2026-01-14 12:43:49,801 - INFO -   [탐색 11] 희소도: 0.9218 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:43:49,805 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:49,806 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:49,806 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:58,185 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:59,323 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9220825195312501)에 맞춰 변경되었습니다.
2026-01-14 12:43:59,324 - INFO - ==================================================
2026-01-14 12:43:59,327 - INFO -   [탐색 12] 희소도: 0.9221 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:43:59,331 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:59,331 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:59,332 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:08,395 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:09,558 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9219616699218751)에 맞춰 변경되었습니다.
2026-01-14 12:44:09,559 - INFO - ==================================================
2026-01-14 12:44:09,564 - INFO -   [탐색 13] 희소도: 0.9220 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:44:09,570 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:09,570 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:09,570 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:18,012 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:18,674 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9219012451171875)에 맞춰 변경되었습니다.
2026-01-14 12:44:18,674 - INFO - ==================================================
2026-01-14 12:44:18,679 - INFO -   [탐색 14] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:44:18,684 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:18,685 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:18,685 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:26,266 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:27,480 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218710327148438)에 맞춰 변경되었습니다.
2026-01-14 12:44:27,480 - INFO - ==================================================
2026-01-14 12:44:27,484 - INFO -   [탐색 15] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:44:27,488 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:27,488 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:27,488 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:36,252 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:37,374 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218861389160157)에 맞춰 변경되었습니다.
2026-01-14 12:44:37,375 - INFO - ==================================================
2026-01-14 12:44:37,381 - INFO -   [탐색 16] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:44:37,387 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:37,388 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:37,388 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:47,430 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:48,318 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218785858154297)에 맞춰 변경되었습니다.
2026-01-14 12:44:48,318 - INFO - ==================================================
2026-01-14 12:44:48,323 - INFO -   [탐색 17] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:44:48,327 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:48,327 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:48,328 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:57,780 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:58,694 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218748092651368)에 맞춰 변경되었습니다.
2026-01-14 12:44:58,694 - INFO - ==================================================
2026-01-14 12:44:58,697 - INFO -   [탐색 18] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:44:58,701 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:58,701 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:58,701 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:07,976 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:08,497 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218766975402832)에 맞춰 변경되었습니다.
2026-01-14 12:45:08,498 - INFO - ==================================================
2026-01-14 12:45:08,502 - INFO -   [탐색 19] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:45:08,505 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:08,506 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:08,506 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:17,279 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:17,948 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.92187575340271)에 맞춰 변경되었습니다.
2026-01-14 12:45:17,948 - INFO - ==================================================
2026-01-14 12:45:17,955 - INFO -   [탐색 20] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:45:17,959 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:17,959 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:17,959 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:26,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:27,313 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218752813339234)에 맞춰 변경되었습니다.
2026-01-14 12:45:27,313 - INFO - ==================================================
2026-01-14 12:45:27,317 - INFO -   [탐색 21] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:45:27,321 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:27,322 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:27,322 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:37,526 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:38,080 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750452995301)에 맞춰 변경되었습니다.
2026-01-14 12:45:38,081 - INFO - ==================================================
2026-01-14 12:45:38,084 - INFO -   [탐색 22] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:45:38,088 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:38,088 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:38,088 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:48,242 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:48,945 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749272823334)에 맞춰 변경되었습니다.
2026-01-14 12:45:48,945 - INFO - ==================================================
2026-01-14 12:45:48,952 - INFO -   [탐색 23] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:45:48,959 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:48,959 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:48,960 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:57,494 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:58,656 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749862909318)에 맞춰 변경되었습니다.
2026-01-14 12:45:58,656 - INFO - ==================================================
2026-01-14 12:45:58,661 - INFO -   [탐색 24] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:45:58,665 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:58,666 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:58,666 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:07,322 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:08,216 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750157952309)에 맞춰 변경되었습니다.
2026-01-14 12:46:08,217 - INFO - ==================================================
2026-01-14 12:46:08,222 - INFO -   [탐색 25] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:46:08,226 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:08,227 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:08,227 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:16,668 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:17,315 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750010430814)에 맞춰 변경되었습니다.
2026-01-14 12:46:17,315 - INFO - ==================================================
2026-01-14 12:46:17,320 - INFO -   [탐색 26] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:46:17,325 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:17,326 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:17,327 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:26,708 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:27,569 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749936670065)에 맞춰 변경되었습니다.
2026-01-14 12:46:27,569 - INFO - ==================================================
2026-01-14 12:46:27,575 - INFO -   [탐색 27] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:46:27,580 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:27,580 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:27,580 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:36,530 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:37,244 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921874997355044)에 맞춰 변경되었습니다.
2026-01-14 12:46:37,245 - INFO - ==================================================
2026-01-14 12:46:37,249 - INFO -   [탐색 28] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:46:37,254 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:37,255 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:37,255 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:46,623 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:47,234 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749991990627)에 맞춰 변경되었습니다.
2026-01-14 12:46:47,234 - INFO - ==================================================
2026-01-14 12:46:47,239 - INFO -   [탐색 29] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:46:47,244 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:47,245 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:47,245 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:56,852 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:57,490 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875000121072)에 맞춰 변경되었습니다.
2026-01-14 12:46:57,491 - INFO - ==================================================
2026-01-14 12:46:57,497 - INFO -   [탐색 30] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:46:57,502 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:57,503 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:57,503 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:06,002 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:06,613 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749996600674)에 맞춰 변경되었습니다.
2026-01-14 12:47:06,613 - INFO - ==================================================
2026-01-14 12:47:06,618 - INFO -   [탐색 31] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:47:06,624 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:06,624 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:06,625 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:16,056 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:16,900 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749998905698)에 맞춰 변경되었습니다.
2026-01-14 12:47:16,900 - INFO - ==================================================
2026-01-14 12:47:16,904 - INFO -   [탐색 32] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:47:16,907 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:16,908 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:16,908 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:25,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:25,848 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000058209)에 맞춰 변경되었습니다.
2026-01-14 12:47:25,848 - INFO - ==================================================
2026-01-14 12:47:25,853 - INFO -   [탐색 33] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:47:25,859 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:25,859 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:25,860 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:35,262 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:35,930 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999481953)에 맞춰 변경되었습니다.
2026-01-14 12:47:35,930 - INFO - ==================================================
2026-01-14 12:47:35,936 - INFO -   [탐색 34] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:47:35,942 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:35,942 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:35,943 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:44,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:44,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999770082)에 맞춰 변경되었습니다.
2026-01-14 12:47:44,905 - INFO - ==================================================
2026-01-14 12:47:44,909 - INFO -   [탐색 35] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:47:44,913 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:44,914 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:44,914 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:53,922 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:54,575 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999914145)에 맞춰 변경되었습니다.
2026-01-14 12:47:54,575 - INFO - ==================================================
2026-01-14 12:47:54,580 - INFO -   [탐색 36] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:47:54,585 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:54,586 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:54,586 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:02,877 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:04,202 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999986178)에 맞춰 변경되었습니다.
2026-01-14 12:48:04,204 - INFO - ==================================================
2026-01-14 12:48:04,210 - INFO -   [탐색 37] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:48:04,215 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:04,216 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:04,217 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:13,339 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:14,317 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000022193)에 맞춰 변경되었습니다.
2026-01-14 12:48:14,318 - INFO - ==================================================
2026-01-14 12:48:14,323 - INFO -   [탐색 38] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:48:14,329 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:14,330 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:14,330 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:22,692 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:23,505 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000004186)에 맞춰 변경되었습니다.
2026-01-14 12:48:23,509 - INFO - ==================================================
2026-01-14 12:48:23,516 - INFO -   [탐색 39] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:48:23,524 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:23,524 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:23,525 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:30,956 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:31,701 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999995182)에 맞춰 변경되었습니다.
2026-01-14 12:48:31,702 - INFO - ==================================================
2026-01-14 12:48:31,707 - INFO -   [탐색 40] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:48:31,713 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:31,713 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:31,714 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:39,724 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:41,067 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999999684)에 맞춰 변경되었습니다.
2026-01-14 12:48:41,068 - INFO - ==================================================
2026-01-14 12:48:41,073 - INFO -   [탐색 41] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:48:41,079 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:41,079 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:41,080 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:50,031 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:51,283 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000001934)에 맞춰 변경되었습니다.
2026-01-14 12:48:51,284 - INFO - ==================================================
2026-01-14 12:48:51,288 - INFO -   [탐색 42] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:48:51,293 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:51,294 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:51,294 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:00,915 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:01,789 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000808)에 맞춰 변경되었습니다.
2026-01-14 12:49:01,790 - INFO - ==================================================
2026-01-14 12:49:01,795 - INFO -   [탐색 43] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:49:01,800 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:01,801 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:01,801 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:12,001 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:12,856 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000246)에 맞춰 변경되었습니다.
2026-01-14 12:49:12,856 - INFO - ==================================================
2026-01-14 12:49:12,862 - INFO -   [탐색 44] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:49:12,868 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:12,868 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:12,869 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:22,587 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:23,183 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999999964)에 맞춰 변경되었습니다.
2026-01-14 12:49:23,184 - INFO - ==================================================
2026-01-14 12:49:23,188 - INFO -   [탐색 45] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:49:23,193 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:23,193 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:23,194 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:31,840 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:32,744 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000105)에 맞춰 변경되었습니다.
2026-01-14 12:49:32,744 - INFO - ==================================================
2026-01-14 12:49:32,750 - INFO -   [탐색 46] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:49:32,756 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:32,757 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:32,758 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:40,808 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:42,241 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000036)에 맞춰 변경되었습니다.
2026-01-14 12:49:42,243 - INFO - ==================================================
2026-01-14 12:49:42,248 - INFO -   [탐색 47] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:49:42,251 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:42,252 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:42,252 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:50,507 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:51,850 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:49:51,850 - INFO - ==================================================
2026-01-14 12:49:51,855 - INFO -   [탐색 48] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:49:51,860 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:51,860 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:51,861 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:00,719 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:01,377 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000018)에 맞춰 변경되었습니다.
2026-01-14 12:50:01,378 - INFO - ==================================================
2026-01-14 12:50:01,382 - INFO -   [탐색 49] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:50:01,386 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:01,387 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:01,388 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:10,811 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:11,379 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000009)에 맞춰 변경되었습니다.
2026-01-14 12:50:11,380 - INFO - ==================================================
2026-01-14 12:50:11,383 - INFO -   [탐색 50] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:50:11,389 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:11,389 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:11,390 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:18,966 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:19,634 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000004)에 맞춰 변경되었습니다.
2026-01-14 12:50:19,635 - INFO - ==================================================
2026-01-14 12:50:19,639 - INFO -   [탐색 51] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:50:19,644 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:19,644 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:19,645 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:29,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:30,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000002)에 맞춰 변경되었습니다.
2026-01-14 12:50:30,493 - INFO - ==================================================
2026-01-14 12:50:30,499 - INFO -   [탐색 52] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:50:30,506 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:30,507 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:30,508 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:39,320 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:40,082 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000001)에 맞춰 변경되었습니다.
2026-01-14 12:50:40,082 - INFO - ==================================================
2026-01-14 12:50:40,085 - INFO -   [탐색 53] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 12:50:40,089 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:40,089 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:40,090 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:48,486 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:49,422 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:50:49,423 - INFO - ==================================================
2026-01-14 12:50:49,427 - INFO -   [탐색 54] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:50:49,431 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:49,432 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:49,432 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:58,872 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:59,553 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:50:59,554 - INFO - ==================================================
2026-01-14 12:50:59,559 - INFO -   [탐색 55] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:50:59,564 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:59,565 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:59,566 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:08,924 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:09,555 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:51:09,555 - INFO - ==================================================
2026-01-14 12:51:09,559 - INFO -   [탐색 56] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:51:09,572 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:09,575 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:09,575 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:20,899 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:21,657 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:51:21,658 - INFO - ==================================================
2026-01-14 12:51:21,663 - INFO -   [탐색 57] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:51:21,667 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:21,668 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:21,669 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:31,049 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:31,605 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:51:31,605 - INFO - ==================================================
2026-01-14 12:51:31,610 - INFO -   [탐색 58] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:51:31,615 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:31,616 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:31,617 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:41,693 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:42,348 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:51:42,349 - INFO - ==================================================
2026-01-14 12:51:42,353 - INFO -   [탐색 59] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:51:42,358 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:42,359 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:42,359 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:51,883 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:52,415 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:51:52,416 - INFO - ==================================================
2026-01-14 12:51:52,420 - INFO -   [탐색 60] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:51:52,423 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:52,424 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:52,424 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:01,558 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:02,371 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:52:02,371 - INFO - ==================================================
2026-01-14 12:52:02,374 - INFO -   [탐색 61] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:52:02,378 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:02,378 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:02,379 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:11,282 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:11,888 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:52:11,888 - INFO - ==================================================
2026-01-14 12:52:11,893 - INFO -   [탐색 62] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:52:11,898 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:11,898 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:11,899 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:21,316 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:22,025 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:52:22,026 - INFO - ==================================================
2026-01-14 12:52:22,030 - INFO -   [탐색 63] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:52:22,035 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:22,036 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:22,037 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:31,630 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:32,407 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:52:32,411 - INFO - ==================================================
2026-01-14 12:52:32,420 - INFO -   [탐색 64] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:52:32,428 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:32,430 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:32,431 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:41,704 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:42,226 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:52:42,227 - INFO - ==================================================
2026-01-14 12:52:42,234 - INFO -   [탐색 65] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:52:42,238 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:42,239 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:42,239 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:51,309 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:52,051 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:52:52,051 - INFO - ==================================================
2026-01-14 12:52:52,055 - INFO -   [탐색 66] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:52:52,060 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:52,060 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:52,061 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:00,867 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:01,776 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:53:01,776 - INFO - ==================================================
2026-01-14 12:53:01,781 - INFO -   [탐색 67] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:53:01,787 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:01,788 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:01,788 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:09,772 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:10,675 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:53:10,675 - INFO - ==================================================
2026-01-14 12:53:10,684 - INFO -   [탐색 68] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:53:10,689 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:10,690 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:10,691 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:20,170 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:20,905 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:53:20,905 - INFO - ==================================================
2026-01-14 12:53:20,911 - INFO -   [탐색 69] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:53:20,922 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:20,922 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:20,922 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:30,056 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:30,761 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:53:30,761 - INFO - ==================================================
2026-01-14 12:53:30,765 - INFO -   [탐색 70] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:53:30,770 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:30,770 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:30,771 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:38,963 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:39,798 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:53:39,799 - INFO - ==================================================
2026-01-14 12:53:39,805 - INFO -   [탐색 71] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:53:39,812 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:39,813 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:39,815 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:48,471 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:49,781 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:53:49,782 - INFO - ==================================================
2026-01-14 12:53:49,787 - INFO -   [탐색 72] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:53:49,793 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:49,794 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:49,795 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:59,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:00,311 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:00,312 - INFO - ==================================================
2026-01-14 12:54:00,317 - INFO -   [탐색 73] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:00,322 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:00,322 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:00,323 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:08,159 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:08,951 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:08,951 - INFO - ==================================================
2026-01-14 12:54:08,956 - INFO -   [탐색 74] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:08,961 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:08,961 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:08,962 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:16,900 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:17,525 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:17,526 - INFO - ==================================================
2026-01-14 12:54:17,531 - INFO -   [탐색 75] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:17,536 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:17,537 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:17,537 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:27,536 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:28,267 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:28,268 - INFO - ==================================================
2026-01-14 12:54:28,273 - INFO -   [탐색 76] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:28,278 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:28,279 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:28,280 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:37,513 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:38,747 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:38,749 - INFO - ==================================================
2026-01-14 12:54:38,753 - INFO -   [탐색 77] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:38,758 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:38,759 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:38,759 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:47,796 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:49,069 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:49,070 - INFO - ==================================================
2026-01-14 12:54:49,075 - INFO -   [탐색 78] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:49,080 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:49,081 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:49,082 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:57,254 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:58,345 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:54:58,346 - INFO - ==================================================
2026-01-14 12:54:58,351 - INFO -   [탐색 79] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:54:58,357 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:58,358 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:58,358 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:07,564 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:08,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:55:08,158 - INFO - ==================================================
2026-01-14 12:55:08,163 - INFO -   [탐색 80] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:55:08,168 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:08,169 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:08,169 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:16,227 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:17,128 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:55:17,129 - INFO - ==================================================
2026-01-14 12:55:17,134 - INFO -   [탐색 81] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:55:17,140 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:17,141 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:17,142 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:25,614 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:26,349 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:55:26,350 - INFO - ==================================================
2026-01-14 12:55:26,354 - INFO -   [탐색 82] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:55:26,358 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:26,358 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:26,359 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:35,666 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:36,884 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:55:36,884 - INFO - ==================================================
2026-01-14 12:55:36,889 - INFO -   [탐색 83] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:55:36,894 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:36,895 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:36,896 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:46,553 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:47,072 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:55:47,073 - INFO - ==================================================
2026-01-14 12:55:47,076 - INFO -   [탐색 84] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:55:47,080 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:47,080 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:47,080 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:56,697 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:57,176 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:55:57,176 - INFO - ==================================================
2026-01-14 12:55:57,179 - INFO -   [탐색 85] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:55:57,182 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:57,182 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:57,182 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:05,843 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:06,341 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:56:06,341 - INFO - ==================================================
2026-01-14 12:56:06,345 - INFO -   [탐색 86] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:56:06,349 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:06,350 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:06,350 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:15,323 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:16,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:56:16,156 - INFO - ==================================================
2026-01-14 12:56:16,162 - INFO -   [탐색 87] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:56:16,168 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:16,168 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:16,169 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:25,369 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:26,159 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:56:26,159 - INFO - ==================================================
2026-01-14 12:56:26,164 - INFO -   [탐색 88] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:56:26,179 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:26,179 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:26,180 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:35,145 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:36,006 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:56:36,007 - INFO - ==================================================
2026-01-14 12:56:36,012 - INFO -   [탐색 89] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:56:36,018 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:36,018 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:36,019 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:44,667 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:45,948 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:56:45,949 - INFO - ==================================================
2026-01-14 12:56:45,954 - INFO -   [탐색 90] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:56:45,961 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:45,962 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:45,963 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:55,095 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:55,797 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:56:55,797 - INFO - ==================================================
2026-01-14 12:56:55,802 - INFO -   [탐색 91] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:56:55,807 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:55,808 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:55,808 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:04,458 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:05,557 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:57:05,558 - INFO - ==================================================
2026-01-14 12:57:05,563 - INFO -   [탐색 92] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:57:05,568 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:05,569 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:05,569 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:15,367 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:16,507 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:57:16,507 - INFO - ==================================================
2026-01-14 12:57:16,511 - INFO -   [탐색 93] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:57:16,515 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:16,515 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:16,516 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:24,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:25,191 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:57:25,192 - INFO - ==================================================
2026-01-14 12:57:25,201 - INFO -   [탐색 94] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:57:25,210 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:25,211 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:25,212 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:33,085 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:33,858 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:57:33,862 - INFO - ==================================================
2026-01-14 12:57:33,872 - INFO -   [탐색 95] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:57:33,879 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:33,881 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:33,881 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:43,229 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:43,849 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:57:43,850 - INFO - ==================================================
2026-01-14 12:57:43,856 - INFO -   [탐색 96] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:57:43,862 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:43,862 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:43,862 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:52,288 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:53,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:57:53,970 - INFO - ==================================================
2026-01-14 12:57:53,975 - INFO -   [탐색 97] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:57:53,980 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:53,980 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:53,981 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:01,535 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:02,232 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:58:02,233 - INFO - ==================================================
2026-01-14 12:58:02,239 - INFO -   [탐색 98] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:58:02,245 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:02,246 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:02,247 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:11,449 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:11,985 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:58:11,986 - INFO - ==================================================
2026-01-14 12:58:11,989 - INFO -   [탐색 99] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:58:11,993 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:11,994 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:11,995 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:21,677 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:22,243 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 12:58:22,244 - INFO - ==================================================
2026-01-14 12:58:22,250 - INFO -   [탐색 100] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 12:58:22,251 - INFO - 탐색 완료. 목표 FLOPs(0.1829)에 가장 근접한 최적 희소도는 0.9214 입니다.
2026-01-14 12:58:22,251 - INFO - ================================================================================
2026-01-14 12:58:22,253 - INFO - 계산된 Pruning 정보(희소도: 0.9214)를 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/pruning_info.yaml'에 저장했습니다.
2026-01-14 12:58:22,262 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 12:58:22,275 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:22,276 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:22,277 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:32,110 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:32,790 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921357421875)에 맞춰 변경되었습니다.
2026-01-14 12:58:32,790 - INFO - ==================================================
2026-01-14 12:58:32,790 - INFO - ==================================================
2026-01-14 12:58:32,791 - INFO - 모델 파라미터 수:
2026-01-14 12:58:32,791 - INFO -   - 총 파라미터: 57,792 개
2026-01-14 12:58:32,791 - INFO -   - 학습 가능한 파라미터: 57,792 개
2026-01-14 12:58:32,796 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 12:58:32,803 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1854 GFLOPs로 감소했습니다 (감소율: 93.54%).
2026-01-14 12:58:32,803 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 12:58:32,804 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:58:32,804 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 12:58:32,805 - INFO - ==================================================
2026-01-14 12:58:32,805 - INFO - train 모드를 시작합니다.
2026-01-14 12:58:32,805 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:58:32,805 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:58:32,805 - INFO - --------------------------------------------------
2026-01-14 12:58:32,806 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 12:58:43,108 - INFO - [Train] [11/90] | Loss: 0.5449 | Train Acc: 78.42%
2026-01-14 12:58:45,250 - INFO - [Valid] [11/90] | Loss: 0.5396 | Val Acc: 76.99%
2026-01-14 12:58:45,266 - INFO - [Metrics for 'abnormal'] | Precision: 0.7687 | Recall: 0.7197 | F1: 0.7434
2026-01-14 12:58:45,268 - INFO - [Metrics for 'normal'] | Precision: 0.7708 | Recall: 0.8132 | F1: 0.7914
2026-01-14 12:58:45,278 - INFO - [Best Model Saved] (val loss: 0.5396) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:58:45,279 - INFO - --------------------------------------------------
2026-01-14 12:58:45,279 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 12:58:53,908 - INFO - [Train] [12/90] | Loss: 0.5197 | Train Acc: 80.58%
2026-01-14 12:58:57,456 - INFO - [Valid] [12/90] | Loss: 0.5394 | Val Acc: 77.58%
2026-01-14 12:58:57,468 - INFO - [Metrics for 'abnormal'] | Precision: 0.8293 | Recall: 0.6497 | F1: 0.7286
2026-01-14 12:58:57,468 - INFO - [Metrics for 'normal'] | Precision: 0.7454 | Recall: 0.8846 | F1: 0.8090
2026-01-14 12:58:57,477 - INFO - [Best Model Saved] (val loss: 0.5394) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:58:57,477 - INFO - --------------------------------------------------
2026-01-14 12:58:57,478 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 12:59:06,042 - INFO - [Train] [13/90] | Loss: 0.5047 | Train Acc: 80.88%
2026-01-14 12:59:09,146 - INFO - [Valid] [13/90] | Loss: 0.5182 | Val Acc: 75.81%
2026-01-14 12:59:09,155 - INFO - [Metrics for 'abnormal'] | Precision: 0.7143 | Recall: 0.7962 | F1: 0.7530
2026-01-14 12:59:09,156 - INFO - [Metrics for 'normal'] | Precision: 0.8049 | Recall: 0.7253 | F1: 0.7630
2026-01-14 12:59:09,163 - INFO - [Best Model Saved] (val loss: 0.5182) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:59:09,165 - INFO - --------------------------------------------------
2026-01-14 12:59:09,166 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 12:59:18,125 - INFO - [Train] [14/90] | Loss: 0.4998 | Train Acc: 81.03%
2026-01-14 12:59:21,257 - INFO - [Valid] [14/90] | Loss: 0.5204 | Val Acc: 75.22%
2026-01-14 12:59:21,280 - INFO - [Metrics for 'abnormal'] | Precision: 0.7086 | Recall: 0.7898 | F1: 0.7470
2026-01-14 12:59:21,281 - INFO - [Metrics for 'normal'] | Precision: 0.7988 | Recall: 0.7198 | F1: 0.7572
2026-01-14 12:59:21,288 - INFO - --------------------------------------------------
2026-01-14 12:59:21,290 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 12:59:29,760 - INFO - [Train] [15/90] | Loss: 0.4898 | Train Acc: 81.25%
2026-01-14 12:59:33,186 - INFO - [Valid] [15/90] | Loss: 0.5304 | Val Acc: 77.88%
2026-01-14 12:59:33,233 - INFO - [Metrics for 'abnormal'] | Precision: 0.8060 | Recall: 0.6879 | F1: 0.7423
2026-01-14 12:59:33,233 - INFO - [Metrics for 'normal'] | Precision: 0.7610 | Recall: 0.8571 | F1: 0.8062
2026-01-14 12:59:33,240 - INFO - --------------------------------------------------
2026-01-14 12:59:33,242 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 12:59:42,117 - INFO - [Train] [16/90] | Loss: 0.4921 | Train Acc: 81.99%
2026-01-14 12:59:44,757 - INFO - [Valid] [16/90] | Loss: 0.5019 | Val Acc: 79.35%
2026-01-14 12:59:44,770 - INFO - [Metrics for 'abnormal'] | Precision: 0.8175 | Recall: 0.7134 | F1: 0.7619
2026-01-14 12:59:44,772 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.8626 | F1: 0.8177
2026-01-14 12:59:44,781 - INFO - [Best Model Saved] (val loss: 0.5019) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 12:59:44,782 - INFO - --------------------------------------------------
2026-01-14 12:59:44,782 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 12:59:52,966 - INFO - [Train] [17/90] | Loss: 0.4866 | Train Acc: 83.11%
2026-01-14 12:59:55,935 - INFO - [Valid] [17/90] | Loss: 0.5157 | Val Acc: 77.88%
2026-01-14 12:59:55,946 - INFO - [Metrics for 'abnormal'] | Precision: 0.7808 | Recall: 0.7261 | F1: 0.7525
2026-01-14 12:59:55,947 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.8242 | F1: 0.8000
2026-01-14 12:59:55,950 - INFO - --------------------------------------------------
2026-01-14 12:59:55,951 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:00:04,099 - INFO - [Train] [18/90] | Loss: 0.4854 | Train Acc: 82.59%
2026-01-14 13:00:06,987 - INFO - [Valid] [18/90] | Loss: 0.5034 | Val Acc: 77.88%
2026-01-14 13:00:06,997 - INFO - [Metrics for 'abnormal'] | Precision: 0.7356 | Recall: 0.8153 | F1: 0.7734
2026-01-14 13:00:06,998 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.7473 | F1: 0.7839
2026-01-14 13:00:07,001 - INFO - --------------------------------------------------
2026-01-14 13:00:07,001 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:00:15,621 - INFO - [Train] [19/90] | Loss: 0.4919 | Train Acc: 82.37%
2026-01-14 13:00:18,789 - INFO - [Valid] [19/90] | Loss: 0.5088 | Val Acc: 78.47%
2026-01-14 13:00:18,810 - INFO - [Metrics for 'abnormal'] | Precision: 0.7625 | Recall: 0.7771 | F1: 0.7697
2026-01-14 13:00:18,815 - INFO - [Metrics for 'normal'] | Precision: 0.8045 | Recall: 0.7912 | F1: 0.7978
2026-01-14 13:00:18,830 - INFO - --------------------------------------------------
2026-01-14 13:00:18,831 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:00:26,169 - INFO - [Train] [20/90] | Loss: 0.4844 | Train Acc: 82.51%
2026-01-14 13:00:29,249 - INFO - [Valid] [20/90] | Loss: 0.4968 | Val Acc: 79.94%
2026-01-14 13:00:29,260 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 13:00:29,260 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 13:00:29,338 - INFO - [Best Model Saved] (val loss: 0.4968) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:00:29,338 - INFO - --------------------------------------------------
2026-01-14 13:00:29,338 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:00:37,100 - INFO - [Train] [21/90] | Loss: 0.4660 | Train Acc: 83.26%
2026-01-14 13:00:40,984 - INFO - [Valid] [21/90] | Loss: 0.5033 | Val Acc: 78.76%
2026-01-14 13:00:41,015 - INFO - [Metrics for 'abnormal'] | Precision: 0.7374 | Recall: 0.8408 | F1: 0.7857
2026-01-14 13:00:41,016 - INFO - [Metrics for 'normal'] | Precision: 0.8438 | Recall: 0.7418 | F1: 0.7895
2026-01-14 13:00:41,021 - INFO - --------------------------------------------------
2026-01-14 13:00:41,022 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:00:49,663 - INFO - [Train] [22/90] | Loss: 0.4698 | Train Acc: 84.15%
2026-01-14 13:00:51,886 - INFO - [Valid] [22/90] | Loss: 0.4956 | Val Acc: 79.94%
2026-01-14 13:00:51,898 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-01-14 13:00:51,898 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-01-14 13:00:51,905 - INFO - [Best Model Saved] (val loss: 0.4956) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:00:51,906 - INFO - --------------------------------------------------
2026-01-14 13:00:51,906 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:01:00,777 - INFO - [Train] [23/90] | Loss: 0.4612 | Train Acc: 85.71%
2026-01-14 13:01:03,373 - INFO - [Valid] [23/90] | Loss: 0.5076 | Val Acc: 77.58%
2026-01-14 13:01:03,391 - INFO - [Metrics for 'abnormal'] | Precision: 0.7189 | Recall: 0.8471 | F1: 0.7778
2026-01-14 13:01:03,392 - INFO - [Metrics for 'normal'] | Precision: 0.8442 | Recall: 0.7143 | F1: 0.7738
2026-01-14 13:01:03,395 - INFO - --------------------------------------------------
2026-01-14 13:01:03,399 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:01:11,742 - INFO - [Train] [24/90] | Loss: 0.4533 | Train Acc: 85.49%
2026-01-14 13:01:14,209 - INFO - [Valid] [24/90] | Loss: 0.4809 | Val Acc: 82.89%
2026-01-14 13:01:14,232 - INFO - [Metrics for 'abnormal'] | Precision: 0.8278 | Recall: 0.7962 | F1: 0.8117
2026-01-14 13:01:14,232 - INFO - [Metrics for 'normal'] | Precision: 0.8298 | Recall: 0.8571 | F1: 0.8432
2026-01-14 13:01:14,241 - INFO - [Best Model Saved] (val loss: 0.4809) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:01:14,242 - INFO - --------------------------------------------------
2026-01-14 13:01:14,242 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:01:22,578 - INFO - [Train] [25/90] | Loss: 0.4582 | Train Acc: 85.19%
2026-01-14 13:01:25,234 - INFO - [Valid] [25/90] | Loss: 0.5036 | Val Acc: 79.65%
2026-01-14 13:01:25,268 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.8153 | F1: 0.7877
2026-01-14 13:01:25,269 - INFO - [Metrics for 'normal'] | Precision: 0.8304 | Recall: 0.7802 | F1: 0.8045
2026-01-14 13:01:25,278 - INFO - --------------------------------------------------
2026-01-14 13:01:25,281 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:01:33,496 - INFO - [Train] [26/90] | Loss: 0.4525 | Train Acc: 84.90%
2026-01-14 13:01:35,887 - INFO - [Valid] [26/90] | Loss: 0.5060 | Val Acc: 80.53%
2026-01-14 13:01:35,900 - INFO - [Metrics for 'abnormal'] | Precision: 0.8321 | Recall: 0.7261 | F1: 0.7755
2026-01-14 13:01:35,901 - INFO - [Metrics for 'normal'] | Precision: 0.7871 | Recall: 0.8736 | F1: 0.8281
2026-01-14 13:01:35,905 - INFO - --------------------------------------------------
2026-01-14 13:01:35,906 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:01:43,998 - INFO - [Train] [27/90] | Loss: 0.4567 | Train Acc: 83.85%
2026-01-14 13:01:47,663 - INFO - [Valid] [27/90] | Loss: 0.4877 | Val Acc: 80.83%
2026-01-14 13:01:47,691 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 13:01:47,691 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 13:01:47,697 - INFO - --------------------------------------------------
2026-01-14 13:01:47,701 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:01:55,915 - INFO - [Train] [28/90] | Loss: 0.4531 | Train Acc: 84.90%
2026-01-14 13:01:58,778 - INFO - [Valid] [28/90] | Loss: 0.4910 | Val Acc: 81.71%
2026-01-14 13:01:58,790 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-01-14 13:01:58,791 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-01-14 13:01:58,796 - INFO - --------------------------------------------------
2026-01-14 13:01:58,797 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:02:08,259 - INFO - [Train] [29/90] | Loss: 0.4473 | Train Acc: 85.42%
2026-01-14 13:02:10,997 - INFO - [Valid] [29/90] | Loss: 0.4807 | Val Acc: 81.71%
2026-01-14 13:02:11,018 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-01-14 13:02:11,018 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-01-14 13:02:11,030 - INFO - [Best Model Saved] (val loss: 0.4807) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:02:11,030 - INFO - --------------------------------------------------
2026-01-14 13:02:11,031 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:02:21,273 - INFO - [Train] [30/90] | Loss: 0.4475 | Train Acc: 85.27%
2026-01-14 13:02:23,970 - INFO - [Valid] [30/90] | Loss: 0.4844 | Val Acc: 80.83%
2026-01-14 13:02:23,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.8333 | Recall: 0.7325 | F1: 0.7797
2026-01-14 13:02:23,985 - INFO - [Metrics for 'normal'] | Precision: 0.7910 | Recall: 0.8736 | F1: 0.8303
2026-01-14 13:02:23,990 - INFO - --------------------------------------------------
2026-01-14 13:02:23,991 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:02:33,591 - INFO - [Train] [31/90] | Loss: 0.4388 | Train Acc: 86.16%
2026-01-14 13:02:36,120 - INFO - [Valid] [31/90] | Loss: 0.4906 | Val Acc: 80.83%
2026-01-14 13:02:36,130 - INFO - [Metrics for 'abnormal'] | Precision: 0.7614 | Recall: 0.8535 | F1: 0.8048
2026-01-14 13:02:36,131 - INFO - [Metrics for 'normal'] | Precision: 0.8589 | Recall: 0.7692 | F1: 0.8116
2026-01-14 13:02:36,135 - INFO - --------------------------------------------------
2026-01-14 13:02:36,136 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:02:45,312 - INFO - [Train] [32/90] | Loss: 0.4302 | Train Acc: 87.28%
2026-01-14 13:02:47,876 - INFO - [Valid] [32/90] | Loss: 0.4724 | Val Acc: 83.19%
2026-01-14 13:02:47,900 - INFO - [Metrics for 'abnormal'] | Precision: 0.8205 | Recall: 0.8153 | F1: 0.8179
2026-01-14 13:02:47,900 - INFO - [Metrics for 'normal'] | Precision: 0.8415 | Recall: 0.8462 | F1: 0.8438
2026-01-14 13:02:47,975 - INFO - [Best Model Saved] (val loss: 0.4724) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:02:47,975 - INFO - --------------------------------------------------
2026-01-14 13:02:47,975 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:02:57,256 - INFO - [Train] [33/90] | Loss: 0.4287 | Train Acc: 85.19%
2026-01-14 13:02:59,399 - INFO - [Valid] [33/90] | Loss: 0.4846 | Val Acc: 81.42%
2026-01-14 13:02:59,549 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-01-14 13:02:59,550 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-01-14 13:02:59,559 - INFO - --------------------------------------------------
2026-01-14 13:02:59,563 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:03:09,508 - INFO - [Train] [34/90] | Loss: 0.4249 | Train Acc: 87.72%
2026-01-14 13:03:11,607 - INFO - [Valid] [34/90] | Loss: 0.4696 | Val Acc: 82.60%
2026-01-14 13:03:11,633 - INFO - [Metrics for 'abnormal'] | Precision: 0.8063 | Recall: 0.8217 | F1: 0.8139
2026-01-14 13:03:11,633 - INFO - [Metrics for 'normal'] | Precision: 0.8436 | Recall: 0.8297 | F1: 0.8366
2026-01-14 13:03:11,653 - INFO - [Best Model Saved] (val loss: 0.4696) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:03:11,653 - INFO - --------------------------------------------------
2026-01-14 13:03:11,653 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:03:21,356 - INFO - [Train] [35/90] | Loss: 0.4215 | Train Acc: 86.76%
2026-01-14 13:03:24,076 - INFO - [Valid] [35/90] | Loss: 0.4715 | Val Acc: 82.01%
2026-01-14 13:03:24,122 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 13:03:24,122 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 13:03:24,126 - INFO - --------------------------------------------------
2026-01-14 13:03:24,154 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:03:33,641 - INFO - [Train] [36/90] | Loss: 0.4178 | Train Acc: 86.38%
2026-01-14 13:03:36,209 - INFO - [Valid] [36/90] | Loss: 0.4634 | Val Acc: 81.71%
2026-01-14 13:03:36,223 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:03:36,223 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:03:36,233 - INFO - [Best Model Saved] (val loss: 0.4634) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:03:36,233 - INFO - --------------------------------------------------
2026-01-14 13:03:36,234 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:03:45,512 - INFO - [Train] [37/90] | Loss: 0.4263 | Train Acc: 85.79%
2026-01-14 13:03:47,474 - INFO - [Valid] [37/90] | Loss: 0.4712 | Val Acc: 82.60%
2026-01-14 13:03:47,485 - INFO - [Metrics for 'abnormal'] | Precision: 0.8101 | Recall: 0.8153 | F1: 0.8127
2026-01-14 13:03:47,486 - INFO - [Metrics for 'normal'] | Precision: 0.8398 | Recall: 0.8352 | F1: 0.8375
2026-01-14 13:03:47,492 - INFO - --------------------------------------------------
2026-01-14 13:03:47,493 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:03:56,197 - INFO - [Train] [38/90] | Loss: 0.4165 | Train Acc: 87.05%
2026-01-14 13:03:59,179 - INFO - [Valid] [38/90] | Loss: 0.4757 | Val Acc: 82.01%
2026-01-14 13:03:59,199 - INFO - [Metrics for 'abnormal'] | Precision: 0.8200 | Recall: 0.7834 | F1: 0.8013
2026-01-14 13:03:59,199 - INFO - [Metrics for 'normal'] | Precision: 0.8201 | Recall: 0.8516 | F1: 0.8356
2026-01-14 13:03:59,268 - INFO - --------------------------------------------------
2026-01-14 13:03:59,268 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:04:09,066 - INFO - [Train] [39/90] | Loss: 0.4089 | Train Acc: 86.98%
2026-01-14 13:04:12,193 - INFO - [Valid] [39/90] | Loss: 0.4630 | Val Acc: 83.48%
2026-01-14 13:04:12,206 - INFO - [Metrics for 'abnormal'] | Precision: 0.8258 | Recall: 0.8153 | F1: 0.8205
2026-01-14 13:04:12,206 - INFO - [Metrics for 'normal'] | Precision: 0.8424 | Recall: 0.8516 | F1: 0.8470
2026-01-14 13:04:12,224 - INFO - [Best Model Saved] (val loss: 0.4630) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:04:12,225 - INFO - --------------------------------------------------
2026-01-14 13:04:12,225 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:04:21,277 - INFO - [Train] [40/90] | Loss: 0.4180 | Train Acc: 86.83%
2026-01-14 13:04:24,525 - INFO - [Valid] [40/90] | Loss: 0.4617 | Val Acc: 82.01%
2026-01-14 13:04:24,537 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-01-14 13:04:24,538 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-01-14 13:04:24,548 - INFO - [Best Model Saved] (val loss: 0.4617) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:04:24,549 - INFO - --------------------------------------------------
2026-01-14 13:04:24,550 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:04:32,912 - INFO - [Train] [41/90] | Loss: 0.4052 | Train Acc: 87.35%
2026-01-14 13:04:36,123 - INFO - [Valid] [41/90] | Loss: 0.4668 | Val Acc: 82.01%
2026-01-14 13:04:36,134 - INFO - [Metrics for 'abnormal'] | Precision: 0.7824 | Recall: 0.8471 | F1: 0.8135
2026-01-14 13:04:36,134 - INFO - [Metrics for 'normal'] | Precision: 0.8580 | Recall: 0.7967 | F1: 0.8262
2026-01-14 13:04:36,138 - INFO - --------------------------------------------------
2026-01-14 13:04:36,138 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:04:44,351 - INFO - [Train] [42/90] | Loss: 0.4065 | Train Acc: 87.65%
2026-01-14 13:04:47,348 - INFO - [Valid] [42/90] | Loss: 0.4525 | Val Acc: 82.01%
2026-01-14 13:04:47,363 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 13:04:47,364 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 13:04:47,410 - INFO - [Best Model Saved] (val loss: 0.4525) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:04:47,410 - INFO - --------------------------------------------------
2026-01-14 13:04:47,411 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:04:56,524 - INFO - [Train] [43/90] | Loss: 0.3971 | Train Acc: 87.50%
2026-01-14 13:04:59,806 - INFO - [Valid] [43/90] | Loss: 0.4595 | Val Acc: 82.30%
2026-01-14 13:04:59,817 - INFO - [Metrics for 'abnormal'] | Precision: 0.8129 | Recall: 0.8025 | F1: 0.8077
2026-01-14 13:04:59,817 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8407 | F1: 0.8361
2026-01-14 13:04:59,821 - INFO - --------------------------------------------------
2026-01-14 13:04:59,822 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:05:08,237 - INFO - [Train] [44/90] | Loss: 0.4021 | Train Acc: 88.10%
2026-01-14 13:05:11,255 - INFO - [Valid] [44/90] | Loss: 0.4593 | Val Acc: 83.48%
2026-01-14 13:05:11,275 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.8280 | F1: 0.8228
2026-01-14 13:05:11,276 - INFO - [Metrics for 'normal'] | Precision: 0.8500 | Recall: 0.8407 | F1: 0.8453
2026-01-14 13:05:11,283 - INFO - --------------------------------------------------
2026-01-14 13:05:11,287 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:05:20,971 - INFO - [Train] [45/90] | Loss: 0.3937 | Train Acc: 88.32%
2026-01-14 13:05:24,157 - INFO - [Valid] [45/90] | Loss: 0.4512 | Val Acc: 82.60%
2026-01-14 13:05:24,169 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 13:05:24,169 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 13:05:24,177 - INFO - [Best Model Saved] (val loss: 0.4512) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:05:24,178 - INFO - --------------------------------------------------
2026-01-14 13:05:24,178 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:05:32,637 - INFO - [Train] [46/90] | Loss: 0.3928 | Train Acc: 88.17%
2026-01-14 13:05:35,491 - INFO - [Valid] [46/90] | Loss: 0.4639 | Val Acc: 81.42%
2026-01-14 13:05:35,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.8471 | F1: 0.8085
2026-01-14 13:05:35,524 - INFO - [Metrics for 'normal'] | Precision: 0.8563 | Recall: 0.7857 | F1: 0.8195
2026-01-14 13:05:35,534 - INFO - --------------------------------------------------
2026-01-14 13:05:35,540 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:05:44,730 - INFO - [Train] [47/90] | Loss: 0.3845 | Train Acc: 88.47%
2026-01-14 13:05:47,753 - INFO - [Valid] [47/90] | Loss: 0.4565 | Val Acc: 80.83%
2026-01-14 13:05:47,768 - INFO - [Metrics for 'abnormal'] | Precision: 0.7644 | Recall: 0.8471 | F1: 0.8036
2026-01-14 13:05:47,769 - INFO - [Metrics for 'normal'] | Precision: 0.8545 | Recall: 0.7747 | F1: 0.8127
2026-01-14 13:05:47,773 - INFO - --------------------------------------------------
2026-01-14 13:05:47,774 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:05:55,711 - INFO - [Train] [48/90] | Loss: 0.3800 | Train Acc: 89.29%
2026-01-14 13:05:58,900 - INFO - [Valid] [48/90] | Loss: 0.4579 | Val Acc: 83.19%
2026-01-14 13:05:58,918 - INFO - [Metrics for 'abnormal'] | Precision: 0.8086 | Recall: 0.8344 | F1: 0.8213
2026-01-14 13:05:58,918 - INFO - [Metrics for 'normal'] | Precision: 0.8531 | Recall: 0.8297 | F1: 0.8412
2026-01-14 13:05:58,926 - INFO - --------------------------------------------------
2026-01-14 13:05:58,928 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:06:09,520 - INFO - [Train] [49/90] | Loss: 0.3854 | Train Acc: 88.54%
2026-01-14 13:06:12,474 - INFO - [Valid] [49/90] | Loss: 0.4615 | Val Acc: 82.30%
2026-01-14 13:06:12,482 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 13:06:12,482 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 13:06:12,485 - INFO - --------------------------------------------------
2026-01-14 13:06:12,485 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:06:20,876 - INFO - [Train] [50/90] | Loss: 0.3843 | Train Acc: 89.21%
2026-01-14 13:06:23,466 - INFO - [Valid] [50/90] | Loss: 0.4593 | Val Acc: 82.30%
2026-01-14 13:06:23,480 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 13:06:23,481 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 13:06:23,486 - INFO - --------------------------------------------------
2026-01-14 13:06:23,487 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:06:32,077 - INFO - [Train] [51/90] | Loss: 0.3810 | Train Acc: 89.21%
2026-01-14 13:06:34,287 - INFO - [Valid] [51/90] | Loss: 0.4653 | Val Acc: 81.42%
2026-01-14 13:06:34,306 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8025 | F1: 0.8000
2026-01-14 13:06:34,308 - INFO - [Metrics for 'normal'] | Precision: 0.8287 | Recall: 0.8242 | F1: 0.8264
2026-01-14 13:06:34,316 - INFO - --------------------------------------------------
2026-01-14 13:06:34,316 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:06:42,491 - INFO - [Train] [52/90] | Loss: 0.3669 | Train Acc: 90.18%
2026-01-14 13:06:45,937 - INFO - [Valid] [52/90] | Loss: 0.4671 | Val Acc: 82.30%
2026-01-14 13:06:45,948 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8662 | F1: 0.8193
2026-01-14 13:06:45,948 - INFO - [Metrics for 'normal'] | Precision: 0.8720 | Recall: 0.7857 | F1: 0.8266
2026-01-14 13:06:45,953 - INFO - --------------------------------------------------
2026-01-14 13:06:45,953 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:06:54,310 - INFO - [Train] [53/90] | Loss: 0.3684 | Train Acc: 89.66%
2026-01-14 13:06:57,800 - INFO - [Valid] [53/90] | Loss: 0.4577 | Val Acc: 82.30%
2026-01-14 13:06:57,821 - INFO - [Metrics for 'abnormal'] | Precision: 0.7803 | Recall: 0.8599 | F1: 0.8182
2026-01-14 13:06:57,821 - INFO - [Metrics for 'normal'] | Precision: 0.8675 | Recall: 0.7912 | F1: 0.8276
2026-01-14 13:06:57,827 - INFO - --------------------------------------------------
2026-01-14 13:06:57,828 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:07:06,557 - INFO - [Train] [54/90] | Loss: 0.3590 | Train Acc: 90.33%
2026-01-14 13:07:09,396 - INFO - [Valid] [54/90] | Loss: 0.4604 | Val Acc: 83.19%
2026-01-14 13:07:09,410 - INFO - [Metrics for 'abnormal'] | Precision: 0.8012 | Recall: 0.8471 | F1: 0.8235
2026-01-14 13:07:09,411 - INFO - [Metrics for 'normal'] | Precision: 0.8613 | Recall: 0.8187 | F1: 0.8394
2026-01-14 13:07:09,416 - INFO - --------------------------------------------------
2026-01-14 13:07:09,417 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:07:17,336 - INFO - [Train] [55/90] | Loss: 0.3637 | Train Acc: 90.48%
2026-01-14 13:07:20,190 - INFO - [Valid] [55/90] | Loss: 0.4676 | Val Acc: 82.01%
2026-01-14 13:07:20,216 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8535 | F1: 0.8146
2026-01-14 13:07:20,217 - INFO - [Metrics for 'normal'] | Precision: 0.8623 | Recall: 0.7912 | F1: 0.8252
2026-01-14 13:07:20,221 - INFO - --------------------------------------------------
2026-01-14 13:07:20,226 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:07:29,007 - INFO - [Train] [56/90] | Loss: 0.3704 | Train Acc: 89.88%
2026-01-14 13:07:31,807 - INFO - [Valid] [56/90] | Loss: 0.4638 | Val Acc: 82.60%
2026-01-14 13:07:31,830 - INFO - [Metrics for 'abnormal'] | Precision: 0.7917 | Recall: 0.8471 | F1: 0.8185
2026-01-14 13:07:31,831 - INFO - [Metrics for 'normal'] | Precision: 0.8596 | Recall: 0.8077 | F1: 0.8329
2026-01-14 13:07:31,838 - INFO - --------------------------------------------------
2026-01-14 13:07:31,839 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:07:41,717 - INFO - [Train] [57/90] | Loss: 0.3612 | Train Acc: 91.29%
2026-01-14 13:07:44,351 - INFO - [Valid] [57/90] | Loss: 0.4505 | Val Acc: 81.12%
2026-01-14 13:07:44,362 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 13:07:44,363 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 13:07:44,376 - INFO - [Best Model Saved] (val loss: 0.4505) -> 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:07:44,376 - INFO - --------------------------------------------------
2026-01-14 13:07:44,376 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:07:52,418 - INFO - [Train] [58/90] | Loss: 0.3486 | Train Acc: 92.26%
2026-01-14 13:07:55,652 - INFO - [Valid] [58/90] | Loss: 0.4672 | Val Acc: 81.12%
2026-01-14 13:07:55,676 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 13:07:55,676 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 13:07:55,679 - INFO - --------------------------------------------------
2026-01-14 13:07:55,680 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:08:04,682 - INFO - [Train] [59/90] | Loss: 0.3534 | Train Acc: 91.59%
2026-01-14 13:08:07,038 - INFO - [Valid] [59/90] | Loss: 0.4571 | Val Acc: 81.42%
2026-01-14 13:08:07,062 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 13:08:07,062 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 13:08:07,069 - INFO - --------------------------------------------------
2026-01-14 13:08:07,073 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:08:15,679 - INFO - [Train] [60/90] | Loss: 0.3527 | Train Acc: 91.07%
2026-01-14 13:08:19,001 - INFO - [Valid] [60/90] | Loss: 0.4769 | Val Acc: 82.60%
2026-01-14 13:08:19,013 - INFO - [Metrics for 'abnormal'] | Precision: 0.7952 | Recall: 0.8408 | F1: 0.8173
2026-01-14 13:08:19,014 - INFO - [Metrics for 'normal'] | Precision: 0.8555 | Recall: 0.8132 | F1: 0.8338
2026-01-14 13:08:19,019 - INFO - --------------------------------------------------
2026-01-14 13:08:19,020 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:08:27,809 - INFO - [Train] [61/90] | Loss: 0.3529 | Train Acc: 91.74%
2026-01-14 13:08:30,324 - INFO - [Valid] [61/90] | Loss: 0.4673 | Val Acc: 82.30%
2026-01-14 13:08:30,335 - INFO - [Metrics for 'abnormal'] | Precision: 0.7870 | Recall: 0.8471 | F1: 0.8160
2026-01-14 13:08:30,336 - INFO - [Metrics for 'normal'] | Precision: 0.8588 | Recall: 0.8022 | F1: 0.8295
2026-01-14 13:08:30,340 - INFO - --------------------------------------------------
2026-01-14 13:08:30,341 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:08:39,974 - INFO - [Train] [62/90] | Loss: 0.3535 | Train Acc: 91.29%
2026-01-14 13:08:41,921 - INFO - [Valid] [62/90] | Loss: 0.4707 | Val Acc: 82.01%
2026-01-14 13:08:41,948 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.8662 | F1: 0.8168
2026-01-14 13:08:41,948 - INFO - [Metrics for 'normal'] | Precision: 0.8712 | Recall: 0.7802 | F1: 0.8232
2026-01-14 13:08:41,952 - INFO - --------------------------------------------------
2026-01-14 13:08:41,956 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:08:50,724 - INFO - [Train] [63/90] | Loss: 0.3461 | Train Acc: 91.07%
2026-01-14 13:08:52,925 - INFO - [Valid] [63/90] | Loss: 0.4719 | Val Acc: 81.71%
2026-01-14 13:08:52,934 - INFO - [Metrics for 'abnormal'] | Precision: 0.7811 | Recall: 0.8408 | F1: 0.8098
2026-01-14 13:08:52,934 - INFO - [Metrics for 'normal'] | Precision: 0.8529 | Recall: 0.7967 | F1: 0.8239
2026-01-14 13:08:52,938 - INFO - --------------------------------------------------
2026-01-14 13:08:52,938 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:09:01,302 - INFO - [Train] [64/90] | Loss: 0.3333 | Train Acc: 92.56%
2026-01-14 13:09:03,623 - INFO - [Valid] [64/90] | Loss: 0.4617 | Val Acc: 81.71%
2026-01-14 13:09:03,635 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:09:03,635 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:09:03,640 - INFO - --------------------------------------------------
2026-01-14 13:09:03,640 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:09:11,370 - INFO - [Train] [65/90] | Loss: 0.3443 | Train Acc: 92.04%
2026-01-14 13:09:14,176 - INFO - [Valid] [65/90] | Loss: 0.4736 | Val Acc: 81.42%
2026-01-14 13:09:14,192 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 13:09:14,194 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 13:09:14,199 - INFO - --------------------------------------------------
2026-01-14 13:09:14,201 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:09:23,080 - INFO - [Train] [66/90] | Loss: 0.3386 | Train Acc: 92.86%
2026-01-14 13:09:25,803 - INFO - [Valid] [66/90] | Loss: 0.4781 | Val Acc: 81.71%
2026-01-14 13:09:25,826 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:09:25,826 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:09:25,831 - INFO - --------------------------------------------------
2026-01-14 13:09:25,831 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:09:34,622 - INFO - [Train] [67/90] | Loss: 0.3318 | Train Acc: 92.71%
2026-01-14 13:09:37,185 - INFO - [Valid] [67/90] | Loss: 0.4759 | Val Acc: 82.01%
2026-01-14 13:09:37,200 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-01-14 13:09:37,200 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-01-14 13:09:37,204 - INFO - --------------------------------------------------
2026-01-14 13:09:37,205 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:09:45,504 - INFO - [Train] [68/90] | Loss: 0.3303 | Train Acc: 92.78%
2026-01-14 13:09:47,765 - INFO - [Valid] [68/90] | Loss: 0.4910 | Val Acc: 81.42%
2026-01-14 13:09:47,781 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-01-14 13:09:47,782 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-01-14 13:09:47,787 - INFO - --------------------------------------------------
2026-01-14 13:09:47,789 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:09:56,091 - INFO - [Train] [69/90] | Loss: 0.3451 | Train Acc: 92.34%
2026-01-14 13:09:59,368 - INFO - [Valid] [69/90] | Loss: 0.4778 | Val Acc: 81.42%
2026-01-14 13:09:59,377 - INFO - [Metrics for 'abnormal'] | Precision: 0.7798 | Recall: 0.8344 | F1: 0.8062
2026-01-14 13:09:59,377 - INFO - [Metrics for 'normal'] | Precision: 0.8480 | Recall: 0.7967 | F1: 0.8215
2026-01-14 13:09:59,381 - INFO - --------------------------------------------------
2026-01-14 13:09:59,381 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:10:07,615 - INFO - [Train] [70/90] | Loss: 0.3238 | Train Acc: 93.82%
2026-01-14 13:10:10,917 - INFO - [Valid] [70/90] | Loss: 0.4775 | Val Acc: 81.42%
2026-01-14 13:10:10,962 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 13:10:10,966 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 13:10:10,973 - INFO - --------------------------------------------------
2026-01-14 13:10:10,974 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:10:18,744 - INFO - [Train] [71/90] | Loss: 0.3297 | Train Acc: 92.78%
2026-01-14 13:10:22,568 - INFO - [Valid] [71/90] | Loss: 0.4877 | Val Acc: 82.60%
2026-01-14 13:10:22,610 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 13:10:22,612 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 13:10:22,619 - INFO - --------------------------------------------------
2026-01-14 13:10:22,686 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:10:31,403 - INFO - [Train] [72/90] | Loss: 0.3216 | Train Acc: 93.97%
2026-01-14 13:10:34,328 - INFO - [Valid] [72/90] | Loss: 0.4823 | Val Acc: 82.30%
2026-01-14 13:10:34,343 - INFO - [Metrics for 'abnormal'] | Precision: 0.7904 | Recall: 0.8408 | F1: 0.8148
2026-01-14 13:10:34,343 - INFO - [Metrics for 'normal'] | Precision: 0.8547 | Recall: 0.8077 | F1: 0.8305
2026-01-14 13:10:34,348 - INFO - --------------------------------------------------
2026-01-14 13:10:34,349 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:10:42,327 - INFO - [Train] [73/90] | Loss: 0.3247 | Train Acc: 93.08%
2026-01-14 13:10:45,794 - INFO - [Valid] [73/90] | Loss: 0.4884 | Val Acc: 81.71%
2026-01-14 13:10:45,813 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-01-14 13:10:45,813 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-01-14 13:10:45,823 - INFO - --------------------------------------------------
2026-01-14 13:10:45,826 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:10:53,894 - INFO - [Train] [74/90] | Loss: 0.3266 | Train Acc: 93.08%
2026-01-14 13:10:57,235 - INFO - [Valid] [74/90] | Loss: 0.4955 | Val Acc: 81.12%
2026-01-14 13:10:57,303 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 13:10:57,307 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 13:10:57,315 - INFO - --------------------------------------------------
2026-01-14 13:10:57,316 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:11:06,045 - INFO - [Train] [75/90] | Loss: 0.3205 | Train Acc: 94.20%
2026-01-14 13:11:08,668 - INFO - [Valid] [75/90] | Loss: 0.4855 | Val Acc: 82.60%
2026-01-14 13:11:08,682 - INFO - [Metrics for 'abnormal'] | Precision: 0.7952 | Recall: 0.8408 | F1: 0.8173
2026-01-14 13:11:08,682 - INFO - [Metrics for 'normal'] | Precision: 0.8555 | Recall: 0.8132 | F1: 0.8338
2026-01-14 13:11:08,686 - INFO - --------------------------------------------------
2026-01-14 13:11:08,687 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:11:17,291 - INFO - [Train] [76/90] | Loss: 0.3184 | Train Acc: 93.45%
2026-01-14 13:11:20,200 - INFO - [Valid] [76/90] | Loss: 0.4870 | Val Acc: 83.48%
2026-01-14 13:11:20,273 - INFO - [Metrics for 'abnormal'] | Precision: 0.8061 | Recall: 0.8471 | F1: 0.8261
2026-01-14 13:11:20,273 - INFO - [Metrics for 'normal'] | Precision: 0.8621 | Recall: 0.8242 | F1: 0.8427
2026-01-14 13:11:20,284 - INFO - --------------------------------------------------
2026-01-14 13:11:20,288 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:11:29,482 - INFO - [Train] [77/90] | Loss: 0.3191 | Train Acc: 94.35%
2026-01-14 13:11:31,996 - INFO - [Valid] [77/90] | Loss: 0.4885 | Val Acc: 82.60%
2026-01-14 13:11:32,150 - INFO - [Metrics for 'abnormal'] | Precision: 0.7882 | Recall: 0.8535 | F1: 0.8196
2026-01-14 13:11:32,160 - INFO - [Metrics for 'normal'] | Precision: 0.8639 | Recall: 0.8022 | F1: 0.8319
2026-01-14 13:11:32,173 - INFO - --------------------------------------------------
2026-01-14 13:11:32,174 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:11:41,241 - INFO - [Train] [78/90] | Loss: 0.3205 | Train Acc: 93.90%
2026-01-14 13:11:44,323 - INFO - [Valid] [78/90] | Loss: 0.4870 | Val Acc: 82.30%
2026-01-14 13:11:45,268 - INFO - [Metrics for 'abnormal'] | Precision: 0.7939 | Recall: 0.8344 | F1: 0.8137
2026-01-14 13:11:45,268 - INFO - [Metrics for 'normal'] | Precision: 0.8506 | Recall: 0.8132 | F1: 0.8315
2026-01-14 13:11:45,282 - INFO - --------------------------------------------------
2026-01-14 13:11:45,283 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:11:54,003 - INFO - [Train] [79/90] | Loss: 0.3134 | Train Acc: 94.94%
2026-01-14 13:11:57,123 - INFO - [Valid] [79/90] | Loss: 0.4926 | Val Acc: 82.01%
2026-01-14 13:11:57,135 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-01-14 13:11:57,135 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-01-14 13:11:57,139 - INFO - --------------------------------------------------
2026-01-14 13:11:57,160 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:12:06,262 - INFO - [Train] [80/90] | Loss: 0.3180 | Train Acc: 94.20%
2026-01-14 13:12:08,493 - INFO - [Valid] [80/90] | Loss: 0.4913 | Val Acc: 82.01%
2026-01-14 13:12:08,505 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 13:12:08,506 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 13:12:08,511 - INFO - --------------------------------------------------
2026-01-14 13:12:08,512 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:12:17,039 - INFO - [Train] [81/90] | Loss: 0.3151 | Train Acc: 94.64%
2026-01-14 13:12:19,755 - INFO - [Valid] [81/90] | Loss: 0.4932 | Val Acc: 82.60%
2026-01-14 13:12:19,778 - INFO - [Metrics for 'abnormal'] | Precision: 0.7952 | Recall: 0.8408 | F1: 0.8173
2026-01-14 13:12:19,778 - INFO - [Metrics for 'normal'] | Precision: 0.8555 | Recall: 0.8132 | F1: 0.8338
2026-01-14 13:12:19,788 - INFO - --------------------------------------------------
2026-01-14 13:12:19,792 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:12:29,474 - INFO - [Train] [82/90] | Loss: 0.3143 | Train Acc: 94.72%
2026-01-14 13:12:32,469 - INFO - [Valid] [82/90] | Loss: 0.4933 | Val Acc: 81.71%
2026-01-14 13:12:32,482 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 13:12:32,482 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 13:12:32,487 - INFO - --------------------------------------------------
2026-01-14 13:12:32,488 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:12:41,060 - INFO - [Train] [83/90] | Loss: 0.3194 | Train Acc: 93.60%
2026-01-14 13:12:43,675 - INFO - [Valid] [83/90] | Loss: 0.4886 | Val Acc: 82.30%
2026-01-14 13:12:43,687 - INFO - [Metrics for 'abnormal'] | Precision: 0.7939 | Recall: 0.8344 | F1: 0.8137
2026-01-14 13:12:43,688 - INFO - [Metrics for 'normal'] | Precision: 0.8506 | Recall: 0.8132 | F1: 0.8315
2026-01-14 13:12:43,692 - INFO - --------------------------------------------------
2026-01-14 13:12:43,693 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:12:52,498 - INFO - [Train] [84/90] | Loss: 0.3194 | Train Acc: 93.60%
2026-01-14 13:12:55,574 - INFO - [Valid] [84/90] | Loss: 0.4890 | Val Acc: 82.60%
2026-01-14 13:12:55,606 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8280 | F1: 0.8150
2026-01-14 13:12:55,608 - INFO - [Metrics for 'normal'] | Precision: 0.8475 | Recall: 0.8242 | F1: 0.8357
2026-01-14 13:12:55,616 - INFO - --------------------------------------------------
2026-01-14 13:12:55,619 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:13:03,801 - INFO - [Train] [85/90] | Loss: 0.3160 | Train Acc: 94.05%
2026-01-14 13:13:06,707 - INFO - [Valid] [85/90] | Loss: 0.4925 | Val Acc: 82.60%
2026-01-14 13:13:06,721 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8280 | F1: 0.8150
2026-01-14 13:13:06,722 - INFO - [Metrics for 'normal'] | Precision: 0.8475 | Recall: 0.8242 | F1: 0.8357
2026-01-14 13:13:06,728 - INFO - --------------------------------------------------
2026-01-14 13:13:06,728 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:13:14,584 - INFO - [Train] [86/90] | Loss: 0.3135 | Train Acc: 94.20%
2026-01-14 13:13:16,365 - INFO - [Valid] [86/90] | Loss: 0.4952 | Val Acc: 82.89%
2026-01-14 13:13:16,410 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8408 | F1: 0.8199
2026-01-14 13:13:16,410 - INFO - [Metrics for 'normal'] | Precision: 0.8563 | Recall: 0.8187 | F1: 0.8371
2026-01-14 13:13:16,415 - INFO - --------------------------------------------------
2026-01-14 13:13:16,415 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:13:25,502 - INFO - [Train] [87/90] | Loss: 0.3196 | Train Acc: 94.27%
2026-01-14 13:13:27,437 - INFO - [Valid] [87/90] | Loss: 0.4957 | Val Acc: 82.01%
2026-01-14 13:13:27,452 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 13:13:27,452 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 13:13:27,457 - INFO - --------------------------------------------------
2026-01-14 13:13:27,458 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:13:35,918 - INFO - [Train] [88/90] | Loss: 0.3082 | Train Acc: 94.94%
2026-01-14 13:13:38,511 - INFO - [Valid] [88/90] | Loss: 0.4950 | Val Acc: 82.01%
2026-01-14 13:13:38,536 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 13:13:38,536 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 13:13:38,542 - INFO - --------------------------------------------------
2026-01-14 13:13:38,544 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:13:48,163 - INFO - [Train] [89/90] | Loss: 0.3102 | Train Acc: 94.94%
2026-01-14 13:13:51,915 - INFO - [Valid] [89/90] | Loss: 0.4934 | Val Acc: 82.30%
2026-01-14 13:13:51,922 - INFO - [Metrics for 'abnormal'] | Precision: 0.7939 | Recall: 0.8344 | F1: 0.8137
2026-01-14 13:13:51,922 - INFO - [Metrics for 'normal'] | Precision: 0.8506 | Recall: 0.8132 | F1: 0.8315
2026-01-14 13:13:51,925 - INFO - --------------------------------------------------
2026-01-14 13:13:51,925 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:13:59,499 - INFO - [Train] [90/90] | Loss: 0.3103 | Train Acc: 94.79%
2026-01-14 13:14:01,115 - INFO - [Valid] [90/90] | Loss: 0.4984 | Val Acc: 82.30%
2026-01-14 13:14:01,132 - INFO - [Metrics for 'abnormal'] | Precision: 0.7975 | Recall: 0.8280 | F1: 0.8125
2026-01-14 13:14:01,132 - INFO - [Metrics for 'normal'] | Precision: 0.8466 | Recall: 0.8187 | F1: 0.8324
2026-01-14 13:14:01,136 - INFO - ==================================================
2026-01-14 13:14:01,136 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:14:01,137 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:14:01,137 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:14:01,255 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:14:01,257 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 13:14:01,258 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 13:14:01,258 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 13:14:08,228 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:14:08,689 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921357421875)에 맞춰 변경되었습니다.
2026-01-14 13:14:08,689 - INFO - ==================================================
2026-01-14 13:14:08,696 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/best_model.pth'
2026-01-14 13:14:08,696 - INFO - ==================================================
2026-01-14 13:14:08,697 - INFO - Test 모드를 시작합니다.
2026-01-14 13:14:09,162 - INFO - 연산량 (MACs): 0.0927 GMACs per sample
2026-01-14 13:14:09,163 - INFO - 연산량 (FLOPs): 0.1854 GFLOPs per sample
2026-01-14 13:14:09,163 - INFO - ==================================================
2026-01-14 13:14:09,163 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:14:09,639 - INFO - 샘플 당 평균 Forward Pass 시간: 0.52ms (std: 0.08ms), FPS: 1963.20 (std: 162.37) (1개 샘플 x 100회 반복)
2026-01-14 13:14:09,640 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 160.08 MB
2026-01-14 13:14:09,641 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:14:13,292 - INFO - [Test] Loss: 0.3690 | Test Acc: 81.12%
2026-01-14 13:14:13,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 13:14:13,304 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 13:14:13,885 - INFO - ==================================================
2026-01-14 13:14:13,886 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/confusion_matrix_20260114_123956.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/confusion_matrix_20260114_123956.pdf'
2026-01-14 13:14:13,886 - INFO - ==================================================
2026-01-14 13:14:13,886 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:14:14,150 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/model_fp32_20260114_123956.onnx'에 저장되었습니다. (크기: 0.22 MB)
2026-01-14 13:14:14,531 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2404.68 MB (증가량: 6.89 MB)
2026-01-14 13:14:14,532 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:14:15,594 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 7.12ms (std: 6.60ms)
2026-01-14 13:14:15,594 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 274.77 FPS (std: 231.69) (1개 샘플 x 100회 반복)
2026-01-14 13:14:15,594 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2410.68 MB (순수 증가량: 5.50 MB)
2026-01-14 13:14:15,594 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2410.68 MB (전체 증가량: 12.89 MB)
2026-01-14 13:14:19,110 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.12%
2026-01-14 13:14:19,139 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 13:14:19,140 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 13:14:19,951 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/val_acc.pdf'
2026-01-14 13:14:20,476 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/train_val_acc.pdf'
2026-01-14 13:14:20,889 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/F1_normal.pdf'
2026-01-14 13:14:21,296 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/val_loss.pdf'
2026-01-14 13:14:21,690 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/learning_rate.pdf'
2026-01-14 13:14:28,489 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_wanda_20260114_123956/graph_20260114_123956/compile.pdf'
