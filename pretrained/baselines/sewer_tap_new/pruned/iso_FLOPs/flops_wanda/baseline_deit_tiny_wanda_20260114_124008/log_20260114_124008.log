2026-01-14 12:40:08,959 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/log_20260114_124008.log'에 저장됩니다.
2026-01-14 12:40:08,968 - INFO - ==================================================
2026-01-14 12:40:08,969 - INFO - config.yaml:
2026-01-14 12:40:08,969 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: deit_tiny
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_flops_target: 0.1829

2026-01-14 12:40:08,970 - INFO - ==================================================
2026-01-14 12:40:09,040 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 12:40:09,041 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 12:40:09,041 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 12:40:09,055 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 12:40:09,056 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 12:40:09,056 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 12:40:09,056 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:40:14,889 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 12:40:14,893 - INFO - ==================================================
2026-01-14 12:40:14,893 - INFO - 모델 파라미터 수:
2026-01-14 12:40:14,893 - INFO -   - 총 파라미터: 5,524,802 개
2026-01-14 12:40:14,894 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-01-14 12:40:14,894 - INFO - ================================================================================
2026-01-14 12:40:14,894 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 12:40:14,894 - INFO - ================================================================================
2026-01-14 12:40:14,894 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:40:14,896 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 12:40:14,896 - INFO - ==================================================
2026-01-14 12:40:14,896 - INFO - train 모드를 시작합니다.
2026-01-14 12:40:14,897 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:40:14,897 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:40:14,897 - INFO - --------------------------------------------------
2026-01-14 12:40:14,899 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 12:40:24,944 - INFO - [Train] [1/10] | Loss: 0.7051 | Train Acc: 60.49%
2026-01-14 12:40:28,399 - INFO - [Valid] [1/10] | Loss: 0.6723 | Val Acc: 59.88%
2026-01-14 12:40:28,420 - INFO - [Metrics for 'abnormal'] | Precision: 0.5484 | Recall: 0.7580 | F1: 0.6364
2026-01-14 12:40:28,420 - INFO - [Metrics for 'normal'] | Precision: 0.6885 | Recall: 0.4615 | F1: 0.5526
2026-01-14 12:40:28,495 - INFO - [Best Model Saved] (val loss: 0.6723) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:40:28,497 - INFO - --------------------------------------------------
2026-01-14 12:40:28,500 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 12:40:38,351 - INFO - [Train] [2/10] | Loss: 0.6454 | Train Acc: 65.33%
2026-01-14 12:40:41,304 - INFO - [Valid] [2/10] | Loss: 0.6487 | Val Acc: 63.42%
2026-01-14 12:40:41,326 - INFO - [Metrics for 'abnormal'] | Precision: 0.7260 | Recall: 0.3376 | F1: 0.4609
2026-01-14 12:40:41,326 - INFO - [Metrics for 'normal'] | Precision: 0.6090 | Recall: 0.8901 | F1: 0.7232
2026-01-14 12:40:41,397 - INFO - [Best Model Saved] (val loss: 0.6487) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:40:41,397 - INFO - --------------------------------------------------
2026-01-14 12:40:41,399 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 12:40:51,439 - INFO - [Train] [3/10] | Loss: 0.5892 | Train Acc: 71.35%
2026-01-14 12:40:53,873 - INFO - [Valid] [3/10] | Loss: 0.5868 | Val Acc: 71.09%
2026-01-14 12:40:53,885 - INFO - [Metrics for 'abnormal'] | Precision: 0.6545 | Recall: 0.7962 | F1: 0.7184
2026-01-14 12:40:53,886 - INFO - [Metrics for 'normal'] | Precision: 0.7838 | Recall: 0.6374 | F1: 0.7030
2026-01-14 12:40:53,962 - INFO - [Best Model Saved] (val loss: 0.5868) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:40:53,962 - INFO - --------------------------------------------------
2026-01-14 12:40:53,963 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 12:41:03,902 - INFO - [Train] [4/10] | Loss: 0.6382 | Train Acc: 64.88%
2026-01-14 12:41:06,445 - INFO - [Valid] [4/10] | Loss: 0.6619 | Val Acc: 61.06%
2026-01-14 12:41:06,454 - INFO - [Metrics for 'abnormal'] | Precision: 0.5479 | Recall: 0.9108 | F1: 0.6842
2026-01-14 12:41:06,455 - INFO - [Metrics for 'normal'] | Precision: 0.8205 | Recall: 0.3516 | F1: 0.4923
2026-01-14 12:41:06,458 - INFO - --------------------------------------------------
2026-01-14 12:41:06,460 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 12:41:16,749 - INFO - [Train] [5/10] | Loss: 0.5693 | Train Acc: 73.14%
2026-01-14 12:41:19,559 - INFO - [Valid] [5/10] | Loss: 0.6780 | Val Acc: 59.00%
2026-01-14 12:41:19,577 - INFO - [Metrics for 'abnormal'] | Precision: 0.5349 | Recall: 0.8790 | F1: 0.6651
2026-01-14 12:41:19,580 - INFO - [Metrics for 'normal'] | Precision: 0.7654 | Recall: 0.3407 | F1: 0.4715
2026-01-14 12:41:19,585 - INFO - --------------------------------------------------
2026-01-14 12:41:19,598 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 12:41:28,952 - INFO - [Train] [6/10] | Loss: 0.5625 | Train Acc: 73.96%
2026-01-14 12:41:31,792 - INFO - [Valid] [6/10] | Loss: 0.5825 | Val Acc: 71.98%
2026-01-14 12:41:31,814 - INFO - [Metrics for 'abnormal'] | Precision: 0.6890 | Recall: 0.7197 | F1: 0.7040
2026-01-14 12:41:31,816 - INFO - [Metrics for 'normal'] | Precision: 0.7486 | Recall: 0.7198 | F1: 0.7339
2026-01-14 12:41:31,876 - INFO - [Best Model Saved] (val loss: 0.5825) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:41:31,876 - INFO - --------------------------------------------------
2026-01-14 12:41:31,878 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 12:41:42,175 - INFO - [Train] [7/10] | Loss: 0.5121 | Train Acc: 79.32%
2026-01-14 12:41:44,802 - INFO - [Valid] [7/10] | Loss: 0.6175 | Val Acc: 71.68%
2026-01-14 12:41:44,812 - INFO - [Metrics for 'abnormal'] | Precision: 0.8280 | Recall: 0.4904 | F1: 0.6160
2026-01-14 12:41:44,812 - INFO - [Metrics for 'normal'] | Precision: 0.6748 | Recall: 0.9121 | F1: 0.7757
2026-01-14 12:41:44,815 - INFO - --------------------------------------------------
2026-01-14 12:41:44,817 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 12:41:54,192 - INFO - [Train] [8/10] | Loss: 0.5099 | Train Acc: 79.84%
2026-01-14 12:41:57,621 - INFO - [Valid] [8/10] | Loss: 0.5498 | Val Acc: 74.63%
2026-01-14 12:41:57,635 - INFO - [Metrics for 'abnormal'] | Precision: 0.8142 | Recall: 0.5860 | F1: 0.6815
2026-01-14 12:41:57,635 - INFO - [Metrics for 'normal'] | Precision: 0.7124 | Recall: 0.8846 | F1: 0.7892
2026-01-14 12:41:57,701 - INFO - [Best Model Saved] (val loss: 0.5498) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:41:57,701 - INFO - --------------------------------------------------
2026-01-14 12:41:57,703 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 12:42:06,665 - INFO - [Train] [9/10] | Loss: 0.5007 | Train Acc: 80.21%
2026-01-14 12:42:10,885 - INFO - [Valid] [9/10] | Loss: 0.5339 | Val Acc: 77.88%
2026-01-14 12:42:10,896 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-01-14 12:42:10,897 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-01-14 12:42:10,963 - INFO - [Best Model Saved] (val loss: 0.5339) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:42:10,966 - INFO - --------------------------------------------------
2026-01-14 12:42:10,968 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 12:42:19,377 - INFO - [Train] [10/10] | Loss: 0.4873 | Train Acc: 80.58%
2026-01-14 12:42:22,479 - INFO - [Valid] [10/10] | Loss: 0.5352 | Val Acc: 76.40%
2026-01-14 12:42:22,491 - INFO - [Metrics for 'abnormal'] | Precision: 0.7278 | Recall: 0.7834 | F1: 0.7546
2026-01-14 12:42:22,491 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.7473 | F1: 0.7727
2026-01-14 12:42:22,496 - INFO - ================================================================================
2026-01-14 12:42:22,496 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 12:42:22,496 - INFO - ================================================================================
2026-01-14 12:42:22,568 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'을(를) 불러왔습니다.
2026-01-14 12:42:22,568 - INFO - ================================================================================
2026-01-14 12:42:22,569 - INFO - 목표 FLOPs (0.1829 GFLOPs)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 12:42:22,623 - INFO - 원본 모델 FLOPs: 2.1493 GFLOPs
2026-01-14 12:42:22,731 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:22,732 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:22,734 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:31,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:31,335 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:42:31,942 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 12:42:31,943 - INFO - ==================================================
2026-01-14 12:42:31,985 - INFO -   [탐색  1] 희소도: 0.4950 -> FLOPs: 0.7288 GFLOPs (감소율: 66.09%)
2026-01-14 12:42:32,072 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:32,073 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:32,088 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:40,904 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:40,906 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:42:41,784 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 12:42:41,784 - INFO - ==================================================
2026-01-14 12:42:41,819 - INFO -   [탐색  2] 희소도: 0.7425 -> FLOPs: 0.2840 GFLOPs (감소율: 86.79%)
2026-01-14 12:42:41,871 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:41,871 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:41,874 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:42:51,238 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:42:51,244 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:42:53,111 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 12:42:53,114 - INFO - ==================================================
2026-01-14 12:42:53,203 - INFO -   [탐색  3] 희소도: 0.8662 -> FLOPs: 0.1224 GFLOPs (감소율: 94.30%)
2026-01-14 12:42:53,289 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:42:53,290 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:42:53,293 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:03,534 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:03,536 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:43:04,300 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.804375)에 맞춰 변경되었습니다.
2026-01-14 12:43:04,300 - INFO - ==================================================
2026-01-14 12:43:04,337 - INFO -   [탐색  4] 희소도: 0.8044 -> FLOPs: 0.1980 GFLOPs (감소율: 90.79%)
2026-01-14 12:43:04,392 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:04,393 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:04,396 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:13,571 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:13,572 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:43:14,067 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8353124999999999)에 맞춰 변경되었습니다.
2026-01-14 12:43:14,067 - INFO - ==================================================
2026-01-14 12:43:14,108 - INFO -   [탐색  5] 희소도: 0.8353 -> FLOPs: 0.1588 GFLOPs (감소율: 92.61%)
2026-01-14 12:43:14,178 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:14,179 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:14,182 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:22,961 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:22,962 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:43:23,454 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.81984375)에 맞춰 변경되었습니다.
2026-01-14 12:43:23,454 - INFO - ==================================================
2026-01-14 12:43:23,495 - INFO -   [탐색  6] 희소도: 0.8198 -> FLOPs: 0.1781 GFLOPs (감소율: 91.72%)
2026-01-14 12:43:23,553 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:23,553 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:23,557 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:32,495 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:32,497 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:43:33,094 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8121093749999999)에 맞춰 변경되었습니다.
2026-01-14 12:43:33,094 - INFO - ==================================================
2026-01-14 12:43:33,136 - INFO -   [탐색  7] 희소도: 0.8121 -> FLOPs: 0.1906 GFLOPs (감소율: 91.13%)
2026-01-14 12:43:33,181 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:33,182 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:33,184 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:41,437 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:41,439 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:43:42,420 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8159765625)에 맞춰 변경되었습니다.
2026-01-14 12:43:42,421 - INFO - ==================================================
2026-01-14 12:43:42,487 - INFO -   [탐색  8] 희소도: 0.8160 -> FLOPs: 0.1843 GFLOPs (감소율: 91.43%)
2026-01-14 12:43:42,546 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:42,547 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:42,550 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:43:51,154 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:43:51,156 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:43:51,861 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.81791015625)에 맞춰 변경되었습니다.
2026-01-14 12:43:51,862 - INFO - ==================================================
2026-01-14 12:43:51,902 - INFO -   [탐색  9] 희소도: 0.8179 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:43:51,962 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:43:51,962 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:43:51,974 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:00,000 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:00,001 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:44:00,924 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.816943359375)에 맞춰 변경되었습니다.
2026-01-14 12:44:00,925 - INFO - ==================================================
2026-01-14 12:44:01,020 - INFO -   [탐색 10] 희소도: 0.8169 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:44:01,098 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:01,099 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:01,102 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:10,631 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:10,632 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:44:11,349 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8174267578125)에 맞춰 변경되었습니다.
2026-01-14 12:44:11,350 - INFO - ==================================================
2026-01-14 12:44:11,390 - INFO -   [탐색 11] 희소도: 0.8174 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:44:11,447 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:11,448 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:11,452 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:20,560 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:20,561 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:44:21,205 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.81766845703125)에 맞춰 변경되었습니다.
2026-01-14 12:44:21,206 - INFO - ==================================================
2026-01-14 12:44:21,246 - INFO -   [탐색 12] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:44:21,304 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:21,304 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:21,308 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:29,872 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:29,873 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:44:30,711 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.817789306640625)에 맞춰 변경되었습니다.
2026-01-14 12:44:30,711 - INFO - ==================================================
2026-01-14 12:44:30,759 - INFO -   [탐색 13] 희소도: 0.8178 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:44:30,822 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:30,823 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:30,825 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:40,126 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:40,127 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:44:40,643 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177288818359375)에 맞춰 변경되었습니다.
2026-01-14 12:44:40,644 - INFO - ==================================================
2026-01-14 12:44:40,684 - INFO -   [탐색 14] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:44:40,741 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:40,741 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:40,744 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:49,072 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:49,073 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:44:49,590 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8176986694335937)에 맞춰 변경되었습니다.
2026-01-14 12:44:49,591 - INFO - ==================================================
2026-01-14 12:44:49,631 - INFO -   [탐색 15] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:44:49,708 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:44:49,709 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:44:49,713 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:44:59,483 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:44:59,485 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:45:00,291 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177137756347657)에 맞춰 변경되었습니다.
2026-01-14 12:45:00,294 - INFO - ==================================================
2026-01-14 12:45:00,379 - INFO -   [탐색 16] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:45:00,512 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:00,513 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:00,520 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:08,770 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:08,771 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:45:09,561 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177062225341797)에 맞춰 변경되었습니다.
2026-01-14 12:45:09,562 - INFO - ==================================================
2026-01-14 12:45:09,606 - INFO -   [탐색 17] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:45:09,662 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:09,662 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:09,666 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:19,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:19,658 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:45:21,033 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177099990844727)에 맞춰 변경되었습니다.
2026-01-14 12:45:21,037 - INFO - ==================================================
2026-01-14 12:45:21,122 - INFO -   [탐색 18] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:45:21,265 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:21,269 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:21,272 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:29,270 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:29,272 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:45:30,185 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177081108093263)에 맞춰 변경되었습니다.
2026-01-14 12:45:30,186 - INFO - ==================================================
2026-01-14 12:45:30,234 - INFO -   [탐색 19] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:45:30,306 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:30,307 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:30,310 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:39,603 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:39,623 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:45:40,194 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177090549468995)에 맞춰 변경되었습니다.
2026-01-14 12:45:40,196 - INFO - ==================================================
2026-01-14 12:45:40,238 - INFO -   [탐색 20] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:45:40,298 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:40,299 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:40,302 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:49,688 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:49,693 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:45:50,835 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177085828781129)에 맞춰 변경되었습니다.
2026-01-14 12:45:50,836 - INFO - ==================================================
2026-01-14 12:45:51,026 - INFO -   [탐색 21] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:45:51,139 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:45:51,140 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:45:51,143 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:45:59,628 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:45:59,629 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:01,039 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083468437196)에 맞춰 변경되었습니다.
2026-01-14 12:46:01,040 - INFO - ==================================================
2026-01-14 12:46:01,084 - INFO -   [탐색 22] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:46:01,208 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:01,208 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:01,211 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:10,323 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:10,324 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:10,814 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177082288265229)에 맞춰 변경되었습니다.
2026-01-14 12:46:10,814 - INFO - ==================================================
2026-01-14 12:46:10,845 - INFO -   [탐색 23] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:46:10,888 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:10,889 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:10,892 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:19,548 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:19,549 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:20,147 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177082878351213)에 맞춰 변경되었습니다.
2026-01-14 12:46:20,148 - INFO - ==================================================
2026-01-14 12:46:20,199 - INFO -   [탐색 24] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:46:20,304 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:20,305 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:20,327 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:28,778 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:28,779 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:29,609 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083173394204)에 맞춰 변경되었습니다.
2026-01-14 12:46:29,609 - INFO - ==================================================
2026-01-14 12:46:29,646 - INFO -   [탐색 25] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:46:29,703 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:29,704 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:29,707 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:39,316 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:39,321 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:40,238 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.81770833209157)에 맞춰 변경되었습니다.
2026-01-14 12:46:40,238 - INFO - ==================================================
2026-01-14 12:46:40,276 - INFO -   [탐색 26] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:46:40,331 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:40,331 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:40,335 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:47,459 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:47,460 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:48,480 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083394676448)에 맞춰 변경되었습니다.
2026-01-14 12:46:48,480 - INFO - ==================================================
2026-01-14 12:46:48,518 - INFO -   [탐색 27] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:46:48,575 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:48,576 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:48,579 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:46:57,550 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:46:57,551 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:46:58,437 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083357796073)에 맞춰 변경되었습니다.
2026-01-14 12:46:58,437 - INFO - ==================================================
2026-01-14 12:46:58,475 - INFO -   [탐색 28] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:46:58,562 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:46:58,562 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:46:58,572 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:07,679 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:07,686 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:47:08,546 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083339355886)에 맞춰 변경되었습니다.
2026-01-14 12:47:08,549 - INFO - ==================================================
2026-01-14 12:47:08,636 - INFO -   [탐색 29] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:47:08,756 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:08,756 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:08,764 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:18,333 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:18,334 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:47:19,239 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083330135793)에 맞춰 변경되었습니다.
2026-01-14 12:47:19,239 - INFO - ==================================================
2026-01-14 12:47:19,319 - INFO -   [탐색 30] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:47:19,391 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:19,391 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:19,395 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:28,407 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:28,408 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:47:29,571 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083334745839)에 맞춰 변경되었습니다.
2026-01-14 12:47:29,571 - INFO - ==================================================
2026-01-14 12:47:29,619 - INFO -   [탐색 31] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:47:29,691 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:29,692 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:29,696 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:38,350 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:38,352 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:47:39,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083332440815)에 맞춰 변경되었습니다.
2026-01-14 12:47:39,801 - INFO - ==================================================
2026-01-14 12:47:39,881 - INFO -   [탐색 32] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:47:40,012 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:40,014 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:40,018 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:48,380 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:48,382 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:47:48,989 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333593327)에 맞춰 변경되었습니다.
2026-01-14 12:47:48,989 - INFO - ==================================================
2026-01-14 12:47:49,029 - INFO -   [탐색 33] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:47:49,129 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:49,130 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:49,134 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:47:58,629 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:47:58,630 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:47:59,438 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333017071)에 맞춰 변경되었습니다.
2026-01-14 12:47:59,438 - INFO - ==================================================
2026-01-14 12:47:59,540 - INFO -   [탐색 34] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:47:59,598 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:47:59,598 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:47:59,600 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:07,636 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:07,638 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:48:08,157 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.81770833333052)에 맞춰 변경되었습니다.
2026-01-14 12:48:08,160 - INFO - ==================================================
2026-01-14 12:48:08,189 - INFO -   [탐색 35] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:48:08,232 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:08,232 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:08,234 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:16,475 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:16,476 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:48:17,364 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333449263)에 맞춰 변경되었습니다.
2026-01-14 12:48:17,364 - INFO - ==================================================
2026-01-14 12:48:17,415 - INFO -   [탐색 36] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:48:17,470 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:17,471 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:17,474 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:25,848 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:25,850 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:48:26,448 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333377231)에 맞춰 변경되었습니다.
2026-01-14 12:48:26,448 - INFO - ==================================================
2026-01-14 12:48:26,488 - INFO -   [탐색 37] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:48:26,582 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:26,582 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:26,589 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:34,920 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:34,921 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:48:35,647 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333341215)에 맞춰 변경되었습니다.
2026-01-14 12:48:35,648 - INFO - ==================================================
2026-01-14 12:48:35,694 - INFO -   [탐색 38] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:48:35,755 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:35,756 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:35,759 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:46,270 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:46,271 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:48:47,110 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333323207)에 맞춰 변경되었습니다.
2026-01-14 12:48:47,110 - INFO - ==================================================
2026-01-14 12:48:47,196 - INFO -   [탐색 39] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:48:47,314 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:47,315 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:47,321 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:48:56,354 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:48:56,356 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:48:56,846 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333332211)에 맞춰 변경되었습니다.
2026-01-14 12:48:56,846 - INFO - ==================================================
2026-01-14 12:48:56,884 - INFO -   [탐색 40] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:48:56,934 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:48:56,935 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:48:56,938 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:05,807 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:05,808 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:49:06,685 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333336713)에 맞춰 변경되었습니다.
2026-01-14 12:49:06,686 - INFO - ==================================================
2026-01-14 12:49:06,725 - INFO -   [탐색 41] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:49:06,782 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:06,782 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:06,785 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:16,387 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:16,388 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:49:17,223 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333334463)에 맞춰 변경되었습니다.
2026-01-14 12:49:17,229 - INFO - ==================================================
2026-01-14 12:49:17,335 - INFO -   [탐색 42] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:49:17,486 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:17,490 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:17,493 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:25,548 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:25,552 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:49:26,430 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333337)에 맞춰 변경되었습니다.
2026-01-14 12:49:26,431 - INFO - ==================================================
2026-01-14 12:49:26,471 - INFO -   [탐색 43] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:49:26,534 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:26,535 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:26,538 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:34,970 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:34,972 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:49:35,593 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333332774)에 맞춰 변경되었습니다.
2026-01-14 12:49:35,596 - INFO - ==================================================
2026-01-14 12:49:35,636 - INFO -   [탐색 44] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:49:35,696 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:35,697 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:35,700 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:44,517 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:44,521 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:49:45,508 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333055)에 맞춰 변경되었습니다.
2026-01-14 12:49:45,508 - INFO - ==================================================
2026-01-14 12:49:45,605 - INFO -   [탐색 45] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:49:45,677 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:45,677 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:45,680 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:49:54,032 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:49:54,033 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:49:55,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333196)에 맞춰 변경되었습니다.
2026-01-14 12:49:55,403 - INFO - ==================================================
2026-01-14 12:49:55,441 - INFO -   [탐색 46] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:49:55,497 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:49:55,497 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:49:55,501 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:03,474 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:03,475 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:50:04,247 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333266)에 맞춰 변경되었습니다.
2026-01-14 12:50:04,248 - INFO - ==================================================
2026-01-14 12:50:04,283 - INFO -   [탐색 47] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:50:04,388 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:04,388 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:04,391 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:12,279 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:12,280 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:50:13,012 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333302)에 맞춰 변경되었습니다.
2026-01-14 12:50:13,012 - INFO - ==================================================
2026-01-14 12:50:13,093 - INFO -   [탐색 48] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:50:13,216 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:13,217 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:13,224 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:23,058 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:23,059 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:50:23,728 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333319)에 맞춰 변경되었습니다.
2026-01-14 12:50:23,728 - INFO - ==================================================
2026-01-14 12:50:23,796 - INFO -   [탐색 49] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:50:23,919 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:23,920 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:23,924 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:32,688 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:32,689 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:50:33,110 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333328)에 맞춰 변경되었습니다.
2026-01-14 12:50:33,110 - INFO - ==================================================
2026-01-14 12:50:33,174 - INFO -   [탐색 50] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:50:33,229 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:33,230 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:33,232 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:41,218 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:41,219 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:50:42,349 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:50:42,350 - INFO - ==================================================
2026-01-14 12:50:42,425 - INFO -   [탐색 51] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:50:42,494 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:42,495 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:42,499 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:50,718 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:50,719 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:50:51,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333335)에 맞춰 변경되었습니다.
2026-01-14 12:50:51,583 - INFO - ==================================================
2026-01-14 12:50:51,630 - INFO -   [탐색 52] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:50:51,706 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:50:51,707 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:50:51,714 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:50:59,586 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:50:59,588 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:51:00,081 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333334)에 맞춰 변경되었습니다.
2026-01-14 12:51:00,081 - INFO - ==================================================
2026-01-14 12:51:00,113 - INFO -   [탐색 53] 희소도: 0.8177 -> FLOPs: 0.1784 GFLOPs (감소율: 91.70%)
2026-01-14 12:51:00,154 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:00,155 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:00,157 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:09,594 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:09,596 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:51:10,106 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:51:10,107 - INFO - ==================================================
2026-01-14 12:51:10,146 - INFO -   [탐색 54] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:51:10,209 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:10,210 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:10,217 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:21,189 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:21,190 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:51:22,415 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:51:22,416 - INFO - ==================================================
2026-01-14 12:51:22,457 - INFO -   [탐색 55] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:51:22,515 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:22,516 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:22,520 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:32,142 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:32,143 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:51:32,651 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:51:32,651 - INFO - ==================================================
2026-01-14 12:51:32,691 - INFO -   [탐색 56] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:51:32,747 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:32,747 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:32,751 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:41,666 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:41,669 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:51:42,148 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:51:42,149 - INFO - ==================================================
2026-01-14 12:51:42,192 - INFO -   [탐색 57] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:51:42,248 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:42,249 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:42,251 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:51:51,223 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:51:51,224 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:51:51,719 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:51:51,720 - INFO - ==================================================
2026-01-14 12:51:51,763 - INFO -   [탐색 58] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:51:51,826 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:51:51,827 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:51:51,830 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:00,560 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:00,562 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:01,063 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:01,064 - INFO - ==================================================
2026-01-14 12:52:01,097 - INFO -   [탐색 59] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:01,140 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:01,141 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:01,143 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:10,363 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:10,364 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:11,150 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:11,151 - INFO - ==================================================
2026-01-14 12:52:11,196 - INFO -   [탐색 60] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:11,260 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:11,260 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:11,264 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:20,309 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:20,310 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:20,748 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:20,749 - INFO - ==================================================
2026-01-14 12:52:20,773 - INFO -   [탐색 61] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:20,811 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:20,811 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:20,813 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:29,238 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:29,239 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:29,740 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:29,740 - INFO - ==================================================
2026-01-14 12:52:29,770 - INFO -   [탐색 62] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:29,814 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:29,815 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:29,817 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:37,191 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:37,193 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:38,060 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:38,064 - INFO - ==================================================
2026-01-14 12:52:38,153 - INFO -   [탐색 63] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:38,224 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:38,225 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:38,229 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:45,789 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:45,791 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:46,434 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:46,434 - INFO - ==================================================
2026-01-14 12:52:46,466 - INFO -   [탐색 64] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:46,510 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:46,510 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:46,513 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:52:54,657 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:52:54,661 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:52:55,841 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:52:55,842 - INFO - ==================================================
2026-01-14 12:52:55,910 - INFO -   [탐색 65] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:52:55,974 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:52:55,975 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:52:55,978 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:03,929 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:03,930 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:53:04,574 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:53:04,575 - INFO - ==================================================
2026-01-14 12:53:04,614 - INFO -   [탐색 66] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:53:04,683 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:04,683 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:04,690 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:16,114 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:16,118 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:53:16,799 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:53:16,800 - INFO - ==================================================
2026-01-14 12:53:16,856 - INFO -   [탐색 67] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:53:16,939 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:16,939 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:16,942 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:25,387 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:25,389 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:53:25,915 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:53:25,915 - INFO - ==================================================
2026-01-14 12:53:25,947 - INFO -   [탐색 68] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:53:26,017 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:26,019 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:26,022 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:33,355 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:33,357 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:53:33,925 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:53:33,926 - INFO - ==================================================
2026-01-14 12:53:33,967 - INFO -   [탐색 69] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:53:34,023 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:34,023 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:34,026 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:43,334 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:43,336 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:53:44,200 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:53:44,201 - INFO - ==================================================
2026-01-14 12:53:44,236 - INFO -   [탐색 70] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:53:44,280 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:44,281 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:44,283 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:53:52,674 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:53:52,675 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:53:53,119 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:53:53,123 - INFO - ==================================================
2026-01-14 12:53:53,200 - INFO -   [탐색 71] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:53:53,301 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:53:53,301 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:53:53,304 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:00,804 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:00,805 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:01,342 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:01,343 - INFO - ==================================================
2026-01-14 12:54:01,381 - INFO -   [탐색 72] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:01,436 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:01,439 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:01,443 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:11,030 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:11,033 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:11,639 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:11,640 - INFO - ==================================================
2026-01-14 12:54:11,673 - INFO -   [탐색 73] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:11,734 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:11,735 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:11,738 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:21,203 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:21,204 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:22,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:22,110 - INFO - ==================================================
2026-01-14 12:54:22,157 - INFO -   [탐색 74] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:22,779 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:22,780 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:22,783 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:31,593 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:31,594 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:32,429 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:32,429 - INFO - ==================================================
2026-01-14 12:54:32,472 - INFO -   [탐색 75] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:32,541 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:32,542 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:32,546 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:41,547 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:41,548 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:42,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:42,156 - INFO - ==================================================
2026-01-14 12:54:42,246 - INFO -   [탐색 76] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:42,354 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:42,355 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:42,359 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:50,536 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:50,537 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:51,035 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:51,036 - INFO - ==================================================
2026-01-14 12:54:51,071 - INFO -   [탐색 77] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:51,118 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:51,119 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:51,123 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:54:59,331 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:54:59,332 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:54:59,779 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:54:59,780 - INFO - ==================================================
2026-01-14 12:54:59,811 - INFO -   [탐색 78] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:54:59,868 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:54:59,869 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:54:59,872 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:09,957 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:09,958 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:55:11,091 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:55:11,092 - INFO - ==================================================
2026-01-14 12:55:11,133 - INFO -   [탐색 79] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:55:11,197 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:11,198 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:11,202 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:19,718 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:19,719 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:55:20,494 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:55:20,495 - INFO - ==================================================
2026-01-14 12:55:20,529 - INFO -   [탐색 80] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:55:20,574 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:20,574 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:20,577 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:28,821 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:28,822 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:55:29,322 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:55:29,322 - INFO - ==================================================
2026-01-14 12:55:29,358 - INFO -   [탐색 81] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:55:29,405 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:29,406 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:29,409 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:36,981 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:36,982 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:55:37,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:55:37,682 - INFO - ==================================================
2026-01-14 12:55:37,723 - INFO -   [탐색 82] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:55:37,789 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:37,790 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:37,793 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:46,585 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:46,586 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:55:47,040 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:55:47,040 - INFO - ==================================================
2026-01-14 12:55:47,077 - INFO -   [탐색 83] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:55:47,133 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:47,134 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:47,137 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:55:56,683 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:55:56,684 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:55:57,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:55:57,585 - INFO - ==================================================
2026-01-14 12:55:57,625 - INFO -   [탐색 84] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:55:57,682 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:55:57,683 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:55:57,686 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:06,246 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:06,248 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:56:06,783 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:56:06,783 - INFO - ==================================================
2026-01-14 12:56:06,821 - INFO -   [탐색 85] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:56:06,899 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:06,899 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:06,903 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:15,936 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:15,938 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:56:16,684 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:56:16,684 - INFO - ==================================================
2026-01-14 12:56:16,722 - INFO -   [탐색 86] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:56:16,778 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:16,779 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:16,782 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:24,323 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:24,325 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:56:24,774 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:56:24,775 - INFO - ==================================================
2026-01-14 12:56:24,814 - INFO -   [탐색 87] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:56:24,872 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:24,873 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:24,877 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:33,991 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:33,994 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:56:34,510 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:56:34,510 - INFO - ==================================================
2026-01-14 12:56:34,549 - INFO -   [탐색 88] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:56:34,606 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:34,606 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:34,610 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:43,627 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:43,628 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:56:44,331 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:56:44,331 - INFO - ==================================================
2026-01-14 12:56:44,365 - INFO -   [탐색 89] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:56:44,427 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:44,428 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:44,430 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:56:53,437 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:56:53,438 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:56:53,852 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:56:53,852 - INFO - ==================================================
2026-01-14 12:56:53,886 - INFO -   [탐색 90] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:56:53,942 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:56:53,943 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:56:53,946 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:02,886 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:02,887 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:57:03,441 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:57:03,442 - INFO - ==================================================
2026-01-14 12:57:03,482 - INFO -   [탐색 91] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:57:03,539 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:03,540 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:03,544 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:12,770 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:12,771 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:57:13,413 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:57:13,413 - INFO - ==================================================
2026-01-14 12:57:13,457 - INFO -   [탐색 92] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:57:13,519 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:13,520 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:13,523 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:21,659 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:21,661 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:57:22,270 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:57:22,272 - INFO - ==================================================
2026-01-14 12:57:22,314 - INFO -   [탐색 93] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:57:22,375 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:22,376 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:22,379 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:31,358 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:31,361 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:57:32,634 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:57:32,635 - INFO - ==================================================
2026-01-14 12:57:32,676 - INFO -   [탐색 94] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:57:32,737 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:32,738 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:32,742 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:40,486 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:40,488 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:57:40,979 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:57:40,980 - INFO - ==================================================
2026-01-14 12:57:41,042 - INFO -   [탐색 95] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:57:41,090 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:41,091 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:41,095 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:57:50,552 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:57:50,553 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:57:51,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:57:51,113 - INFO - ==================================================
2026-01-14 12:57:51,180 - INFO -   [탐색 96] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:57:51,276 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:57:51,277 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:57:51,280 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:00,189 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:00,190 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:58:00,716 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:58:00,716 - INFO - ==================================================
2026-01-14 12:58:00,755 - INFO -   [탐색 97] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:58:00,810 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:00,811 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:00,815 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:09,935 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:09,936 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:58:10,792 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:58:10,792 - INFO - ==================================================
2026-01-14 12:58:10,830 - INFO -   [탐색 98] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:58:10,888 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:10,888 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:10,892 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:20,490 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:20,491 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:58:21,058 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:58:21,058 - INFO - ==================================================
2026-01-14 12:58:21,102 - INFO -   [탐색 99] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:58:21,159 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:21,160 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:21,163 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:29,616 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:29,621 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:58:30,366 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8177083333333333)에 맞춰 변경되었습니다.
2026-01-14 12:58:30,367 - INFO - ==================================================
2026-01-14 12:58:30,410 - INFO -   [탐색 100] 희소도: 0.8177 -> FLOPs: 0.1840 GFLOPs (감소율: 91.44%)
2026-01-14 12:58:30,411 - INFO - 탐색 완료. 목표 FLOPs(0.1829)에 가장 근접한 최적 희소도는 0.8169 입니다.
2026-01-14 12:58:30,411 - INFO - ================================================================================
2026-01-14 12:58:30,415 - INFO - 계산된 Pruning 정보(희소도: 0.8169)를 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/pruning_info.yaml'에 저장했습니다.
2026-01-14 12:58:30,460 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 12:58:30,578 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 12:58:30,578 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 12:58:30,582 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 12:58:38,422 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:58:38,424 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:58:38,970 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.816943359375)에 맞춰 변경되었습니다.
2026-01-14 12:58:38,971 - INFO - ==================================================
2026-01-14 12:58:38,973 - INFO - ==================================================
2026-01-14 12:58:38,974 - INFO - 모델 파라미터 수:
2026-01-14 12:58:38,974 - INFO -   - 총 파라미터: 485,259 개
2026-01-14 12:58:38,974 - INFO -   - 학습 가능한 파라미터: 485,259 개
2026-01-14 12:58:39,058 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 12:58:39,258 - INFO - FLOPs가 2.1493 GFLOPs에서 0.1840 GFLOPs로 감소했습니다 (감소율: 91.44%).
2026-01-14 12:58:39,259 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 12:58:39,259 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:58:39,260 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 12:58:39,261 - INFO - ==================================================
2026-01-14 12:58:39,261 - INFO - train 모드를 시작합니다.
2026-01-14 12:58:39,262 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:58:39,262 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:58:39,262 - INFO - --------------------------------------------------
2026-01-14 12:58:39,264 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 12:58:48,081 - INFO - [Train] [11/90] | Loss: 0.5603 | Train Acc: 76.12%
2026-01-14 12:58:50,851 - INFO - [Valid] [11/90] | Loss: 0.5808 | Val Acc: 73.45%
2026-01-14 12:58:50,864 - INFO - [Metrics for 'abnormal'] | Precision: 0.6718 | Recall: 0.8344 | F1: 0.7443
2026-01-14 12:58:50,865 - INFO - [Metrics for 'normal'] | Precision: 0.8194 | Recall: 0.6484 | F1: 0.7239
2026-01-14 12:58:50,904 - INFO - [Best Model Saved] (val loss: 0.5808) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:58:50,905 - INFO - --------------------------------------------------
2026-01-14 12:58:50,907 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 12:58:58,742 - INFO - [Train] [12/90] | Loss: 0.5226 | Train Acc: 78.94%
2026-01-14 12:59:01,418 - INFO - [Valid] [12/90] | Loss: 0.5454 | Val Acc: 75.52%
2026-01-14 12:59:01,432 - INFO - [Metrics for 'abnormal'] | Precision: 0.7534 | Recall: 0.7006 | F1: 0.7261
2026-01-14 12:59:01,433 - INFO - [Metrics for 'normal'] | Precision: 0.7565 | Recall: 0.8022 | F1: 0.7787
2026-01-14 12:59:01,470 - INFO - [Best Model Saved] (val loss: 0.5454) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:59:01,471 - INFO - --------------------------------------------------
2026-01-14 12:59:01,473 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 12:59:10,947 - INFO - [Train] [13/90] | Loss: 0.5062 | Train Acc: 79.84%
2026-01-14 12:59:14,184 - INFO - [Valid] [13/90] | Loss: 0.5506 | Val Acc: 75.22%
2026-01-14 12:59:14,196 - INFO - [Metrics for 'abnormal'] | Precision: 0.7626 | Recall: 0.6752 | F1: 0.7162
2026-01-14 12:59:14,197 - INFO - [Metrics for 'normal'] | Precision: 0.7450 | Recall: 0.8187 | F1: 0.7801
2026-01-14 12:59:14,201 - INFO - --------------------------------------------------
2026-01-14 12:59:14,204 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 12:59:22,383 - INFO - [Train] [14/90] | Loss: 0.4990 | Train Acc: 79.84%
2026-01-14 12:59:24,619 - INFO - [Valid] [14/90] | Loss: 0.5328 | Val Acc: 78.17%
2026-01-14 12:59:24,631 - INFO - [Metrics for 'abnormal'] | Precision: 0.7318 | Recall: 0.8344 | F1: 0.7798
2026-01-14 12:59:24,632 - INFO - [Metrics for 'normal'] | Precision: 0.8375 | Recall: 0.7363 | F1: 0.7836
2026-01-14 12:59:24,663 - INFO - [Best Model Saved] (val loss: 0.5328) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:59:24,663 - INFO - --------------------------------------------------
2026-01-14 12:59:24,665 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 12:59:33,770 - INFO - [Train] [15/90] | Loss: 0.4911 | Train Acc: 80.06%
2026-01-14 12:59:35,788 - INFO - [Valid] [15/90] | Loss: 0.5343 | Val Acc: 76.70%
2026-01-14 12:59:35,801 - INFO - [Metrics for 'abnormal'] | Precision: 0.8095 | Recall: 0.6497 | F1: 0.7208
2026-01-14 12:59:35,801 - INFO - [Metrics for 'normal'] | Precision: 0.7418 | Recall: 0.8681 | F1: 0.8000
2026-01-14 12:59:35,806 - INFO - --------------------------------------------------
2026-01-14 12:59:35,808 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 12:59:44,994 - INFO - [Train] [16/90] | Loss: 0.4912 | Train Acc: 81.47%
2026-01-14 12:59:47,163 - INFO - [Valid] [16/90] | Loss: 0.5246 | Val Acc: 77.58%
2026-01-14 12:59:47,184 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.7643 | F1: 0.7595
2026-01-14 12:59:47,184 - INFO - [Metrics for 'normal'] | Precision: 0.7944 | Recall: 0.7857 | F1: 0.7901
2026-01-14 12:59:47,230 - INFO - [Best Model Saved] (val loss: 0.5246) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 12:59:47,231 - INFO - --------------------------------------------------
2026-01-14 12:59:47,233 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 12:59:57,080 - INFO - [Train] [17/90] | Loss: 0.4928 | Train Acc: 79.54%
2026-01-14 12:59:59,907 - INFO - [Valid] [17/90] | Loss: 0.5370 | Val Acc: 76.40%
2026-01-14 12:59:59,934 - INFO - [Metrics for 'abnormal'] | Precision: 0.7421 | Recall: 0.7516 | F1: 0.7468
2026-01-14 12:59:59,934 - INFO - [Metrics for 'normal'] | Precision: 0.7833 | Recall: 0.7747 | F1: 0.7790
2026-01-14 12:59:59,939 - INFO - --------------------------------------------------
2026-01-14 12:59:59,945 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 13:00:08,633 - INFO - [Train] [18/90] | Loss: 0.4786 | Train Acc: 82.37%
2026-01-14 13:00:11,317 - INFO - [Valid] [18/90] | Loss: 0.5409 | Val Acc: 74.93%
2026-01-14 13:00:11,338 - INFO - [Metrics for 'abnormal'] | Precision: 0.7687 | Recall: 0.6561 | F1: 0.7079
2026-01-14 13:00:11,338 - INFO - [Metrics for 'normal'] | Precision: 0.7366 | Recall: 0.8297 | F1: 0.7804
2026-01-14 13:00:11,344 - INFO - --------------------------------------------------
2026-01-14 13:00:11,349 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 13:00:19,319 - INFO - [Train] [19/90] | Loss: 0.4705 | Train Acc: 82.59%
2026-01-14 13:00:21,602 - INFO - [Valid] [19/90] | Loss: 0.5611 | Val Acc: 78.17%
2026-01-14 13:00:21,611 - INFO - [Metrics for 'abnormal'] | Precision: 0.7219 | Recall: 0.8599 | F1: 0.7849
2026-01-14 13:00:21,611 - INFO - [Metrics for 'normal'] | Precision: 0.8553 | Recall: 0.7143 | F1: 0.7784
2026-01-14 13:00:21,615 - INFO - --------------------------------------------------
2026-01-14 13:00:21,616 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 13:00:30,451 - INFO - [Train] [20/90] | Loss: 0.4705 | Train Acc: 83.41%
2026-01-14 13:00:34,474 - INFO - [Valid] [20/90] | Loss: 0.5249 | Val Acc: 76.40%
2026-01-14 13:00:34,503 - INFO - [Metrics for 'abnormal'] | Precision: 0.8130 | Recall: 0.6369 | F1: 0.7143
2026-01-14 13:00:34,508 - INFO - [Metrics for 'normal'] | Precision: 0.7361 | Recall: 0.8736 | F1: 0.7990
2026-01-14 13:00:34,513 - INFO - --------------------------------------------------
2026-01-14 13:00:34,519 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 13:00:43,778 - INFO - [Train] [21/90] | Loss: 0.4650 | Train Acc: 82.14%
2026-01-14 13:00:46,974 - INFO - [Valid] [21/90] | Loss: 0.5199 | Val Acc: 76.40%
2026-01-14 13:00:46,989 - INFO - [Metrics for 'abnormal'] | Precision: 0.7852 | Recall: 0.6752 | F1: 0.7260
2026-01-14 13:00:46,994 - INFO - [Metrics for 'normal'] | Precision: 0.7500 | Recall: 0.8407 | F1: 0.7927
2026-01-14 13:00:47,033 - INFO - [Best Model Saved] (val loss: 0.5199) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:00:47,034 - INFO - --------------------------------------------------
2026-01-14 13:00:47,035 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 13:00:55,851 - INFO - [Train] [22/90] | Loss: 0.4667 | Train Acc: 82.14%
2026-01-14 13:00:58,161 - INFO - [Valid] [22/90] | Loss: 0.5018 | Val Acc: 77.88%
2026-01-14 13:00:58,175 - INFO - [Metrics for 'abnormal'] | Precision: 0.7808 | Recall: 0.7261 | F1: 0.7525
2026-01-14 13:00:58,175 - INFO - [Metrics for 'normal'] | Precision: 0.7772 | Recall: 0.8242 | F1: 0.8000
2026-01-14 13:00:58,211 - INFO - [Best Model Saved] (val loss: 0.5018) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:00:58,212 - INFO - --------------------------------------------------
2026-01-14 13:00:58,214 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 13:01:07,035 - INFO - [Train] [23/90] | Loss: 0.4542 | Train Acc: 82.59%
2026-01-14 13:01:10,000 - INFO - [Valid] [23/90] | Loss: 0.5092 | Val Acc: 77.58%
2026-01-14 13:01:10,016 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.7643 | F1: 0.7595
2026-01-14 13:01:10,017 - INFO - [Metrics for 'normal'] | Precision: 0.7944 | Recall: 0.7857 | F1: 0.7901
2026-01-14 13:01:10,021 - INFO - --------------------------------------------------
2026-01-14 13:01:10,023 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 13:01:18,843 - INFO - [Train] [24/90] | Loss: 0.4638 | Train Acc: 82.74%
2026-01-14 13:01:21,276 - INFO - [Valid] [24/90] | Loss: 0.5121 | Val Acc: 79.65%
2026-01-14 13:01:21,298 - INFO - [Metrics for 'abnormal'] | Precision: 0.7619 | Recall: 0.8153 | F1: 0.7877
2026-01-14 13:01:21,298 - INFO - [Metrics for 'normal'] | Precision: 0.8304 | Recall: 0.7802 | F1: 0.8045
2026-01-14 13:01:21,302 - INFO - --------------------------------------------------
2026-01-14 13:01:21,304 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 13:01:29,419 - INFO - [Train] [25/90] | Loss: 0.4575 | Train Acc: 82.96%
2026-01-14 13:01:32,091 - INFO - [Valid] [25/90] | Loss: 0.5168 | Val Acc: 78.17%
2026-01-14 13:01:32,100 - INFO - [Metrics for 'abnormal'] | Precision: 0.8320 | Recall: 0.6624 | F1: 0.7376
2026-01-14 13:01:32,100 - INFO - [Metrics for 'normal'] | Precision: 0.7523 | Recall: 0.8846 | F1: 0.8131
2026-01-14 13:01:32,104 - INFO - --------------------------------------------------
2026-01-14 13:01:32,106 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 13:01:41,073 - INFO - [Train] [26/90] | Loss: 0.4497 | Train Acc: 84.90%
2026-01-14 13:01:43,784 - INFO - [Valid] [26/90] | Loss: 0.5048 | Val Acc: 77.58%
2026-01-14 13:01:43,797 - INFO - [Metrics for 'abnormal'] | Precision: 0.7314 | Recall: 0.8153 | F1: 0.7711
2026-01-14 13:01:43,798 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.7418 | F1: 0.7803
2026-01-14 13:01:43,803 - INFO - --------------------------------------------------
2026-01-14 13:01:43,806 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 13:01:53,395 - INFO - [Train] [27/90] | Loss: 0.4445 | Train Acc: 84.00%
2026-01-14 13:01:56,088 - INFO - [Valid] [27/90] | Loss: 0.5265 | Val Acc: 77.88%
2026-01-14 13:01:56,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7356 | Recall: 0.8153 | F1: 0.7734
2026-01-14 13:01:56,124 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.7473 | F1: 0.7839
2026-01-14 13:01:56,140 - INFO - --------------------------------------------------
2026-01-14 13:01:56,147 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 13:02:06,807 - INFO - [Train] [28/90] | Loss: 0.4530 | Train Acc: 82.44%
2026-01-14 13:02:08,973 - INFO - [Valid] [28/90] | Loss: 0.5240 | Val Acc: 80.83%
2026-01-14 13:02:08,983 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 13:02:08,984 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 13:02:08,988 - INFO - --------------------------------------------------
2026-01-14 13:02:08,991 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 13:02:19,899 - INFO - [Train] [29/90] | Loss: 0.4422 | Train Acc: 84.00%
2026-01-14 13:02:22,569 - INFO - [Valid] [29/90] | Loss: 0.4915 | Val Acc: 79.94%
2026-01-14 13:02:22,583 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-01-14 13:02:22,584 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-01-14 13:02:22,619 - INFO - [Best Model Saved] (val loss: 0.4915) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:02:22,620 - INFO - --------------------------------------------------
2026-01-14 13:02:22,622 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 13:02:32,212 - INFO - [Train] [30/90] | Loss: 0.4356 | Train Acc: 84.60%
2026-01-14 13:02:33,816 - INFO - [Valid] [30/90] | Loss: 0.5103 | Val Acc: 81.71%
2026-01-14 13:02:33,828 - INFO - [Metrics for 'abnormal'] | Precision: 0.7811 | Recall: 0.8408 | F1: 0.8098
2026-01-14 13:02:33,829 - INFO - [Metrics for 'normal'] | Precision: 0.8529 | Recall: 0.7967 | F1: 0.8239
2026-01-14 13:02:33,833 - INFO - --------------------------------------------------
2026-01-14 13:02:33,836 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 13:02:43,177 - INFO - [Train] [31/90] | Loss: 0.4393 | Train Acc: 85.64%
2026-01-14 13:02:45,139 - INFO - [Valid] [31/90] | Loss: 0.5360 | Val Acc: 79.06%
2026-01-14 13:02:45,149 - INFO - [Metrics for 'abnormal'] | Precision: 0.7150 | Recall: 0.9108 | F1: 0.8011
2026-01-14 13:02:45,149 - INFO - [Metrics for 'normal'] | Precision: 0.8993 | Recall: 0.6868 | F1: 0.7788
2026-01-14 13:02:45,153 - INFO - --------------------------------------------------
2026-01-14 13:02:45,155 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 13:02:54,559 - INFO - [Train] [32/90] | Loss: 0.4421 | Train Acc: 83.78%
2026-01-14 13:02:56,772 - INFO - [Valid] [32/90] | Loss: 0.4823 | Val Acc: 79.94%
2026-01-14 13:02:56,780 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-01-14 13:02:56,780 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-01-14 13:02:56,800 - INFO - [Best Model Saved] (val loss: 0.4823) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:02:56,800 - INFO - --------------------------------------------------
2026-01-14 13:02:56,801 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 13:03:05,887 - INFO - [Train] [33/90] | Loss: 0.4300 | Train Acc: 84.60%
2026-01-14 13:03:08,058 - INFO - [Valid] [33/90] | Loss: 0.4995 | Val Acc: 79.06%
2026-01-14 13:03:08,066 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-01-14 13:03:08,066 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-01-14 13:03:08,069 - INFO - --------------------------------------------------
2026-01-14 13:03:08,070 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 13:03:16,448 - INFO - [Train] [34/90] | Loss: 0.4375 | Train Acc: 84.60%
2026-01-14 13:03:18,965 - INFO - [Valid] [34/90] | Loss: 0.4822 | Val Acc: 80.24%
2026-01-14 13:03:18,977 - INFO - [Metrics for 'abnormal'] | Precision: 0.7744 | Recall: 0.8089 | F1: 0.7913
2026-01-14 13:03:18,978 - INFO - [Metrics for 'normal'] | Precision: 0.8286 | Recall: 0.7967 | F1: 0.8123
2026-01-14 13:03:19,014 - INFO - [Best Model Saved] (val loss: 0.4822) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:03:19,015 - INFO - --------------------------------------------------
2026-01-14 13:03:19,017 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 13:03:27,503 - INFO - [Train] [35/90] | Loss: 0.4211 | Train Acc: 85.04%
2026-01-14 13:03:30,080 - INFO - [Valid] [35/90] | Loss: 0.4920 | Val Acc: 79.06%
2026-01-14 13:03:30,092 - INFO - [Metrics for 'abnormal'] | Precision: 0.7263 | Recall: 0.8790 | F1: 0.7954
2026-01-14 13:03:30,092 - INFO - [Metrics for 'normal'] | Precision: 0.8725 | Recall: 0.7143 | F1: 0.7855
2026-01-14 13:03:30,097 - INFO - --------------------------------------------------
2026-01-14 13:03:30,099 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 13:03:37,503 - INFO - [Train] [36/90] | Loss: 0.4248 | Train Acc: 85.12%
2026-01-14 13:03:40,955 - INFO - [Valid] [36/90] | Loss: 0.4866 | Val Acc: 80.24%
2026-01-14 13:03:40,967 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-01-14 13:03:40,968 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-01-14 13:03:40,973 - INFO - --------------------------------------------------
2026-01-14 13:03:40,975 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 13:03:50,305 - INFO - [Train] [37/90] | Loss: 0.4386 | Train Acc: 84.52%
2026-01-14 13:03:54,131 - INFO - [Valid] [37/90] | Loss: 0.5295 | Val Acc: 77.29%
2026-01-14 13:03:54,157 - INFO - [Metrics for 'abnormal'] | Precision: 0.8448 | Recall: 0.6242 | F1: 0.7179
2026-01-14 13:03:54,158 - INFO - [Metrics for 'normal'] | Precision: 0.7354 | Recall: 0.9011 | F1: 0.8099
2026-01-14 13:03:54,169 - INFO - --------------------------------------------------
2026-01-14 13:03:54,171 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 13:04:04,491 - INFO - [Train] [38/90] | Loss: 0.4515 | Train Acc: 82.96%
2026-01-14 13:04:07,666 - INFO - [Valid] [38/90] | Loss: 0.4889 | Val Acc: 80.53%
2026-01-14 13:04:07,689 - INFO - [Metrics for 'abnormal'] | Precision: 0.7571 | Recall: 0.8535 | F1: 0.8024
2026-01-14 13:04:07,690 - INFO - [Metrics for 'normal'] | Precision: 0.8580 | Recall: 0.7637 | F1: 0.8081
2026-01-14 13:04:07,694 - INFO - --------------------------------------------------
2026-01-14 13:04:07,696 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 13:04:16,216 - INFO - [Train] [39/90] | Loss: 0.4313 | Train Acc: 85.04%
2026-01-14 13:04:19,014 - INFO - [Valid] [39/90] | Loss: 0.4826 | Val Acc: 81.12%
2026-01-14 13:04:19,026 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 13:04:19,027 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 13:04:19,032 - INFO - --------------------------------------------------
2026-01-14 13:04:19,034 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 13:04:27,973 - INFO - [Train] [40/90] | Loss: 0.4343 | Train Acc: 84.75%
2026-01-14 13:04:30,970 - INFO - [Valid] [40/90] | Loss: 0.4843 | Val Acc: 79.35%
2026-01-14 13:04:30,983 - INFO - [Metrics for 'abnormal'] | Precision: 0.7458 | Recall: 0.8408 | F1: 0.7904
2026-01-14 13:04:30,983 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.7527 | F1: 0.7965
2026-01-14 13:04:30,987 - INFO - --------------------------------------------------
2026-01-14 13:04:30,990 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 13:04:40,006 - INFO - [Train] [41/90] | Loss: 0.4183 | Train Acc: 85.79%
2026-01-14 13:04:42,683 - INFO - [Valid] [41/90] | Loss: 0.4720 | Val Acc: 81.42%
2026-01-14 13:04:42,692 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-01-14 13:04:42,693 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-01-14 13:04:42,724 - INFO - [Best Model Saved] (val loss: 0.4720) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:04:42,724 - INFO - --------------------------------------------------
2026-01-14 13:04:42,730 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 13:04:51,716 - INFO - [Train] [42/90] | Loss: 0.4354 | Train Acc: 84.15%
2026-01-14 13:04:54,325 - INFO - [Valid] [42/90] | Loss: 0.5127 | Val Acc: 78.76%
2026-01-14 13:04:54,338 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-01-14 13:04:54,340 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-01-14 13:04:54,344 - INFO - --------------------------------------------------
2026-01-14 13:04:54,347 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 13:05:03,880 - INFO - [Train] [43/90] | Loss: 0.4333 | Train Acc: 84.67%
2026-01-14 13:05:06,478 - INFO - [Valid] [43/90] | Loss: 0.4808 | Val Acc: 79.65%
2026-01-14 13:05:06,490 - INFO - [Metrics for 'abnormal'] | Precision: 0.8143 | Recall: 0.7261 | F1: 0.7677
2026-01-14 13:05:06,490 - INFO - [Metrics for 'normal'] | Precision: 0.7839 | Recall: 0.8571 | F1: 0.8189
2026-01-14 13:05:06,495 - INFO - --------------------------------------------------
2026-01-14 13:05:06,497 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 13:05:15,696 - INFO - [Train] [44/90] | Loss: 0.4208 | Train Acc: 86.83%
2026-01-14 13:05:17,989 - INFO - [Valid] [44/90] | Loss: 0.4724 | Val Acc: 83.19%
2026-01-14 13:05:18,012 - INFO - [Metrics for 'abnormal'] | Precision: 0.8378 | Recall: 0.7898 | F1: 0.8131
2026-01-14 13:05:18,012 - INFO - [Metrics for 'normal'] | Precision: 0.8272 | Recall: 0.8681 | F1: 0.8472
2026-01-14 13:05:18,016 - INFO - --------------------------------------------------
2026-01-14 13:05:18,018 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 13:05:26,459 - INFO - [Train] [45/90] | Loss: 0.4129 | Train Acc: 85.86%
2026-01-14 13:05:29,121 - INFO - [Valid] [45/90] | Loss: 0.4768 | Val Acc: 80.53%
2026-01-14 13:05:29,133 - INFO - [Metrics for 'abnormal'] | Precision: 0.7725 | Recall: 0.8217 | F1: 0.7963
2026-01-14 13:05:29,134 - INFO - [Metrics for 'normal'] | Precision: 0.8372 | Recall: 0.7912 | F1: 0.8136
2026-01-14 13:05:29,138 - INFO - --------------------------------------------------
2026-01-14 13:05:29,140 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 13:05:37,657 - INFO - [Train] [46/90] | Loss: 0.4029 | Train Acc: 86.76%
2026-01-14 13:05:40,308 - INFO - [Valid] [46/90] | Loss: 0.4842 | Val Acc: 80.53%
2026-01-14 13:05:40,320 - INFO - [Metrics for 'abnormal'] | Precision: 0.8370 | Recall: 0.7197 | F1: 0.7740
2026-01-14 13:05:40,320 - INFO - [Metrics for 'normal'] | Precision: 0.7843 | Recall: 0.8791 | F1: 0.8290
2026-01-14 13:05:40,324 - INFO - --------------------------------------------------
2026-01-14 13:05:40,326 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 13:05:48,697 - INFO - [Train] [47/90] | Loss: 0.4079 | Train Acc: 86.76%
2026-01-14 13:05:50,828 - INFO - [Valid] [47/90] | Loss: 0.4810 | Val Acc: 81.42%
2026-01-14 13:05:50,838 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 13:05:50,838 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 13:05:50,842 - INFO - --------------------------------------------------
2026-01-14 13:05:50,845 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 13:06:01,381 - INFO - [Train] [48/90] | Loss: 0.4079 | Train Acc: 85.86%
2026-01-14 13:06:04,833 - INFO - [Valid] [48/90] | Loss: 0.4668 | Val Acc: 82.30%
2026-01-14 13:06:04,844 - INFO - [Metrics for 'abnormal'] | Precision: 0.8392 | Recall: 0.7643 | F1: 0.8000
2026-01-14 13:06:04,845 - INFO - [Metrics for 'normal'] | Precision: 0.8112 | Recall: 0.8736 | F1: 0.8413
2026-01-14 13:06:04,884 - INFO - [Best Model Saved] (val loss: 0.4668) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:06:04,885 - INFO - --------------------------------------------------
2026-01-14 13:06:04,887 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 13:06:14,318 - INFO - [Train] [49/90] | Loss: 0.3883 | Train Acc: 87.43%
2026-01-14 13:06:17,394 - INFO - [Valid] [49/90] | Loss: 0.4694 | Val Acc: 80.24%
2026-01-14 13:06:17,405 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 13:06:17,405 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 13:06:17,412 - INFO - --------------------------------------------------
2026-01-14 13:06:17,414 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 13:06:26,600 - INFO - [Train] [50/90] | Loss: 0.4084 | Train Acc: 86.46%
2026-01-14 13:06:29,569 - INFO - [Valid] [50/90] | Loss: 0.4931 | Val Acc: 81.12%
2026-01-14 13:06:29,583 - INFO - [Metrics for 'abnormal'] | Precision: 0.7888 | Recall: 0.8089 | F1: 0.7987
2026-01-14 13:06:29,583 - INFO - [Metrics for 'normal'] | Precision: 0.8315 | Recall: 0.8132 | F1: 0.8222
2026-01-14 13:06:29,588 - INFO - --------------------------------------------------
2026-01-14 13:06:29,591 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 13:06:38,248 - INFO - [Train] [51/90] | Loss: 0.3949 | Train Acc: 86.83%
2026-01-14 13:06:40,486 - INFO - [Valid] [51/90] | Loss: 0.4666 | Val Acc: 81.12%
2026-01-14 13:06:40,496 - INFO - [Metrics for 'abnormal'] | Precision: 0.7569 | Recall: 0.8726 | F1: 0.8107
2026-01-14 13:06:40,497 - INFO - [Metrics for 'normal'] | Precision: 0.8734 | Recall: 0.7582 | F1: 0.8118
2026-01-14 13:06:40,530 - INFO - [Best Model Saved] (val loss: 0.4666) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:06:40,530 - INFO - --------------------------------------------------
2026-01-14 13:06:40,532 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 13:06:48,570 - INFO - [Train] [52/90] | Loss: 0.3955 | Train Acc: 87.35%
2026-01-14 13:06:51,259 - INFO - [Valid] [52/90] | Loss: 0.4555 | Val Acc: 82.89%
2026-01-14 13:06:51,273 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 13:06:51,274 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 13:06:51,314 - INFO - [Best Model Saved] (val loss: 0.4555) -> 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:06:51,315 - INFO - --------------------------------------------------
2026-01-14 13:06:51,318 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 13:06:59,903 - INFO - [Train] [53/90] | Loss: 0.3753 | Train Acc: 88.39%
2026-01-14 13:07:02,611 - INFO - [Valid] [53/90] | Loss: 0.4799 | Val Acc: 82.30%
2026-01-14 13:07:02,632 - INFO - [Metrics for 'abnormal'] | Precision: 0.7740 | Recall: 0.8726 | F1: 0.8204
2026-01-14 13:07:02,632 - INFO - [Metrics for 'normal'] | Precision: 0.8765 | Recall: 0.7802 | F1: 0.8256
2026-01-14 13:07:02,636 - INFO - --------------------------------------------------
2026-01-14 13:07:02,639 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 13:07:11,308 - INFO - [Train] [54/90] | Loss: 0.3886 | Train Acc: 88.24%
2026-01-14 13:07:13,777 - INFO - [Valid] [54/90] | Loss: 0.4707 | Val Acc: 80.53%
2026-01-14 13:07:13,792 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 13:07:13,793 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 13:07:13,796 - INFO - --------------------------------------------------
2026-01-14 13:07:13,799 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 13:07:21,696 - INFO - [Train] [55/90] | Loss: 0.3851 | Train Acc: 87.80%
2026-01-14 13:07:24,150 - INFO - [Valid] [55/90] | Loss: 0.4639 | Val Acc: 82.30%
2026-01-14 13:07:24,163 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 13:07:24,163 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 13:07:24,167 - INFO - --------------------------------------------------
2026-01-14 13:07:24,169 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 13:07:32,793 - INFO - [Train] [56/90] | Loss: 0.3854 | Train Acc: 87.43%
2026-01-14 13:07:35,436 - INFO - [Valid] [56/90] | Loss: 0.4800 | Val Acc: 79.35%
2026-01-14 13:07:35,447 - INFO - [Metrics for 'abnormal'] | Precision: 0.7636 | Recall: 0.8025 | F1: 0.7826
2026-01-14 13:07:35,447 - INFO - [Metrics for 'normal'] | Precision: 0.8218 | Recall: 0.7857 | F1: 0.8034
2026-01-14 13:07:35,452 - INFO - --------------------------------------------------
2026-01-14 13:07:35,463 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 13:07:44,815 - INFO - [Train] [57/90] | Loss: 0.3758 | Train Acc: 88.91%
2026-01-14 13:07:47,144 - INFO - [Valid] [57/90] | Loss: 0.4752 | Val Acc: 80.24%
2026-01-14 13:07:47,159 - INFO - [Metrics for 'abnormal'] | Precision: 0.7586 | Recall: 0.8408 | F1: 0.7976
2026-01-14 13:07:47,159 - INFO - [Metrics for 'normal'] | Precision: 0.8485 | Recall: 0.7692 | F1: 0.8069
2026-01-14 13:07:47,165 - INFO - --------------------------------------------------
2026-01-14 13:07:47,169 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 13:07:56,746 - INFO - [Train] [58/90] | Loss: 0.3730 | Train Acc: 89.96%
2026-01-14 13:07:58,752 - INFO - [Valid] [58/90] | Loss: 0.4880 | Val Acc: 80.53%
2026-01-14 13:07:58,771 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 13:07:58,775 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 13:07:58,778 - INFO - --------------------------------------------------
2026-01-14 13:07:58,784 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 13:08:06,904 - INFO - [Train] [59/90] | Loss: 0.3632 | Train Acc: 89.66%
2026-01-14 13:08:09,666 - INFO - [Valid] [59/90] | Loss: 0.4745 | Val Acc: 83.19%
2026-01-14 13:08:09,680 - INFO - [Metrics for 'abnormal'] | Precision: 0.8333 | Recall: 0.7962 | F1: 0.8143
2026-01-14 13:08:09,680 - INFO - [Metrics for 'normal'] | Precision: 0.8307 | Recall: 0.8626 | F1: 0.8464
2026-01-14 13:08:09,685 - INFO - --------------------------------------------------
2026-01-14 13:08:09,687 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 13:08:18,380 - INFO - [Train] [60/90] | Loss: 0.3774 | Train Acc: 88.24%
2026-01-14 13:08:20,778 - INFO - [Valid] [60/90] | Loss: 0.4722 | Val Acc: 82.89%
2026-01-14 13:08:20,790 - INFO - [Metrics for 'abnormal'] | Precision: 0.8194 | Recall: 0.8089 | F1: 0.8141
2026-01-14 13:08:20,791 - INFO - [Metrics for 'normal'] | Precision: 0.8370 | Recall: 0.8462 | F1: 0.8415
2026-01-14 13:08:20,796 - INFO - --------------------------------------------------
2026-01-14 13:08:20,799 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 13:08:30,139 - INFO - [Train] [61/90] | Loss: 0.3596 | Train Acc: 89.88%
2026-01-14 13:08:33,055 - INFO - [Valid] [61/90] | Loss: 0.4964 | Val Acc: 79.65%
2026-01-14 13:08:33,068 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-01-14 13:08:33,069 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-01-14 13:08:33,074 - INFO - --------------------------------------------------
2026-01-14 13:08:33,077 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 13:08:41,459 - INFO - [Train] [62/90] | Loss: 0.3659 | Train Acc: 89.36%
2026-01-14 13:08:43,980 - INFO - [Valid] [62/90] | Loss: 0.4809 | Val Acc: 81.71%
2026-01-14 13:08:43,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7950 | Recall: 0.8153 | F1: 0.8050
2026-01-14 13:08:43,992 - INFO - [Metrics for 'normal'] | Precision: 0.8371 | Recall: 0.8187 | F1: 0.8278
2026-01-14 13:08:43,997 - INFO - --------------------------------------------------
2026-01-14 13:08:43,999 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 13:08:52,421 - INFO - [Train] [63/90] | Loss: 0.3617 | Train Acc: 89.06%
2026-01-14 13:08:54,850 - INFO - [Valid] [63/90] | Loss: 0.4761 | Val Acc: 79.94%
2026-01-14 13:08:54,874 - INFO - [Metrics for 'abnormal'] | Precision: 0.7486 | Recall: 0.8535 | F1: 0.7976
2026-01-14 13:08:54,874 - INFO - [Metrics for 'normal'] | Precision: 0.8562 | Recall: 0.7527 | F1: 0.8012
2026-01-14 13:08:54,882 - INFO - --------------------------------------------------
2026-01-14 13:08:54,884 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 13:09:03,619 - INFO - [Train] [64/90] | Loss: 0.3566 | Train Acc: 89.96%
2026-01-14 13:09:06,480 - INFO - [Valid] [64/90] | Loss: 0.5056 | Val Acc: 78.76%
2026-01-14 13:09:06,503 - INFO - [Metrics for 'abnormal'] | Precision: 0.7348 | Recall: 0.8471 | F1: 0.7870
2026-01-14 13:09:06,503 - INFO - [Metrics for 'normal'] | Precision: 0.8481 | Recall: 0.7363 | F1: 0.7882
2026-01-14 13:09:06,509 - INFO - --------------------------------------------------
2026-01-14 13:09:06,512 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 13:09:15,561 - INFO - [Train] [65/90] | Loss: 0.3584 | Train Acc: 89.51%
2026-01-14 13:09:18,507 - INFO - [Valid] [65/90] | Loss: 0.4836 | Val Acc: 79.65%
2026-01-14 13:09:18,518 - INFO - [Metrics for 'abnormal'] | Precision: 0.7418 | Recall: 0.8599 | F1: 0.7965
2026-01-14 13:09:18,518 - INFO - [Metrics for 'normal'] | Precision: 0.8599 | Recall: 0.7418 | F1: 0.7965
2026-01-14 13:09:18,522 - INFO - --------------------------------------------------
2026-01-14 13:09:18,524 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 13:09:27,508 - INFO - [Train] [66/90] | Loss: 0.3587 | Train Acc: 88.99%
2026-01-14 13:09:30,732 - INFO - [Valid] [66/90] | Loss: 0.4794 | Val Acc: 80.53%
2026-01-14 13:09:30,770 - INFO - [Metrics for 'abnormal'] | Precision: 0.7433 | Recall: 0.8854 | F1: 0.8081
2026-01-14 13:09:30,771 - INFO - [Metrics for 'normal'] | Precision: 0.8816 | Recall: 0.7363 | F1: 0.8024
2026-01-14 13:09:30,784 - INFO - --------------------------------------------------
2026-01-14 13:09:30,786 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 13:09:38,783 - INFO - [Train] [67/90] | Loss: 0.3450 | Train Acc: 90.70%
2026-01-14 13:09:41,924 - INFO - [Valid] [67/90] | Loss: 0.4689 | Val Acc: 81.71%
2026-01-14 13:09:41,937 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8471 | F1: 0.8110
2026-01-14 13:09:41,937 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.7912 | F1: 0.8229
2026-01-14 13:09:41,941 - INFO - --------------------------------------------------
2026-01-14 13:09:41,952 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 13:09:50,577 - INFO - [Train] [68/90] | Loss: 0.3568 | Train Acc: 89.21%
2026-01-14 13:09:53,566 - INFO - [Valid] [68/90] | Loss: 0.5319 | Val Acc: 78.76%
2026-01-14 13:09:53,592 - INFO - [Metrics for 'abnormal'] | Precision: 0.7136 | Recall: 0.9045 | F1: 0.7978
2026-01-14 13:09:53,594 - INFO - [Metrics for 'normal'] | Precision: 0.8929 | Recall: 0.6868 | F1: 0.7764
2026-01-14 13:09:53,600 - INFO - --------------------------------------------------
2026-01-14 13:09:53,602 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 13:10:02,917 - INFO - [Train] [69/90] | Loss: 0.3559 | Train Acc: 89.81%
2026-01-14 13:10:05,145 - INFO - [Valid] [69/90] | Loss: 0.4912 | Val Acc: 82.89%
2026-01-14 13:10:05,158 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.8599 | F1: 0.8232
2026-01-14 13:10:05,159 - INFO - [Metrics for 'normal'] | Precision: 0.8690 | Recall: 0.8022 | F1: 0.8343
2026-01-14 13:10:05,164 - INFO - --------------------------------------------------
2026-01-14 13:10:05,167 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 13:10:15,082 - INFO - [Train] [70/90] | Loss: 0.3485 | Train Acc: 89.81%
2026-01-14 13:10:17,366 - INFO - [Valid] [70/90] | Loss: 0.4740 | Val Acc: 81.12%
2026-01-14 13:10:17,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.7657 | Recall: 0.8535 | F1: 0.8072
2026-01-14 13:10:17,390 - INFO - [Metrics for 'normal'] | Precision: 0.8598 | Recall: 0.7747 | F1: 0.8150
2026-01-14 13:10:17,399 - INFO - --------------------------------------------------
2026-01-14 13:10:17,404 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 13:10:27,092 - INFO - [Train] [71/90] | Loss: 0.3441 | Train Acc: 90.03%
2026-01-14 13:10:29,476 - INFO - [Valid] [71/90] | Loss: 0.5088 | Val Acc: 80.53%
2026-01-14 13:10:29,490 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8662 | F1: 0.8047
2026-01-14 13:10:29,491 - INFO - [Metrics for 'normal'] | Precision: 0.8671 | Recall: 0.7527 | F1: 0.8059
2026-01-14 13:10:29,496 - INFO - --------------------------------------------------
2026-01-14 13:10:29,499 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 13:10:38,445 - INFO - [Train] [72/90] | Loss: 0.3497 | Train Acc: 90.70%
2026-01-14 13:10:40,816 - INFO - [Valid] [72/90] | Loss: 0.4925 | Val Acc: 82.60%
2026-01-14 13:10:40,826 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 13:10:40,826 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 13:10:40,830 - INFO - --------------------------------------------------
2026-01-14 13:10:40,831 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 13:10:50,366 - INFO - [Train] [73/90] | Loss: 0.3465 | Train Acc: 90.70%
2026-01-14 13:10:52,462 - INFO - [Valid] [73/90] | Loss: 0.4795 | Val Acc: 81.42%
2026-01-14 13:10:52,473 - INFO - [Metrics for 'abnormal'] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 13:10:52,473 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 13:10:52,476 - INFO - --------------------------------------------------
2026-01-14 13:10:52,478 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 13:11:02,075 - INFO - [Train] [74/90] | Loss: 0.3343 | Train Acc: 91.29%
2026-01-14 13:11:04,346 - INFO - [Valid] [74/90] | Loss: 0.4925 | Val Acc: 81.71%
2026-01-14 13:11:04,359 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 13:11:04,359 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 13:11:04,364 - INFO - --------------------------------------------------
2026-01-14 13:11:04,367 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 13:11:14,202 - INFO - [Train] [75/90] | Loss: 0.3354 | Train Acc: 91.44%
2026-01-14 13:11:16,271 - INFO - [Valid] [75/90] | Loss: 0.5164 | Val Acc: 81.71%
2026-01-14 13:11:16,299 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8471 | F1: 0.8110
2026-01-14 13:11:16,299 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.7912 | F1: 0.8229
2026-01-14 13:11:16,307 - INFO - --------------------------------------------------
2026-01-14 13:11:16,313 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 13:11:26,424 - INFO - [Train] [76/90] | Loss: 0.3440 | Train Acc: 89.96%
2026-01-14 13:11:28,675 - INFO - [Valid] [76/90] | Loss: 0.4924 | Val Acc: 81.42%
2026-01-14 13:11:28,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7901 | Recall: 0.8153 | F1: 0.8025
2026-01-14 13:11:28,686 - INFO - [Metrics for 'normal'] | Precision: 0.8362 | Recall: 0.8132 | F1: 0.8245
2026-01-14 13:11:28,690 - INFO - --------------------------------------------------
2026-01-14 13:11:28,692 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 13:11:38,303 - INFO - [Train] [77/90] | Loss: 0.3329 | Train Acc: 91.89%
2026-01-14 13:11:40,731 - INFO - [Valid] [77/90] | Loss: 0.4836 | Val Acc: 81.42%
2026-01-14 13:11:40,743 - INFO - [Metrics for 'abnormal'] | Precision: 0.7733 | Recall: 0.8471 | F1: 0.8085
2026-01-14 13:11:40,743 - INFO - [Metrics for 'normal'] | Precision: 0.8563 | Recall: 0.7857 | F1: 0.8195
2026-01-14 13:11:40,747 - INFO - --------------------------------------------------
2026-01-14 13:11:40,749 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 13:11:50,156 - INFO - [Train] [78/90] | Loss: 0.3205 | Train Acc: 92.19%
2026-01-14 13:11:52,369 - INFO - [Valid] [78/90] | Loss: 0.4995 | Val Acc: 81.42%
2026-01-14 13:11:52,392 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.8662 | F1: 0.8119
2026-01-14 13:11:52,392 - INFO - [Metrics for 'normal'] | Precision: 0.8696 | Recall: 0.7692 | F1: 0.8163
2026-01-14 13:11:52,399 - INFO - --------------------------------------------------
2026-01-14 13:11:52,401 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 13:12:01,030 - INFO - [Train] [79/90] | Loss: 0.3223 | Train Acc: 92.19%
2026-01-14 13:12:04,170 - INFO - [Valid] [79/90] | Loss: 0.4850 | Val Acc: 81.12%
2026-01-14 13:12:04,179 - INFO - [Metrics for 'abnormal'] | Precision: 0.7598 | Recall: 0.8662 | F1: 0.8095
2026-01-14 13:12:04,180 - INFO - [Metrics for 'normal'] | Precision: 0.8688 | Recall: 0.7637 | F1: 0.8129
2026-01-14 13:12:04,183 - INFO - --------------------------------------------------
2026-01-14 13:12:04,185 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 13:12:12,189 - INFO - [Train] [80/90] | Loss: 0.3393 | Train Acc: 91.74%
2026-01-14 13:12:15,060 - INFO - [Valid] [80/90] | Loss: 0.5160 | Val Acc: 82.89%
2026-01-14 13:12:15,073 - INFO - [Metrics for 'abnormal'] | Precision: 0.8414 | Recall: 0.7771 | F1: 0.8079
2026-01-14 13:12:15,073 - INFO - [Metrics for 'normal'] | Precision: 0.8196 | Recall: 0.8736 | F1: 0.8457
2026-01-14 13:12:15,098 - INFO - --------------------------------------------------
2026-01-14 13:12:15,100 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 13:12:23,976 - INFO - [Train] [81/90] | Loss: 0.3505 | Train Acc: 90.85%
2026-01-14 13:12:27,131 - INFO - [Valid] [81/90] | Loss: 0.4873 | Val Acc: 82.30%
2026-01-14 13:12:27,145 - INFO - [Metrics for 'abnormal'] | Precision: 0.7709 | Recall: 0.8790 | F1: 0.8214
2026-01-14 13:12:27,145 - INFO - [Metrics for 'normal'] | Precision: 0.8812 | Recall: 0.7747 | F1: 0.8246
2026-01-14 13:12:27,149 - INFO - --------------------------------------------------
2026-01-14 13:12:27,151 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 13:12:35,294 - INFO - [Train] [82/90] | Loss: 0.3249 | Train Acc: 92.49%
2026-01-14 13:12:38,349 - INFO - [Valid] [82/90] | Loss: 0.4764 | Val Acc: 82.60%
2026-01-14 13:12:38,363 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8726 | F1: 0.8228
2026-01-14 13:12:38,364 - INFO - [Metrics for 'normal'] | Precision: 0.8773 | Recall: 0.7857 | F1: 0.8290
2026-01-14 13:12:38,368 - INFO - --------------------------------------------------
2026-01-14 13:12:38,370 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 13:12:48,486 - INFO - [Train] [83/90] | Loss: 0.3259 | Train Acc: 91.15%
2026-01-14 13:12:51,024 - INFO - [Valid] [83/90] | Loss: 0.4731 | Val Acc: 82.89%
2026-01-14 13:12:51,037 - INFO - [Metrics for 'abnormal'] | Precision: 0.7964 | Recall: 0.8471 | F1: 0.8210
2026-01-14 13:12:51,037 - INFO - [Metrics for 'normal'] | Precision: 0.8605 | Recall: 0.8132 | F1: 0.8362
2026-01-14 13:12:51,041 - INFO - --------------------------------------------------
2026-01-14 13:12:51,044 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 13:13:00,606 - INFO - [Train] [84/90] | Loss: 0.3242 | Train Acc: 92.04%
2026-01-14 13:13:03,339 - INFO - [Valid] [84/90] | Loss: 0.4942 | Val Acc: 81.42%
2026-01-14 13:13:03,347 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 13:13:03,347 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 13:13:03,350 - INFO - --------------------------------------------------
2026-01-14 13:13:03,352 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 13:13:12,491 - INFO - [Train] [85/90] | Loss: 0.3119 | Train Acc: 93.38%
2026-01-14 13:13:14,505 - INFO - [Valid] [85/90] | Loss: 0.4841 | Val Acc: 82.89%
2026-01-14 13:13:14,515 - INFO - [Metrics for 'abnormal'] | Precision: 0.7797 | Recall: 0.8790 | F1: 0.8263
2026-01-14 13:13:14,515 - INFO - [Metrics for 'normal'] | Precision: 0.8827 | Recall: 0.7857 | F1: 0.8314
2026-01-14 13:13:14,519 - INFO - --------------------------------------------------
2026-01-14 13:13:14,520 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 13:13:23,578 - INFO - [Train] [86/90] | Loss: 0.3163 | Train Acc: 91.96%
2026-01-14 13:13:25,631 - INFO - [Valid] [86/90] | Loss: 0.4983 | Val Acc: 81.71%
2026-01-14 13:13:25,656 - INFO - [Metrics for 'abnormal'] | Precision: 0.7654 | Recall: 0.8726 | F1: 0.8155
2026-01-14 13:13:25,660 - INFO - [Metrics for 'normal'] | Precision: 0.8750 | Recall: 0.7692 | F1: 0.8187
2026-01-14 13:13:25,667 - INFO - --------------------------------------------------
2026-01-14 13:13:25,668 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 13:13:33,129 - INFO - [Train] [87/90] | Loss: 0.3124 | Train Acc: 93.01%
2026-01-14 13:13:35,386 - INFO - [Valid] [87/90] | Loss: 0.4873 | Val Acc: 82.01%
2026-01-14 13:13:35,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 13:13:35,397 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 13:13:35,401 - INFO - --------------------------------------------------
2026-01-14 13:13:35,403 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 13:13:44,728 - INFO - [Train] [88/90] | Loss: 0.3099 | Train Acc: 93.38%
2026-01-14 13:13:48,786 - INFO - [Valid] [88/90] | Loss: 0.5041 | Val Acc: 82.30%
2026-01-14 13:13:48,821 - INFO - [Metrics for 'abnormal'] | Precision: 0.7709 | Recall: 0.8790 | F1: 0.8214
2026-01-14 13:13:48,825 - INFO - [Metrics for 'normal'] | Precision: 0.8812 | Recall: 0.7747 | F1: 0.8246
2026-01-14 13:13:48,832 - INFO - --------------------------------------------------
2026-01-14 13:13:48,841 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 13:13:57,715 - INFO - [Train] [89/90] | Loss: 0.3192 | Train Acc: 92.26%
2026-01-14 13:14:00,108 - INFO - [Valid] [89/90] | Loss: 0.5122 | Val Acc: 81.42%
2026-01-14 13:14:00,127 - INFO - [Metrics for 'abnormal'] | Precision: 0.7765 | Recall: 0.8408 | F1: 0.8073
2026-01-14 13:14:00,127 - INFO - [Metrics for 'normal'] | Precision: 0.8521 | Recall: 0.7912 | F1: 0.8205
2026-01-14 13:14:00,131 - INFO - --------------------------------------------------
2026-01-14 13:14:00,137 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 13:14:06,651 - INFO - [Train] [90/90] | Loss: 0.3095 | Train Acc: 93.15%
2026-01-14 13:14:08,179 - INFO - [Valid] [90/90] | Loss: 0.5059 | Val Acc: 80.24%
2026-01-14 13:14:08,188 - INFO - [Metrics for 'abnormal'] | Precision: 0.7528 | Recall: 0.8535 | F1: 0.8000
2026-01-14 13:14:08,189 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.7582 | F1: 0.8047
2026-01-14 13:14:08,193 - INFO - ==================================================
2026-01-14 13:14:08,194 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 13:14:08,195 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 13:14:08,195 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 13:14:12,324 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 13:14:12,325 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 13:14:12,327 - INFO - Wanda Pruning을 시작합니다.
2026-01-14 13:14:12,328 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-01-14 13:14:12,331 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-01-14 13:14:20,021 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 13:14:20,023 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 13:14:20,541 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.816943359375)에 맞춰 변경되었습니다.
2026-01-14 13:14:20,541 - INFO - ==================================================
2026-01-14 13:14:20,591 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/best_model.pth'
2026-01-14 13:14:20,591 - INFO - ==================================================
2026-01-14 13:14:20,592 - INFO - Test 모드를 시작합니다.
2026-01-14 13:14:21,093 - INFO - 연산량 (MACs): 0.0920 GMACs per sample
2026-01-14 13:14:21,094 - INFO - 연산량 (FLOPs): 0.1840 GFLOPs per sample
2026-01-14 13:14:21,094 - INFO - ==================================================
2026-01-14 13:14:21,095 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 13:14:23,601 - INFO - 샘플 당 평균 Forward Pass 시간: 8.58ms (std: 8.02ms), FPS: 143.74 (std: 35.08) (1개 샘플 x 100회 반복)
2026-01-14 13:14:23,601 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 112.93 MB
2026-01-14 13:14:23,602 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 13:14:26,901 - INFO - [Test] Loss: 0.3794 | Test Acc: 82.89%
2026-01-14 13:14:26,916 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 13:14:26,916 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 13:14:27,503 - INFO - ==================================================
2026-01-14 13:14:27,503 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/confusion_matrix_20260114_124008.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/confusion_matrix_20260114_124008.pdf'
2026-01-14 13:14:27,503 - INFO - ==================================================
2026-01-14 13:14:27,503 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 13:14:29,232 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/model_fp32_20260114_124008.onnx'에 저장되었습니다. (크기: 1.99 MB)
2026-01-14 13:14:29,651 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2321.61 MB (증가량: 2.12 MB)
2026-01-14 13:14:29,651 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 13:14:32,325 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 18.00ms (std: 9.85ms)
2026-01-14 13:14:32,326 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 67.84 FPS (std: 26.31) (1개 샘플 x 100회 반복)
2026-01-14 13:14:32,327 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2328.03 MB (순수 증가량: 1.03 MB)
2026-01-14 13:14:32,327 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2328.03 MB (전체 증가량: 8.54 MB)
2026-01-14 13:14:36,224 - INFO - [Test (ONNX)] | Test Acc (ONNX): 82.89%
2026-01-14 13:14:36,234 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 13:14:36,235 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 13:14:36,704 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/val_acc.pdf'
2026-01-14 13:14:37,100 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/train_val_acc.pdf'
2026-01-14 13:14:37,440 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/F1_normal.pdf'
2026-01-14 13:14:37,865 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/val_loss.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/val_loss.pdf'
2026-01-14 13:14:38,250 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/learning_rate.pdf'
2026-01-14 13:14:43,257 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/compile.png' and 'log/Sewer-TAPNEW/baseline_deit_tiny_wanda_20260114_124008/graph_20260114_124008/compile.pdf'
