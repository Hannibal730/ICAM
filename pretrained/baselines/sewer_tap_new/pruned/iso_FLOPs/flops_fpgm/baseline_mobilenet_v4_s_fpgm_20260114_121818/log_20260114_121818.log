2026-01-14 12:18:18,908 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/log_20260114_121818.log'에 저장됩니다.
2026-01-14 12:18:18,915 - INFO - ==================================================
2026-01-14 12:18:18,915 - INFO - config.yaml:
2026-01-14 12:18:18,915 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobilenet_v4_s
  use_fpgm_pruning: true
  pruning_flops_target: 0.1829

2026-01-14 12:18:18,915 - INFO - ==================================================
2026-01-14 12:18:18,983 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 12:18:18,984 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 12:18:18,985 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 12:18:19,000 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 12:18:19,000 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 12:18:19,001 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 12:18:19,002 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:18:19,359 - INFO - ==================================================
2026-01-14 12:18:19,359 - INFO - 모델 파라미터 수:
2026-01-14 12:18:19,359 - INFO -   - 총 파라미터: 2,495,586 개
2026-01-14 12:18:19,360 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-01-14 12:18:19,360 - INFO - ================================================================================
2026-01-14 12:18:19,360 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 12:18:19,360 - INFO - ================================================================================
2026-01-14 12:18:19,360 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:18:19,362 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 12:18:19,362 - INFO - ==================================================
2026-01-14 12:18:19,362 - INFO - train 모드를 시작합니다.
2026-01-14 12:18:19,363 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:18:19,363 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:18:19,363 - INFO - --------------------------------------------------
2026-01-14 12:18:19,365 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 12:18:25,578 - INFO - [Train] [1/10] | Loss: 2.8238 | Train Acc: 67.63%
2026-01-14 12:18:28,141 - INFO - [Valid] [1/10] | Loss: 1.0359 | Val Acc: 67.26%
2026-01-14 12:18:28,156 - INFO - [Metrics for 'abnormal'] | Precision: 0.8833 | Recall: 0.3376 | F1: 0.4885
2026-01-14 12:18:28,156 - INFO - [Metrics for 'normal'] | Precision: 0.6272 | Recall: 0.9615 | F1: 0.7592
2026-01-14 12:18:28,205 - INFO - [Best Model Saved] (val loss: 1.0359) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:18:28,205 - INFO - --------------------------------------------------
2026-01-14 12:18:28,207 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 12:18:33,658 - INFO - [Train] [2/10] | Loss: 0.6873 | Train Acc: 73.51%
2026-01-14 12:18:35,112 - INFO - [Valid] [2/10] | Loss: 0.7867 | Val Acc: 69.03%
2026-01-14 12:18:35,121 - INFO - [Metrics for 'abnormal'] | Precision: 0.6398 | Recall: 0.7580 | F1: 0.6939
2026-01-14 12:18:35,121 - INFO - [Metrics for 'normal'] | Precision: 0.7516 | Recall: 0.6319 | F1: 0.6866
2026-01-14 12:18:35,157 - INFO - [Best Model Saved] (val loss: 0.7867) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:18:35,157 - INFO - --------------------------------------------------
2026-01-14 12:18:35,159 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 12:18:40,398 - INFO - [Train] [3/10] | Loss: 0.6559 | Train Acc: 72.25%
2026-01-14 12:18:42,173 - INFO - [Valid] [3/10] | Loss: 1.2866 | Val Acc: 62.83%
2026-01-14 12:18:42,191 - INFO - [Metrics for 'abnormal'] | Precision: 0.8974 | Recall: 0.2229 | F1: 0.3571
2026-01-14 12:18:42,191 - INFO - [Metrics for 'normal'] | Precision: 0.5933 | Recall: 0.9780 | F1: 0.7386
2026-01-14 12:18:42,196 - INFO - --------------------------------------------------
2026-01-14 12:18:42,199 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 12:18:48,907 - INFO - [Train] [4/10] | Loss: 0.6374 | Train Acc: 73.44%
2026-01-14 12:18:50,908 - INFO - [Valid] [4/10] | Loss: 0.7555 | Val Acc: 68.73%
2026-01-14 12:18:50,928 - INFO - [Metrics for 'abnormal'] | Precision: 0.6889 | Recall: 0.5924 | F1: 0.6370
2026-01-14 12:18:50,929 - INFO - [Metrics for 'normal'] | Precision: 0.6863 | Recall: 0.7692 | F1: 0.7254
2026-01-14 12:18:50,992 - INFO - [Best Model Saved] (val loss: 0.7555) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:18:50,993 - INFO - --------------------------------------------------
2026-01-14 12:18:50,995 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 12:18:56,783 - INFO - [Train] [5/10] | Loss: 0.5943 | Train Acc: 75.97%
2026-01-14 12:18:58,733 - INFO - [Valid] [5/10] | Loss: 0.6756 | Val Acc: 77.58%
2026-01-14 12:18:58,746 - INFO - [Metrics for 'abnormal'] | Precision: 0.7035 | Recall: 0.8917 | F1: 0.7865
2026-01-14 12:18:58,747 - INFO - [Metrics for 'normal'] | Precision: 0.8786 | Recall: 0.6758 | F1: 0.7640
2026-01-14 12:18:58,798 - INFO - [Best Model Saved] (val loss: 0.6756) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:18:58,799 - INFO - --------------------------------------------------
2026-01-14 12:18:58,801 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 12:19:05,626 - INFO - [Train] [6/10] | Loss: 0.5819 | Train Acc: 76.26%
2026-01-14 12:19:07,481 - INFO - [Valid] [6/10] | Loss: 1.0748 | Val Acc: 52.51%
2026-01-14 12:19:07,492 - INFO - [Metrics for 'abnormal'] | Precision: 0.4937 | Recall: 1.0000 | F1: 0.6611
2026-01-14 12:19:07,493 - INFO - [Metrics for 'normal'] | Precision: 1.0000 | Recall: 0.1154 | F1: 0.2069
2026-01-14 12:19:07,496 - INFO - --------------------------------------------------
2026-01-14 12:19:07,499 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 12:19:14,450 - INFO - [Train] [7/10] | Loss: 0.5064 | Train Acc: 79.99%
2026-01-14 12:19:16,137 - INFO - [Valid] [7/10] | Loss: 0.7492 | Val Acc: 74.93%
2026-01-14 12:19:16,151 - INFO - [Metrics for 'abnormal'] | Precision: 0.7118 | Recall: 0.7707 | F1: 0.7401
2026-01-14 12:19:16,152 - INFO - [Metrics for 'normal'] | Precision: 0.7870 | Recall: 0.7308 | F1: 0.7578
2026-01-14 12:19:16,156 - INFO - --------------------------------------------------
2026-01-14 12:19:16,159 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 12:19:24,745 - INFO - [Train] [8/10] | Loss: 0.5218 | Train Acc: 79.39%
2026-01-14 12:19:27,117 - INFO - [Valid] [8/10] | Loss: 0.5229 | Val Acc: 79.35%
2026-01-14 12:19:27,130 - INFO - [Metrics for 'abnormal'] | Precision: 0.8085 | Recall: 0.7261 | F1: 0.7651
2026-01-14 12:19:27,130 - INFO - [Metrics for 'normal'] | Precision: 0.7828 | Recall: 0.8516 | F1: 0.8158
2026-01-14 12:19:27,198 - INFO - [Best Model Saved] (val loss: 0.5229) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:19:27,199 - INFO - --------------------------------------------------
2026-01-14 12:19:27,202 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 12:19:35,017 - INFO - [Train] [9/10] | Loss: 0.4601 | Train Acc: 83.48%
2026-01-14 12:19:37,310 - INFO - [Valid] [9/10] | Loss: 0.5065 | Val Acc: 82.30%
2026-01-14 12:19:37,336 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-01-14 12:19:37,337 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-01-14 12:19:37,487 - INFO - [Best Model Saved] (val loss: 0.5065) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:19:37,488 - INFO - --------------------------------------------------
2026-01-14 12:19:37,490 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 12:19:45,492 - INFO - [Train] [10/10] | Loss: 0.4426 | Train Acc: 84.23%
2026-01-14 12:19:47,472 - INFO - [Valid] [10/10] | Loss: 0.5812 | Val Acc: 78.47%
2026-01-14 12:19:47,484 - INFO - [Metrics for 'abnormal'] | Precision: 0.8043 | Recall: 0.7070 | F1: 0.7525
2026-01-14 12:19:47,485 - INFO - [Metrics for 'normal'] | Precision: 0.7711 | Recall: 0.8516 | F1: 0.8094
2026-01-14 12:19:47,490 - INFO - ================================================================================
2026-01-14 12:19:47,491 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 12:19:47,491 - INFO - ================================================================================
2026-01-14 12:19:47,732 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'을(를) 불러왔습니다.
2026-01-14 12:19:47,733 - INFO - ================================================================================
2026-01-14 12:19:47,734 - INFO - 목표 FLOPs (0.1829 GFLOPs)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 12:19:47,857 - INFO - 원본 모델 FLOPs: 0.3853 GFLOPs
2026-01-14 12:19:48,141 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:48,141 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:48,565 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 12:19:48,566 - INFO - ==================================================
2026-01-14 12:19:48,644 - INFO -   [탐색  1] 희소도: 0.4950 -> FLOPs: 0.1092 GFLOPs (감소율: 71.66%)
2026-01-14 12:19:48,754 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:48,755 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:49,141 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.2475)에 맞춰 변경되었습니다.
2026-01-14 12:19:49,141 - INFO - ==================================================
2026-01-14 12:19:49,220 - INFO -   [탐색  2] 희소도: 0.2475 -> FLOPs: 0.2263 GFLOPs (감소율: 41.26%)
2026-01-14 12:19:49,302 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:49,303 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:49,664 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.37124999999999997)에 맞춰 변경되었습니다.
2026-01-14 12:19:49,664 - INFO - ==================================================
2026-01-14 12:19:49,733 - INFO -   [탐색  3] 희소도: 0.3712 -> FLOPs: 0.1626 GFLOPs (감소율: 57.81%)
2026-01-14 12:19:49,804 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:49,805 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:50,035 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.30937499999999996)에 맞춰 변경되었습니다.
2026-01-14 12:19:50,035 - INFO - ==================================================
2026-01-14 12:19:50,110 - INFO -   [탐색  4] 희소도: 0.3094 -> FLOPs: 0.1932 GFLOPs (감소율: 49.86%)
2026-01-14 12:19:50,170 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:50,170 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:50,415 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.34031249999999996)에 맞춰 변경되었습니다.
2026-01-14 12:19:50,416 - INFO - ==================================================
2026-01-14 12:19:50,605 - INFO -   [탐색  5] 희소도: 0.3403 -> FLOPs: 0.1775 GFLOPs (감소율: 53.92%)
2026-01-14 12:19:50,696 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:50,697 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:50,952 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32484375)에 맞춰 변경되었습니다.
2026-01-14 12:19:50,953 - INFO - ==================================================
2026-01-14 12:19:51,039 - INFO -   [탐색  6] 희소도: 0.3248 -> FLOPs: 0.1825 GFLOPs (감소율: 52.64%)
2026-01-14 12:19:51,107 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:51,107 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:51,736 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.31710937499999997)에 맞춰 변경되었습니다.
2026-01-14 12:19:51,737 - INFO - ==================================================
2026-01-14 12:19:51,797 - INFO -   [탐색  7] 희소도: 0.3171 -> FLOPs: 0.1856 GFLOPs (감소율: 51.83%)
2026-01-14 12:19:51,858 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:51,858 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:52,086 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32097656249999995)에 맞춰 변경되었습니다.
2026-01-14 12:19:52,086 - INFO - ==================================================
2026-01-14 12:19:52,145 - INFO -   [탐색  8] 희소도: 0.3210 -> FLOPs: 0.1844 GFLOPs (감소율: 52.14%)
2026-01-14 12:19:52,196 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:52,196 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:52,466 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291015624999997)에 맞춰 변경되었습니다.
2026-01-14 12:19:52,466 - INFO - ==================================================
2026-01-14 12:19:52,516 - INFO -   [탐색  9] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:19:52,591 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:52,592 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:52,961 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.323876953125)에 맞춰 변경되었습니다.
2026-01-14 12:19:52,962 - INFO - ==================================================
2026-01-14 12:19:53,126 - INFO -   [탐색 10] 희소도: 0.3239 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:53,288 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:53,289 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:53,493 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3233935546875)에 맞춰 변경되었습니다.
2026-01-14 12:19:53,494 - INFO - ==================================================
2026-01-14 12:19:53,554 - INFO -   [탐색 11] 희소도: 0.3234 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:53,622 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:53,623 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:53,829 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32315185546874997)에 맞춰 변경되었습니다.
2026-01-14 12:19:53,830 - INFO - ==================================================
2026-01-14 12:19:53,892 - INFO -   [탐색 12] 희소도: 0.3232 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:53,966 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:53,968 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:54,280 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32303100585937494)에 맞춰 변경되었습니다.
2026-01-14 12:19:54,280 - INFO - ==================================================
2026-01-14 12:19:54,342 - INFO -   [탐색 13] 희소도: 0.3230 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:54,442 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:54,443 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:54,747 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32297058105468746)에 맞춰 변경되었습니다.
2026-01-14 12:19:54,747 - INFO - ==================================================
2026-01-14 12:19:54,803 - INFO -   [탐색 14] 희소도: 0.3230 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:54,949 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:54,949 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:55,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229403686523437)에 맞춰 변경되었습니다.
2026-01-14 12:19:55,308 - INFO - ==================================================
2026-01-14 12:19:55,365 - INFO -   [탐색 15] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:55,534 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:55,534 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:55,879 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229252624511718)에 맞춰 변경되었습니다.
2026-01-14 12:19:55,879 - INFO - ==================================================
2026-01-14 12:19:55,959 - INFO -   [탐색 16] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:56,047 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:56,048 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:56,306 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229177093505859)에 맞춰 변경되었습니다.
2026-01-14 12:19:56,308 - INFO - ==================================================
2026-01-14 12:19:56,371 - INFO -   [탐색 17] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:56,450 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:56,450 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:56,948 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229139328002929)에 맞춰 변경되었습니다.
2026-01-14 12:19:56,948 - INFO - ==================================================
2026-01-14 12:19:57,017 - INFO -   [탐색 18] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:19:57,086 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:57,087 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:57,777 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291582107543937)에 맞춰 변경되었습니다.
2026-01-14 12:19:57,782 - INFO - ==================================================
2026-01-14 12:19:57,857 - INFO -   [탐색 19] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:19:57,925 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:57,926 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:58,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229167652130126)에 맞춰 변경되었습니다.
2026-01-14 12:19:58,178 - INFO - ==================================================
2026-01-14 12:19:58,235 - INFO -   [탐색 20] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:19:58,312 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:58,313 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:58,619 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916293144226)에 맞춰 변경되었습니다.
2026-01-14 12:19:58,620 - INFO - ==================================================
2026-01-14 12:19:58,681 - INFO -   [탐색 21] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:19:58,764 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:58,765 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:59,022 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229165291786193)에 맞춰 변경되었습니다.
2026-01-14 12:19:59,023 - INFO - ==================================================
2026-01-14 12:19:59,080 - INFO -   [탐색 22] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:19:59,162 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:59,163 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:59,470 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166471958159)에 맞춰 변경되었습니다.
2026-01-14 12:19:59,471 - INFO - ==================================================
2026-01-14 12:19:59,536 - INFO -   [탐색 23] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:19:59,590 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:19:59,591 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:19:59,917 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291670620441426)에 맞춰 변경되었습니다.
2026-01-14 12:19:59,917 - INFO - ==================================================
2026-01-14 12:19:59,967 - INFO -   [탐색 24] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:00,028 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:00,029 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:00,378 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166767001151)에 맞춰 변경되었습니다.
2026-01-14 12:20:00,378 - INFO - ==================================================
2026-01-14 12:20:00,432 - INFO -   [탐색 25] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:00,493 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:00,493 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:00,692 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666194796553)에 맞춰 변경되었습니다.
2026-01-14 12:20:00,693 - INFO - ==================================================
2026-01-14 12:20:00,739 - INFO -   [탐색 26] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:00,791 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:00,791 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:01,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166693240403)에 맞춰 변경되었습니다.
2026-01-14 12:20:01,191 - INFO - ==================================================
2026-01-14 12:20:01,247 - INFO -   [탐색 27] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:01,315 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:01,316 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:01,566 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166656360029)에 맞춰 변경되었습니다.
2026-01-14 12:20:01,566 - INFO - ==================================================
2026-01-14 12:20:01,623 - INFO -   [탐색 28] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:01,693 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:01,694 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:02,026 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666748002157)에 맞춰 변경되었습니다.
2026-01-14 12:20:02,026 - INFO - ==================================================
2026-01-14 12:20:02,154 - INFO -   [탐색 29] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:02,268 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:02,269 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:02,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166665580122)에 맞춰 변경되었습니다.
2026-01-14 12:20:02,568 - INFO - ==================================================
2026-01-14 12:20:02,634 - INFO -   [탐색 30] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:02,702 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:02,702 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:02,967 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166670190169)에 맞춰 변경되었습니다.
2026-01-14 12:20:02,968 - INFO - ==================================================
2026-01-14 12:20:03,392 - INFO -   [탐색 31] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:03,469 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:03,470 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:03,699 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666678851455)에 맞춰 변경되었습니다.
2026-01-14 12:20:03,700 - INFO - ==================================================
2026-01-14 12:20:03,760 - INFO -   [탐색 32] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:03,831 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:03,831 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:04,066 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666667326335)에 맞춰 변경되었습니다.
2026-01-14 12:20:04,067 - INFO - ==================================================
2026-01-14 12:20:04,117 - INFO -   [탐색 33] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:04,181 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:04,182 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:04,403 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666156378)에 맞춰 변경되었습니다.
2026-01-14 12:20:04,403 - INFO - ==================================================
2026-01-14 12:20:04,465 - INFO -   [탐색 34] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:04,538 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:04,539 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:04,753 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666664445057)에 맞춰 변경되었습니다.
2026-01-14 12:20:04,754 - INFO - ==================================================
2026-01-14 12:20:04,811 - INFO -   [탐색 35] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:04,884 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:04,884 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:05,097 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916666658857)에 맞춰 변경되었습니다.
2026-01-14 12:20:05,097 - INFO - ==================================================
2026-01-14 12:20:05,154 - INFO -   [탐색 36] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:05,223 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:05,224 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:05,620 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666606017)에 맞춰 변경되었습니다.
2026-01-14 12:20:05,621 - INFO - ==================================================
2026-01-14 12:20:05,717 - INFO -   [탐색 37] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:05,791 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:05,792 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:06,026 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666696618)에 맞춰 변경되었습니다.
2026-01-14 12:20:06,027 - INFO - ==================================================
2026-01-14 12:20:06,083 - INFO -   [탐색 38] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:06,151 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:06,152 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:06,420 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916666667861)에 맞춰 변경되었습니다.
2026-01-14 12:20:06,420 - INFO - ==================================================
2026-01-14 12:20:06,477 - INFO -   [탐색 39] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:06,555 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:06,559 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:06,895 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666669606)에 맞춰 변경되었습니다.
2026-01-14 12:20:06,897 - INFO - ==================================================
2026-01-14 12:20:06,953 - INFO -   [탐색 40] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:07,023 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:07,024 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:07,322 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666665104)에 맞춰 변경되었습니다.
2026-01-14 12:20:07,322 - INFO - ==================================================
2026-01-14 12:20:07,378 - INFO -   [탐색 41] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:07,734 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:07,734 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:07,976 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666667355)에 맞춰 변경되었습니다.
2026-01-14 12:20:07,977 - INFO - ==================================================
2026-01-14 12:20:08,034 - INFO -   [탐색 42] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:08,103 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:08,104 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:08,346 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916666666623)에 맞춰 변경되었습니다.
2026-01-14 12:20:08,347 - INFO - ==================================================
2026-01-14 12:20:08,407 - INFO -   [탐색 43] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:08,479 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:08,480 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:08,823 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666793)에 맞춰 변경되었습니다.
2026-01-14 12:20:08,824 - INFO - ==================================================
2026-01-14 12:20:08,880 - INFO -   [탐색 44] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:08,949 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:08,950 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:09,282 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666665114)에 맞춰 변경되었습니다.
2026-01-14 12:20:09,282 - INFO - ==================================================
2026-01-14 12:20:09,338 - INFO -   [탐색 45] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:09,398 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:09,398 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:09,622 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666652)에 맞춰 변경되었습니다.
2026-01-14 12:20:09,622 - INFO - ==================================================
2026-01-14 12:20:09,681 - INFO -   [탐색 46] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:09,738 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:09,738 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:09,960 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666667224)에 맞춰 변경되었습니다.
2026-01-14 12:20:09,960 - INFO - ==================================================
2026-01-14 12:20:10,016 - INFO -   [탐색 47] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:10,084 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:10,085 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:10,312 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666874)에 맞춰 변경되었습니다.
2026-01-14 12:20:10,312 - INFO - ==================================================
2026-01-14 12:20:10,365 - INFO -   [탐색 48] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:10,434 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:10,434 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:10,631 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666696)에 맞춰 변경되었습니다.
2026-01-14 12:20:10,631 - INFO - ==================================================
2026-01-14 12:20:10,677 - INFO -   [탐색 49] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:10,746 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:10,746 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:10,930 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666661)에 맞춰 변경되었습니다.
2026-01-14 12:20:10,930 - INFO - ==================================================
2026-01-14 12:20:10,974 - INFO -   [탐색 50] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:11,031 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:11,032 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:11,227 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666665)에 맞춰 변경되었습니다.
2026-01-14 12:20:11,228 - INFO - ==================================================
2026-01-14 12:20:11,286 - INFO -   [탐색 51] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 12:20:11,356 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:11,356 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:11,545 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666674)에 맞춰 변경되었습니다.
2026-01-14 12:20:11,546 - INFO - ==================================================
2026-01-14 12:20:11,591 - INFO -   [탐색 52] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.19%)
2026-01-14 12:20:11,961 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:11,961 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:12,200 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:12,201 - INFO - ==================================================
2026-01-14 12:20:12,255 - INFO -   [탐색 53] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:12,321 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:12,321 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:12,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666668)에 맞춰 변경되었습니다.
2026-01-14 12:20:12,516 - INFO - ==================================================
2026-01-14 12:20:12,577 - INFO -   [탐색 54] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.19%)
2026-01-14 12:20:12,651 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:12,652 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:12,988 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:12,989 - INFO - ==================================================
2026-01-14 12:20:13,046 - INFO -   [탐색 55] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:13,110 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:13,111 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:13,335 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:13,336 - INFO - ==================================================
2026-01-14 12:20:13,396 - INFO -   [탐색 56] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:13,472 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:13,473 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:13,736 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:13,737 - INFO - ==================================================
2026-01-14 12:20:13,794 - INFO -   [탐색 57] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:13,861 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:13,862 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:14,168 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:14,168 - INFO - ==================================================
2026-01-14 12:20:14,226 - INFO -   [탐색 58] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:14,295 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:14,295 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:14,540 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:14,541 - INFO - ==================================================
2026-01-14 12:20:14,598 - INFO -   [탐색 59] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:14,669 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:14,669 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:15,042 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:15,043 - INFO - ==================================================
2026-01-14 12:20:15,102 - INFO -   [탐색 60] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:15,174 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:15,174 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:15,412 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:15,413 - INFO - ==================================================
2026-01-14 12:20:15,468 - INFO -   [탐색 61] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:15,537 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:15,537 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:15,906 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:15,906 - INFO - ==================================================
2026-01-14 12:20:15,960 - INFO -   [탐색 62] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:16,019 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:16,020 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:16,227 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:16,228 - INFO - ==================================================
2026-01-14 12:20:16,284 - INFO -   [탐색 63] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:16,640 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:16,641 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:16,932 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:16,933 - INFO - ==================================================
2026-01-14 12:20:16,984 - INFO -   [탐색 64] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:17,039 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:17,040 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:17,223 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:17,224 - INFO - ==================================================
2026-01-14 12:20:17,287 - INFO -   [탐색 65] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:17,362 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:17,362 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:17,573 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:17,573 - INFO - ==================================================
2026-01-14 12:20:17,633 - INFO -   [탐색 66] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:17,714 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:17,714 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:17,873 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:17,874 - INFO - ==================================================
2026-01-14 12:20:17,928 - INFO -   [탐색 67] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:17,991 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:17,992 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:18,202 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:18,202 - INFO - ==================================================
2026-01-14 12:20:18,259 - INFO -   [탐색 68] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:18,330 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:18,330 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:18,525 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:18,525 - INFO - ==================================================
2026-01-14 12:20:18,582 - INFO -   [탐색 69] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:18,649 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:18,649 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:18,867 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:18,868 - INFO - ==================================================
2026-01-14 12:20:18,923 - INFO -   [탐색 70] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:18,990 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:18,990 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:19,181 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:19,181 - INFO - ==================================================
2026-01-14 12:20:19,237 - INFO -   [탐색 71] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:19,308 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:19,309 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:19,562 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:19,563 - INFO - ==================================================
2026-01-14 12:20:19,642 - INFO -   [탐색 72] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:19,713 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:19,714 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:19,963 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:19,963 - INFO - ==================================================
2026-01-14 12:20:20,026 - INFO -   [탐색 73] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:20,099 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:20,100 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:20,349 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:20,350 - INFO - ==================================================
2026-01-14 12:20:20,407 - INFO -   [탐색 74] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:20,475 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:20,476 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:21,063 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:21,064 - INFO - ==================================================
2026-01-14 12:20:21,121 - INFO -   [탐색 75] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:21,191 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:21,192 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:21,418 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:21,418 - INFO - ==================================================
2026-01-14 12:20:21,472 - INFO -   [탐색 76] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:21,542 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:21,543 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:21,836 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:21,837 - INFO - ==================================================
2026-01-14 12:20:21,891 - INFO -   [탐색 77] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:21,958 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:21,958 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:22,177 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:22,178 - INFO - ==================================================
2026-01-14 12:20:22,234 - INFO -   [탐색 78] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:22,301 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:22,302 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:22,669 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:22,669 - INFO - ==================================================
2026-01-14 12:20:22,735 - INFO -   [탐색 79] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:22,810 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:22,810 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:23,046 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:23,046 - INFO - ==================================================
2026-01-14 12:20:23,136 - INFO -   [탐색 80] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:23,222 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:23,223 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:23,460 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:23,460 - INFO - ==================================================
2026-01-14 12:20:23,516 - INFO -   [탐색 81] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:23,583 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:23,583 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:23,828 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:23,828 - INFO - ==================================================
2026-01-14 12:20:23,876 - INFO -   [탐색 82] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:23,927 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:23,927 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:24,169 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:24,169 - INFO - ==================================================
2026-01-14 12:20:24,212 - INFO -   [탐색 83] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:24,263 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:24,263 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:24,428 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:24,428 - INFO - ==================================================
2026-01-14 12:20:24,482 - INFO -   [탐색 84] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:24,558 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:24,558 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:24,747 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:24,747 - INFO - ==================================================
2026-01-14 12:20:24,803 - INFO -   [탐색 85] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:24,870 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:24,871 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:25,062 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:25,063 - INFO - ==================================================
2026-01-14 12:20:25,126 - INFO -   [탐색 86] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:25,199 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:25,199 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:25,721 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:25,722 - INFO - ==================================================
2026-01-14 12:20:25,774 - INFO -   [탐색 87] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:25,836 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:25,836 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:26,069 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:26,070 - INFO - ==================================================
2026-01-14 12:20:26,142 - INFO -   [탐색 88] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:26,224 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:26,225 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:26,450 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:26,451 - INFO - ==================================================
2026-01-14 12:20:26,514 - INFO -   [탐색 89] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:26,583 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:26,583 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:26,839 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:26,840 - INFO - ==================================================
2026-01-14 12:20:26,899 - INFO -   [탐색 90] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:26,971 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:26,972 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:27,165 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:27,166 - INFO - ==================================================
2026-01-14 12:20:27,225 - INFO -   [탐색 91] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:27,294 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:27,295 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:27,599 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:27,600 - INFO - ==================================================
2026-01-14 12:20:27,659 - INFO -   [탐색 92] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:27,731 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:27,731 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:27,997 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:27,998 - INFO - ==================================================
2026-01-14 12:20:28,075 - INFO -   [탐색 93] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:28,167 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:28,167 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:28,444 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:28,444 - INFO - ==================================================
2026-01-14 12:20:28,504 - INFO -   [탐색 94] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:28,578 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:28,578 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:28,915 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:28,915 - INFO - ==================================================
2026-01-14 12:20:28,971 - INFO -   [탐색 95] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:29,044 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:29,044 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:29,338 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:29,338 - INFO - ==================================================
2026-01-14 12:20:29,394 - INFO -   [탐색 96] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:29,461 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:29,461 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:29,799 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:29,799 - INFO - ==================================================
2026-01-14 12:20:29,843 - INFO -   [탐색 97] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:29,908 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:29,908 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:30,154 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:30,154 - INFO - ==================================================
2026-01-14 12:20:30,224 - INFO -   [탐색 98] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:30,300 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:30,301 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:30,524 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:30,525 - INFO - ==================================================
2026-01-14 12:20:30,873 - INFO -   [탐색 99] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:30,925 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:30,925 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:31,125 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 12:20:31,125 - INFO - ==================================================
2026-01-14 12:20:31,165 - INFO -   [탐색 100] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 12:20:31,165 - INFO - 탐색 완료. 목표 FLOPs(0.1829)에 가장 근접한 최적 희소도는 0.3234 입니다.
2026-01-14 12:20:31,165 - INFO - ================================================================================
2026-01-14 12:20:31,168 - INFO - 계산된 Pruning 정보(희소도: 0.3234)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/pruning_info.yaml'에 저장했습니다.
2026-01-14 12:20:31,210 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 12:20:31,304 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:31,304 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:31,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3233935546875)에 맞춰 변경되었습니다.
2026-01-14 12:20:31,584 - INFO - ==================================================
2026-01-14 12:20:31,587 - INFO - ==================================================
2026-01-14 12:20:31,588 - INFO - 모델 파라미터 수:
2026-01-14 12:20:31,588 - INFO -   - 총 파라미터: 1,156,016 개
2026-01-14 12:20:31,588 - INFO -   - 학습 가능한 파라미터: 1,156,016 개
2026-01-14 12:20:31,646 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 12:20:31,764 - INFO - FLOPs가 0.3853 GFLOPs에서 0.1826 GFLOPs로 감소했습니다 (감소율: 52.61%).
2026-01-14 12:20:31,765 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 12:20:31,765 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:20:31,767 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 12:20:31,767 - INFO - ==================================================
2026-01-14 12:20:31,768 - INFO - train 모드를 시작합니다.
2026-01-14 12:20:31,768 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:20:31,768 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:20:31,769 - INFO - --------------------------------------------------
2026-01-14 12:20:31,771 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 12:20:37,169 - INFO - [Train] [11/90] | Loss: 0.8211 | Train Acc: 68.30%
2026-01-14 12:20:38,644 - INFO - [Valid] [11/90] | Loss: 0.7751 | Val Acc: 64.60%
2026-01-14 12:20:38,652 - INFO - [Metrics for 'abnormal'] | Precision: 0.8491 | Recall: 0.2866 | F1: 0.4286
2026-01-14 12:20:38,652 - INFO - [Metrics for 'normal'] | Precision: 0.6084 | Recall: 0.9560 | F1: 0.7436
2026-01-14 12:20:38,693 - INFO - [Best Model Saved] (val loss: 0.7751) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:20:38,694 - INFO - --------------------------------------------------
2026-01-14 12:20:38,696 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 12:20:43,938 - INFO - [Train] [12/90] | Loss: 0.6516 | Train Acc: 73.29%
2026-01-14 12:20:45,623 - INFO - [Valid] [12/90] | Loss: 0.5587 | Val Acc: 78.76%
2026-01-14 12:20:45,636 - INFO - [Metrics for 'abnormal'] | Precision: 0.8148 | Recall: 0.7006 | F1: 0.7534
2026-01-14 12:20:45,637 - INFO - [Metrics for 'normal'] | Precision: 0.7696 | Recall: 0.8626 | F1: 0.8135
2026-01-14 12:20:45,694 - INFO - [Best Model Saved] (val loss: 0.5587) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:20:45,695 - INFO - --------------------------------------------------
2026-01-14 12:20:45,697 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 12:20:51,411 - INFO - [Train] [13/90] | Loss: 0.5325 | Train Acc: 78.57%
2026-01-14 12:20:52,846 - INFO - [Valid] [13/90] | Loss: 0.6188 | Val Acc: 74.34%
2026-01-14 12:20:52,858 - INFO - [Metrics for 'abnormal'] | Precision: 0.8070 | Recall: 0.5860 | F1: 0.6790
2026-01-14 12:20:52,858 - INFO - [Metrics for 'normal'] | Precision: 0.7111 | Recall: 0.8791 | F1: 0.7862
2026-01-14 12:20:52,862 - INFO - --------------------------------------------------
2026-01-14 12:20:52,865 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 12:20:57,941 - INFO - [Train] [14/90] | Loss: 0.5671 | Train Acc: 77.60%
2026-01-14 12:20:59,388 - INFO - [Valid] [14/90] | Loss: 0.7333 | Val Acc: 74.93%
2026-01-14 12:20:59,396 - INFO - [Metrics for 'abnormal'] | Precision: 0.6698 | Recall: 0.9045 | F1: 0.7696
2026-01-14 12:20:59,396 - INFO - [Metrics for 'normal'] | Precision: 0.8819 | Recall: 0.6154 | F1: 0.7249
2026-01-14 12:20:59,399 - INFO - --------------------------------------------------
2026-01-14 12:20:59,400 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 12:21:04,751 - INFO - [Train] [15/90] | Loss: 0.5238 | Train Acc: 80.06%
2026-01-14 12:21:06,232 - INFO - [Valid] [15/90] | Loss: 0.8372 | Val Acc: 76.99%
2026-01-14 12:21:06,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.7365 | Recall: 0.7834 | F1: 0.7593
2026-01-14 12:21:06,243 - INFO - [Metrics for 'normal'] | Precision: 0.8023 | Recall: 0.7582 | F1: 0.7797
2026-01-14 12:21:06,247 - INFO - --------------------------------------------------
2026-01-14 12:21:06,249 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 12:21:11,681 - INFO - [Train] [16/90] | Loss: 0.5201 | Train Acc: 79.61%
2026-01-14 12:21:13,116 - INFO - [Valid] [16/90] | Loss: 0.6983 | Val Acc: 65.19%
2026-01-14 12:21:13,126 - INFO - [Metrics for 'abnormal'] | Precision: 0.8679 | Recall: 0.2930 | F1: 0.4381
2026-01-14 12:21:13,127 - INFO - [Metrics for 'normal'] | Precision: 0.6119 | Recall: 0.9615 | F1: 0.7479
2026-01-14 12:21:13,130 - INFO - --------------------------------------------------
2026-01-14 12:21:13,132 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 12:21:18,587 - INFO - [Train] [17/90] | Loss: 0.4782 | Train Acc: 82.74%
2026-01-14 12:21:20,423 - INFO - [Valid] [17/90] | Loss: 0.5871 | Val Acc: 79.65%
2026-01-14 12:21:20,436 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-01-14 12:21:20,436 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-01-14 12:21:20,441 - INFO - --------------------------------------------------
2026-01-14 12:21:20,444 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 12:21:26,708 - INFO - [Train] [18/90] | Loss: 0.4884 | Train Acc: 83.63%
2026-01-14 12:21:28,424 - INFO - [Valid] [18/90] | Loss: 0.7581 | Val Acc: 76.11%
2026-01-14 12:21:28,437 - INFO - [Metrics for 'abnormal'] | Precision: 0.7289 | Recall: 0.7707 | F1: 0.7492
2026-01-14 12:21:28,437 - INFO - [Metrics for 'normal'] | Precision: 0.7919 | Recall: 0.7527 | F1: 0.7718
2026-01-14 12:21:28,442 - INFO - --------------------------------------------------
2026-01-14 12:21:28,445 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 12:21:34,598 - INFO - [Train] [19/90] | Loss: 0.4899 | Train Acc: 84.15%
2026-01-14 12:21:36,332 - INFO - [Valid] [19/90] | Loss: 0.5975 | Val Acc: 79.35%
2026-01-14 12:21:36,344 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 12:21:36,345 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 12:21:36,348 - INFO - --------------------------------------------------
2026-01-14 12:21:36,351 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 12:21:42,534 - INFO - [Train] [20/90] | Loss: 0.4621 | Train Acc: 82.59%
2026-01-14 12:21:44,300 - INFO - [Valid] [20/90] | Loss: 0.6766 | Val Acc: 78.47%
2026-01-14 12:21:44,312 - INFO - [Metrics for 'abnormal'] | Precision: 0.8333 | Recall: 0.6688 | F1: 0.7420
2026-01-14 12:21:44,313 - INFO - [Metrics for 'normal'] | Precision: 0.7559 | Recall: 0.8846 | F1: 0.8152
2026-01-14 12:21:44,318 - INFO - --------------------------------------------------
2026-01-14 12:21:44,321 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 12:21:53,062 - INFO - [Train] [21/90] | Loss: 0.5105 | Train Acc: 81.40%
2026-01-14 12:21:55,200 - INFO - [Valid] [21/90] | Loss: 0.9882 | Val Acc: 73.16%
2026-01-14 12:21:55,222 - INFO - [Metrics for 'abnormal'] | Precision: 0.7797 | Recall: 0.5860 | F1: 0.6691
2026-01-14 12:21:55,223 - INFO - [Metrics for 'normal'] | Precision: 0.7059 | Recall: 0.8571 | F1: 0.7742
2026-01-14 12:21:55,227 - INFO - --------------------------------------------------
2026-01-14 12:21:55,230 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 12:22:03,435 - INFO - [Train] [22/90] | Loss: 0.4711 | Train Acc: 83.78%
2026-01-14 12:22:05,130 - INFO - [Valid] [22/90] | Loss: 0.6018 | Val Acc: 76.40%
2026-01-14 12:22:05,144 - INFO - [Metrics for 'abnormal'] | Precision: 0.7305 | Recall: 0.7771 | F1: 0.7531
2026-01-14 12:22:05,145 - INFO - [Metrics for 'normal'] | Precision: 0.7965 | Recall: 0.7527 | F1: 0.7740
2026-01-14 12:22:05,149 - INFO - --------------------------------------------------
2026-01-14 12:22:05,153 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 12:22:13,250 - INFO - [Train] [23/90] | Loss: 0.4442 | Train Acc: 86.09%
2026-01-14 12:22:15,153 - INFO - [Valid] [23/90] | Loss: 0.4943 | Val Acc: 81.12%
2026-01-14 12:22:15,165 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8854 | F1: 0.8129
2026-01-14 12:22:15,166 - INFO - [Metrics for 'normal'] | Precision: 0.8831 | Recall: 0.7473 | F1: 0.8095
2026-01-14 12:22:15,223 - INFO - [Best Model Saved] (val loss: 0.4943) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:22:15,223 - INFO - --------------------------------------------------
2026-01-14 12:22:15,226 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 12:22:23,027 - INFO - [Train] [24/90] | Loss: 0.4602 | Train Acc: 84.00%
2026-01-14 12:22:25,201 - INFO - [Valid] [24/90] | Loss: 0.5773 | Val Acc: 83.48%
2026-01-14 12:22:25,215 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.8280 | F1: 0.8228
2026-01-14 12:22:25,216 - INFO - [Metrics for 'normal'] | Precision: 0.8500 | Recall: 0.8407 | F1: 0.8453
2026-01-14 12:22:25,220 - INFO - --------------------------------------------------
2026-01-14 12:22:25,223 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 12:22:32,581 - INFO - [Train] [25/90] | Loss: 0.4330 | Train Acc: 86.68%
2026-01-14 12:22:34,780 - INFO - [Valid] [25/90] | Loss: 0.4933 | Val Acc: 83.48%
2026-01-14 12:22:34,792 - INFO - [Metrics for 'abnormal'] | Precision: 0.8741 | Recall: 0.7516 | F1: 0.8082
2026-01-14 12:22:34,792 - INFO - [Metrics for 'normal'] | Precision: 0.8088 | Recall: 0.9066 | F1: 0.8549
2026-01-14 12:22:34,852 - INFO - [Best Model Saved] (val loss: 0.4933) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:22:34,852 - INFO - --------------------------------------------------
2026-01-14 12:22:34,855 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 12:22:42,451 - INFO - [Train] [26/90] | Loss: 0.4060 | Train Acc: 88.39%
2026-01-14 12:22:44,582 - INFO - [Valid] [26/90] | Loss: 0.5885 | Val Acc: 79.06%
2026-01-14 12:22:44,595 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 12:22:44,596 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 12:22:44,600 - INFO - --------------------------------------------------
2026-01-14 12:22:44,603 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 12:22:52,702 - INFO - [Train] [27/90] | Loss: 0.4022 | Train Acc: 89.73%
2026-01-14 12:22:54,759 - INFO - [Valid] [27/90] | Loss: 0.6511 | Val Acc: 74.04%
2026-01-14 12:22:54,772 - INFO - [Metrics for 'abnormal'] | Precision: 0.7018 | Recall: 0.7643 | F1: 0.7317
2026-01-14 12:22:54,772 - INFO - [Metrics for 'normal'] | Precision: 0.7798 | Recall: 0.7198 | F1: 0.7486
2026-01-14 12:22:54,776 - INFO - --------------------------------------------------
2026-01-14 12:22:54,779 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 12:23:03,030 - INFO - [Train] [28/90] | Loss: 0.4141 | Train Acc: 87.87%
2026-01-14 12:23:06,388 - INFO - [Valid] [28/90] | Loss: 0.5692 | Val Acc: 74.93%
2026-01-14 12:23:06,421 - INFO - [Metrics for 'abnormal'] | Precision: 0.7143 | Recall: 0.7643 | F1: 0.7385
2026-01-14 12:23:06,421 - INFO - [Metrics for 'normal'] | Precision: 0.7836 | Recall: 0.7363 | F1: 0.7592
2026-01-14 12:23:06,425 - INFO - --------------------------------------------------
2026-01-14 12:23:06,437 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 12:23:14,592 - INFO - [Train] [29/90] | Loss: 0.3738 | Train Acc: 90.10%
2026-01-14 12:23:17,616 - INFO - [Valid] [29/90] | Loss: 0.5383 | Val Acc: 81.71%
2026-01-14 12:23:17,627 - INFO - [Metrics for 'abnormal'] | Precision: 0.8146 | Recall: 0.7834 | F1: 0.7987
2026-01-14 12:23:17,628 - INFO - [Metrics for 'normal'] | Precision: 0.8191 | Recall: 0.8462 | F1: 0.8324
2026-01-14 12:23:17,632 - INFO - --------------------------------------------------
2026-01-14 12:23:17,636 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 12:23:25,882 - INFO - [Train] [30/90] | Loss: 0.3690 | Train Acc: 89.96%
2026-01-14 12:23:29,361 - INFO - [Valid] [30/90] | Loss: 0.5024 | Val Acc: 80.53%
2026-01-14 12:23:29,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.8280 | F1: 0.7975
2026-01-14 12:23:29,372 - INFO - [Metrics for 'normal'] | Precision: 0.8412 | Recall: 0.7857 | F1: 0.8125
2026-01-14 12:23:29,376 - INFO - --------------------------------------------------
2026-01-14 12:23:29,378 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 12:23:38,098 - INFO - [Train] [31/90] | Loss: 0.3665 | Train Acc: 91.22%
2026-01-14 12:23:41,565 - INFO - [Valid] [31/90] | Loss: 0.5721 | Val Acc: 77.88%
2026-01-14 12:23:41,577 - INFO - [Metrics for 'abnormal'] | Precision: 0.7628 | Recall: 0.7580 | F1: 0.7604
2026-01-14 12:23:41,578 - INFO - [Metrics for 'normal'] | Precision: 0.7923 | Recall: 0.7967 | F1: 0.7945
2026-01-14 12:23:41,582 - INFO - --------------------------------------------------
2026-01-14 12:23:41,585 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 12:23:49,439 - INFO - [Train] [32/90] | Loss: 0.3673 | Train Acc: 91.67%
2026-01-14 12:23:52,102 - INFO - [Valid] [32/90] | Loss: 0.5550 | Val Acc: 78.17%
2026-01-14 12:23:52,126 - INFO - [Metrics for 'abnormal'] | Precision: 0.7173 | Recall: 0.8726 | F1: 0.7874
2026-01-14 12:23:52,128 - INFO - [Metrics for 'normal'] | Precision: 0.8649 | Recall: 0.7033 | F1: 0.7758
2026-01-14 12:23:52,141 - INFO - --------------------------------------------------
2026-01-14 12:23:52,148 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 12:24:01,946 - INFO - [Train] [33/90] | Loss: 0.3536 | Train Acc: 92.19%
2026-01-14 12:24:04,161 - INFO - [Valid] [33/90] | Loss: 0.5531 | Val Acc: 82.01%
2026-01-14 12:24:04,188 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.7898 | F1: 0.8026
2026-01-14 12:24:04,192 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.8462 | F1: 0.8347
2026-01-14 12:24:04,200 - INFO - --------------------------------------------------
2026-01-14 12:24:04,206 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 12:24:14,427 - INFO - [Train] [34/90] | Loss: 0.3156 | Train Acc: 94.20%
2026-01-14 12:24:16,842 - INFO - [Valid] [34/90] | Loss: 0.5285 | Val Acc: 79.94%
2026-01-14 12:24:16,854 - INFO - [Metrics for 'abnormal'] | Precision: 0.8201 | Recall: 0.7261 | F1: 0.7703
2026-01-14 12:24:16,855 - INFO - [Metrics for 'normal'] | Precision: 0.7850 | Recall: 0.8626 | F1: 0.8220
2026-01-14 12:24:16,859 - INFO - --------------------------------------------------
2026-01-14 12:24:16,862 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 12:24:26,487 - INFO - [Train] [35/90] | Loss: 0.3355 | Train Acc: 93.82%
2026-01-14 12:24:28,503 - INFO - [Valid] [35/90] | Loss: 0.5379 | Val Acc: 79.06%
2026-01-14 12:24:28,517 - INFO - [Metrics for 'abnormal'] | Precision: 0.8162 | Recall: 0.7070 | F1: 0.7577
2026-01-14 12:24:28,518 - INFO - [Metrics for 'normal'] | Precision: 0.7734 | Recall: 0.8626 | F1: 0.8156
2026-01-14 12:24:28,522 - INFO - --------------------------------------------------
2026-01-14 12:24:28,525 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 12:24:38,572 - INFO - [Train] [36/90] | Loss: 0.3445 | Train Acc: 92.56%
2026-01-14 12:24:40,586 - INFO - [Valid] [36/90] | Loss: 0.5760 | Val Acc: 81.12%
2026-01-14 12:24:40,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-01-14 12:24:40,600 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-01-14 12:24:40,606 - INFO - --------------------------------------------------
2026-01-14 12:24:40,611 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 12:24:50,455 - INFO - [Train] [37/90] | Loss: 0.3324 | Train Acc: 93.08%
2026-01-14 12:24:52,622 - INFO - [Valid] [37/90] | Loss: 0.6142 | Val Acc: 80.83%
2026-01-14 12:24:52,636 - INFO - [Metrics for 'abnormal'] | Precision: 0.8538 | Recall: 0.7070 | F1: 0.7735
2026-01-14 12:24:52,637 - INFO - [Metrics for 'normal'] | Precision: 0.7799 | Recall: 0.8956 | F1: 0.8338
2026-01-14 12:24:52,643 - INFO - --------------------------------------------------
2026-01-14 12:24:52,646 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 12:25:03,006 - INFO - [Train] [38/90] | Loss: 0.3381 | Train Acc: 93.08%
2026-01-14 12:25:05,331 - INFO - [Valid] [38/90] | Loss: 0.5485 | Val Acc: 78.47%
2026-01-14 12:25:05,343 - INFO - [Metrics for 'abnormal'] | Precision: 0.7958 | Recall: 0.7197 | F1: 0.7559
2026-01-14 12:25:05,343 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8407 | F1: 0.8074
2026-01-14 12:25:05,347 - INFO - --------------------------------------------------
2026-01-14 12:25:05,350 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 12:25:14,416 - INFO - [Train] [39/90] | Loss: 0.3335 | Train Acc: 93.15%
2026-01-14 12:25:17,214 - INFO - [Valid] [39/90] | Loss: 0.7591 | Val Acc: 79.94%
2026-01-14 12:25:17,241 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8471 | F1: 0.7964
2026-01-14 12:25:17,241 - INFO - [Metrics for 'normal'] | Precision: 0.8519 | Recall: 0.7582 | F1: 0.8023
2026-01-14 12:25:17,252 - INFO - --------------------------------------------------
2026-01-14 12:25:17,261 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 12:25:26,844 - INFO - [Train] [40/90] | Loss: 0.3334 | Train Acc: 93.23%
2026-01-14 12:25:29,223 - INFO - [Valid] [40/90] | Loss: 0.5732 | Val Acc: 79.94%
2026-01-14 12:25:29,236 - INFO - [Metrics for 'abnormal'] | Precision: 0.8346 | Recall: 0.7070 | F1: 0.7655
2026-01-14 12:25:29,237 - INFO - [Metrics for 'normal'] | Precision: 0.7767 | Recall: 0.8791 | F1: 0.8247
2026-01-14 12:25:29,242 - INFO - --------------------------------------------------
2026-01-14 12:25:29,244 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 12:25:38,147 - INFO - [Train] [41/90] | Loss: 0.2913 | Train Acc: 95.61%
2026-01-14 12:25:40,318 - INFO - [Valid] [41/90] | Loss: 0.5266 | Val Acc: 81.71%
2026-01-14 12:25:40,333 - INFO - [Metrics for 'abnormal'] | Precision: 0.8571 | Recall: 0.7261 | F1: 0.7862
2026-01-14 12:25:40,334 - INFO - [Metrics for 'normal'] | Precision: 0.7913 | Recall: 0.8956 | F1: 0.8402
2026-01-14 12:25:40,341 - INFO - --------------------------------------------------
2026-01-14 12:25:40,347 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 12:25:49,272 - INFO - [Train] [42/90] | Loss: 0.3065 | Train Acc: 94.64%
2026-01-14 12:25:52,384 - INFO - [Valid] [42/90] | Loss: 0.5325 | Val Acc: 79.35%
2026-01-14 12:25:52,395 - INFO - [Metrics for 'abnormal'] | Precision: 0.7959 | Recall: 0.7452 | F1: 0.7697
2026-01-14 12:25:52,396 - INFO - [Metrics for 'normal'] | Precision: 0.7917 | Recall: 0.8352 | F1: 0.8128
2026-01-14 12:25:52,401 - INFO - --------------------------------------------------
2026-01-14 12:25:52,404 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 12:26:02,318 - INFO - [Train] [43/90] | Loss: 0.2786 | Train Acc: 96.88%
2026-01-14 12:26:04,593 - INFO - [Valid] [43/90] | Loss: 0.5436 | Val Acc: 80.53%
2026-01-14 12:26:04,608 - INFO - [Metrics for 'abnormal'] | Precision: 0.7542 | Recall: 0.8599 | F1: 0.8036
2026-01-14 12:26:04,608 - INFO - [Metrics for 'normal'] | Precision: 0.8625 | Recall: 0.7582 | F1: 0.8070
2026-01-14 12:26:04,613 - INFO - --------------------------------------------------
2026-01-14 12:26:04,616 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 12:26:14,716 - INFO - [Train] [44/90] | Loss: 0.2883 | Train Acc: 96.13%
2026-01-14 12:26:17,241 - INFO - [Valid] [44/90] | Loss: 0.5527 | Val Acc: 82.89%
2026-01-14 12:26:17,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.8561 | Recall: 0.7580 | F1: 0.8041
2026-01-14 12:26:17,252 - INFO - [Metrics for 'normal'] | Precision: 0.8100 | Recall: 0.8901 | F1: 0.8482
2026-01-14 12:26:17,259 - INFO - --------------------------------------------------
2026-01-14 12:26:17,261 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 12:26:27,092 - INFO - [Train] [45/90] | Loss: 0.2665 | Train Acc: 96.80%
2026-01-14 12:26:29,104 - INFO - [Valid] [45/90] | Loss: 0.5135 | Val Acc: 79.94%
2026-01-14 12:26:29,116 - INFO - [Metrics for 'abnormal'] | Precision: 0.8156 | Recall: 0.7325 | F1: 0.7718
2026-01-14 12:26:29,117 - INFO - [Metrics for 'normal'] | Precision: 0.7879 | Recall: 0.8571 | F1: 0.8211
2026-01-14 12:26:29,132 - INFO - --------------------------------------------------
2026-01-14 12:26:29,135 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 12:26:39,499 - INFO - [Train] [46/90] | Loss: 0.2808 | Train Acc: 95.31%
2026-01-14 12:26:41,395 - INFO - [Valid] [46/90] | Loss: 0.5617 | Val Acc: 79.94%
2026-01-14 12:26:41,408 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 12:26:41,408 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 12:26:41,412 - INFO - --------------------------------------------------
2026-01-14 12:26:41,416 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 12:26:51,035 - INFO - [Train] [47/90] | Loss: 0.2723 | Train Acc: 96.43%
2026-01-14 12:26:53,057 - INFO - [Valid] [47/90] | Loss: 0.5640 | Val Acc: 80.53%
2026-01-14 12:26:53,075 - INFO - [Metrics for 'abnormal'] | Precision: 0.8421 | Recall: 0.7134 | F1: 0.7724
2026-01-14 12:26:53,076 - INFO - [Metrics for 'normal'] | Precision: 0.7816 | Recall: 0.8846 | F1: 0.8299
2026-01-14 12:26:53,084 - INFO - --------------------------------------------------
2026-01-14 12:26:53,087 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 12:27:02,555 - INFO - [Train] [48/90] | Loss: 0.3020 | Train Acc: 94.05%
2026-01-14 12:27:04,918 - INFO - [Valid] [48/90] | Loss: 0.5483 | Val Acc: 79.65%
2026-01-14 12:27:04,927 - INFO - [Metrics for 'abnormal'] | Precision: 0.7716 | Recall: 0.7962 | F1: 0.7837
2026-01-14 12:27:04,927 - INFO - [Metrics for 'normal'] | Precision: 0.8192 | Recall: 0.7967 | F1: 0.8078
2026-01-14 12:27:04,931 - INFO - --------------------------------------------------
2026-01-14 12:27:04,933 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 12:27:16,251 - INFO - [Train] [49/90] | Loss: 0.2653 | Train Acc: 97.77%
2026-01-14 12:27:18,776 - INFO - [Valid] [49/90] | Loss: 0.5695 | Val Acc: 79.94%
2026-01-14 12:27:18,788 - INFO - [Metrics for 'abnormal'] | Precision: 0.7730 | Recall: 0.8025 | F1: 0.7875
2026-01-14 12:27:18,789 - INFO - [Metrics for 'normal'] | Precision: 0.8239 | Recall: 0.7967 | F1: 0.8101
2026-01-14 12:27:18,793 - INFO - --------------------------------------------------
2026-01-14 12:27:18,796 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 12:27:28,583 - INFO - [Train] [50/90] | Loss: 0.2606 | Train Acc: 97.25%
2026-01-14 12:27:30,909 - INFO - [Valid] [50/90] | Loss: 0.5916 | Val Acc: 80.83%
2026-01-14 12:27:30,921 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 12:27:30,921 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 12:27:30,926 - INFO - --------------------------------------------------
2026-01-14 12:27:30,929 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 12:27:40,739 - INFO - [Train] [51/90] | Loss: 0.2837 | Train Acc: 95.46%
2026-01-14 12:27:43,378 - INFO - [Valid] [51/90] | Loss: 0.5309 | Val Acc: 80.53%
2026-01-14 12:27:43,390 - INFO - [Metrics for 'abnormal'] | Precision: 0.8054 | Recall: 0.7643 | F1: 0.7843
2026-01-14 12:27:43,390 - INFO - [Metrics for 'normal'] | Precision: 0.8053 | Recall: 0.8407 | F1: 0.8226
2026-01-14 12:27:43,394 - INFO - --------------------------------------------------
2026-01-14 12:27:43,397 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 12:27:52,336 - INFO - [Train] [52/90] | Loss: 0.2691 | Train Acc: 96.73%
2026-01-14 12:27:54,961 - INFO - [Valid] [52/90] | Loss: 0.6338 | Val Acc: 79.94%
2026-01-14 12:27:54,976 - INFO - [Metrics for 'abnormal'] | Precision: 0.8027 | Recall: 0.7516 | F1: 0.7763
2026-01-14 12:27:54,977 - INFO - [Metrics for 'normal'] | Precision: 0.7969 | Recall: 0.8407 | F1: 0.8182
2026-01-14 12:27:54,981 - INFO - --------------------------------------------------
2026-01-14 12:27:54,984 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 12:28:04,948 - INFO - [Train] [53/90] | Loss: 0.2846 | Train Acc: 95.83%
2026-01-14 12:28:07,857 - INFO - [Valid] [53/90] | Loss: 0.5593 | Val Acc: 78.47%
2026-01-14 12:28:07,869 - INFO - [Metrics for 'abnormal'] | Precision: 0.7561 | Recall: 0.7898 | F1: 0.7726
2026-01-14 12:28:07,869 - INFO - [Metrics for 'normal'] | Precision: 0.8114 | Recall: 0.7802 | F1: 0.7955
2026-01-14 12:28:07,873 - INFO - --------------------------------------------------
2026-01-14 12:28:07,876 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 12:28:17,291 - INFO - [Train] [54/90] | Loss: 0.2628 | Train Acc: 97.40%
2026-01-14 12:28:20,164 - INFO - [Valid] [54/90] | Loss: 0.6086 | Val Acc: 79.65%
2026-01-14 12:28:20,175 - INFO - [Metrics for 'abnormal'] | Precision: 0.7558 | Recall: 0.8280 | F1: 0.7903
2026-01-14 12:28:20,176 - INFO - [Metrics for 'normal'] | Precision: 0.8383 | Recall: 0.7692 | F1: 0.8023
2026-01-14 12:28:20,180 - INFO - --------------------------------------------------
2026-01-14 12:28:20,183 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 12:28:30,300 - INFO - [Train] [55/90] | Loss: 0.2717 | Train Acc: 96.58%
2026-01-14 12:28:33,101 - INFO - [Valid] [55/90] | Loss: 0.5930 | Val Acc: 78.47%
2026-01-14 12:28:33,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.7593 | Recall: 0.7834 | F1: 0.7712
2026-01-14 12:28:33,115 - INFO - [Metrics for 'normal'] | Precision: 0.8079 | Recall: 0.7857 | F1: 0.7967
2026-01-14 12:28:33,120 - INFO - --------------------------------------------------
2026-01-14 12:28:33,123 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 12:28:41,211 - INFO - [Train] [56/90] | Loss: 0.2551 | Train Acc: 97.99%
2026-01-14 12:28:44,434 - INFO - [Valid] [56/90] | Loss: 0.5648 | Val Acc: 80.24%
2026-01-14 12:28:44,444 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 12:28:44,445 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 12:28:44,449 - INFO - --------------------------------------------------
2026-01-14 12:28:44,451 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 12:28:52,534 - INFO - [Train] [57/90] | Loss: 0.2562 | Train Acc: 98.07%
2026-01-14 12:28:55,551 - INFO - [Valid] [57/90] | Loss: 0.6649 | Val Acc: 74.04%
2026-01-14 12:28:55,565 - INFO - [Metrics for 'abnormal'] | Precision: 0.6949 | Recall: 0.7834 | F1: 0.7365
2026-01-14 12:28:55,567 - INFO - [Metrics for 'normal'] | Precision: 0.7901 | Recall: 0.7033 | F1: 0.7442
2026-01-14 12:28:55,572 - INFO - --------------------------------------------------
2026-01-14 12:28:55,575 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 12:29:04,570 - INFO - [Train] [58/90] | Loss: 0.2429 | Train Acc: 98.81%
2026-01-14 12:29:07,491 - INFO - [Valid] [58/90] | Loss: 0.5824 | Val Acc: 80.53%
2026-01-14 12:29:07,514 - INFO - [Metrics for 'abnormal'] | Precision: 0.8273 | Recall: 0.7325 | F1: 0.7770
2026-01-14 12:29:07,515 - INFO - [Metrics for 'normal'] | Precision: 0.7900 | Recall: 0.8681 | F1: 0.8272
2026-01-14 12:29:07,519 - INFO - --------------------------------------------------
2026-01-14 12:29:07,522 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 12:29:15,995 - INFO - [Train] [59/90] | Loss: 0.2462 | Train Acc: 98.44%
2026-01-14 12:29:19,137 - INFO - [Valid] [59/90] | Loss: 0.5826 | Val Acc: 78.17%
2026-01-14 12:29:19,168 - INFO - [Metrics for 'abnormal'] | Precision: 0.7748 | Recall: 0.7452 | F1: 0.7597
2026-01-14 12:29:19,168 - INFO - [Metrics for 'normal'] | Precision: 0.7872 | Recall: 0.8132 | F1: 0.8000
2026-01-14 12:29:19,177 - INFO - --------------------------------------------------
2026-01-14 12:29:19,183 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 12:29:27,376 - INFO - [Train] [60/90] | Loss: 0.2457 | Train Acc: 98.14%
2026-01-14 12:29:30,901 - INFO - [Valid] [60/90] | Loss: 0.5835 | Val Acc: 79.65%
2026-01-14 12:29:30,920 - INFO - [Metrics for 'abnormal'] | Precision: 0.8056 | Recall: 0.7389 | F1: 0.7708
2026-01-14 12:29:30,921 - INFO - [Metrics for 'normal'] | Precision: 0.7897 | Recall: 0.8462 | F1: 0.8170
2026-01-14 12:29:30,931 - INFO - --------------------------------------------------
2026-01-14 12:29:30,938 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 12:29:38,240 - INFO - [Train] [61/90] | Loss: 0.2504 | Train Acc: 98.29%
2026-01-14 12:29:42,576 - INFO - [Valid] [61/90] | Loss: 0.5992 | Val Acc: 79.35%
2026-01-14 12:29:42,622 - INFO - [Metrics for 'abnormal'] | Precision: 0.7702 | Recall: 0.7898 | F1: 0.7799
2026-01-14 12:29:42,622 - INFO - [Metrics for 'normal'] | Precision: 0.8146 | Recall: 0.7967 | F1: 0.8056
2026-01-14 12:29:42,630 - INFO - --------------------------------------------------
2026-01-14 12:29:42,639 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 12:29:52,879 - INFO - [Train] [62/90] | Loss: 0.2333 | Train Acc: 99.11%
2026-01-14 12:29:56,344 - INFO - [Valid] [62/90] | Loss: 0.6285 | Val Acc: 79.35%
2026-01-14 12:29:56,356 - INFO - [Metrics for 'abnormal'] | Precision: 0.7605 | Recall: 0.8089 | F1: 0.7840
2026-01-14 12:29:56,357 - INFO - [Metrics for 'normal'] | Precision: 0.8256 | Recall: 0.7802 | F1: 0.8023
2026-01-14 12:29:56,361 - INFO - --------------------------------------------------
2026-01-14 12:29:56,364 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 12:30:04,609 - INFO - [Train] [63/90] | Loss: 0.2342 | Train Acc: 98.88%
2026-01-14 12:30:07,856 - INFO - [Valid] [63/90] | Loss: 0.5888 | Val Acc: 79.94%
2026-01-14 12:30:07,868 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-01-14 12:30:07,868 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-01-14 12:30:07,873 - INFO - --------------------------------------------------
2026-01-14 12:30:07,876 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 12:30:16,996 - INFO - [Train] [64/90] | Loss: 0.2290 | Train Acc: 99.11%
2026-01-14 12:30:20,177 - INFO - [Valid] [64/90] | Loss: 0.5875 | Val Acc: 80.24%
2026-01-14 12:30:20,189 - INFO - [Metrics for 'abnormal'] | Precision: 0.8041 | Recall: 0.7580 | F1: 0.7803
2026-01-14 12:30:20,190 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8407 | F1: 0.8204
2026-01-14 12:30:20,195 - INFO - --------------------------------------------------
2026-01-14 12:30:20,198 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 12:30:29,529 - INFO - [Train] [65/90] | Loss: 0.2358 | Train Acc: 98.88%
2026-01-14 12:30:32,131 - INFO - [Valid] [65/90] | Loss: 0.5828 | Val Acc: 80.53%
2026-01-14 12:30:32,156 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7707 | F1: 0.7857
2026-01-14 12:30:32,156 - INFO - [Metrics for 'normal'] | Precision: 0.8085 | Recall: 0.8352 | F1: 0.8216
2026-01-14 12:30:32,163 - INFO - --------------------------------------------------
2026-01-14 12:30:32,167 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 12:30:40,591 - INFO - [Train] [66/90] | Loss: 0.2596 | Train Acc: 97.10%
2026-01-14 12:30:43,676 - INFO - [Valid] [66/90] | Loss: 0.5634 | Val Acc: 80.53%
2026-01-14 12:30:43,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.7862 | Recall: 0.7962 | F1: 0.7911
2026-01-14 12:30:43,686 - INFO - [Metrics for 'normal'] | Precision: 0.8222 | Recall: 0.8132 | F1: 0.8177
2026-01-14 12:30:43,691 - INFO - --------------------------------------------------
2026-01-14 12:30:43,693 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 12:30:52,067 - INFO - [Train] [67/90] | Loss: 0.2675 | Train Acc: 96.80%
2026-01-14 12:30:55,929 - INFO - [Valid] [67/90] | Loss: 0.5912 | Val Acc: 78.76%
2026-01-14 12:30:55,939 - INFO - [Metrics for 'abnormal'] | Precision: 0.7640 | Recall: 0.7834 | F1: 0.7736
2026-01-14 12:30:55,939 - INFO - [Metrics for 'normal'] | Precision: 0.8090 | Recall: 0.7912 | F1: 0.8000
2026-01-14 12:30:55,943 - INFO - --------------------------------------------------
2026-01-14 12:30:55,945 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 12:31:04,778 - INFO - [Train] [68/90] | Loss: 0.2487 | Train Acc: 98.07%
2026-01-14 12:31:07,753 - INFO - [Valid] [68/90] | Loss: 0.5753 | Val Acc: 81.12%
2026-01-14 12:31:07,779 - INFO - [Metrics for 'abnormal'] | Precision: 0.8121 | Recall: 0.7707 | F1: 0.7908
2026-01-14 12:31:07,779 - INFO - [Metrics for 'normal'] | Precision: 0.8105 | Recall: 0.8462 | F1: 0.8280
2026-01-14 12:31:07,788 - INFO - --------------------------------------------------
2026-01-14 12:31:07,791 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 12:31:16,653 - INFO - [Train] [69/90] | Loss: 0.2463 | Train Acc: 98.14%
2026-01-14 12:31:20,044 - INFO - [Valid] [69/90] | Loss: 0.5871 | Val Acc: 80.53%
2026-01-14 12:31:20,067 - INFO - [Metrics for 'abnormal'] | Precision: 0.8227 | Recall: 0.7389 | F1: 0.7785
2026-01-14 12:31:20,072 - INFO - [Metrics for 'normal'] | Precision: 0.7929 | Recall: 0.8626 | F1: 0.8263
2026-01-14 12:31:20,080 - INFO - --------------------------------------------------
2026-01-14 12:31:20,087 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 12:31:28,654 - INFO - [Train] [70/90] | Loss: 0.2424 | Train Acc: 98.21%
2026-01-14 12:31:32,120 - INFO - [Valid] [70/90] | Loss: 0.5260 | Val Acc: 82.01%
2026-01-14 12:31:32,144 - INFO - [Metrics for 'abnormal'] | Precision: 0.8243 | Recall: 0.7771 | F1: 0.8000
2026-01-14 12:31:32,144 - INFO - [Metrics for 'normal'] | Precision: 0.8168 | Recall: 0.8571 | F1: 0.8365
2026-01-14 12:31:32,162 - INFO - --------------------------------------------------
2026-01-14 12:31:32,167 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 12:31:41,410 - INFO - [Train] [71/90] | Loss: 0.2404 | Train Acc: 98.88%
2026-01-14 12:31:44,908 - INFO - [Valid] [71/90] | Loss: 0.5285 | Val Acc: 80.83%
2026-01-14 12:31:44,919 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 12:31:44,919 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 12:31:44,923 - INFO - --------------------------------------------------
2026-01-14 12:31:44,926 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 12:31:53,293 - INFO - [Train] [72/90] | Loss: 0.2321 | Train Acc: 99.18%
2026-01-14 12:31:56,635 - INFO - [Valid] [72/90] | Loss: 0.5829 | Val Acc: 81.12%
2026-01-14 12:31:56,648 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 12:31:56,648 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 12:31:56,653 - INFO - --------------------------------------------------
2026-01-14 12:31:56,656 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 12:32:06,018 - INFO - [Train] [73/90] | Loss: 0.2254 | Train Acc: 99.40%
2026-01-14 12:32:09,056 - INFO - [Valid] [73/90] | Loss: 0.5432 | Val Acc: 82.01%
2026-01-14 12:32:09,078 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 12:32:09,078 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 12:32:09,082 - INFO - --------------------------------------------------
2026-01-14 12:32:09,085 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 12:32:18,113 - INFO - [Train] [74/90] | Loss: 0.2280 | Train Acc: 99.33%
2026-01-14 12:32:20,948 - INFO - [Valid] [74/90] | Loss: 0.5923 | Val Acc: 80.83%
2026-01-14 12:32:20,982 - INFO - [Metrics for 'abnormal'] | Precision: 0.7674 | Recall: 0.8408 | F1: 0.8024
2026-01-14 12:32:20,986 - INFO - [Metrics for 'normal'] | Precision: 0.8503 | Recall: 0.7802 | F1: 0.8138
2026-01-14 12:32:20,994 - INFO - --------------------------------------------------
2026-01-14 12:32:21,000 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 12:32:29,541 - INFO - [Train] [75/90] | Loss: 0.2261 | Train Acc: 99.33%
2026-01-14 12:32:32,375 - INFO - [Valid] [75/90] | Loss: 0.5706 | Val Acc: 81.71%
2026-01-14 12:32:32,389 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-01-14 12:32:32,390 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-01-14 12:32:32,396 - INFO - --------------------------------------------------
2026-01-14 12:32:32,400 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 12:32:41,236 - INFO - [Train] [76/90] | Loss: 0.2238 | Train Acc: 99.63%
2026-01-14 12:32:43,794 - INFO - [Valid] [76/90] | Loss: 0.5574 | Val Acc: 82.30%
2026-01-14 12:32:43,808 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 12:32:43,809 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 12:32:43,815 - INFO - --------------------------------------------------
2026-01-14 12:32:43,819 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 12:32:53,058 - INFO - [Train] [77/90] | Loss: 0.2239 | Train Acc: 99.70%
2026-01-14 12:32:55,074 - INFO - [Valid] [77/90] | Loss: 0.5990 | Val Acc: 81.12%
2026-01-14 12:32:55,089 - INFO - [Metrics for 'abnormal'] | Precision: 0.8252 | Recall: 0.7516 | F1: 0.7867
2026-01-14 12:32:55,090 - INFO - [Metrics for 'normal'] | Precision: 0.8010 | Recall: 0.8626 | F1: 0.8307
2026-01-14 12:32:55,095 - INFO - --------------------------------------------------
2026-01-14 12:32:55,098 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 12:33:03,934 - INFO - [Train] [78/90] | Loss: 0.2287 | Train Acc: 99.11%
2026-01-14 12:33:06,487 - INFO - [Valid] [78/90] | Loss: 0.5944 | Val Acc: 80.24%
2026-01-14 12:33:06,512 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-01-14 12:33:06,512 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-01-14 12:33:06,516 - INFO - --------------------------------------------------
2026-01-14 12:33:06,518 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 12:33:15,821 - INFO - [Train] [79/90] | Loss: 0.2237 | Train Acc: 99.55%
2026-01-14 12:33:18,371 - INFO - [Valid] [79/90] | Loss: 0.5880 | Val Acc: 81.42%
2026-01-14 12:33:18,386 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 12:33:18,386 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 12:33:18,393 - INFO - --------------------------------------------------
2026-01-14 12:33:18,396 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 12:33:26,670 - INFO - [Train] [80/90] | Loss: 0.2203 | Train Acc: 99.63%
2026-01-14 12:33:29,736 - INFO - [Valid] [80/90] | Loss: 0.5890 | Val Acc: 82.30%
2026-01-14 12:33:29,749 - INFO - [Metrics for 'abnormal'] | Precision: 0.8212 | Recall: 0.7898 | F1: 0.8052
2026-01-14 12:33:29,749 - INFO - [Metrics for 'normal'] | Precision: 0.8245 | Recall: 0.8516 | F1: 0.8378
2026-01-14 12:33:29,752 - INFO - --------------------------------------------------
2026-01-14 12:33:29,754 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 12:33:39,256 - INFO - [Train] [81/90] | Loss: 0.2225 | Train Acc: 99.40%
2026-01-14 12:33:42,011 - INFO - [Valid] [81/90] | Loss: 0.6195 | Val Acc: 79.65%
2026-01-14 12:33:42,022 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.8089 | F1: 0.7864
2026-01-14 12:33:42,022 - INFO - [Metrics for 'normal'] | Precision: 0.8266 | Recall: 0.7857 | F1: 0.8056
2026-01-14 12:33:42,025 - INFO - --------------------------------------------------
2026-01-14 12:33:42,027 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 12:33:51,850 - INFO - [Train] [82/90] | Loss: 0.2171 | Train Acc: 99.78%
2026-01-14 12:33:54,569 - INFO - [Valid] [82/90] | Loss: 0.5748 | Val Acc: 80.83%
2026-01-14 12:33:54,578 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 12:33:54,579 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 12:33:54,582 - INFO - --------------------------------------------------
2026-01-14 12:33:54,584 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 12:34:03,383 - INFO - [Train] [83/90] | Loss: 0.2183 | Train Acc: 99.63%
2026-01-14 12:34:05,944 - INFO - [Valid] [83/90] | Loss: 0.5617 | Val Acc: 81.42%
2026-01-14 12:34:05,955 - INFO - [Metrics for 'abnormal'] | Precision: 0.8219 | Recall: 0.7643 | F1: 0.7921
2026-01-14 12:34:05,955 - INFO - [Metrics for 'normal'] | Precision: 0.8083 | Recall: 0.8571 | F1: 0.8320
2026-01-14 12:34:05,959 - INFO - --------------------------------------------------
2026-01-14 12:34:05,961 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 12:34:15,331 - INFO - [Train] [84/90] | Loss: 0.2235 | Train Acc: 99.40%
2026-01-14 12:34:17,807 - INFO - [Valid] [84/90] | Loss: 0.6075 | Val Acc: 79.35%
2026-01-14 12:34:17,822 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 12:34:17,822 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 12:34:17,826 - INFO - --------------------------------------------------
2026-01-14 12:34:17,829 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 12:34:27,008 - INFO - [Train] [85/90] | Loss: 0.2243 | Train Acc: 99.78%
2026-01-14 12:34:30,115 - INFO - [Valid] [85/90] | Loss: 0.6084 | Val Acc: 80.83%
2026-01-14 12:34:30,129 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 12:34:30,129 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 12:34:30,135 - INFO - --------------------------------------------------
2026-01-14 12:34:30,138 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 12:34:39,374 - INFO - [Train] [86/90] | Loss: 0.2255 | Train Acc: 99.33%
2026-01-14 12:34:42,331 - INFO - [Valid] [86/90] | Loss: 0.6514 | Val Acc: 80.53%
2026-01-14 12:34:42,342 - INFO - [Metrics for 'abnormal'] | Precision: 0.7692 | Recall: 0.8280 | F1: 0.7975
2026-01-14 12:34:42,343 - INFO - [Metrics for 'normal'] | Precision: 0.8412 | Recall: 0.7857 | F1: 0.8125
2026-01-14 12:34:42,347 - INFO - --------------------------------------------------
2026-01-14 12:34:42,351 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 12:34:51,133 - INFO - [Train] [87/90] | Loss: 0.2210 | Train Acc: 99.40%
2026-01-14 12:34:54,134 - INFO - [Valid] [87/90] | Loss: 0.6114 | Val Acc: 81.12%
2026-01-14 12:34:54,147 - INFO - [Metrics for 'abnormal'] | Precision: 0.7962 | Recall: 0.7962 | F1: 0.7962
2026-01-14 12:34:54,147 - INFO - [Metrics for 'normal'] | Precision: 0.8242 | Recall: 0.8242 | F1: 0.8242
2026-01-14 12:34:54,152 - INFO - --------------------------------------------------
2026-01-14 12:34:54,155 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 12:35:02,985 - INFO - [Train] [88/90] | Loss: 0.2199 | Train Acc: 99.70%
2026-01-14 12:35:05,323 - INFO - [Valid] [88/90] | Loss: 0.6162 | Val Acc: 79.65%
2026-01-14 12:35:05,336 - INFO - [Metrics for 'abnormal'] | Precision: 0.7716 | Recall: 0.7962 | F1: 0.7837
2026-01-14 12:35:05,336 - INFO - [Metrics for 'normal'] | Precision: 0.8192 | Recall: 0.7967 | F1: 0.8078
2026-01-14 12:35:05,340 - INFO - --------------------------------------------------
2026-01-14 12:35:05,342 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 12:35:13,366 - INFO - [Train] [89/90] | Loss: 0.2157 | Train Acc: 99.85%
2026-01-14 12:35:16,813 - INFO - [Valid] [89/90] | Loss: 0.6168 | Val Acc: 80.53%
2026-01-14 12:35:16,825 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-01-14 12:35:16,826 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-01-14 12:35:16,829 - INFO - --------------------------------------------------
2026-01-14 12:35:16,831 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 12:35:24,843 - INFO - [Train] [90/90] | Loss: 0.2326 | Train Acc: 98.74%
2026-01-14 12:35:27,979 - INFO - [Valid] [90/90] | Loss: 0.6001 | Val Acc: 79.35%
2026-01-14 12:35:27,991 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8280 | F1: 0.7879
2026-01-14 12:35:27,992 - INFO - [Metrics for 'normal'] | Precision: 0.8373 | Recall: 0.7637 | F1: 0.7989
2026-01-14 12:35:27,997 - INFO - ==================================================
2026-01-14 12:35:28,007 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 12:35:28,007 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 12:35:28,007 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:35:28,285 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 12:35:28,288 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:35:28,288 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:35:28,579 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3233935546875)에 맞춰 변경되었습니다.
2026-01-14 12:35:28,580 - INFO - ==================================================
2026-01-14 12:35:28,782 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/best_model.pth'
2026-01-14 12:35:28,787 - INFO - ==================================================
2026-01-14 12:35:28,787 - INFO - Test 모드를 시작합니다.
2026-01-14 12:35:29,065 - INFO - 연산량 (MACs): 0.0913 GMACs per sample
2026-01-14 12:35:29,066 - INFO - 연산량 (FLOPs): 0.1826 GFLOPs per sample
2026-01-14 12:35:29,067 - INFO - ==================================================
2026-01-14 12:35:29,067 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 12:35:30,264 - INFO - 샘플 당 평균 Forward Pass 시간: 5.51ms (std: 0.79ms), FPS: 185.96 (std: 31.34) (1개 샘플 x 100회 반복)
2026-01-14 12:35:30,264 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 82.04 MB
2026-01-14 12:35:30,264 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 12:35:33,980 - INFO - [Test] Loss: 0.4253 | Test Acc: 83.48%
2026-01-14 12:35:33,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.8741 | Recall: 0.7516 | F1: 0.8082
2026-01-14 12:35:33,997 - INFO - [Metrics for 'normal'] | Precision: 0.8088 | Recall: 0.9066 | F1: 0.8549
2026-01-14 12:35:34,799 - INFO - ==================================================
2026-01-14 12:35:34,800 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/confusion_matrix_20260114_121818.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/confusion_matrix_20260114_121818.pdf'
2026-01-14 12:35:34,801 - INFO - ==================================================
2026-01-14 12:35:34,801 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 12:35:45,843 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/model_fp32_20260114_121818.onnx'에 저장되었습니다. (크기: 4.40 MB)
2026-01-14 12:35:46,247 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2571.70 MB (증가량: 6.39 MB)
2026-01-14 12:35:46,248 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 12:35:49,367 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 24.63ms (std: 27.36ms)
2026-01-14 12:35:49,368 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 71.42 FPS (std: 44.95) (1개 샘플 x 100회 반복)
2026-01-14 12:35:49,368 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2576.76 MB (순수 증가량: 5.06 MB)
2026-01-14 12:35:49,369 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2576.76 MB (전체 증가량: 11.45 MB)
2026-01-14 12:35:54,715 - INFO - [Test (ONNX)] | Test Acc (ONNX): 83.19%
2026-01-14 12:35:54,725 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8676 | Recall: 0.7516 | F1: 0.8055
2026-01-14 12:35:54,726 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8079 | Recall: 0.9011 | F1: 0.8519
2026-01-14 12:35:55,768 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/val_acc.pdf'
2026-01-14 12:35:56,253 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/train_val_acc.pdf'
2026-01-14 12:35:56,671 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/F1_normal.pdf'
2026-01-14 12:35:57,218 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/val_loss.pdf'
2026-01-14 12:35:57,701 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/learning_rate.pdf'
2026-01-14 12:36:04,430 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_fpgm_20260114_121818/graph_20260114_121818/compile.pdf'
