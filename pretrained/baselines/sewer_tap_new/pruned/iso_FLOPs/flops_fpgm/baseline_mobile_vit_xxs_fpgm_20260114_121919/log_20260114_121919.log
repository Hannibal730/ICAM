2026-01-14 12:19:19,047 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/log_20260114_121919.log'에 저장됩니다.
2026-01-14 12:19:19,055 - INFO - ==================================================
2026-01-14 12:19:19,056 - INFO - config.yaml:
2026-01-14 12:19:19,057 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobile_vit_xxs
  use_fpgm_pruning: true
  pruning_flops_target: 0.1829

2026-01-14 12:19:19,058 - INFO - ==================================================
2026-01-14 12:19:19,127 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 12:19:19,128 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 12:19:19,129 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 12:19:19,143 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 12:19:19,144 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 12:19:19,145 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 12:19:19,146 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:19:19,517 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 12:19:19,564 - INFO - ==================================================
2026-01-14 12:19:19,566 - INFO - 모델 파라미터 수:
2026-01-14 12:19:19,567 - INFO -   - 총 파라미터: 951,666 개
2026-01-14 12:19:19,567 - INFO -   - 학습 가능한 파라미터: 951,666 개
2026-01-14 12:19:19,568 - INFO - ================================================================================
2026-01-14 12:19:19,568 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 12:19:19,568 - INFO - ================================================================================
2026-01-14 12:19:19,569 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:19:19,571 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 12:19:19,572 - INFO - ==================================================
2026-01-14 12:19:19,573 - INFO - train 모드를 시작합니다.
2026-01-14 12:19:19,574 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:19:19,574 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:19:19,575 - INFO - --------------------------------------------------
2026-01-14 12:19:19,579 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 12:19:32,950 - INFO - [Train] [1/10] | Loss: 0.5202 | Train Acc: 78.50%
2026-01-14 12:19:35,960 - INFO - [Valid] [1/10] | Loss: 0.5376 | Val Acc: 80.83%
2026-01-14 12:19:35,976 - INFO - [Metrics for 'abnormal'] | Precision: 0.7949 | Recall: 0.7898 | F1: 0.7923
2026-01-14 12:19:35,977 - INFO - [Metrics for 'normal'] | Precision: 0.8197 | Recall: 0.8242 | F1: 0.8219
2026-01-14 12:19:36,027 - INFO - [Best Model Saved] (val loss: 0.5376) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:19:36,027 - INFO - --------------------------------------------------
2026-01-14 12:19:36,030 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 12:19:43,996 - INFO - [Train] [2/10] | Loss: 0.4610 | Train Acc: 83.56%
2026-01-14 12:19:46,507 - INFO - [Valid] [2/10] | Loss: 0.5111 | Val Acc: 81.71%
2026-01-14 12:19:46,523 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 12:19:46,523 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 12:19:46,597 - INFO - [Best Model Saved] (val loss: 0.5111) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:19:46,598 - INFO - --------------------------------------------------
2026-01-14 12:19:46,603 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 12:19:52,974 - INFO - [Train] [3/10] | Loss: 0.4285 | Train Acc: 85.57%
2026-01-14 12:19:55,309 - INFO - [Valid] [3/10] | Loss: 0.5345 | Val Acc: 81.42%
2026-01-14 12:19:55,322 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 12:19:55,323 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 12:19:55,328 - INFO - --------------------------------------------------
2026-01-14 12:19:55,332 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 12:20:01,647 - INFO - [Train] [4/10] | Loss: 0.3883 | Train Acc: 88.17%
2026-01-14 12:20:03,653 - INFO - [Valid] [4/10] | Loss: 0.5516 | Val Acc: 80.53%
2026-01-14 12:20:03,665 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 12:20:03,665 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 12:20:03,670 - INFO - --------------------------------------------------
2026-01-14 12:20:03,673 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 12:20:10,073 - INFO - [Train] [5/10] | Loss: 0.3826 | Train Acc: 87.72%
2026-01-14 12:20:11,587 - INFO - [Valid] [5/10] | Loss: 0.5194 | Val Acc: 80.53%
2026-01-14 12:20:11,600 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-01-14 12:20:11,600 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-01-14 12:20:11,604 - INFO - --------------------------------------------------
2026-01-14 12:20:11,607 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 12:20:17,240 - INFO - [Train] [6/10] | Loss: 0.3623 | Train Acc: 91.29%
2026-01-14 12:20:18,693 - INFO - [Valid] [6/10] | Loss: 0.4998 | Val Acc: 81.12%
2026-01-14 12:20:18,705 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 12:20:18,705 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 12:20:18,755 - INFO - [Best Model Saved] (val loss: 0.4998) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:20:18,755 - INFO - --------------------------------------------------
2026-01-14 12:20:18,758 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 12:20:24,281 - INFO - [Train] [7/10] | Loss: 0.3065 | Train Acc: 94.35%
2026-01-14 12:20:26,023 - INFO - [Valid] [7/10] | Loss: 0.4716 | Val Acc: 81.71%
2026-01-14 12:20:26,033 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8025 | F1: 0.8025
2026-01-14 12:20:26,034 - INFO - [Metrics for 'normal'] | Precision: 0.8297 | Recall: 0.8297 | F1: 0.8297
2026-01-14 12:20:26,087 - INFO - [Best Model Saved] (val loss: 0.4716) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:20:26,087 - INFO - --------------------------------------------------
2026-01-14 12:20:26,090 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 12:20:31,473 - INFO - [Train] [8/10] | Loss: 0.2848 | Train Acc: 96.06%
2026-01-14 12:20:33,092 - INFO - [Valid] [8/10] | Loss: 0.4874 | Val Acc: 82.30%
2026-01-14 12:20:33,101 - INFO - [Metrics for 'abnormal'] | Precision: 0.7803 | Recall: 0.8599 | F1: 0.8182
2026-01-14 12:20:33,102 - INFO - [Metrics for 'normal'] | Precision: 0.8675 | Recall: 0.7912 | F1: 0.8276
2026-01-14 12:20:33,105 - INFO - --------------------------------------------------
2026-01-14 12:20:33,108 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 12:20:38,660 - INFO - [Train] [9/10] | Loss: 0.2694 | Train Acc: 97.17%
2026-01-14 12:20:40,408 - INFO - [Valid] [9/10] | Loss: 0.4716 | Val Acc: 82.01%
2026-01-14 12:20:40,420 - INFO - [Metrics for 'abnormal'] | Precision: 0.7824 | Recall: 0.8471 | F1: 0.8135
2026-01-14 12:20:40,420 - INFO - [Metrics for 'normal'] | Precision: 0.8580 | Recall: 0.7967 | F1: 0.8262
2026-01-14 12:20:40,424 - INFO - --------------------------------------------------
2026-01-14 12:20:40,428 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 12:20:46,036 - INFO - [Train] [10/10] | Loss: 0.2625 | Train Acc: 97.25%
2026-01-14 12:20:48,361 - INFO - [Valid] [10/10] | Loss: 0.4747 | Val Acc: 82.60%
2026-01-14 12:20:48,372 - INFO - [Metrics for 'abnormal'] | Precision: 0.7952 | Recall: 0.8408 | F1: 0.8173
2026-01-14 12:20:48,373 - INFO - [Metrics for 'normal'] | Precision: 0.8555 | Recall: 0.8132 | F1: 0.8338
2026-01-14 12:20:48,378 - INFO - ================================================================================
2026-01-14 12:20:48,379 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 12:20:48,379 - INFO - ================================================================================
2026-01-14 12:20:48,519 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'을(를) 불러왔습니다.
2026-01-14 12:20:48,519 - INFO - ================================================================================
2026-01-14 12:20:48,520 - INFO - 목표 FLOPs (0.1829 GFLOPs)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 12:20:48,651 - INFO - 원본 모델 FLOPs: 0.5384 GFLOPs
2026-01-14 12:20:48,818 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:48,819 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:48,820 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:49,869 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 12:20:49,870 - INFO - ==================================================
2026-01-14 12:20:49,986 - INFO -   [탐색  1] 희소도: 0.4950 -> FLOPs: 0.1747 GFLOPs (감소율: 67.56%)
2026-01-14 12:20:50,094 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:50,094 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:50,095 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:51,127 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.2475)에 맞춰 변경되었습니다.
2026-01-14 12:20:51,128 - INFO - ==================================================
2026-01-14 12:20:51,232 - INFO -   [탐색  2] 희소도: 0.2475 -> FLOPs: 0.3329 GFLOPs (감소율: 38.17%)
2026-01-14 12:20:51,321 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:51,321 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:51,323 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:52,436 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.37124999999999997)에 맞춰 변경되었습니다.
2026-01-14 12:20:52,436 - INFO - ==================================================
2026-01-14 12:20:52,524 - INFO -   [탐색  3] 희소도: 0.3712 -> FLOPs: 0.2479 GFLOPs (감소율: 53.96%)
2026-01-14 12:20:52,591 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:52,591 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:52,592 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:53,345 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.433125)에 맞춰 변경되었습니다.
2026-01-14 12:20:53,345 - INFO - ==================================================
2026-01-14 12:20:53,456 - INFO -   [탐색  4] 희소도: 0.4331 -> FLOPs: 0.2093 GFLOPs (감소율: 61.13%)
2026-01-14 12:20:53,540 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:53,541 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:53,543 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:54,375 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4640625)에 맞춰 변경되었습니다.
2026-01-14 12:20:54,375 - INFO - ==================================================
2026-01-14 12:20:54,567 - INFO -   [탐색  5] 희소도: 0.4641 -> FLOPs: 0.1880 GFLOPs (감소율: 65.08%)
2026-01-14 12:20:54,657 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:54,658 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:54,659 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:55,591 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47953124999999996)에 맞춰 변경되었습니다.
2026-01-14 12:20:55,592 - INFO - ==================================================
2026-01-14 12:20:55,697 - INFO -   [탐색  6] 희소도: 0.4795 -> FLOPs: 0.1790 GFLOPs (감소율: 66.74%)
2026-01-14 12:20:55,787 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:55,788 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:55,789 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:57,027 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.471796875)에 맞춰 변경되었습니다.
2026-01-14 12:20:57,028 - INFO - ==================================================
2026-01-14 12:20:57,125 - INFO -   [탐색  7] 희소도: 0.4718 -> FLOPs: 0.1838 GFLOPs (감소율: 65.85%)
2026-01-14 12:20:57,213 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:57,214 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:57,215 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:58,077 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4756640625)에 맞춰 변경되었습니다.
2026-01-14 12:20:58,078 - INFO - ==================================================
2026-01-14 12:20:58,170 - INFO -   [탐색  8] 희소도: 0.4757 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:20:58,262 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:58,262 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:58,264 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:59,130 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47373046875)에 맞춰 변경되었습니다.
2026-01-14 12:20:59,131 - INFO - ==================================================
2026-01-14 12:20:59,196 - INFO -   [탐색  9] 희소도: 0.4737 -> FLOPs: 0.1838 GFLOPs (감소율: 65.85%)
2026-01-14 12:20:59,261 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:20:59,261 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:20:59,262 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:20:59,862 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47469726562500003)에 맞춰 변경되었습니다.
2026-01-14 12:20:59,863 - INFO - ==================================================
2026-01-14 12:20:59,943 - INFO -   [탐색 10] 희소도: 0.4747 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:00,033 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:00,034 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:00,035 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:00,833 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47518066406250004)에 맞춰 변경되었습니다.
2026-01-14 12:21:00,834 - INFO - ==================================================
2026-01-14 12:21:00,912 - INFO -   [탐색 11] 희소도: 0.4752 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:00,991 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:00,992 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:00,993 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:02,104 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47493896484375003)에 맞춰 변경되었습니다.
2026-01-14 12:21:02,104 - INFO - ==================================================
2026-01-14 12:21:02,173 - INFO -   [탐색 12] 희소도: 0.4749 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:02,261 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:02,261 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:02,263 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:03,058 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47505981445312506)에 맞춰 변경되었습니다.
2026-01-14 12:21:03,059 - INFO - ==================================================
2026-01-14 12:21:03,143 - INFO -   [탐색 13] 희소도: 0.4751 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:03,247 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:03,248 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:03,249 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:04,057 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749993896484376)에 맞춰 변경되었습니다.
2026-01-14 12:21:04,057 - INFO - ==================================================
2026-01-14 12:21:04,121 - INFO -   [탐색 14] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:04,186 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:04,187 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:04,188 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:04,757 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750296020507813)에 맞춰 변경되었습니다.
2026-01-14 12:21:04,757 - INFO - ==================================================
2026-01-14 12:21:04,837 - INFO -   [탐색 15] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:04,923 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:04,924 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:04,925 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:05,729 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750144958496094)에 맞춰 변경되었습니다.
2026-01-14 12:21:05,730 - INFO - ==================================================
2026-01-14 12:21:05,821 - INFO -   [탐색 16] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:06,147 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:06,148 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:06,149 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:07,059 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750069427490235)에 맞춰 변경되었습니다.
2026-01-14 12:21:07,060 - INFO - ==================================================
2026-01-14 12:21:07,151 - INFO -   [탐색 17] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:07,252 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:07,252 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:07,254 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:08,151 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750031661987305)에 맞춰 변경되었습니다.
2026-01-14 12:21:08,152 - INFO - ==================================================
2026-01-14 12:21:08,232 - INFO -   [탐색 18] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:08,318 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:08,318 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:08,320 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:09,168 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500127792358404)에 맞춰 변경되었습니다.
2026-01-14 12:21:09,168 - INFO - ==================================================
2026-01-14 12:21:09,248 - INFO -   [탐색 19] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:09,333 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:09,334 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:09,336 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:10,200 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750003337860108)에 맞춰 변경되었습니다.
2026-01-14 12:21:10,201 - INFO - ==================================================
2026-01-14 12:21:10,282 - INFO -   [탐색 20] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:10,371 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:10,372 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:10,373 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:11,542 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749998617172242)에 맞춰 변경되었습니다.
2026-01-14 12:21:11,543 - INFO - ==================================================
2026-01-14 12:21:11,625 - INFO -   [탐색 21] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:11,722 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:11,723 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:11,725 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:12,528 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000977516175)에 맞춰 변경되었습니다.
2026-01-14 12:21:12,528 - INFO - ==================================================
2026-01-14 12:21:12,578 - INFO -   [탐색 22] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:12,632 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:12,632 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:12,633 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:13,199 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999797344209)에 맞춰 변경되었습니다.
2026-01-14 12:21:13,200 - INFO - ==================================================
2026-01-14 12:21:13,281 - INFO -   [탐색 23] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:13,373 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:13,373 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:13,375 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:14,241 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000387430192)에 맞춰 변경되었습니다.
2026-01-14 12:21:14,242 - INFO - ==================================================
2026-01-14 12:21:14,327 - INFO -   [탐색 24] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:14,429 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:14,433 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:14,434 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:15,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500000923872004)에 맞춰 변경되었습니다.
2026-01-14 12:21:15,310 - INFO - ==================================================
2026-01-14 12:21:15,398 - INFO -   [탐색 25] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:15,484 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:15,485 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:15,487 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:16,807 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999944865705)에 맞춰 변경되었습니다.
2026-01-14 12:21:16,807 - INFO - ==================================================
2026-01-14 12:21:16,918 - INFO -   [탐색 26] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:17,000 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:17,000 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:17,002 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:17,761 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500000186264524)에 맞춰 변경되었습니다.
2026-01-14 12:21:17,762 - INFO - ==================================================
2026-01-14 12:21:17,834 - INFO -   [탐색 27] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:17,934 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:17,934 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:17,935 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:18,776 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47499999817460786)에 맞춰 변경되었습니다.
2026-01-14 12:21:18,777 - INFO - ==================================================
2026-01-14 12:21:18,858 - INFO -   [탐색 28] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:18,947 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:18,948 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:18,949 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:19,752 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000186265)에 맞춰 변경되었습니다.
2026-01-14 12:21:19,753 - INFO - ==================================================
2026-01-14 12:21:19,835 - INFO -   [탐색 29] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:19,918 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:19,919 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:19,920 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:20,686 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47499999909661716)에 맞춰 변경되었습니다.
2026-01-14 12:21:20,687 - INFO - ==================================================
2026-01-14 12:21:20,748 - INFO -   [탐색 30] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:21,406 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:21,410 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:21,412 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:22,514 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47499999955762184)에 맞춰 변경되었습니다.
2026-01-14 12:21:22,515 - INFO - ==================================================
2026-01-14 12:21:22,620 - INFO -   [탐색 31] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:22,731 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:22,733 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:22,735 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:23,665 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999997881242)에 맞춰 변경되었습니다.
2026-01-14 12:21:23,665 - INFO - ==================================================
2026-01-14 12:21:23,753 - INFO -   [탐색 32] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:23,855 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:23,856 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:23,857 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:24,917 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999999033754)에 맞춰 변경되었습니다.
2026-01-14 12:21:24,918 - INFO - ==================================================
2026-01-14 12:21:24,999 - INFO -   [탐색 33] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:25,106 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:25,107 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:25,108 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:26,020 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47499999996100095)에 맞춰 변경되었습니다.
2026-01-14 12:21:26,021 - INFO - ==================================================
2026-01-14 12:21:26,105 - INFO -   [탐색 34] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:26,192 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:26,193 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:26,194 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:27,597 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47499999998981374)에 맞춰 변경되었습니다.
2026-01-14 12:21:27,597 - INFO - ==================================================
2026-01-14 12:21:27,684 - INFO -   [탐색 35] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:27,764 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:27,765 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:27,766 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:28,838 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500000000422016)에 맞춰 변경되었습니다.
2026-01-14 12:21:28,839 - INFO - ==================================================
2026-01-14 12:21:28,923 - INFO -   [탐색 36] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:29,064 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:29,065 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:29,066 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:30,016 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999999970169)에 맞춰 변경되었습니다.
2026-01-14 12:21:30,016 - INFO - ==================================================
2026-01-14 12:21:30,172 - INFO -   [탐색 37] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:30,299 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:30,300 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:30,302 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:31,311 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500000000061854)에 맞춰 변경되었습니다.
2026-01-14 12:21:31,312 - INFO - ==================================================
2026-01-14 12:21:31,397 - INFO -   [탐색 38] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:31,495 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:31,499 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:31,502 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:32,399 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999999988177)에 맞춰 변경되었습니다.
2026-01-14 12:21:32,399 - INFO - ==================================================
2026-01-14 12:21:32,492 - INFO -   [탐색 39] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:32,592 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:32,592 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:32,594 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:33,778 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999999997181)에 맞춰 변경되었습니다.
2026-01-14 12:21:33,778 - INFO - ==================================================
2026-01-14 12:21:33,861 - INFO -   [탐색 40] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:33,947 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:33,947 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:33,949 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:34,880 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000001683)에 맞춰 변경되었습니다.
2026-01-14 12:21:34,881 - INFO - ==================================================
2026-01-14 12:21:34,962 - INFO -   [탐색 41] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:35,052 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:35,052 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:35,053 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:35,871 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999999999432)에 맞춰 변경되었습니다.
2026-01-14 12:21:35,872 - INFO - ==================================================
2026-01-14 12:21:35,954 - INFO -   [탐색 42] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:36,038 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:36,039 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:36,041 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:36,817 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000000557)에 맞춰 변경되었습니다.
2026-01-14 12:21:36,818 - INFO - ==================================================
2026-01-14 12:21:36,892 - INFO -   [탐색 43] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:36,982 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:36,982 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:36,984 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:37,857 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4749999999999994)에 맞춰 변경되었습니다.
2026-01-14 12:21:37,857 - INFO - ==================================================
2026-01-14 12:21:37,945 - INFO -   [탐색 44] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:38,386 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:38,387 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:38,388 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:39,354 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500000000002757)에 맞춰 변경되었습니다.
2026-01-14 12:21:39,355 - INFO - ==================================================
2026-01-14 12:21:39,448 - INFO -   [탐색 45] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:39,549 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:39,551 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:39,553 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:40,428 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000000135)에 맞춰 변경되었습니다.
2026-01-14 12:21:40,428 - INFO - ==================================================
2026-01-14 12:21:40,558 - INFO -   [탐색 46] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:40,657 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:40,658 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:40,660 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:41,740 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000000065)에 맞춰 변경되었습니다.
2026-01-14 12:21:41,741 - INFO - ==================================================
2026-01-14 12:21:41,826 - INFO -   [탐색 47] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:41,919 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:41,919 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:41,921 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:42,890 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475000000000003)에 맞춰 변경되었습니다.
2026-01-14 12:21:42,890 - INFO - ==================================================
2026-01-14 12:21:42,987 - INFO -   [탐색 48] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:43,059 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:43,060 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:43,061 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:44,411 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000000012)에 맞춰 변경되었습니다.
2026-01-14 12:21:44,411 - INFO - ==================================================
2026-01-14 12:21:44,499 - INFO -   [탐색 49] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:44,588 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:44,589 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:44,590 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:45,428 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000000003)에 맞춰 변경되었습니다.
2026-01-14 12:21:45,429 - INFO - ==================================================
2026-01-14 12:21:45,625 - INFO -   [탐색 50] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:45,809 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:45,813 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:45,814 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:46,954 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47499999999999987)에 맞춰 변경되었습니다.
2026-01-14 12:21:46,957 - INFO - ==================================================
2026-01-14 12:21:47,068 - INFO -   [탐색 51] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:47,159 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:47,160 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:47,161 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:48,279 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4750000000000001)에 맞춰 변경되었습니다.
2026-01-14 12:21:48,281 - INFO - ==================================================
2026-01-14 12:21:48,391 - INFO -   [탐색 52] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:48,481 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:48,482 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:48,483 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:49,300 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:49,301 - INFO - ==================================================
2026-01-14 12:21:49,378 - INFO -   [탐색 53] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:49,466 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:49,467 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:49,468 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:50,594 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.47500000000000003)에 맞춰 변경되었습니다.
2026-01-14 12:21:50,594 - INFO - ==================================================
2026-01-14 12:21:50,677 - INFO -   [탐색 54] 희소도: 0.4750 -> FLOPs: 0.1826 GFLOPs (감소율: 66.08%)
2026-01-14 12:21:50,774 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:50,775 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:50,777 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:52,627 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:52,628 - INFO - ==================================================
2026-01-14 12:21:52,710 - INFO -   [탐색 55] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:52,796 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:52,797 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:52,799 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:53,627 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:53,627 - INFO - ==================================================
2026-01-14 12:21:53,709 - INFO -   [탐색 56] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:53,803 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:53,804 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:53,805 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:54,512 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:54,513 - INFO - ==================================================
2026-01-14 12:21:54,595 - INFO -   [탐색 57] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:54,678 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:54,679 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:54,680 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:55,549 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:55,549 - INFO - ==================================================
2026-01-14 12:21:55,650 - INFO -   [탐색 58] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:56,498 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:56,499 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:56,500 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:57,584 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:57,585 - INFO - ==================================================
2026-01-14 12:21:57,841 - INFO -   [탐색 59] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:58,083 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:58,083 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:58,085 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:21:59,557 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:21:59,558 - INFO - ==================================================
2026-01-14 12:21:59,664 - INFO -   [탐색 60] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:21:59,756 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:21:59,757 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:21:59,759 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:00,792 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:00,793 - INFO - ==================================================
2026-01-14 12:22:00,879 - INFO -   [탐색 61] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:00,971 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:00,971 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:00,972 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:01,846 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:01,847 - INFO - ==================================================
2026-01-14 12:22:01,934 - INFO -   [탐색 62] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:02,033 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:02,034 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:02,035 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:03,945 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:03,946 - INFO - ==================================================
2026-01-14 12:22:04,033 - INFO -   [탐색 63] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:04,154 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:04,157 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:04,159 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:05,045 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:05,047 - INFO - ==================================================
2026-01-14 12:22:05,181 - INFO -   [탐색 64] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:05,270 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:05,270 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:05,272 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:06,108 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:06,108 - INFO - ==================================================
2026-01-14 12:22:06,190 - INFO -   [탐색 65] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:06,278 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:06,280 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:06,281 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:07,104 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:07,105 - INFO - ==================================================
2026-01-14 12:22:07,187 - INFO -   [탐색 66] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:07,279 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:07,279 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:07,281 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:08,085 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:08,086 - INFO - ==================================================
2026-01-14 12:22:08,167 - INFO -   [탐색 67] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:08,553 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:08,553 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:08,555 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:09,436 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:09,436 - INFO - ==================================================
2026-01-14 12:22:09,519 - INFO -   [탐색 68] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:09,594 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:09,595 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:09,596 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:10,488 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:10,489 - INFO - ==================================================
2026-01-14 12:22:10,574 - INFO -   [탐색 69] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:10,658 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:10,658 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:10,660 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:11,709 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:11,713 - INFO - ==================================================
2026-01-14 12:22:11,887 - INFO -   [탐색 70] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:11,977 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:11,978 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:11,980 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:13,121 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:13,122 - INFO - ==================================================
2026-01-14 12:22:13,200 - INFO -   [탐색 71] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:13,284 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:13,285 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:13,287 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:14,717 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:14,718 - INFO - ==================================================
2026-01-14 12:22:14,802 - INFO -   [탐색 72] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:14,902 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:14,902 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:14,906 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:15,657 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:15,658 - INFO - ==================================================
2026-01-14 12:22:15,740 - INFO -   [탐색 73] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:15,829 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:15,830 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:15,832 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:16,965 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:16,965 - INFO - ==================================================
2026-01-14 12:22:17,027 - INFO -   [탐색 74] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:17,093 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:17,094 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:17,095 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:17,895 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:17,895 - INFO - ==================================================
2026-01-14 12:22:17,981 - INFO -   [탐색 75] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:18,073 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:18,073 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:18,075 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:19,793 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:19,794 - INFO - ==================================================
2026-01-14 12:22:20,003 - INFO -   [탐색 76] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:20,220 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:20,220 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:20,222 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:22,124 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:22,125 - INFO - ==================================================
2026-01-14 12:22:22,239 - INFO -   [탐색 77] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:22,384 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:22,385 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:22,389 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:23,524 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:23,525 - INFO - ==================================================
2026-01-14 12:22:23,629 - INFO -   [탐색 78] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:23,779 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:23,780 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:23,782 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:24,754 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:24,754 - INFO - ==================================================
2026-01-14 12:22:24,845 - INFO -   [탐색 79] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:24,937 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:24,938 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:24,939 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:25,993 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:25,994 - INFO - ==================================================
2026-01-14 12:22:26,067 - INFO -   [탐색 80] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:26,165 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:26,166 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:26,167 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:28,275 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:28,278 - INFO - ==================================================
2026-01-14 12:22:28,376 - INFO -   [탐색 81] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:28,560 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:28,560 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:28,562 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:29,942 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:29,943 - INFO - ==================================================
2026-01-14 12:22:30,033 - INFO -   [탐색 82] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:30,123 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:30,124 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:30,127 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:31,311 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:31,311 - INFO - ==================================================
2026-01-14 12:22:31,478 - INFO -   [탐색 83] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:31,585 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:31,585 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:31,586 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:32,387 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:32,388 - INFO - ==================================================
2026-01-14 12:22:32,484 - INFO -   [탐색 84] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:32,623 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:32,623 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:32,624 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:33,815 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:33,815 - INFO - ==================================================
2026-01-14 12:22:33,903 - INFO -   [탐색 85] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:34,301 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:34,301 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:34,303 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:35,139 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:35,141 - INFO - ==================================================
2026-01-14 12:22:35,281 - INFO -   [탐색 86] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:35,373 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:35,374 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:35,376 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:36,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:36,307 - INFO - ==================================================
2026-01-14 12:22:36,407 - INFO -   [탐색 87] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:36,505 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:36,506 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:36,508 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:37,590 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:37,590 - INFO - ==================================================
2026-01-14 12:22:37,676 - INFO -   [탐색 88] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:37,772 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:37,774 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:37,775 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:38,990 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:38,991 - INFO - ==================================================
2026-01-14 12:22:39,129 - INFO -   [탐색 89] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:39,243 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:39,244 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:39,247 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:40,519 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:40,520 - INFO - ==================================================
2026-01-14 12:22:40,605 - INFO -   [탐색 90] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:40,691 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:40,692 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:40,705 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:41,921 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:41,921 - INFO - ==================================================
2026-01-14 12:22:42,147 - INFO -   [탐색 91] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:42,225 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:42,226 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:42,228 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:43,013 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:43,014 - INFO - ==================================================
2026-01-14 12:22:43,101 - INFO -   [탐색 92] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:43,230 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:43,231 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:43,233 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:44,461 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:44,461 - INFO - ==================================================
2026-01-14 12:22:44,524 - INFO -   [탐색 93] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:44,629 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:44,629 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:44,631 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:45,433 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:45,434 - INFO - ==================================================
2026-01-14 12:22:45,535 - INFO -   [탐색 94] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:46,228 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:46,229 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:46,230 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:47,462 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:47,463 - INFO - ==================================================
2026-01-14 12:22:47,546 - INFO -   [탐색 95] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:47,637 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:47,637 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:47,640 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:49,249 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:49,253 - INFO - ==================================================
2026-01-14 12:22:49,389 - INFO -   [탐색 96] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:49,485 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:49,486 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:49,487 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:50,958 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:50,958 - INFO - ==================================================
2026-01-14 12:22:51,045 - INFO -   [탐색 97] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:51,130 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:51,131 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:51,133 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:52,325 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:52,326 - INFO - ==================================================
2026-01-14 12:22:52,400 - INFO -   [탐색 98] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:52,513 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:52,513 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:52,514 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:53,522 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:53,523 - INFO - ==================================================
2026-01-14 12:22:53,748 - INFO -   [탐색 99] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:54,640 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:54,640 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:54,642 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:55,606 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.475)에 맞춰 변경되었습니다.
2026-01-14 12:22:55,606 - INFO - ==================================================
2026-01-14 12:22:55,940 - INFO -   [탐색 100] 희소도: 0.4750 -> FLOPs: 0.1838 GFLOPs (감소율: 65.86%)
2026-01-14 12:22:55,941 - INFO - 탐색 완료. 목표 FLOPs(0.1829)에 가장 근접한 최적 희소도는 0.4757 입니다.
2026-01-14 12:22:55,942 - INFO - ================================================================================
2026-01-14 12:22:55,948 - INFO - 계산된 Pruning 정보(희소도: 0.4757)를 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/pruning_info.yaml'에 저장했습니다.
2026-01-14 12:22:56,032 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 12:22:56,206 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:22:56,208 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:22:56,209 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:22:57,204 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4756640625)에 맞춰 변경되었습니다.
2026-01-14 12:22:57,205 - INFO - ==================================================
2026-01-14 12:22:57,212 - INFO - ==================================================
2026-01-14 12:22:57,213 - INFO - 모델 파라미터 수:
2026-01-14 12:22:57,213 - INFO -   - 총 파라미터: 320,767 개
2026-01-14 12:22:57,213 - INFO -   - 학습 가능한 파라미터: 320,767 개
2026-01-14 12:22:57,329 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 12:22:57,533 - INFO - FLOPs가 0.5384 GFLOPs에서 0.1826 GFLOPs로 감소했습니다 (감소율: 66.08%).
2026-01-14 12:22:57,534 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 12:22:57,535 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 12:22:57,538 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 12:22:57,539 - INFO - ==================================================
2026-01-14 12:22:57,539 - INFO - train 모드를 시작합니다.
2026-01-14 12:22:57,540 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 12:22:57,540 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 12:22:57,541 - INFO - --------------------------------------------------
2026-01-14 12:22:57,544 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 12:23:08,313 - INFO - [Train] [11/90] | Loss: 0.5122 | Train Acc: 78.57%
2026-01-14 12:23:11,113 - INFO - [Valid] [11/90] | Loss: 0.5131 | Val Acc: 79.94%
2026-01-14 12:23:11,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.7764 | Recall: 0.7962 | F1: 0.7862
2026-01-14 12:23:11,144 - INFO - [Metrics for 'normal'] | Precision: 0.8202 | Recall: 0.8022 | F1: 0.8111
2026-01-14 12:23:11,204 - INFO - [Best Model Saved] (val loss: 0.5131) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:23:11,205 - INFO - --------------------------------------------------
2026-01-14 12:23:11,208 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 12:23:20,745 - INFO - [Train] [12/90] | Loss: 0.4660 | Train Acc: 83.71%
2026-01-14 12:23:23,225 - INFO - [Valid] [12/90] | Loss: 0.5032 | Val Acc: 80.53%
2026-01-14 12:23:23,238 - INFO - [Metrics for 'abnormal'] | Precision: 0.8054 | Recall: 0.7643 | F1: 0.7843
2026-01-14 12:23:23,239 - INFO - [Metrics for 'normal'] | Precision: 0.8053 | Recall: 0.8407 | F1: 0.8226
2026-01-14 12:23:23,297 - INFO - [Best Model Saved] (val loss: 0.5032) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:23:23,298 - INFO - --------------------------------------------------
2026-01-14 12:23:23,301 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 12:23:33,708 - INFO - [Train] [13/90] | Loss: 0.4361 | Train Acc: 84.82%
2026-01-14 12:23:36,125 - INFO - [Valid] [13/90] | Loss: 0.5296 | Val Acc: 79.06%
2026-01-14 12:23:36,136 - INFO - [Metrics for 'abnormal'] | Precision: 0.7416 | Recall: 0.8408 | F1: 0.7881
2026-01-14 12:23:36,136 - INFO - [Metrics for 'normal'] | Precision: 0.8447 | Recall: 0.7473 | F1: 0.7930
2026-01-14 12:23:36,139 - INFO - --------------------------------------------------
2026-01-14 12:23:36,142 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 12:23:47,325 - INFO - [Train] [14/90] | Loss: 0.4287 | Train Acc: 85.57%
2026-01-14 12:23:49,546 - INFO - [Valid] [14/90] | Loss: 0.4809 | Val Acc: 82.60%
2026-01-14 12:23:49,586 - INFO - [Metrics for 'abnormal'] | Precision: 0.8141 | Recall: 0.8089 | F1: 0.8115
2026-01-14 12:23:49,586 - INFO - [Metrics for 'normal'] | Precision: 0.8361 | Recall: 0.8407 | F1: 0.8384
2026-01-14 12:23:49,732 - INFO - [Best Model Saved] (val loss: 0.4809) -> 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:23:49,735 - INFO - --------------------------------------------------
2026-01-14 12:23:49,745 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 12:24:00,817 - INFO - [Train] [15/90] | Loss: 0.4144 | Train Acc: 86.31%
2026-01-14 12:24:03,015 - INFO - [Valid] [15/90] | Loss: 0.5238 | Val Acc: 78.17%
2026-01-14 12:24:03,028 - INFO - [Metrics for 'abnormal'] | Precision: 0.7219 | Recall: 0.8599 | F1: 0.7849
2026-01-14 12:24:03,029 - INFO - [Metrics for 'normal'] | Precision: 0.8553 | Recall: 0.7143 | F1: 0.7784
2026-01-14 12:24:03,034 - INFO - --------------------------------------------------
2026-01-14 12:24:03,039 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 12:24:14,131 - INFO - [Train] [16/90] | Loss: 0.3969 | Train Acc: 88.47%
2026-01-14 12:24:16,687 - INFO - [Valid] [16/90] | Loss: 0.5172 | Val Acc: 81.71%
2026-01-14 12:24:16,700 - INFO - [Metrics for 'abnormal'] | Precision: 0.7811 | Recall: 0.8408 | F1: 0.8098
2026-01-14 12:24:16,701 - INFO - [Metrics for 'normal'] | Precision: 0.8529 | Recall: 0.7967 | F1: 0.8239
2026-01-14 12:24:16,705 - INFO - --------------------------------------------------
2026-01-14 12:24:16,709 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 12:24:27,718 - INFO - [Train] [17/90] | Loss: 0.3500 | Train Acc: 90.85%
2026-01-14 12:24:31,234 - INFO - [Valid] [17/90] | Loss: 0.5036 | Val Acc: 82.60%
2026-01-14 12:24:31,342 - INFO - [Metrics for 'abnormal'] | Precision: 0.8712 | Recall: 0.7325 | F1: 0.7958
2026-01-14 12:24:31,343 - INFO - [Metrics for 'normal'] | Precision: 0.7971 | Recall: 0.9066 | F1: 0.8483
2026-01-14 12:24:31,347 - INFO - --------------------------------------------------
2026-01-14 12:24:31,351 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 12:24:41,114 - INFO - [Train] [18/90] | Loss: 0.3430 | Train Acc: 91.37%
2026-01-14 12:24:44,935 - INFO - [Valid] [18/90] | Loss: 0.5022 | Val Acc: 80.83%
2026-01-14 12:24:44,960 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 12:24:44,961 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 12:24:44,969 - INFO - --------------------------------------------------
2026-01-14 12:24:44,975 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 12:24:54,427 - INFO - [Train] [19/90] | Loss: 0.3285 | Train Acc: 93.30%
2026-01-14 12:24:58,600 - INFO - [Valid] [19/90] | Loss: 0.5314 | Val Acc: 76.40%
2026-01-14 12:24:58,623 - INFO - [Metrics for 'abnormal'] | Precision: 0.7984 | Recall: 0.6561 | F1: 0.7203
2026-01-14 12:24:58,623 - INFO - [Metrics for 'normal'] | Precision: 0.7429 | Recall: 0.8571 | F1: 0.7959
2026-01-14 12:24:58,628 - INFO - --------------------------------------------------
2026-01-14 12:24:58,631 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 12:25:10,160 - INFO - [Train] [20/90] | Loss: 0.2999 | Train Acc: 94.72%
2026-01-14 12:25:13,711 - INFO - [Valid] [20/90] | Loss: 0.5149 | Val Acc: 81.12%
2026-01-14 12:25:13,730 - INFO - [Metrics for 'abnormal'] | Precision: 0.8079 | Recall: 0.7771 | F1: 0.7922
2026-01-14 12:25:13,730 - INFO - [Metrics for 'normal'] | Precision: 0.8138 | Recall: 0.8407 | F1: 0.8270
2026-01-14 12:25:13,738 - INFO - --------------------------------------------------
2026-01-14 12:25:13,741 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 12:25:22,680 - INFO - [Train] [21/90] | Loss: 0.3091 | Train Acc: 94.64%
2026-01-14 12:25:25,709 - INFO - [Valid] [21/90] | Loss: 0.5240 | Val Acc: 79.65%
2026-01-14 12:25:25,719 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-01-14 12:25:25,719 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-01-14 12:25:25,723 - INFO - --------------------------------------------------
2026-01-14 12:25:25,726 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 12:25:36,014 - INFO - [Train] [22/90] | Loss: 0.2869 | Train Acc: 95.76%
2026-01-14 12:25:38,863 - INFO - [Valid] [22/90] | Loss: 0.5518 | Val Acc: 77.58%
2026-01-14 12:25:38,888 - INFO - [Metrics for 'abnormal'] | Precision: 0.7547 | Recall: 0.7643 | F1: 0.7595
2026-01-14 12:25:38,888 - INFO - [Metrics for 'normal'] | Precision: 0.7944 | Recall: 0.7857 | F1: 0.7901
2026-01-14 12:25:38,892 - INFO - --------------------------------------------------
2026-01-14 12:25:38,899 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 12:25:49,253 - INFO - [Train] [23/90] | Loss: 0.2705 | Train Acc: 97.02%
2026-01-14 12:25:51,540 - INFO - [Valid] [23/90] | Loss: 0.5231 | Val Acc: 82.60%
2026-01-14 12:25:51,574 - INFO - [Metrics for 'abnormal'] | Precision: 0.7988 | Recall: 0.8344 | F1: 0.8162
2026-01-14 12:25:51,575 - INFO - [Metrics for 'normal'] | Precision: 0.8514 | Recall: 0.8187 | F1: 0.8347
2026-01-14 12:25:51,585 - INFO - --------------------------------------------------
2026-01-14 12:25:51,587 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 12:26:01,325 - INFO - [Train] [24/90] | Loss: 0.2717 | Train Acc: 96.35%
2026-01-14 12:26:03,627 - INFO - [Valid] [24/90] | Loss: 0.5582 | Val Acc: 78.47%
2026-01-14 12:26:03,638 - INFO - [Metrics for 'abnormal'] | Precision: 0.7333 | Recall: 0.8408 | F1: 0.7834
2026-01-14 12:26:03,639 - INFO - [Metrics for 'normal'] | Precision: 0.8428 | Recall: 0.7363 | F1: 0.7859
2026-01-14 12:26:03,644 - INFO - --------------------------------------------------
2026-01-14 12:26:03,647 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 12:26:13,170 - INFO - [Train] [25/90] | Loss: 0.2761 | Train Acc: 96.13%
2026-01-14 12:26:15,432 - INFO - [Valid] [25/90] | Loss: 0.5120 | Val Acc: 80.53%
2026-01-14 12:26:15,442 - INFO - [Metrics for 'abnormal'] | Precision: 0.7974 | Recall: 0.7771 | F1: 0.7871
2026-01-14 12:26:15,442 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.8297 | F1: 0.8207
2026-01-14 12:26:15,447 - INFO - --------------------------------------------------
2026-01-14 12:26:15,453 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 12:26:25,818 - INFO - [Train] [26/90] | Loss: 0.2853 | Train Acc: 95.39%
2026-01-14 12:26:28,131 - INFO - [Valid] [26/90] | Loss: 0.4896 | Val Acc: 80.24%
2026-01-14 12:26:28,143 - INFO - [Metrics for 'abnormal'] | Precision: 0.8082 | Recall: 0.7516 | F1: 0.7789
2026-01-14 12:26:28,144 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8462 | F1: 0.8213
2026-01-14 12:26:28,147 - INFO - --------------------------------------------------
2026-01-14 12:26:28,150 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 12:26:38,965 - INFO - [Train] [27/90] | Loss: 0.2888 | Train Acc: 95.01%
2026-01-14 12:26:41,073 - INFO - [Valid] [27/90] | Loss: 0.5594 | Val Acc: 80.53%
2026-01-14 12:26:41,084 - INFO - [Metrics for 'abnormal'] | Precision: 0.7791 | Recall: 0.8089 | F1: 0.7937
2026-01-14 12:26:41,084 - INFO - [Metrics for 'normal'] | Precision: 0.8295 | Recall: 0.8022 | F1: 0.8156
2026-01-14 12:26:41,088 - INFO - --------------------------------------------------
2026-01-14 12:26:41,091 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 12:26:51,367 - INFO - [Train] [28/90] | Loss: 0.2712 | Train Acc: 96.65%
2026-01-14 12:26:53,499 - INFO - [Valid] [28/90] | Loss: 0.5203 | Val Acc: 80.24%
2026-01-14 12:26:53,509 - INFO - [Metrics for 'abnormal'] | Precision: 0.7500 | Recall: 0.8599 | F1: 0.8012
2026-01-14 12:26:53,510 - INFO - [Metrics for 'normal'] | Precision: 0.8616 | Recall: 0.7527 | F1: 0.8035
2026-01-14 12:26:53,514 - INFO - --------------------------------------------------
2026-01-14 12:26:53,517 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 12:27:03,900 - INFO - [Train] [29/90] | Loss: 0.2472 | Train Acc: 97.99%
2026-01-14 12:27:05,775 - INFO - [Valid] [29/90] | Loss: 0.5652 | Val Acc: 80.83%
2026-01-14 12:27:05,800 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 12:27:05,800 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 12:27:05,807 - INFO - --------------------------------------------------
2026-01-14 12:27:05,814 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 12:27:16,849 - INFO - [Train] [30/90] | Loss: 0.2516 | Train Acc: 97.47%
2026-01-14 12:27:18,845 - INFO - [Valid] [30/90] | Loss: 0.5567 | Val Acc: 82.30%
2026-01-14 12:27:18,859 - INFO - [Metrics for 'abnormal'] | Precision: 0.8255 | Recall: 0.7834 | F1: 0.8039
2026-01-14 12:27:18,859 - INFO - [Metrics for 'normal'] | Precision: 0.8211 | Recall: 0.8571 | F1: 0.8387
2026-01-14 12:27:18,863 - INFO - --------------------------------------------------
2026-01-14 12:27:18,867 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 12:27:29,368 - INFO - [Train] [31/90] | Loss: 0.2460 | Train Acc: 98.14%
2026-01-14 12:27:31,748 - INFO - [Valid] [31/90] | Loss: 0.5771 | Val Acc: 80.83%
2026-01-14 12:27:31,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7834 | F1: 0.7910
2026-01-14 12:27:31,774 - INFO - [Metrics for 'normal'] | Precision: 0.8162 | Recall: 0.8297 | F1: 0.8229
2026-01-14 12:27:31,782 - INFO - --------------------------------------------------
2026-01-14 12:27:31,786 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 12:27:41,402 - INFO - [Train] [32/90] | Loss: 0.2586 | Train Acc: 97.40%
2026-01-14 12:27:44,015 - INFO - [Valid] [32/90] | Loss: 0.5281 | Val Acc: 81.12%
2026-01-14 12:27:44,039 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7898 | F1: 0.7949
2026-01-14 12:27:44,040 - INFO - [Metrics for 'normal'] | Precision: 0.8207 | Recall: 0.8297 | F1: 0.8251
2026-01-14 12:27:44,049 - INFO - --------------------------------------------------
2026-01-14 12:27:44,055 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 12:27:53,761 - INFO - [Train] [33/90] | Loss: 0.2401 | Train Acc: 98.74%
2026-01-14 12:27:55,885 - INFO - [Valid] [33/90] | Loss: 0.5577 | Val Acc: 81.42%
2026-01-14 12:27:55,899 - INFO - [Metrics for 'abnormal'] | Precision: 0.8176 | Recall: 0.7707 | F1: 0.7934
2026-01-14 12:27:55,899 - INFO - [Metrics for 'normal'] | Precision: 0.8115 | Recall: 0.8516 | F1: 0.8311
2026-01-14 12:27:55,903 - INFO - --------------------------------------------------
2026-01-14 12:27:55,906 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 12:28:05,816 - INFO - [Train] [34/90] | Loss: 0.2471 | Train Acc: 98.07%
2026-01-14 12:28:07,962 - INFO - [Valid] [34/90] | Loss: 0.5214 | Val Acc: 82.89%
2026-01-14 12:28:07,975 - INFO - [Metrics for 'abnormal'] | Precision: 0.8113 | Recall: 0.8217 | F1: 0.8165
2026-01-14 12:28:07,976 - INFO - [Metrics for 'normal'] | Precision: 0.8444 | Recall: 0.8352 | F1: 0.8398
2026-01-14 12:28:07,981 - INFO - --------------------------------------------------
2026-01-14 12:28:07,986 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 12:28:17,676 - INFO - [Train] [35/90] | Loss: 0.2382 | Train Acc: 98.74%
2026-01-14 12:28:20,122 - INFO - [Valid] [35/90] | Loss: 0.5685 | Val Acc: 81.42%
2026-01-14 12:28:20,131 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-01-14 12:28:20,132 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-01-14 12:28:20,136 - INFO - --------------------------------------------------
2026-01-14 12:28:20,138 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 12:28:29,427 - INFO - [Train] [36/90] | Loss: 0.2398 | Train Acc: 98.59%
2026-01-14 12:28:32,488 - INFO - [Valid] [36/90] | Loss: 0.5684 | Val Acc: 81.12%
2026-01-14 12:28:32,499 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 12:28:32,500 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 12:28:32,504 - INFO - --------------------------------------------------
2026-01-14 12:28:32,508 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 12:28:41,793 - INFO - [Train] [37/90] | Loss: 0.2393 | Train Acc: 98.44%
2026-01-14 12:28:44,696 - INFO - [Valid] [37/90] | Loss: 0.5642 | Val Acc: 81.71%
2026-01-14 12:28:44,708 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 12:28:44,708 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 12:28:44,714 - INFO - --------------------------------------------------
2026-01-14 12:28:44,717 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 12:28:53,971 - INFO - [Train] [38/90] | Loss: 0.2443 | Train Acc: 98.14%
2026-01-14 12:28:57,240 - INFO - [Valid] [38/90] | Loss: 0.5594 | Val Acc: 80.53%
2026-01-14 12:28:57,267 - INFO - [Metrics for 'abnormal'] | Precision: 0.7935 | Recall: 0.7834 | F1: 0.7885
2026-01-14 12:28:57,267 - INFO - [Metrics for 'normal'] | Precision: 0.8152 | Recall: 0.8242 | F1: 0.8197
2026-01-14 12:28:57,276 - INFO - --------------------------------------------------
2026-01-14 12:28:57,283 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 12:29:06,637 - INFO - [Train] [39/90] | Loss: 0.2402 | Train Acc: 98.36%
2026-01-14 12:29:09,518 - INFO - [Valid] [39/90] | Loss: 0.5780 | Val Acc: 79.06%
2026-01-14 12:29:09,532 - INFO - [Metrics for 'abnormal'] | Precision: 0.7529 | Recall: 0.8153 | F1: 0.7829
2026-01-14 12:29:09,533 - INFO - [Metrics for 'normal'] | Precision: 0.8284 | Recall: 0.7692 | F1: 0.7977
2026-01-14 12:29:09,537 - INFO - --------------------------------------------------
2026-01-14 12:29:09,541 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 12:29:18,966 - INFO - [Train] [40/90] | Loss: 0.2281 | Train Acc: 99.40%
2026-01-14 12:29:22,233 - INFO - [Valid] [40/90] | Loss: 0.6337 | Val Acc: 79.06%
2026-01-14 12:29:22,246 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-01-14 12:29:22,247 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-01-14 12:29:22,251 - INFO - --------------------------------------------------
2026-01-14 12:29:22,255 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 12:29:33,319 - INFO - [Train] [41/90] | Loss: 0.2328 | Train Acc: 98.59%
2026-01-14 12:29:35,647 - INFO - [Valid] [41/90] | Loss: 0.5319 | Val Acc: 80.24%
2026-01-14 12:29:35,659 - INFO - [Metrics for 'abnormal'] | Precision: 0.8214 | Recall: 0.7325 | F1: 0.7744
2026-01-14 12:29:35,660 - INFO - [Metrics for 'normal'] | Precision: 0.7889 | Recall: 0.8626 | F1: 0.8241
2026-01-14 12:29:35,664 - INFO - --------------------------------------------------
2026-01-14 12:29:35,667 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 12:29:46,469 - INFO - [Train] [42/90] | Loss: 0.2329 | Train Acc: 98.66%
2026-01-14 12:29:48,555 - INFO - [Valid] [42/90] | Loss: 0.6062 | Val Acc: 78.17%
2026-01-14 12:29:48,569 - INFO - [Metrics for 'abnormal'] | Precision: 0.7399 | Recall: 0.8153 | F1: 0.7758
2026-01-14 12:29:48,570 - INFO - [Metrics for 'normal'] | Precision: 0.8253 | Recall: 0.7527 | F1: 0.7874
2026-01-14 12:29:48,576 - INFO - --------------------------------------------------
2026-01-14 12:29:48,580 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 12:29:58,988 - INFO - [Train] [43/90] | Loss: 0.2412 | Train Acc: 98.14%
2026-01-14 12:30:01,015 - INFO - [Valid] [43/90] | Loss: 0.5991 | Val Acc: 78.76%
2026-01-14 12:30:01,026 - INFO - [Metrics for 'abnormal'] | Precision: 0.7348 | Recall: 0.8471 | F1: 0.7870
2026-01-14 12:30:01,027 - INFO - [Metrics for 'normal'] | Precision: 0.8481 | Recall: 0.7363 | F1: 0.7882
2026-01-14 12:30:01,031 - INFO - --------------------------------------------------
2026-01-14 12:30:01,035 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 12:30:10,683 - INFO - [Train] [44/90] | Loss: 0.2281 | Train Acc: 98.88%
2026-01-14 12:30:12,652 - INFO - [Valid] [44/90] | Loss: 0.5967 | Val Acc: 80.53%
2026-01-14 12:30:12,665 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 12:30:12,666 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 12:30:12,671 - INFO - --------------------------------------------------
2026-01-14 12:30:12,675 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 12:30:22,766 - INFO - [Train] [45/90] | Loss: 0.2249 | Train Acc: 99.18%
2026-01-14 12:30:25,238 - INFO - [Valid] [45/90] | Loss: 0.6081 | Val Acc: 81.71%
2026-01-14 12:30:25,251 - INFO - [Metrics for 'abnormal'] | Precision: 0.7684 | Recall: 0.8662 | F1: 0.8144
2026-01-14 12:30:25,251 - INFO - [Metrics for 'normal'] | Precision: 0.8704 | Recall: 0.7747 | F1: 0.8198
2026-01-14 12:30:25,256 - INFO - --------------------------------------------------
2026-01-14 12:30:25,260 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 12:30:34,629 - INFO - [Train] [46/90] | Loss: 0.2302 | Train Acc: 98.74%
2026-01-14 12:30:36,962 - INFO - [Valid] [46/90] | Loss: 0.5380 | Val Acc: 80.24%
2026-01-14 12:30:37,008 - INFO - [Metrics for 'abnormal'] | Precision: 0.7616 | Recall: 0.8344 | F1: 0.7964
2026-01-14 12:30:37,009 - INFO - [Metrics for 'normal'] | Precision: 0.8443 | Recall: 0.7747 | F1: 0.8080
2026-01-14 12:30:37,023 - INFO - --------------------------------------------------
2026-01-14 12:30:37,033 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 12:30:46,687 - INFO - [Train] [47/90] | Loss: 0.2269 | Train Acc: 99.26%
2026-01-14 12:30:49,021 - INFO - [Valid] [47/90] | Loss: 0.5655 | Val Acc: 81.12%
2026-01-14 12:30:49,035 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 12:30:49,035 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 12:30:49,040 - INFO - --------------------------------------------------
2026-01-14 12:30:49,047 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 12:30:59,672 - INFO - [Train] [48/90] | Loss: 0.2268 | Train Acc: 98.88%
2026-01-14 12:31:02,451 - INFO - [Valid] [48/90] | Loss: 0.5331 | Val Acc: 81.42%
2026-01-14 12:31:02,476 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-01-14 12:31:02,476 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-01-14 12:31:02,481 - INFO - --------------------------------------------------
2026-01-14 12:31:02,485 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 12:31:13,556 - INFO - [Train] [49/90] | Loss: 0.2188 | Train Acc: 99.63%
2026-01-14 12:31:16,083 - INFO - [Valid] [49/90] | Loss: 0.5463 | Val Acc: 80.83%
2026-01-14 12:31:16,098 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 12:31:16,099 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 12:31:16,104 - INFO - --------------------------------------------------
2026-01-14 12:31:16,109 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 12:31:26,315 - INFO - [Train] [50/90] | Loss: 0.2183 | Train Acc: 99.26%
2026-01-14 12:31:28,415 - INFO - [Valid] [50/90] | Loss: 0.5568 | Val Acc: 81.12%
2026-01-14 12:31:28,428 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-01-14 12:31:28,429 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-01-14 12:31:28,436 - INFO - --------------------------------------------------
2026-01-14 12:31:28,440 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 12:31:38,801 - INFO - [Train] [51/90] | Loss: 0.2207 | Train Acc: 99.33%
2026-01-14 12:31:41,594 - INFO - [Valid] [51/90] | Loss: 0.5531 | Val Acc: 82.89%
2026-01-14 12:31:41,617 - INFO - [Metrics for 'abnormal'] | Precision: 0.8037 | Recall: 0.8344 | F1: 0.8187
2026-01-14 12:31:41,621 - INFO - [Metrics for 'normal'] | Precision: 0.8523 | Recall: 0.8242 | F1: 0.8380
2026-01-14 12:31:41,628 - INFO - --------------------------------------------------
2026-01-14 12:31:41,634 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 12:31:50,631 - INFO - [Train] [52/90] | Loss: 0.2276 | Train Acc: 98.74%
2026-01-14 12:31:53,104 - INFO - [Valid] [52/90] | Loss: 0.5810 | Val Acc: 80.24%
2026-01-14 12:31:53,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 12:31:53,116 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 12:31:53,124 - INFO - --------------------------------------------------
2026-01-14 12:31:53,126 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 12:32:02,941 - INFO - [Train] [53/90] | Loss: 0.2202 | Train Acc: 99.40%
2026-01-14 12:32:05,291 - INFO - [Valid] [53/90] | Loss: 0.6039 | Val Acc: 81.42%
2026-01-14 12:32:05,302 - INFO - [Metrics for 'abnormal'] | Precision: 0.7831 | Recall: 0.8280 | F1: 0.8050
2026-01-14 12:32:05,302 - INFO - [Metrics for 'normal'] | Precision: 0.8439 | Recall: 0.8022 | F1: 0.8225
2026-01-14 12:32:05,306 - INFO - --------------------------------------------------
2026-01-14 12:32:05,310 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 12:32:14,557 - INFO - [Train] [54/90] | Loss: 0.2185 | Train Acc: 99.26%
2026-01-14 12:32:17,172 - INFO - [Valid] [54/90] | Loss: 0.5581 | Val Acc: 80.24%
2026-01-14 12:32:17,185 - INFO - [Metrics for 'abnormal'] | Precision: 0.7885 | Recall: 0.7834 | F1: 0.7859
2026-01-14 12:32:17,189 - INFO - [Metrics for 'normal'] | Precision: 0.8142 | Recall: 0.8187 | F1: 0.8164
2026-01-14 12:32:17,194 - INFO - --------------------------------------------------
2026-01-14 12:32:17,197 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 12:32:27,249 - INFO - [Train] [55/90] | Loss: 0.2131 | Train Acc: 99.85%
2026-01-14 12:32:29,944 - INFO - [Valid] [55/90] | Loss: 0.5967 | Val Acc: 79.65%
2026-01-14 12:32:29,957 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-01-14 12:32:29,958 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-01-14 12:32:29,962 - INFO - --------------------------------------------------
2026-01-14 12:32:29,966 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 12:32:38,986 - INFO - [Train] [56/90] | Loss: 0.2114 | Train Acc: 99.78%
2026-01-14 12:32:42,876 - INFO - [Valid] [56/90] | Loss: 0.6299 | Val Acc: 79.06%
2026-01-14 12:32:42,889 - INFO - [Metrics for 'abnormal'] | Precision: 0.7263 | Recall: 0.8790 | F1: 0.7954
2026-01-14 12:32:42,890 - INFO - [Metrics for 'normal'] | Precision: 0.8725 | Recall: 0.7143 | F1: 0.7855
2026-01-14 12:32:42,895 - INFO - --------------------------------------------------
2026-01-14 12:32:42,899 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 12:32:54,079 - INFO - [Train] [57/90] | Loss: 0.2115 | Train Acc: 99.70%
2026-01-14 12:32:56,447 - INFO - [Valid] [57/90] | Loss: 0.5585 | Val Acc: 81.12%
2026-01-14 12:32:56,471 - INFO - [Metrics for 'abnormal'] | Precision: 0.7688 | Recall: 0.8471 | F1: 0.8061
2026-01-14 12:32:56,473 - INFO - [Metrics for 'normal'] | Precision: 0.8554 | Recall: 0.7802 | F1: 0.8161
2026-01-14 12:32:56,481 - INFO - --------------------------------------------------
2026-01-14 12:32:56,487 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 12:33:06,370 - INFO - [Train] [58/90] | Loss: 0.2165 | Train Acc: 99.63%
2026-01-14 12:33:08,682 - INFO - [Valid] [58/90] | Loss: 0.5466 | Val Acc: 82.30%
2026-01-14 12:33:08,696 - INFO - [Metrics for 'abnormal'] | Precision: 0.8345 | Recall: 0.7707 | F1: 0.8013
2026-01-14 12:33:08,697 - INFO - [Metrics for 'normal'] | Precision: 0.8144 | Recall: 0.8681 | F1: 0.8404
2026-01-14 12:33:08,701 - INFO - --------------------------------------------------
2026-01-14 12:33:08,706 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 12:33:18,316 - INFO - [Train] [59/90] | Loss: 0.2163 | Train Acc: 99.33%
2026-01-14 12:33:20,631 - INFO - [Valid] [59/90] | Loss: 0.5182 | Val Acc: 82.01%
2026-01-14 12:33:20,640 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 12:33:20,641 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 12:33:20,644 - INFO - --------------------------------------------------
2026-01-14 12:33:20,647 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 12:33:30,678 - INFO - [Train] [60/90] | Loss: 0.2114 | Train Acc: 99.63%
2026-01-14 12:33:32,915 - INFO - [Valid] [60/90] | Loss: 0.5902 | Val Acc: 81.42%
2026-01-14 12:33:32,928 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 12:33:32,929 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 12:33:32,933 - INFO - --------------------------------------------------
2026-01-14 12:33:32,938 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 12:33:42,683 - INFO - [Train] [61/90] | Loss: 0.2084 | Train Acc: 99.78%
2026-01-14 12:33:45,465 - INFO - [Valid] [61/90] | Loss: 0.5728 | Val Acc: 82.60%
2026-01-14 12:33:45,478 - INFO - [Metrics for 'abnormal'] | Precision: 0.8025 | Recall: 0.8280 | F1: 0.8150
2026-01-14 12:33:45,479 - INFO - [Metrics for 'normal'] | Precision: 0.8475 | Recall: 0.8242 | F1: 0.8357
2026-01-14 12:33:45,484 - INFO - --------------------------------------------------
2026-01-14 12:33:45,489 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 12:33:55,388 - INFO - [Train] [62/90] | Loss: 0.2065 | Train Acc: 99.78%
2026-01-14 12:33:57,627 - INFO - [Valid] [62/90] | Loss: 0.5947 | Val Acc: 82.30%
2026-01-14 12:33:57,648 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 12:33:57,651 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 12:33:57,657 - INFO - --------------------------------------------------
2026-01-14 12:33:57,663 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 12:34:07,958 - INFO - [Train] [63/90] | Loss: 0.2048 | Train Acc: 100.00%
2026-01-14 12:34:10,478 - INFO - [Valid] [63/90] | Loss: 0.5704 | Val Acc: 82.30%
2026-01-14 12:34:10,491 - INFO - [Metrics for 'abnormal'] | Precision: 0.8212 | Recall: 0.7898 | F1: 0.8052
2026-01-14 12:34:10,492 - INFO - [Metrics for 'normal'] | Precision: 0.8245 | Recall: 0.8516 | F1: 0.8378
2026-01-14 12:34:10,496 - INFO - --------------------------------------------------
2026-01-14 12:34:10,500 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 12:34:20,583 - INFO - [Train] [64/90] | Loss: 0.2107 | Train Acc: 99.55%
2026-01-14 12:34:22,857 - INFO - [Valid] [64/90] | Loss: 0.5560 | Val Acc: 82.89%
2026-01-14 12:34:22,868 - INFO - [Metrics for 'abnormal'] | Precision: 0.8194 | Recall: 0.8089 | F1: 0.8141
2026-01-14 12:34:22,869 - INFO - [Metrics for 'normal'] | Precision: 0.8370 | Recall: 0.8462 | F1: 0.8415
2026-01-14 12:34:22,895 - INFO - --------------------------------------------------
2026-01-14 12:34:22,899 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 12:34:32,360 - INFO - [Train] [65/90] | Loss: 0.2077 | Train Acc: 99.70%
2026-01-14 12:34:34,194 - INFO - [Valid] [65/90] | Loss: 0.5865 | Val Acc: 80.83%
2026-01-14 12:34:34,205 - INFO - [Metrics for 'abnormal'] | Precision: 0.8026 | Recall: 0.7771 | F1: 0.7896
2026-01-14 12:34:34,206 - INFO - [Metrics for 'normal'] | Precision: 0.8128 | Recall: 0.8352 | F1: 0.8238
2026-01-14 12:34:34,210 - INFO - --------------------------------------------------
2026-01-14 12:34:34,214 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 12:34:44,333 - INFO - [Train] [66/90] | Loss: 0.2057 | Train Acc: 99.78%
2026-01-14 12:34:47,225 - INFO - [Valid] [66/90] | Loss: 0.5745 | Val Acc: 80.83%
2026-01-14 12:34:47,237 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-01-14 12:34:47,238 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-01-14 12:34:47,250 - INFO - --------------------------------------------------
2026-01-14 12:34:47,252 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 12:34:56,362 - INFO - [Train] [67/90] | Loss: 0.2052 | Train Acc: 99.78%
2026-01-14 12:35:00,020 - INFO - [Valid] [67/90] | Loss: 0.5656 | Val Acc: 81.12%
2026-01-14 12:35:00,050 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 12:35:00,050 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 12:35:00,059 - INFO - --------------------------------------------------
2026-01-14 12:35:00,066 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 12:35:09,378 - INFO - [Train] [68/90] | Loss: 0.2038 | Train Acc: 99.85%
2026-01-14 12:35:12,766 - INFO - [Valid] [68/90] | Loss: 0.5995 | Val Acc: 82.01%
2026-01-14 12:35:12,778 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.8153 | F1: 0.8076
2026-01-14 12:35:12,779 - INFO - [Metrics for 'normal'] | Precision: 0.8380 | Recall: 0.8242 | F1: 0.8310
2026-01-14 12:35:12,783 - INFO - --------------------------------------------------
2026-01-14 12:35:12,787 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 12:35:22,100 - INFO - [Train] [69/90] | Loss: 0.2047 | Train Acc: 99.85%
2026-01-14 12:35:25,516 - INFO - [Valid] [69/90] | Loss: 0.5793 | Val Acc: 81.71%
2026-01-14 12:35:25,528 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-01-14 12:35:25,528 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-01-14 12:35:25,533 - INFO - --------------------------------------------------
2026-01-14 12:35:25,537 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 12:35:34,234 - INFO - [Train] [70/90] | Loss: 0.2047 | Train Acc: 99.93%
2026-01-14 12:35:37,080 - INFO - [Valid] [70/90] | Loss: 0.5907 | Val Acc: 81.71%
2026-01-14 12:35:37,108 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-01-14 12:35:37,108 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-01-14 12:35:37,112 - INFO - --------------------------------------------------
2026-01-14 12:35:37,117 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 12:35:46,284 - INFO - [Train] [71/90] | Loss: 0.2028 | Train Acc: 99.85%
2026-01-14 12:35:50,880 - INFO - [Valid] [71/90] | Loss: 0.5716 | Val Acc: 82.01%
2026-01-14 12:35:50,895 - INFO - [Metrics for 'abnormal'] | Precision: 0.8200 | Recall: 0.7834 | F1: 0.8013
2026-01-14 12:35:50,951 - INFO - [Metrics for 'normal'] | Precision: 0.8201 | Recall: 0.8516 | F1: 0.8356
2026-01-14 12:35:50,956 - INFO - --------------------------------------------------
2026-01-14 12:35:50,986 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 12:36:01,659 - INFO - [Train] [72/90] | Loss: 0.2037 | Train Acc: 99.85%
2026-01-14 12:36:03,714 - INFO - [Valid] [72/90] | Loss: 0.5990 | Val Acc: 82.30%
2026-01-14 12:36:03,724 - INFO - [Metrics for 'abnormal'] | Precision: 0.7870 | Recall: 0.8471 | F1: 0.8160
2026-01-14 12:36:03,724 - INFO - [Metrics for 'normal'] | Precision: 0.8588 | Recall: 0.8022 | F1: 0.8295
2026-01-14 12:36:03,727 - INFO - --------------------------------------------------
2026-01-14 12:36:03,730 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 12:36:12,238 - INFO - [Train] [73/90] | Loss: 0.2022 | Train Acc: 99.93%
2026-01-14 12:36:14,063 - INFO - [Valid] [73/90] | Loss: 0.5951 | Val Acc: 81.42%
2026-01-14 12:36:14,076 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 12:36:14,077 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 12:36:14,081 - INFO - --------------------------------------------------
2026-01-14 12:36:14,085 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 12:36:19,868 - INFO - [Train] [74/90] | Loss: 0.2019 | Train Acc: 99.93%
2026-01-14 12:36:21,765 - INFO - [Valid] [74/90] | Loss: 0.6019 | Val Acc: 82.01%
2026-01-14 12:36:21,783 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-01-14 12:36:21,783 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-01-14 12:36:21,790 - INFO - --------------------------------------------------
2026-01-14 12:36:21,795 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 12:36:29,793 - INFO - [Train] [75/90] | Loss: 0.2055 | Train Acc: 99.85%
2026-01-14 12:36:31,341 - INFO - [Valid] [75/90] | Loss: 0.5813 | Val Acc: 82.01%
2026-01-14 12:36:31,359 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-01-14 12:36:31,359 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-01-14 12:36:31,365 - INFO - --------------------------------------------------
2026-01-14 12:36:31,368 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 12:36:42,187 - INFO - [Train] [76/90] | Loss: 0.2034 | Train Acc: 100.00%
2026-01-14 12:36:43,714 - INFO - [Valid] [76/90] | Loss: 0.5838 | Val Acc: 82.01%
2026-01-14 12:36:43,726 - INFO - [Metrics for 'abnormal'] | Precision: 0.8038 | Recall: 0.8089 | F1: 0.8063
2026-01-14 12:36:43,726 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8297 | F1: 0.8320
2026-01-14 12:36:43,731 - INFO - --------------------------------------------------
2026-01-14 12:36:43,734 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 12:36:49,236 - INFO - [Train] [77/90] | Loss: 0.2050 | Train Acc: 99.63%
2026-01-14 12:36:50,700 - INFO - [Valid] [77/90] | Loss: 0.5672 | Val Acc: 82.30%
2026-01-14 12:36:50,708 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 12:36:50,708 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 12:36:50,710 - INFO - --------------------------------------------------
2026-01-14 12:36:50,712 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 12:36:55,672 - INFO - [Train] [78/90] | Loss: 0.2025 | Train Acc: 99.93%
2026-01-14 12:36:57,164 - INFO - [Valid] [78/90] | Loss: 0.5798 | Val Acc: 81.42%
2026-01-14 12:36:57,172 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 12:36:57,173 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 12:36:57,176 - INFO - --------------------------------------------------
2026-01-14 12:36:57,178 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 12:37:02,506 - INFO - [Train] [79/90] | Loss: 0.2003 | Train Acc: 100.00%
2026-01-14 12:37:03,974 - INFO - [Valid] [79/90] | Loss: 0.5856 | Val Acc: 81.42%
2026-01-14 12:37:03,982 - INFO - [Metrics for 'abnormal'] | Precision: 0.7901 | Recall: 0.8153 | F1: 0.8025
2026-01-14 12:37:03,982 - INFO - [Metrics for 'normal'] | Precision: 0.8362 | Recall: 0.8132 | F1: 0.8245
2026-01-14 12:37:03,985 - INFO - --------------------------------------------------
2026-01-14 12:37:03,987 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 12:37:09,069 - INFO - [Train] [80/90] | Loss: 0.2007 | Train Acc: 100.00%
2026-01-14 12:37:10,396 - INFO - [Valid] [80/90] | Loss: 0.5810 | Val Acc: 82.01%
2026-01-14 12:37:10,403 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.8217 | F1: 0.8088
2026-01-14 12:37:10,403 - INFO - [Metrics for 'normal'] | Precision: 0.8418 | Recall: 0.8187 | F1: 0.8301
2026-01-14 12:37:10,406 - INFO - --------------------------------------------------
2026-01-14 12:37:10,408 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 12:37:15,152 - INFO - [Train] [81/90] | Loss: 0.2024 | Train Acc: 99.93%
2026-01-14 12:37:16,597 - INFO - [Valid] [81/90] | Loss: 0.5829 | Val Acc: 80.83%
2026-01-14 12:37:16,610 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 12:37:16,610 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 12:37:16,614 - INFO - --------------------------------------------------
2026-01-14 12:37:16,618 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 12:37:21,785 - INFO - [Train] [82/90] | Loss: 0.2016 | Train Acc: 99.85%
2026-01-14 12:37:24,111 - INFO - [Valid] [82/90] | Loss: 0.5937 | Val Acc: 80.53%
2026-01-14 12:37:24,122 - INFO - [Metrics for 'abnormal'] | Precision: 0.7725 | Recall: 0.8217 | F1: 0.7963
2026-01-14 12:37:24,123 - INFO - [Metrics for 'normal'] | Precision: 0.8372 | Recall: 0.7912 | F1: 0.8136
2026-01-14 12:37:24,126 - INFO - --------------------------------------------------
2026-01-14 12:37:24,129 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 12:37:30,138 - INFO - [Train] [83/90] | Loss: 0.2033 | Train Acc: 99.85%
2026-01-14 12:37:31,488 - INFO - [Valid] [83/90] | Loss: 0.5812 | Val Acc: 82.01%
2026-01-14 12:37:31,496 - INFO - [Metrics for 'abnormal'] | Precision: 0.8158 | Recall: 0.7898 | F1: 0.8026
2026-01-14 12:37:31,496 - INFO - [Metrics for 'normal'] | Precision: 0.8235 | Recall: 0.8462 | F1: 0.8347
2026-01-14 12:37:31,498 - INFO - --------------------------------------------------
2026-01-14 12:37:31,500 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 12:37:36,170 - INFO - [Train] [84/90] | Loss: 0.2016 | Train Acc: 99.85%
2026-01-14 12:37:37,518 - INFO - [Valid] [84/90] | Loss: 0.5754 | Val Acc: 81.12%
2026-01-14 12:37:37,528 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 12:37:37,528 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 12:37:37,531 - INFO - --------------------------------------------------
2026-01-14 12:37:37,533 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 12:37:42,017 - INFO - [Train] [85/90] | Loss: 0.2005 | Train Acc: 100.00%
2026-01-14 12:37:43,343 - INFO - [Valid] [85/90] | Loss: 0.5901 | Val Acc: 81.42%
2026-01-14 12:37:43,351 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 12:37:43,351 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 12:37:43,354 - INFO - --------------------------------------------------
2026-01-14 12:37:43,355 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 12:37:47,754 - INFO - [Train] [86/90] | Loss: 0.2011 | Train Acc: 99.85%
2026-01-14 12:37:49,086 - INFO - [Valid] [86/90] | Loss: 0.5942 | Val Acc: 81.42%
2026-01-14 12:37:49,095 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-01-14 12:37:49,095 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-01-14 12:37:49,098 - INFO - --------------------------------------------------
2026-01-14 12:37:49,100 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 12:37:53,592 - INFO - [Train] [87/90] | Loss: 0.2000 | Train Acc: 100.00%
2026-01-14 12:37:54,830 - INFO - [Valid] [87/90] | Loss: 0.5932 | Val Acc: 80.83%
2026-01-14 12:37:54,839 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 12:37:54,840 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 12:37:54,843 - INFO - --------------------------------------------------
2026-01-14 12:37:54,845 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 12:37:59,311 - INFO - [Train] [88/90] | Loss: 0.2033 | Train Acc: 99.78%
2026-01-14 12:38:00,635 - INFO - [Valid] [88/90] | Loss: 0.5898 | Val Acc: 82.01%
2026-01-14 12:38:00,644 - INFO - [Metrics for 'abnormal'] | Precision: 0.8038 | Recall: 0.8089 | F1: 0.8063
2026-01-14 12:38:00,644 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8297 | F1: 0.8320
2026-01-14 12:38:00,647 - INFO - --------------------------------------------------
2026-01-14 12:38:00,649 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 12:38:05,336 - INFO - [Train] [89/90] | Loss: 0.2051 | Train Acc: 99.78%
2026-01-14 12:38:06,789 - INFO - [Valid] [89/90] | Loss: 0.5741 | Val Acc: 82.60%
2026-01-14 12:38:06,797 - INFO - [Metrics for 'abnormal'] | Precision: 0.8182 | Recall: 0.8025 | F1: 0.8103
2026-01-14 12:38:06,798 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8462 | F1: 0.8392
2026-01-14 12:38:06,801 - INFO - --------------------------------------------------
2026-01-14 12:38:06,803 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 12:38:11,489 - INFO - [Train] [90/90] | Loss: 0.2147 | Train Acc: 99.48%
2026-01-14 12:38:12,856 - INFO - [Valid] [90/90] | Loss: 0.5868 | Val Acc: 82.89%
2026-01-14 12:38:12,863 - INFO - [Metrics for 'abnormal'] | Precision: 0.8367 | Recall: 0.7834 | F1: 0.8092
2026-01-14 12:38:12,864 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.8681 | F1: 0.8449
2026-01-14 12:38:12,867 - INFO - ==================================================
2026-01-14 12:38:12,867 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 12:38:12,867 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 12:38:12,867 - INFO - Baseline 모델 'mobile_vit_xxs'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:38:12,913 - INFO - timm 모델(mobile_vit_xxs)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-01-14 12:38:12,929 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 12:38:12,930 - INFO - FPGM Pruning을 시작합니다.
2026-01-14 12:38:12,930 - INFO - 분류 레이어 'ClassifierHead'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:38:12,931 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-01-14 12:38:13,641 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.4756640625)에 맞춰 변경되었습니다.
2026-01-14 12:38:13,641 - INFO - ==================================================
2026-01-14 12:38:13,746 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/best_model.pth'
2026-01-14 12:38:13,746 - INFO - ==================================================
2026-01-14 12:38:13,746 - INFO - Test 모드를 시작합니다.
2026-01-14 12:38:13,866 - INFO - 연산량 (MACs): 0.0913 GMACs per sample
2026-01-14 12:38:13,866 - INFO - 연산량 (FLOPs): 0.1826 GFLOPs per sample
2026-01-14 12:38:13,866 - INFO - ==================================================
2026-01-14 12:38:13,866 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 12:38:15,431 - INFO - 샘플 당 평균 Forward Pass 시간: 10.16ms (std: 2.78ms), FPS: 105.27 (std: 25.14) (1개 샘플 x 100회 반복)
2026-01-14 12:38:15,431 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 44.36 MB
2026-01-14 12:38:15,431 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 12:38:17,746 - INFO - [Test] Loss: 0.4224 | Test Acc: 82.60%
2026-01-14 12:38:17,761 - INFO - [Metrics for 'abnormal'] | Precision: 0.8141 | Recall: 0.8089 | F1: 0.8115
2026-01-14 12:38:17,761 - INFO - [Metrics for 'normal'] | Precision: 0.8361 | Recall: 0.8407 | F1: 0.8384
2026-01-14 12:38:18,275 - INFO - ==================================================
2026-01-14 12:38:18,276 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/confusion_matrix_20260114_121919.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/confusion_matrix_20260114_121919.pdf'
2026-01-14 12:38:18,276 - INFO - ==================================================
2026-01-14 12:38:18,276 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 12:38:19,640 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/model_fp32_20260114_121919.onnx'에 저장되었습니다. (크기: 1.44 MB)
2026-01-14 12:38:20,036 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2619.66 MB (증가량: 7.39 MB)
2026-01-14 12:38:20,037 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 12:38:21,949 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 14.84ms (std: 13.80ms)
2026-01-14 12:38:21,949 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 85.72 FPS (std: 26.00) (1개 샘플 x 100회 반복)
2026-01-14 12:38:21,949 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2629.16 MB (순수 증가량: 9.50 MB)
2026-01-14 12:38:21,950 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2629.16 MB (전체 증가량: 16.89 MB)
2026-01-14 12:38:25,699 - INFO - [Test (ONNX)] | Test Acc (ONNX): 82.60%
2026-01-14 12:38:25,710 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8141 | Recall: 0.8089 | F1: 0.8115
2026-01-14 12:38:25,710 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8361 | Recall: 0.8407 | F1: 0.8384
2026-01-14 12:38:26,173 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/val_acc.pdf'
2026-01-14 12:38:26,625 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/train_val_acc.pdf'
2026-01-14 12:38:27,038 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/F1_normal.pdf'
2026-01-14 12:38:27,516 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/val_loss.pdf'
2026-01-14 12:38:27,854 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/learning_rate.pdf'
2026-01-14 12:38:31,957 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/compile.png' and 'log/Sewer-TAPNEW/baseline_mobile_vit_xxs_fpgm_20260114_121919/graph_20260114_121919/compile.pdf'
