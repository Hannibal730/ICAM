2026-01-14 11:55:45,737 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/log_20260114_115545.log'에 저장됩니다.
2026-01-14 11:55:45,746 - INFO - ==================================================
2026-01-14 11:55:45,746 - INFO - config.yaml:
2026-01-14 11:55:45,747 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: mobilenet_v4_s
  use_l1_pruning: true
  pruning_flops_target: 0.1829

2026-01-14 11:55:45,747 - INFO - ==================================================
2026-01-14 11:55:45,815 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 11:55:45,816 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 11:55:45,816 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 11:55:45,831 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 11:55:45,832 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 11:55:45,833 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 11:55:45,833 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 11:55:46,100 - INFO - ==================================================
2026-01-14 11:55:46,100 - INFO - 모델 파라미터 수:
2026-01-14 11:55:46,101 - INFO -   - 총 파라미터: 2,495,586 개
2026-01-14 11:55:46,101 - INFO -   - 학습 가능한 파라미터: 2,495,586 개
2026-01-14 11:55:46,101 - INFO - ================================================================================
2026-01-14 11:55:46,101 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 11:55:46,101 - INFO - ================================================================================
2026-01-14 11:55:46,101 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 11:55:46,102 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 11:55:46,102 - INFO - ==================================================
2026-01-14 11:55:46,102 - INFO - train 모드를 시작합니다.
2026-01-14 11:55:46,103 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 11:55:46,103 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 11:55:46,103 - INFO - --------------------------------------------------
2026-01-14 11:55:46,105 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 11:55:52,682 - INFO - [Train] [1/10] | Loss: 2.9175 | Train Acc: 67.56%
2026-01-14 11:55:55,093 - INFO - [Valid] [1/10] | Loss: 0.6761 | Val Acc: 72.57%
2026-01-14 11:55:55,118 - INFO - [Metrics for 'abnormal'] | Precision: 0.7963 | Recall: 0.5478 | F1: 0.6491
2026-01-14 11:55:55,120 - INFO - [Metrics for 'normal'] | Precision: 0.6926 | Recall: 0.8791 | F1: 0.7748
2026-01-14 11:55:55,184 - INFO - [Best Model Saved] (val loss: 0.6761) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:55:55,185 - INFO - --------------------------------------------------
2026-01-14 11:55:55,186 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 11:56:00,500 - INFO - [Train] [2/10] | Loss: 0.7497 | Train Acc: 70.01%
2026-01-14 11:56:02,123 - INFO - [Valid] [2/10] | Loss: 0.7040 | Val Acc: 67.26%
2026-01-14 11:56:02,136 - INFO - [Metrics for 'abnormal'] | Precision: 0.6513 | Recall: 0.6306 | F1: 0.6408
2026-01-14 11:56:02,136 - INFO - [Metrics for 'normal'] | Precision: 0.6898 | Recall: 0.7088 | F1: 0.6992
2026-01-14 11:56:02,140 - INFO - --------------------------------------------------
2026-01-14 11:56:02,143 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 11:56:07,259 - INFO - [Train] [3/10] | Loss: 0.6390 | Train Acc: 74.03%
2026-01-14 11:56:08,885 - INFO - [Valid] [3/10] | Loss: 1.0994 | Val Acc: 66.67%
2026-01-14 11:56:08,899 - INFO - [Metrics for 'abnormal'] | Precision: 0.8333 | Recall: 0.3503 | F1: 0.4933
2026-01-14 11:56:08,899 - INFO - [Metrics for 'normal'] | Precision: 0.6264 | Recall: 0.9396 | F1: 0.7516
2026-01-14 11:56:08,904 - INFO - --------------------------------------------------
2026-01-14 11:56:08,907 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 11:56:13,943 - INFO - [Train] [4/10] | Loss: 0.5864 | Train Acc: 75.67%
2026-01-14 11:56:15,901 - INFO - [Valid] [4/10] | Loss: 0.7546 | Val Acc: 68.44%
2026-01-14 11:56:15,928 - INFO - [Metrics for 'abnormal'] | Precision: 0.7155 | Recall: 0.5287 | F1: 0.6081
2026-01-14 11:56:15,929 - INFO - [Metrics for 'normal'] | Precision: 0.6682 | Recall: 0.8187 | F1: 0.7358
2026-01-14 11:56:15,935 - INFO - --------------------------------------------------
2026-01-14 11:56:15,941 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 11:56:21,815 - INFO - [Train] [5/10] | Loss: 0.6195 | Train Acc: 73.88%
2026-01-14 11:56:23,828 - INFO - [Valid] [5/10] | Loss: 0.8189 | Val Acc: 75.22%
2026-01-14 11:56:23,841 - INFO - [Metrics for 'abnormal'] | Precision: 0.7160 | Recall: 0.7707 | F1: 0.7423
2026-01-14 11:56:23,842 - INFO - [Metrics for 'normal'] | Precision: 0.7882 | Recall: 0.7363 | F1: 0.7614
2026-01-14 11:56:23,846 - INFO - --------------------------------------------------
2026-01-14 11:56:23,849 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 11:56:30,099 - INFO - [Train] [6/10] | Loss: 0.5554 | Train Acc: 77.83%
2026-01-14 11:56:32,028 - INFO - [Valid] [6/10] | Loss: 1.3452 | Val Acc: 51.03%
2026-01-14 11:56:32,039 - INFO - [Metrics for 'abnormal'] | Precision: 0.4859 | Recall: 0.9873 | F1: 0.6513
2026-01-14 11:56:32,040 - INFO - [Metrics for 'normal'] | Precision: 0.9000 | Recall: 0.0989 | F1: 0.1782
2026-01-14 11:56:32,043 - INFO - --------------------------------------------------
2026-01-14 11:56:32,046 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 11:56:37,889 - INFO - [Train] [7/10] | Loss: 0.5234 | Train Acc: 80.65%
2026-01-14 11:56:39,427 - INFO - [Valid] [7/10] | Loss: 0.6652 | Val Acc: 71.68%
2026-01-14 11:56:39,440 - INFO - [Metrics for 'abnormal'] | Precision: 0.7293 | Recall: 0.6178 | F1: 0.6690
2026-01-14 11:56:39,440 - INFO - [Metrics for 'normal'] | Precision: 0.7087 | Recall: 0.8022 | F1: 0.7526
2026-01-14 11:56:39,493 - INFO - [Best Model Saved] (val loss: 0.6652) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:56:39,493 - INFO - --------------------------------------------------
2026-01-14 11:56:39,495 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 11:56:44,834 - INFO - [Train] [8/10] | Loss: 0.4946 | Train Acc: 81.10%
2026-01-14 11:56:46,270 - INFO - [Valid] [8/10] | Loss: 0.5320 | Val Acc: 78.76%
2026-01-14 11:56:46,279 - INFO - [Metrics for 'abnormal'] | Precision: 0.7742 | Recall: 0.7643 | F1: 0.7692
2026-01-14 11:56:46,279 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8077 | F1: 0.8033
2026-01-14 11:56:46,325 - INFO - [Best Model Saved] (val loss: 0.5320) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:56:46,325 - INFO - --------------------------------------------------
2026-01-14 11:56:46,327 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 11:56:52,969 - INFO - [Train] [9/10] | Loss: 0.4576 | Train Acc: 82.74%
2026-01-14 11:56:54,757 - INFO - [Valid] [9/10] | Loss: 0.5522 | Val Acc: 79.94%
2026-01-14 11:56:54,768 - INFO - [Metrics for 'abnormal'] | Precision: 0.8248 | Recall: 0.7197 | F1: 0.7687
2026-01-14 11:56:54,769 - INFO - [Metrics for 'normal'] | Precision: 0.7822 | Recall: 0.8681 | F1: 0.8229
2026-01-14 11:56:54,772 - INFO - --------------------------------------------------
2026-01-14 11:56:54,775 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 11:57:01,294 - INFO - [Train] [10/10] | Loss: 0.4571 | Train Acc: 83.63%
2026-01-14 11:57:02,976 - INFO - [Valid] [10/10] | Loss: 0.5507 | Val Acc: 81.12%
2026-01-14 11:57:02,984 - INFO - [Metrics for 'abnormal'] | Precision: 0.8079 | Recall: 0.7771 | F1: 0.7922
2026-01-14 11:57:02,985 - INFO - [Metrics for 'normal'] | Precision: 0.8138 | Recall: 0.8407 | F1: 0.8270
2026-01-14 11:57:02,988 - INFO - ================================================================================
2026-01-14 11:57:02,989 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 11:57:02,989 - INFO - ================================================================================
2026-01-14 11:57:03,059 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'을(를) 불러왔습니다.
2026-01-14 11:57:03,060 - INFO - ================================================================================
2026-01-14 11:57:03,060 - INFO - 목표 FLOPs (0.1829 GFLOPs)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 11:57:03,130 - INFO - 원본 모델 FLOPs: 0.3853 GFLOPs
2026-01-14 11:57:03,228 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:03,228 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:03,490 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 11:57:03,490 - INFO - ==================================================
2026-01-14 11:57:03,571 - INFO -   [탐색  1] 희소도: 0.4950 -> FLOPs: 0.1092 GFLOPs (감소율: 71.66%)
2026-01-14 11:57:03,644 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:03,645 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:03,826 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.2475)에 맞춰 변경되었습니다.
2026-01-14 11:57:03,827 - INFO - ==================================================
2026-01-14 11:57:03,909 - INFO -   [탐색  2] 희소도: 0.2475 -> FLOPs: 0.2263 GFLOPs (감소율: 41.26%)
2026-01-14 11:57:03,984 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:03,985 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:04,314 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.37124999999999997)에 맞춰 변경되었습니다.
2026-01-14 11:57:04,315 - INFO - ==================================================
2026-01-14 11:57:04,413 - INFO -   [탐색  3] 희소도: 0.3712 -> FLOPs: 0.1626 GFLOPs (감소율: 57.81%)
2026-01-14 11:57:04,487 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:04,488 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:04,729 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.30937499999999996)에 맞춰 변경되었습니다.
2026-01-14 11:57:04,730 - INFO - ==================================================
2026-01-14 11:57:04,810 - INFO -   [탐색  4] 희소도: 0.3094 -> FLOPs: 0.1932 GFLOPs (감소율: 49.86%)
2026-01-14 11:57:04,884 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:04,885 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:05,135 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.34031249999999996)에 맞춰 변경되었습니다.
2026-01-14 11:57:05,135 - INFO - ==================================================
2026-01-14 11:57:05,221 - INFO -   [탐색  5] 희소도: 0.3403 -> FLOPs: 0.1775 GFLOPs (감소율: 53.92%)
2026-01-14 11:57:05,293 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:05,294 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:05,568 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32484375)에 맞춰 변경되었습니다.
2026-01-14 11:57:05,569 - INFO - ==================================================
2026-01-14 11:57:05,657 - INFO -   [탐색  6] 희소도: 0.3248 -> FLOPs: 0.1825 GFLOPs (감소율: 52.64%)
2026-01-14 11:57:06,073 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:06,075 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:06,412 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.31710937499999997)에 맞춰 변경되었습니다.
2026-01-14 11:57:06,412 - INFO - ==================================================
2026-01-14 11:57:06,494 - INFO -   [탐색  7] 희소도: 0.3171 -> FLOPs: 0.1856 GFLOPs (감소율: 51.83%)
2026-01-14 11:57:06,561 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:06,562 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:06,753 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32097656249999995)에 맞춰 변경되었습니다.
2026-01-14 11:57:06,753 - INFO - ==================================================
2026-01-14 11:57:06,811 - INFO -   [탐색  8] 희소도: 0.3210 -> FLOPs: 0.1844 GFLOPs (감소율: 52.14%)
2026-01-14 11:57:06,869 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:06,870 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:07,220 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291015624999997)에 맞춰 변경되었습니다.
2026-01-14 11:57:07,220 - INFO - ==================================================
2026-01-14 11:57:07,288 - INFO -   [탐색  9] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:07,363 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:07,364 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:07,629 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.323876953125)에 맞춰 변경되었습니다.
2026-01-14 11:57:07,629 - INFO - ==================================================
2026-01-14 11:57:07,684 - INFO -   [탐색 10] 희소도: 0.3239 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:07,744 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:07,745 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:07,897 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3233935546875)에 맞춰 변경되었습니다.
2026-01-14 11:57:07,897 - INFO - ==================================================
2026-01-14 11:57:07,961 - INFO -   [탐색 11] 희소도: 0.3234 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:08,042 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:08,043 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:08,223 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32315185546874997)에 맞춰 변경되었습니다.
2026-01-14 11:57:08,223 - INFO - ==================================================
2026-01-14 11:57:08,280 - INFO -   [탐색 12] 희소도: 0.3232 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:08,337 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:08,338 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:08,549 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32303100585937494)에 맞춰 변경되었습니다.
2026-01-14 11:57:08,550 - INFO - ==================================================
2026-01-14 11:57:08,610 - INFO -   [탐색 13] 희소도: 0.3230 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:08,686 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:08,687 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:08,882 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32297058105468746)에 맞춰 변경되었습니다.
2026-01-14 11:57:08,883 - INFO - ==================================================
2026-01-14 11:57:08,944 - INFO -   [탐색 14] 희소도: 0.3230 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:09,020 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:09,021 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:09,221 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229403686523437)에 맞춰 변경되었습니다.
2026-01-14 11:57:09,222 - INFO - ==================================================
2026-01-14 11:57:09,282 - INFO -   [탐색 15] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:09,356 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:09,357 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:09,538 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229252624511718)에 맞춰 변경되었습니다.
2026-01-14 11:57:09,539 - INFO - ==================================================
2026-01-14 11:57:09,605 - INFO -   [탐색 16] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:09,688 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:09,688 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:09,893 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229177093505859)에 맞춰 변경되었습니다.
2026-01-14 11:57:09,893 - INFO - ==================================================
2026-01-14 11:57:09,947 - INFO -   [탐색 17] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:10,346 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:10,347 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:10,603 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229139328002929)에 맞춰 변경되었습니다.
2026-01-14 11:57:10,603 - INFO - ==================================================
2026-01-14 11:57:10,664 - INFO -   [탐색 18] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:10,740 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:10,741 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:10,952 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291582107543937)에 맞춰 변경되었습니다.
2026-01-14 11:57:10,953 - INFO - ==================================================
2026-01-14 11:57:11,014 - INFO -   [탐색 19] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:11,091 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:11,092 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:11,481 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229167652130126)에 맞춰 변경되었습니다.
2026-01-14 11:57:11,482 - INFO - ==================================================
2026-01-14 11:57:11,542 - INFO -   [탐색 20] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:11,615 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:11,616 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:11,850 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916293144226)에 맞춰 변경되었습니다.
2026-01-14 11:57:11,850 - INFO - ==================================================
2026-01-14 11:57:11,910 - INFO -   [탐색 21] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:11,976 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:11,976 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:12,204 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229165291786193)에 맞춰 변경되었습니다.
2026-01-14 11:57:12,204 - INFO - ==================================================
2026-01-14 11:57:12,260 - INFO -   [탐색 22] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:12,328 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:12,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:12,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166471958159)에 맞춰 변경되었습니다.
2026-01-14 11:57:12,583 - INFO - ==================================================
2026-01-14 11:57:12,637 - INFO -   [탐색 23] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:12,703 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:12,704 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:12,998 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291670620441426)에 맞춰 변경되었습니다.
2026-01-14 11:57:12,999 - INFO - ==================================================
2026-01-14 11:57:13,067 - INFO -   [탐색 24] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:13,152 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:13,153 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:13,455 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166767001151)에 맞춰 변경되었습니다.
2026-01-14 11:57:13,455 - INFO - ==================================================
2026-01-14 11:57:13,518 - INFO -   [탐색 25] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:13,594 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:13,594 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:13,857 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666194796553)에 맞춰 변경되었습니다.
2026-01-14 11:57:13,858 - INFO - ==================================================
2026-01-14 11:57:13,923 - INFO -   [탐색 26] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:13,998 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:13,999 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:14,211 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166693240403)에 맞춰 변경되었습니다.
2026-01-14 11:57:14,212 - INFO - ==================================================
2026-01-14 11:57:14,264 - INFO -   [탐색 27] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:14,329 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:14,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:14,480 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166656360029)에 맞춰 변경되었습니다.
2026-01-14 11:57:14,480 - INFO - ==================================================
2026-01-14 11:57:14,525 - INFO -   [탐색 28] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:14,940 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:14,940 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:15,189 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666748002157)에 맞춰 변경되었습니다.
2026-01-14 11:57:15,190 - INFO - ==================================================
2026-01-14 11:57:15,243 - INFO -   [탐색 29] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:15,305 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:15,306 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:15,494 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166665580122)에 맞춰 변경되었습니다.
2026-01-14 11:57:15,495 - INFO - ==================================================
2026-01-14 11:57:15,556 - INFO -   [탐색 30] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:15,633 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:15,634 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:15,910 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166670190169)에 맞춰 변경되었습니다.
2026-01-14 11:57:15,910 - INFO - ==================================================
2026-01-14 11:57:15,966 - INFO -   [탐색 31] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:16,034 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:16,035 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:16,293 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666678851455)에 맞춰 변경되었습니다.
2026-01-14 11:57:16,294 - INFO - ==================================================
2026-01-14 11:57:16,350 - INFO -   [탐색 32] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:16,418 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:16,419 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:16,614 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666667326335)에 맞춰 변경되었습니다.
2026-01-14 11:57:16,615 - INFO - ==================================================
2026-01-14 11:57:16,667 - INFO -   [탐색 33] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:16,749 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:16,751 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:16,980 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666156378)에 맞춰 변경되었습니다.
2026-01-14 11:57:16,981 - INFO - ==================================================
2026-01-14 11:57:17,038 - INFO -   [탐색 34] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:17,112 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:17,113 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:17,340 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666664445057)에 맞춰 변경되었습니다.
2026-01-14 11:57:17,341 - INFO - ==================================================
2026-01-14 11:57:17,399 - INFO -   [탐색 35] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:17,471 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:17,472 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:17,696 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916666658857)에 맞춰 변경되었습니다.
2026-01-14 11:57:17,697 - INFO - ==================================================
2026-01-14 11:57:17,753 - INFO -   [탐색 36] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:17,822 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:17,823 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:18,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666606017)에 맞춰 변경되었습니다.
2026-01-14 11:57:18,157 - INFO - ==================================================
2026-01-14 11:57:18,229 - INFO -   [탐색 37] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:18,315 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:18,315 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:18,586 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666696618)에 맞춰 변경되었습니다.
2026-01-14 11:57:18,587 - INFO - ==================================================
2026-01-14 11:57:18,644 - INFO -   [탐색 38] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:18,738 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:18,738 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:19,088 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916666667861)에 맞춰 변경되었습니다.
2026-01-14 11:57:19,088 - INFO - ==================================================
2026-01-14 11:57:19,152 - INFO -   [탐색 39] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:19,213 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:19,214 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:19,828 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666669606)에 맞춰 변경되었습니다.
2026-01-14 11:57:19,829 - INFO - ==================================================
2026-01-14 11:57:19,885 - INFO -   [탐색 40] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:19,953 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:19,954 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:20,152 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666665104)에 맞춰 변경되었습니다.
2026-01-14 11:57:20,153 - INFO - ==================================================
2026-01-14 11:57:20,208 - INFO -   [탐색 41] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:20,274 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:20,275 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:20,567 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666667355)에 맞춰 변경되었습니다.
2026-01-14 11:57:20,568 - INFO - ==================================================
2026-01-14 11:57:20,624 - INFO -   [탐색 42] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:20,692 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:20,693 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:20,901 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.322916666666623)에 맞춰 변경되었습니다.
2026-01-14 11:57:20,902 - INFO - ==================================================
2026-01-14 11:57:20,959 - INFO -   [탐색 43] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:21,032 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:21,033 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:21,302 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666793)에 맞춰 변경되었습니다.
2026-01-14 11:57:21,303 - INFO - ==================================================
2026-01-14 11:57:21,374 - INFO -   [탐색 44] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:21,448 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:21,449 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:21,689 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666665114)에 맞춰 변경되었습니다.
2026-01-14 11:57:21,690 - INFO - ==================================================
2026-01-14 11:57:21,776 - INFO -   [탐색 45] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:21,845 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:21,846 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:22,093 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666652)에 맞춰 변경되었습니다.
2026-01-14 11:57:22,094 - INFO - ==================================================
2026-01-14 11:57:22,152 - INFO -   [탐색 46] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:22,223 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:22,223 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:22,579 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666667224)에 맞춰 변경되었습니다.
2026-01-14 11:57:22,579 - INFO - ==================================================
2026-01-14 11:57:22,638 - INFO -   [탐색 47] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:22,702 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:22,702 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:22,902 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666874)에 맞춰 변경되었습니다.
2026-01-14 11:57:22,902 - INFO - ==================================================
2026-01-14 11:57:22,955 - INFO -   [탐색 48] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:23,016 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:23,018 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:23,183 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666696)에 맞춰 변경되었습니다.
2026-01-14 11:57:23,184 - INFO - ==================================================
2026-01-14 11:57:23,250 - INFO -   [탐색 49] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:23,316 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:23,317 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:23,455 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666661)에 맞춰 변경되었습니다.
2026-01-14 11:57:23,456 - INFO - ==================================================
2026-01-14 11:57:23,501 - INFO -   [탐색 50] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:23,553 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:23,554 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:23,791 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666665)에 맞춰 변경되었습니다.
2026-01-14 11:57:23,791 - INFO - ==================================================
2026-01-14 11:57:23,832 - INFO -   [탐색 51] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.18%)
2026-01-14 11:57:23,932 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:23,932 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:24,476 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666674)에 맞춰 변경되었습니다.
2026-01-14 11:57:24,477 - INFO - ==================================================
2026-01-14 11:57:24,524 - INFO -   [탐색 52] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.19%)
2026-01-14 11:57:24,575 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:24,576 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:24,889 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:24,889 - INFO - ==================================================
2026-01-14 11:57:24,945 - INFO -   [탐색 53] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:25,014 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:25,014 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:25,241 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3229166666666668)에 맞춰 변경되었습니다.
2026-01-14 11:57:25,241 - INFO - ==================================================
2026-01-14 11:57:25,302 - INFO -   [탐색 54] 희소도: 0.3229 -> FLOPs: 0.1842 GFLOPs (감소율: 52.19%)
2026-01-14 11:57:25,374 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:25,374 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:25,768 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:25,769 - INFO - ==================================================
2026-01-14 11:57:25,836 - INFO -   [탐색 55] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:25,905 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:25,906 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:26,179 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:26,180 - INFO - ==================================================
2026-01-14 11:57:26,263 - INFO -   [탐색 56] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:26,395 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:26,395 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:26,962 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:26,963 - INFO - ==================================================
2026-01-14 11:57:27,041 - INFO -   [탐색 57] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:27,137 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:27,137 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:27,355 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:27,356 - INFO - ==================================================
2026-01-14 11:57:27,435 - INFO -   [탐색 58] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:27,537 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:27,538 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:27,978 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:27,979 - INFO - ==================================================
2026-01-14 11:57:28,038 - INFO -   [탐색 59] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:28,136 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:28,136 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:28,438 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:28,438 - INFO - ==================================================
2026-01-14 11:57:28,494 - INFO -   [탐색 60] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:28,561 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:28,561 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:28,944 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:28,945 - INFO - ==================================================
2026-01-14 11:57:29,000 - INFO -   [탐색 61] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:29,068 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:29,068 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:29,279 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:29,280 - INFO - ==================================================
2026-01-14 11:57:29,332 - INFO -   [탐색 62] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:29,402 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:29,403 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:29,788 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:29,788 - INFO - ==================================================
2026-01-14 11:57:29,844 - INFO -   [탐색 63] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:29,915 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:29,916 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:30,259 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:30,260 - INFO - ==================================================
2026-01-14 11:57:30,608 - INFO -   [탐색 64] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:30,661 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:30,662 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:30,901 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:30,901 - INFO - ==================================================
2026-01-14 11:57:30,967 - INFO -   [탐색 65] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:31,030 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:31,030 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:31,250 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:31,250 - INFO - ==================================================
2026-01-14 11:57:31,326 - INFO -   [탐색 66] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:31,403 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:31,403 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:31,566 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:31,567 - INFO - ==================================================
2026-01-14 11:57:31,612 - INFO -   [탐색 67] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:31,673 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:31,674 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:31,904 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:31,905 - INFO - ==================================================
2026-01-14 11:57:31,970 - INFO -   [탐색 68] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:32,041 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:32,042 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:32,305 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:32,306 - INFO - ==================================================
2026-01-14 11:57:32,350 - INFO -   [탐색 69] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:32,404 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:32,405 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:32,607 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:32,608 - INFO - ==================================================
2026-01-14 11:57:32,669 - INFO -   [탐색 70] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:32,746 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:32,747 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:32,998 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:32,999 - INFO - ==================================================
2026-01-14 11:57:33,055 - INFO -   [탐색 71] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:33,132 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:33,133 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:33,349 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:33,350 - INFO - ==================================================
2026-01-14 11:57:33,412 - INFO -   [탐색 72] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:33,476 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:33,477 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:33,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:33,682 - INFO - ==================================================
2026-01-14 11:57:33,745 - INFO -   [탐색 73] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:33,824 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:33,826 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:34,117 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:34,118 - INFO - ==================================================
2026-01-14 11:57:34,178 - INFO -   [탐색 74] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:34,521 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:34,522 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:34,800 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:34,801 - INFO - ==================================================
2026-01-14 11:57:34,857 - INFO -   [탐색 75] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:34,929 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:34,930 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:35,318 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:35,318 - INFO - ==================================================
2026-01-14 11:57:35,375 - INFO -   [탐색 76] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:35,446 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:35,447 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:35,790 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:35,791 - INFO - ==================================================
2026-01-14 11:57:35,849 - INFO -   [탐색 77] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:35,921 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:35,922 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:36,264 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:36,264 - INFO - ==================================================
2026-01-14 11:57:36,323 - INFO -   [탐색 78] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:36,392 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:36,393 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:36,656 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:36,656 - INFO - ==================================================
2026-01-14 11:57:36,722 - INFO -   [탐색 79] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:36,804 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:36,805 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:36,998 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:36,998 - INFO - ==================================================
2026-01-14 11:57:37,041 - INFO -   [탐색 80] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:37,093 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:37,094 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:37,309 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:37,310 - INFO - ==================================================
2026-01-14 11:57:37,374 - INFO -   [탐색 81] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:37,430 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:37,430 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:37,656 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:37,656 - INFO - ==================================================
2026-01-14 11:57:37,714 - INFO -   [탐색 82] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:37,781 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:37,782 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:37,952 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:37,952 - INFO - ==================================================
2026-01-14 11:57:38,008 - INFO -   [탐색 83] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:38,075 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:38,076 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:38,264 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:38,265 - INFO - ==================================================
2026-01-14 11:57:38,317 - INFO -   [탐색 84] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:38,394 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:38,394 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:38,594 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:38,594 - INFO - ==================================================
2026-01-14 11:57:38,657 - INFO -   [탐색 85] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:39,025 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:39,025 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:39,254 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:39,255 - INFO - ==================================================
2026-01-14 11:57:39,312 - INFO -   [탐색 86] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:39,381 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:39,381 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:39,612 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:39,613 - INFO - ==================================================
2026-01-14 11:57:39,672 - INFO -   [탐색 87] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:39,741 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:39,742 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:40,043 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:40,043 - INFO - ==================================================
2026-01-14 11:57:40,099 - INFO -   [탐색 88] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:40,168 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:40,169 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:40,433 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:40,434 - INFO - ==================================================
2026-01-14 11:57:40,489 - INFO -   [탐색 89] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:40,557 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:40,558 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:40,813 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:40,814 - INFO - ==================================================
2026-01-14 11:57:40,870 - INFO -   [탐색 90] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:40,938 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:40,938 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:41,296 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:41,296 - INFO - ==================================================
2026-01-14 11:57:41,364 - INFO -   [탐색 91] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:41,407 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:41,407 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:41,747 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:41,748 - INFO - ==================================================
2026-01-14 11:57:41,803 - INFO -   [탐색 92] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:41,877 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:41,877 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:42,133 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:42,133 - INFO - ==================================================
2026-01-14 11:57:42,180 - INFO -   [탐색 93] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:42,249 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:42,249 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:42,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:42,516 - INFO - ==================================================
2026-01-14 11:57:42,570 - INFO -   [탐색 94] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:42,639 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:42,640 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:42,977 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:42,977 - INFO - ==================================================
2026-01-14 11:57:43,024 - INFO -   [탐색 95] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:43,077 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:43,078 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:43,360 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:43,360 - INFO - ==================================================
2026-01-14 11:57:43,406 - INFO -   [탐색 96] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:43,677 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:43,677 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:43,844 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:43,844 - INFO - ==================================================
2026-01-14 11:57:43,896 - INFO -   [탐색 97] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:43,967 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:43,967 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:44,133 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:44,133 - INFO - ==================================================
2026-01-14 11:57:44,188 - INFO -   [탐색 98] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:44,257 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:44,258 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:44,447 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:44,447 - INFO - ==================================================
2026-01-14 11:57:44,503 - INFO -   [탐색 99] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:44,573 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:44,573 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:44,795 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.32291666666666685)에 맞춰 변경되었습니다.
2026-01-14 11:57:44,795 - INFO - ==================================================
2026-01-14 11:57:44,862 - INFO -   [탐색 100] 희소도: 0.3229 -> FLOPs: 0.1826 GFLOPs (감소율: 52.61%)
2026-01-14 11:57:44,863 - INFO - 탐색 완료. 목표 FLOPs(0.1829)에 가장 근접한 최적 희소도는 0.3234 입니다.
2026-01-14 11:57:44,863 - INFO - ================================================================================
2026-01-14 11:57:44,866 - INFO - 계산된 Pruning 정보(희소도: 0.3234)를 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/pruning_info.yaml'에 저장했습니다.
2026-01-14 11:57:44,931 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 11:57:45,052 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:45,053 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:45,312 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3233935546875)에 맞춰 변경되었습니다.
2026-01-14 11:57:45,312 - INFO - ==================================================
2026-01-14 11:57:45,315 - INFO - ==================================================
2026-01-14 11:57:45,316 - INFO - 모델 파라미터 수:
2026-01-14 11:57:45,316 - INFO -   - 총 파라미터: 1,156,016 개
2026-01-14 11:57:45,316 - INFO -   - 학습 가능한 파라미터: 1,156,016 개
2026-01-14 11:57:45,367 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 11:57:45,473 - INFO - FLOPs가 0.3853 GFLOPs에서 0.1826 GFLOPs로 감소했습니다 (감소율: 52.61%).
2026-01-14 11:57:45,474 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 11:57:45,474 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 11:57:45,475 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 11:57:45,476 - INFO - ==================================================
2026-01-14 11:57:45,476 - INFO - train 모드를 시작합니다.
2026-01-14 11:57:45,476 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 11:57:45,476 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 11:57:45,476 - INFO - --------------------------------------------------
2026-01-14 11:57:45,478 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 11:57:54,231 - INFO - [Train] [11/90] | Loss: 0.7940 | Train Acc: 68.90%
2026-01-14 11:57:56,611 - INFO - [Valid] [11/90] | Loss: 0.6018 | Val Acc: 73.75%
2026-01-14 11:57:56,623 - INFO - [Metrics for 'abnormal'] | Precision: 0.7881 | Recall: 0.5924 | F1: 0.6764
2026-01-14 11:57:56,624 - INFO - [Metrics for 'normal'] | Precision: 0.7104 | Recall: 0.8626 | F1: 0.7792
2026-01-14 11:57:56,679 - INFO - [Best Model Saved] (val loss: 0.6018) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:57:56,679 - INFO - --------------------------------------------------
2026-01-14 11:57:56,681 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 11:58:05,184 - INFO - [Train] [12/90] | Loss: 0.5978 | Train Acc: 74.78%
2026-01-14 11:58:07,052 - INFO - [Valid] [12/90] | Loss: 0.6552 | Val Acc: 69.91%
2026-01-14 11:58:07,066 - INFO - [Metrics for 'abnormal'] | Precision: 0.7670 | Recall: 0.5032 | F1: 0.6077
2026-01-14 11:58:07,069 - INFO - [Metrics for 'normal'] | Precision: 0.6695 | Recall: 0.8681 | F1: 0.7560
2026-01-14 11:58:07,074 - INFO - --------------------------------------------------
2026-01-14 11:58:07,077 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 11:58:14,500 - INFO - [Train] [13/90] | Loss: 0.5247 | Train Acc: 80.06%
2026-01-14 11:58:16,560 - INFO - [Valid] [13/90] | Loss: 0.5735 | Val Acc: 77.58%
2026-01-14 11:58:16,572 - INFO - [Metrics for 'abnormal'] | Precision: 0.7396 | Recall: 0.7962 | F1: 0.7669
2026-01-14 11:58:16,573 - INFO - [Metrics for 'normal'] | Precision: 0.8118 | Recall: 0.7582 | F1: 0.7841
2026-01-14 11:58:16,631 - INFO - [Best Model Saved] (val loss: 0.5735) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:58:16,632 - INFO - --------------------------------------------------
2026-01-14 11:58:16,635 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 11:58:22,849 - INFO - [Train] [14/90] | Loss: 0.5388 | Train Acc: 79.54%
2026-01-14 11:58:24,502 - INFO - [Valid] [14/90] | Loss: 0.9846 | Val Acc: 73.75%
2026-01-14 11:58:24,511 - INFO - [Metrics for 'abnormal'] | Precision: 0.7537 | Recall: 0.6433 | F1: 0.6942
2026-01-14 11:58:24,512 - INFO - [Metrics for 'normal'] | Precision: 0.7268 | Recall: 0.8187 | F1: 0.7700
2026-01-14 11:58:24,516 - INFO - --------------------------------------------------
2026-01-14 11:58:24,518 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 11:58:30,890 - INFO - [Train] [15/90] | Loss: 0.5624 | Train Acc: 77.31%
2026-01-14 11:58:32,725 - INFO - [Valid] [15/90] | Loss: 0.6898 | Val Acc: 76.11%
2026-01-14 11:58:32,735 - INFO - [Metrics for 'abnormal'] | Precision: 0.7209 | Recall: 0.7898 | F1: 0.7538
2026-01-14 11:58:32,736 - INFO - [Metrics for 'normal'] | Precision: 0.8024 | Recall: 0.7363 | F1: 0.7679
2026-01-14 11:58:32,740 - INFO - --------------------------------------------------
2026-01-14 11:58:32,742 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 11:58:38,821 - INFO - [Train] [16/90] | Loss: 0.5198 | Train Acc: 79.02%
2026-01-14 11:58:40,290 - INFO - [Valid] [16/90] | Loss: 0.6603 | Val Acc: 73.45%
2026-01-14 11:58:40,303 - INFO - [Metrics for 'abnormal'] | Precision: 0.6516 | Recall: 0.9172 | F1: 0.7619
2026-01-14 11:58:40,303 - INFO - [Metrics for 'normal'] | Precision: 0.8898 | Recall: 0.5769 | F1: 0.7000
2026-01-14 11:58:40,309 - INFO - --------------------------------------------------
2026-01-14 11:58:40,312 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 11:58:45,574 - INFO - [Train] [17/90] | Loss: 0.5496 | Train Acc: 79.39%
2026-01-14 11:58:47,200 - INFO - [Valid] [17/90] | Loss: 0.7426 | Val Acc: 70.80%
2026-01-14 11:58:47,220 - INFO - [Metrics for 'abnormal'] | Precision: 0.6883 | Recall: 0.6752 | F1: 0.6817
2026-01-14 11:58:47,221 - INFO - [Metrics for 'normal'] | Precision: 0.7243 | Recall: 0.7363 | F1: 0.7302
2026-01-14 11:58:47,230 - INFO - --------------------------------------------------
2026-01-14 11:58:47,235 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 11:58:53,830 - INFO - [Train] [18/90] | Loss: 0.5322 | Train Acc: 80.43%
2026-01-14 11:58:55,524 - INFO - [Valid] [18/90] | Loss: 0.7960 | Val Acc: 70.50%
2026-01-14 11:58:55,536 - INFO - [Metrics for 'abnormal'] | Precision: 0.6462 | Recall: 0.8025 | F1: 0.7159
2026-01-14 11:58:55,537 - INFO - [Metrics for 'normal'] | Precision: 0.7847 | Recall: 0.6209 | F1: 0.6933
2026-01-14 11:58:55,543 - INFO - --------------------------------------------------
2026-01-14 11:58:55,546 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 11:59:01,761 - INFO - [Train] [19/90] | Loss: 0.5530 | Train Acc: 78.79%
2026-01-14 11:59:03,612 - INFO - [Valid] [19/90] | Loss: 0.6787 | Val Acc: 72.86%
2026-01-14 11:59:03,625 - INFO - [Metrics for 'abnormal'] | Precision: 0.8736 | Recall: 0.4841 | F1: 0.6230
2026-01-14 11:59:03,625 - INFO - [Metrics for 'normal'] | Precision: 0.6786 | Recall: 0.9396 | F1: 0.7880
2026-01-14 11:59:03,629 - INFO - --------------------------------------------------
2026-01-14 11:59:03,632 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 11:59:09,666 - INFO - [Train] [20/90] | Loss: 0.5428 | Train Acc: 77.68%
2026-01-14 11:59:11,733 - INFO - [Valid] [20/90] | Loss: 0.6772 | Val Acc: 75.22%
2026-01-14 11:59:11,744 - INFO - [Metrics for 'abnormal'] | Precision: 0.8687 | Recall: 0.5478 | F1: 0.6719
2026-01-14 11:59:11,745 - INFO - [Metrics for 'normal'] | Precision: 0.7042 | Recall: 0.9286 | F1: 0.8009
2026-01-14 11:59:11,749 - INFO - --------------------------------------------------
2026-01-14 11:59:11,751 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 11:59:18,100 - INFO - [Train] [21/90] | Loss: 0.5242 | Train Acc: 79.54%
2026-01-14 11:59:20,012 - INFO - [Valid] [21/90] | Loss: 0.7213 | Val Acc: 71.68%
2026-01-14 11:59:20,021 - INFO - [Metrics for 'abnormal'] | Precision: 0.6614 | Recall: 0.7962 | F1: 0.7225
2026-01-14 11:59:20,022 - INFO - [Metrics for 'normal'] | Precision: 0.7867 | Recall: 0.6484 | F1: 0.7108
2026-01-14 11:59:20,025 - INFO - --------------------------------------------------
2026-01-14 11:59:20,027 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 11:59:26,709 - INFO - [Train] [22/90] | Loss: 0.5542 | Train Acc: 79.17%
2026-01-14 11:59:28,303 - INFO - [Valid] [22/90] | Loss: 0.6375 | Val Acc: 80.24%
2026-01-14 11:59:28,315 - INFO - [Metrics for 'abnormal'] | Precision: 0.8082 | Recall: 0.7516 | F1: 0.7789
2026-01-14 11:59:28,315 - INFO - [Metrics for 'normal'] | Precision: 0.7979 | Recall: 0.8462 | F1: 0.8213
2026-01-14 11:59:28,320 - INFO - --------------------------------------------------
2026-01-14 11:59:28,322 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 11:59:34,479 - INFO - [Train] [23/90] | Loss: 0.4726 | Train Acc: 83.18%
2026-01-14 11:59:36,227 - INFO - [Valid] [23/90] | Loss: 0.5015 | Val Acc: 79.94%
2026-01-14 11:59:36,242 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-01-14 11:59:36,242 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-01-14 11:59:36,301 - INFO - [Best Model Saved] (val loss: 0.5015) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:59:36,302 - INFO - --------------------------------------------------
2026-01-14 11:59:36,304 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 11:59:44,114 - INFO - [Train] [24/90] | Loss: 0.4993 | Train Acc: 80.88%
2026-01-14 11:59:46,312 - INFO - [Valid] [24/90] | Loss: 0.4957 | Val Acc: 79.06%
2026-01-14 11:59:46,324 - INFO - [Metrics for 'abnormal'] | Precision: 0.7792 | Recall: 0.7643 | F1: 0.7717
2026-01-14 11:59:46,325 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8132 | F1: 0.8065
2026-01-14 11:59:46,383 - INFO - [Best Model Saved] (val loss: 0.4957) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 11:59:46,384 - INFO - --------------------------------------------------
2026-01-14 11:59:46,388 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 11:59:54,229 - INFO - [Train] [25/90] | Loss: 0.5003 | Train Acc: 83.04%
2026-01-14 11:59:56,230 - INFO - [Valid] [25/90] | Loss: 0.5631 | Val Acc: 76.40%
2026-01-14 11:59:56,243 - INFO - [Metrics for 'abnormal'] | Precision: 0.8812 | Recall: 0.5669 | F1: 0.6899
2026-01-14 11:59:56,243 - INFO - [Metrics for 'normal'] | Precision: 0.7143 | Recall: 0.9341 | F1: 0.8095
2026-01-14 11:59:56,254 - INFO - --------------------------------------------------
2026-01-14 11:59:56,260 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 12:00:04,466 - INFO - [Train] [26/90] | Loss: 0.4537 | Train Acc: 85.12%
2026-01-14 12:00:06,135 - INFO - [Valid] [26/90] | Loss: 0.5151 | Val Acc: 79.06%
2026-01-14 12:00:06,148 - INFO - [Metrics for 'abnormal'] | Precision: 0.7986 | Recall: 0.7325 | F1: 0.7641
2026-01-14 12:00:06,149 - INFO - [Metrics for 'normal'] | Precision: 0.7846 | Recall: 0.8407 | F1: 0.8117
2026-01-14 12:00:06,155 - INFO - --------------------------------------------------
2026-01-14 12:00:06,158 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 12:00:13,534 - INFO - [Train] [27/90] | Loss: 0.4941 | Train Acc: 81.99%
2026-01-14 12:00:15,893 - INFO - [Valid] [27/90] | Loss: 0.7137 | Val Acc: 72.27%
2026-01-14 12:00:15,906 - INFO - [Metrics for 'abnormal'] | Precision: 0.6684 | Recall: 0.7962 | F1: 0.7267
2026-01-14 12:00:15,907 - INFO - [Metrics for 'normal'] | Precision: 0.7895 | Recall: 0.6593 | F1: 0.7186
2026-01-14 12:00:15,912 - INFO - --------------------------------------------------
2026-01-14 12:00:15,914 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 12:00:23,998 - INFO - [Train] [28/90] | Loss: 0.5208 | Train Acc: 80.13%
2026-01-14 12:00:25,833 - INFO - [Valid] [28/90] | Loss: 0.6991 | Val Acc: 65.49%
2026-01-14 12:00:25,846 - INFO - [Metrics for 'abnormal'] | Precision: 0.6031 | Recall: 0.7452 | F1: 0.6667
2026-01-14 12:00:25,847 - INFO - [Metrics for 'normal'] | Precision: 0.7241 | Recall: 0.5769 | F1: 0.6422
2026-01-14 12:00:25,852 - INFO - --------------------------------------------------
2026-01-14 12:00:25,854 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 12:00:33,164 - INFO - [Train] [29/90] | Loss: 0.4701 | Train Acc: 83.11%
2026-01-14 12:00:35,662 - INFO - [Valid] [29/90] | Loss: 0.5554 | Val Acc: 79.06%
2026-01-14 12:00:35,686 - INFO - [Metrics for 'abnormal'] | Precision: 0.8413 | Recall: 0.6752 | F1: 0.7491
2026-01-14 12:00:35,686 - INFO - [Metrics for 'normal'] | Precision: 0.7606 | Recall: 0.8901 | F1: 0.8203
2026-01-14 12:00:35,693 - INFO - --------------------------------------------------
2026-01-14 12:00:35,695 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 12:00:46,510 - INFO - [Train] [30/90] | Loss: 0.4918 | Train Acc: 80.88%
2026-01-14 12:00:49,727 - INFO - [Valid] [30/90] | Loss: 0.8373 | Val Acc: 59.88%
2026-01-14 12:00:49,738 - INFO - [Metrics for 'abnormal'] | Precision: 0.5463 | Recall: 0.7898 | F1: 0.6458
2026-01-14 12:00:49,739 - INFO - [Metrics for 'normal'] | Precision: 0.7054 | Recall: 0.4341 | F1: 0.5374
2026-01-14 12:00:49,743 - INFO - --------------------------------------------------
2026-01-14 12:00:49,745 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 12:00:57,151 - INFO - [Train] [31/90] | Loss: 0.4987 | Train Acc: 81.03%
2026-01-14 12:00:59,534 - INFO - [Valid] [31/90] | Loss: 0.6334 | Val Acc: 71.09%
2026-01-14 12:00:59,551 - INFO - [Metrics for 'abnormal'] | Precision: 0.7611 | Recall: 0.5478 | F1: 0.6370
2026-01-14 12:00:59,551 - INFO - [Metrics for 'normal'] | Precision: 0.6858 | Recall: 0.8516 | F1: 0.7598
2026-01-14 12:00:59,556 - INFO - --------------------------------------------------
2026-01-14 12:00:59,559 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 12:01:08,110 - INFO - [Train] [32/90] | Loss: 0.5009 | Train Acc: 79.39%
2026-01-14 12:01:10,506 - INFO - [Valid] [32/90] | Loss: 0.6988 | Val Acc: 67.55%
2026-01-14 12:01:10,519 - INFO - [Metrics for 'abnormal'] | Precision: 0.5936 | Recall: 0.9490 | F1: 0.7304
2026-01-14 12:01:10,519 - INFO - [Metrics for 'normal'] | Precision: 0.9091 | Recall: 0.4396 | F1: 0.5926
2026-01-14 12:01:10,523 - INFO - --------------------------------------------------
2026-01-14 12:01:10,526 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 12:01:19,371 - INFO - [Train] [33/90] | Loss: 0.5109 | Train Acc: 80.80%
2026-01-14 12:01:21,824 - INFO - [Valid] [33/90] | Loss: 0.6001 | Val Acc: 78.17%
2026-01-14 12:01:21,836 - INFO - [Metrics for 'abnormal'] | Precision: 0.7128 | Recall: 0.8854 | F1: 0.7898
2026-01-14 12:01:21,837 - INFO - [Metrics for 'normal'] | Precision: 0.8750 | Recall: 0.6923 | F1: 0.7730
2026-01-14 12:01:21,841 - INFO - --------------------------------------------------
2026-01-14 12:01:21,844 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 12:01:32,388 - INFO - [Train] [34/90] | Loss: 0.4617 | Train Acc: 84.75%
2026-01-14 12:01:34,833 - INFO - [Valid] [34/90] | Loss: 0.5486 | Val Acc: 77.58%
2026-01-14 12:01:34,864 - INFO - [Metrics for 'abnormal'] | Precision: 0.8403 | Recall: 0.6369 | F1: 0.7246
2026-01-14 12:01:34,868 - INFO - [Metrics for 'normal'] | Precision: 0.7409 | Recall: 0.8956 | F1: 0.8109
2026-01-14 12:01:34,876 - INFO - --------------------------------------------------
2026-01-14 12:01:34,879 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 12:01:44,429 - INFO - [Train] [35/90] | Loss: 0.4434 | Train Acc: 85.79%
2026-01-14 12:01:47,319 - INFO - [Valid] [35/90] | Loss: 0.5145 | Val Acc: 80.83%
2026-01-14 12:01:47,332 - INFO - [Metrics for 'abnormal'] | Precision: 0.8538 | Recall: 0.7070 | F1: 0.7735
2026-01-14 12:01:47,333 - INFO - [Metrics for 'normal'] | Precision: 0.7799 | Recall: 0.8956 | F1: 0.8338
2026-01-14 12:01:47,337 - INFO - --------------------------------------------------
2026-01-14 12:01:47,340 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 12:01:56,188 - INFO - [Train] [36/90] | Loss: 0.4320 | Train Acc: 86.24%
2026-01-14 12:01:58,967 - INFO - [Valid] [36/90] | Loss: 0.5952 | Val Acc: 80.24%
2026-01-14 12:01:58,979 - INFO - [Metrics for 'abnormal'] | Precision: 0.8571 | Recall: 0.6879 | F1: 0.7633
2026-01-14 12:01:58,979 - INFO - [Metrics for 'normal'] | Precision: 0.7700 | Recall: 0.9011 | F1: 0.8304
2026-01-14 12:01:58,983 - INFO - --------------------------------------------------
2026-01-14 12:01:58,985 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 12:02:07,449 - INFO - [Train] [37/90] | Loss: 0.4018 | Train Acc: 88.39%
2026-01-14 12:02:10,785 - INFO - [Valid] [37/90] | Loss: 0.4942 | Val Acc: 81.42%
2026-01-14 12:02:10,812 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-01-14 12:02:10,814 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-01-14 12:02:10,871 - INFO - [Best Model Saved] (val loss: 0.4942) -> 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 12:02:10,872 - INFO - --------------------------------------------------
2026-01-14 12:02:10,874 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 12:02:19,074 - INFO - [Train] [38/90] | Loss: 0.3980 | Train Acc: 87.87%
2026-01-14 12:02:21,865 - INFO - [Valid] [38/90] | Loss: 0.6507 | Val Acc: 74.93%
2026-01-14 12:02:21,888 - INFO - [Metrics for 'abnormal'] | Precision: 0.8214 | Recall: 0.5860 | F1: 0.6840
2026-01-14 12:02:21,892 - INFO - [Metrics for 'normal'] | Precision: 0.7137 | Recall: 0.8901 | F1: 0.7922
2026-01-14 12:02:21,902 - INFO - --------------------------------------------------
2026-01-14 12:02:21,906 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 12:02:30,852 - INFO - [Train] [39/90] | Loss: 0.4092 | Train Acc: 86.68%
2026-01-14 12:02:33,302 - INFO - [Valid] [39/90] | Loss: 0.5746 | Val Acc: 78.17%
2026-01-14 12:02:33,314 - INFO - [Metrics for 'abnormal'] | Precision: 0.8074 | Recall: 0.6943 | F1: 0.7466
2026-01-14 12:02:33,315 - INFO - [Metrics for 'normal'] | Precision: 0.7647 | Recall: 0.8571 | F1: 0.8083
2026-01-14 12:02:33,320 - INFO - --------------------------------------------------
2026-01-14 12:02:33,323 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 12:02:42,265 - INFO - [Train] [40/90] | Loss: 0.3771 | Train Acc: 89.36%
2026-01-14 12:02:44,217 - INFO - [Valid] [40/90] | Loss: 0.6160 | Val Acc: 79.06%
2026-01-14 12:02:44,241 - INFO - [Metrics for 'abnormal'] | Precision: 0.8028 | Recall: 0.7261 | F1: 0.7625
2026-01-14 12:02:44,242 - INFO - [Metrics for 'normal'] | Precision: 0.7817 | Recall: 0.8462 | F1: 0.8127
2026-01-14 12:02:44,249 - INFO - --------------------------------------------------
2026-01-14 12:02:44,255 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 12:02:54,434 - INFO - [Train] [41/90] | Loss: 0.3667 | Train Acc: 90.25%
2026-01-14 12:02:56,581 - INFO - [Valid] [41/90] | Loss: 0.5303 | Val Acc: 76.99%
2026-01-14 12:02:56,602 - INFO - [Metrics for 'abnormal'] | Precision: 0.7651 | Recall: 0.7261 | F1: 0.7451
2026-01-14 12:02:56,606 - INFO - [Metrics for 'normal'] | Precision: 0.7737 | Recall: 0.8077 | F1: 0.7903
2026-01-14 12:02:56,616 - INFO - --------------------------------------------------
2026-01-14 12:02:56,622 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 12:03:06,677 - INFO - [Train] [42/90] | Loss: 0.3604 | Train Acc: 91.44%
2026-01-14 12:03:08,862 - INFO - [Valid] [42/90] | Loss: 0.5570 | Val Acc: 79.94%
2026-01-14 12:03:08,873 - INFO - [Metrics for 'abnormal'] | Precision: 0.8296 | Recall: 0.7134 | F1: 0.7671
2026-01-14 12:03:08,874 - INFO - [Metrics for 'normal'] | Precision: 0.7794 | Recall: 0.8736 | F1: 0.8238
2026-01-14 12:03:08,878 - INFO - --------------------------------------------------
2026-01-14 12:03:08,881 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 12:03:18,386 - INFO - [Train] [43/90] | Loss: 0.3522 | Train Acc: 91.00%
2026-01-14 12:03:21,041 - INFO - [Valid] [43/90] | Loss: 0.6384 | Val Acc: 77.88%
2026-01-14 12:03:21,055 - INFO - [Metrics for 'abnormal'] | Precision: 0.6990 | Recall: 0.9172 | F1: 0.7934
2026-01-14 12:03:21,056 - INFO - [Metrics for 'normal'] | Precision: 0.9023 | Recall: 0.6593 | F1: 0.7619
2026-01-14 12:03:21,060 - INFO - --------------------------------------------------
2026-01-14 12:03:21,062 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 12:03:32,609 - INFO - [Train] [44/90] | Loss: 0.3394 | Train Acc: 92.34%
2026-01-14 12:03:35,883 - INFO - [Valid] [44/90] | Loss: 0.5336 | Val Acc: 79.94%
2026-01-14 12:03:35,892 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-01-14 12:03:35,893 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-01-14 12:03:35,897 - INFO - --------------------------------------------------
2026-01-14 12:03:35,899 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 12:03:44,660 - INFO - [Train] [45/90] | Loss: 0.3069 | Train Acc: 94.94%
2026-01-14 12:03:47,516 - INFO - [Valid] [45/90] | Loss: 0.5389 | Val Acc: 79.35%
2026-01-14 12:03:47,527 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 12:03:47,528 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 12:03:47,533 - INFO - --------------------------------------------------
2026-01-14 12:03:47,536 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 12:03:55,664 - INFO - [Train] [46/90] | Loss: 0.3201 | Train Acc: 94.20%
2026-01-14 12:03:58,840 - INFO - [Valid] [46/90] | Loss: 0.5743 | Val Acc: 79.65%
2026-01-14 12:03:58,852 - INFO - [Metrics for 'abnormal'] | Precision: 0.7895 | Recall: 0.7643 | F1: 0.7767
2026-01-14 12:03:58,853 - INFO - [Metrics for 'normal'] | Precision: 0.8021 | Recall: 0.8242 | F1: 0.8130
2026-01-14 12:03:58,856 - INFO - --------------------------------------------------
2026-01-14 12:03:58,859 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 12:04:07,714 - INFO - [Train] [47/90] | Loss: 0.3132 | Train Acc: 94.42%
2026-01-14 12:04:11,273 - INFO - [Valid] [47/90] | Loss: 0.5448 | Val Acc: 80.53%
2026-01-14 12:04:11,286 - INFO - [Metrics for 'abnormal'] | Precision: 0.7630 | Recall: 0.8408 | F1: 0.8000
2026-01-14 12:04:11,287 - INFO - [Metrics for 'normal'] | Precision: 0.8494 | Recall: 0.7747 | F1: 0.8103
2026-01-14 12:04:11,291 - INFO - --------------------------------------------------
2026-01-14 12:04:11,294 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 12:04:20,372 - INFO - [Train] [48/90] | Loss: 0.2981 | Train Acc: 94.94%
2026-01-14 12:04:23,618 - INFO - [Valid] [48/90] | Loss: 0.5805 | Val Acc: 78.47%
2026-01-14 12:04:23,628 - INFO - [Metrics for 'abnormal'] | Precision: 0.7414 | Recall: 0.8217 | F1: 0.7795
2026-01-14 12:04:23,629 - INFO - [Metrics for 'normal'] | Precision: 0.8303 | Recall: 0.7527 | F1: 0.7896
2026-01-14 12:04:23,632 - INFO - --------------------------------------------------
2026-01-14 12:04:23,634 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 12:04:33,374 - INFO - [Train] [49/90] | Loss: 0.2825 | Train Acc: 95.98%
2026-01-14 12:04:36,936 - INFO - [Valid] [49/90] | Loss: 0.5600 | Val Acc: 79.06%
2026-01-14 12:04:36,947 - INFO - [Metrics for 'abnormal'] | Precision: 0.7829 | Recall: 0.7580 | F1: 0.7702
2026-01-14 12:04:36,948 - INFO - [Metrics for 'normal'] | Precision: 0.7968 | Recall: 0.8187 | F1: 0.8076
2026-01-14 12:04:36,952 - INFO - --------------------------------------------------
2026-01-14 12:04:36,955 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 12:04:45,974 - INFO - [Train] [50/90] | Loss: 0.2760 | Train Acc: 96.58%
2026-01-14 12:04:49,111 - INFO - [Valid] [50/90] | Loss: 0.6055 | Val Acc: 78.76%
2026-01-14 12:04:49,122 - INFO - [Metrics for 'abnormal'] | Precision: 0.7972 | Recall: 0.7261 | F1: 0.7600
2026-01-14 12:04:49,122 - INFO - [Metrics for 'normal'] | Precision: 0.7806 | Recall: 0.8407 | F1: 0.8095
2026-01-14 12:04:49,126 - INFO - --------------------------------------------------
2026-01-14 12:04:49,128 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 12:04:57,708 - INFO - [Train] [51/90] | Loss: 0.2825 | Train Acc: 95.98%
2026-01-14 12:05:00,328 - INFO - [Valid] [51/90] | Loss: 0.5313 | Val Acc: 81.42%
2026-01-14 12:05:00,339 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 12:05:00,340 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 12:05:00,344 - INFO - --------------------------------------------------
2026-01-14 12:05:00,347 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 12:05:09,581 - INFO - [Train] [52/90] | Loss: 0.2824 | Train Acc: 96.06%
2026-01-14 12:05:11,843 - INFO - [Valid] [52/90] | Loss: 0.5446 | Val Acc: 81.71%
2026-01-14 12:05:11,861 - INFO - [Metrics for 'abnormal'] | Precision: 0.7844 | Recall: 0.8344 | F1: 0.8086
2026-01-14 12:05:11,864 - INFO - [Metrics for 'normal'] | Precision: 0.8488 | Recall: 0.8022 | F1: 0.8249
2026-01-14 12:05:11,870 - INFO - --------------------------------------------------
2026-01-14 12:05:11,872 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 12:05:21,621 - INFO - [Train] [53/90] | Loss: 0.2751 | Train Acc: 96.43%
2026-01-14 12:05:24,512 - INFO - [Valid] [53/90] | Loss: 0.5556 | Val Acc: 82.30%
2026-01-14 12:05:24,531 - INFO - [Metrics for 'abnormal'] | Precision: 0.8170 | Recall: 0.7962 | F1: 0.8065
2026-01-14 12:05:24,531 - INFO - [Metrics for 'normal'] | Precision: 0.8280 | Recall: 0.8462 | F1: 0.8370
2026-01-14 12:05:24,538 - INFO - --------------------------------------------------
2026-01-14 12:05:24,541 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 12:05:33,989 - INFO - [Train] [54/90] | Loss: 0.2647 | Train Acc: 97.10%
2026-01-14 12:05:36,880 - INFO - [Valid] [54/90] | Loss: 0.5734 | Val Acc: 81.12%
2026-01-14 12:05:36,891 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-01-14 12:05:36,892 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-01-14 12:05:36,897 - INFO - --------------------------------------------------
2026-01-14 12:05:36,900 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 12:05:45,965 - INFO - [Train] [55/90] | Loss: 0.2634 | Train Acc: 97.47%
2026-01-14 12:05:48,518 - INFO - [Valid] [55/90] | Loss: 0.5842 | Val Acc: 80.24%
2026-01-14 12:05:48,529 - INFO - [Metrics for 'abnormal'] | Precision: 0.8689 | Recall: 0.6752 | F1: 0.7599
2026-01-14 12:05:48,529 - INFO - [Metrics for 'normal'] | Precision: 0.7650 | Recall: 0.9121 | F1: 0.8321
2026-01-14 12:05:48,534 - INFO - --------------------------------------------------
2026-01-14 12:05:48,536 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 12:05:57,656 - INFO - [Train] [56/90] | Loss: 0.2715 | Train Acc: 97.25%
2026-01-14 12:06:00,334 - INFO - [Valid] [56/90] | Loss: 0.5650 | Val Acc: 80.24%
2026-01-14 12:06:00,346 - INFO - [Metrics for 'abnormal'] | Precision: 0.7557 | Recall: 0.8471 | F1: 0.7988
2026-01-14 12:06:00,347 - INFO - [Metrics for 'normal'] | Precision: 0.8528 | Recall: 0.7637 | F1: 0.8058
2026-01-14 12:06:00,351 - INFO - --------------------------------------------------
2026-01-14 12:06:00,354 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 12:06:10,959 - INFO - [Train] [57/90] | Loss: 0.2744 | Train Acc: 96.73%
2026-01-14 12:06:14,512 - INFO - [Valid] [57/90] | Loss: 0.6323 | Val Acc: 72.86%
2026-01-14 12:06:14,525 - INFO - [Metrics for 'abnormal'] | Precision: 0.6816 | Recall: 0.7771 | F1: 0.7262
2026-01-14 12:06:14,526 - INFO - [Metrics for 'normal'] | Precision: 0.7812 | Recall: 0.6868 | F1: 0.7310
2026-01-14 12:06:14,530 - INFO - --------------------------------------------------
2026-01-14 12:06:14,533 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 12:06:23,171 - INFO - [Train] [58/90] | Loss: 0.2635 | Train Acc: 96.88%
2026-01-14 12:06:26,151 - INFO - [Valid] [58/90] | Loss: 0.5657 | Val Acc: 80.83%
2026-01-14 12:06:26,161 - INFO - [Metrics for 'abnormal'] | Precision: 0.8382 | Recall: 0.7261 | F1: 0.7782
2026-01-14 12:06:26,162 - INFO - [Metrics for 'normal'] | Precision: 0.7882 | Recall: 0.8791 | F1: 0.8312
2026-01-14 12:06:26,167 - INFO - --------------------------------------------------
2026-01-14 12:06:26,169 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 12:06:35,214 - INFO - [Train] [59/90] | Loss: 0.2567 | Train Acc: 97.17%
2026-01-14 12:06:37,866 - INFO - [Valid] [59/90] | Loss: 0.5998 | Val Acc: 81.12%
2026-01-14 12:06:37,899 - INFO - [Metrics for 'abnormal'] | Precision: 0.8444 | Recall: 0.7261 | F1: 0.7808
2026-01-14 12:06:37,899 - INFO - [Metrics for 'normal'] | Precision: 0.7892 | Recall: 0.8846 | F1: 0.8342
2026-01-14 12:06:37,904 - INFO - --------------------------------------------------
2026-01-14 12:06:37,906 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 12:06:47,250 - INFO - [Train] [60/90] | Loss: 0.2480 | Train Acc: 98.14%
2026-01-14 12:06:49,987 - INFO - [Valid] [60/90] | Loss: 0.5732 | Val Acc: 79.06%
2026-01-14 12:06:50,007 - INFO - [Metrics for 'abnormal'] | Precision: 0.7905 | Recall: 0.7452 | F1: 0.7672
2026-01-14 12:06:50,007 - INFO - [Metrics for 'normal'] | Precision: 0.7906 | Recall: 0.8297 | F1: 0.8097
2026-01-14 12:06:50,018 - INFO - --------------------------------------------------
2026-01-14 12:06:50,023 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 12:06:59,080 - INFO - [Train] [61/90] | Loss: 0.2494 | Train Acc: 97.99%
2026-01-14 12:07:01,373 - INFO - [Valid] [61/90] | Loss: 0.5390 | Val Acc: 81.12%
2026-01-14 12:07:01,395 - INFO - [Metrics for 'abnormal'] | Precision: 0.8079 | Recall: 0.7771 | F1: 0.7922
2026-01-14 12:07:01,395 - INFO - [Metrics for 'normal'] | Precision: 0.8138 | Recall: 0.8407 | F1: 0.8270
2026-01-14 12:07:01,402 - INFO - --------------------------------------------------
2026-01-14 12:07:01,407 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 12:07:09,410 - INFO - [Train] [62/90] | Loss: 0.2323 | Train Acc: 98.96%
2026-01-14 12:07:12,609 - INFO - [Valid] [62/90] | Loss: 0.5832 | Val Acc: 79.94%
2026-01-14 12:07:12,638 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-01-14 12:07:12,639 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-01-14 12:07:12,646 - INFO - --------------------------------------------------
2026-01-14 12:07:12,648 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 12:07:21,329 - INFO - [Train] [63/90] | Loss: 0.2387 | Train Acc: 98.44%
2026-01-14 12:07:24,048 - INFO - [Valid] [63/90] | Loss: 0.5624 | Val Acc: 78.47%
2026-01-14 12:07:24,059 - INFO - [Metrics for 'abnormal'] | Precision: 0.7530 | Recall: 0.7962 | F1: 0.7740
2026-01-14 12:07:24,060 - INFO - [Metrics for 'normal'] | Precision: 0.8150 | Recall: 0.7747 | F1: 0.7944
2026-01-14 12:07:24,064 - INFO - --------------------------------------------------
2026-01-14 12:07:24,068 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 12:07:33,931 - INFO - [Train] [64/90] | Loss: 0.2382 | Train Acc: 98.66%
2026-01-14 12:07:36,389 - INFO - [Valid] [64/90] | Loss: 0.5696 | Val Acc: 79.94%
2026-01-14 12:07:36,401 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.7580 | F1: 0.7778
2026-01-14 12:07:36,402 - INFO - [Metrics for 'normal'] | Precision: 0.8000 | Recall: 0.8352 | F1: 0.8172
2026-01-14 12:07:36,407 - INFO - --------------------------------------------------
2026-01-14 12:07:36,411 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 12:07:45,328 - INFO - [Train] [65/90] | Loss: 0.2316 | Train Acc: 98.88%
2026-01-14 12:07:48,073 - INFO - [Valid] [65/90] | Loss: 0.5700 | Val Acc: 79.94%
2026-01-14 12:07:48,085 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-01-14 12:07:48,086 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-01-14 12:07:48,090 - INFO - --------------------------------------------------
2026-01-14 12:07:48,094 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 12:07:57,264 - INFO - [Train] [66/90] | Loss: 0.2376 | Train Acc: 98.66%
2026-01-14 12:08:00,433 - INFO - [Valid] [66/90] | Loss: 0.5514 | Val Acc: 79.94%
2026-01-14 12:08:00,445 - INFO - [Metrics for 'abnormal'] | Precision: 0.7871 | Recall: 0.7771 | F1: 0.7821
2026-01-14 12:08:00,446 - INFO - [Metrics for 'normal'] | Precision: 0.8098 | Recall: 0.8187 | F1: 0.8142
2026-01-14 12:08:00,450 - INFO - --------------------------------------------------
2026-01-14 12:08:00,453 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 12:08:09,040 - INFO - [Train] [67/90] | Loss: 0.2406 | Train Acc: 98.66%
2026-01-14 12:08:11,975 - INFO - [Valid] [67/90] | Loss: 0.5892 | Val Acc: 80.24%
2026-01-14 12:08:11,987 - INFO - [Metrics for 'abnormal'] | Precision: 0.8358 | Recall: 0.7134 | F1: 0.7698
2026-01-14 12:08:11,987 - INFO - [Metrics for 'normal'] | Precision: 0.7805 | Recall: 0.8791 | F1: 0.8269
2026-01-14 12:08:11,991 - INFO - --------------------------------------------------
2026-01-14 12:08:11,994 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 12:08:20,453 - INFO - [Train] [68/90] | Loss: 0.2450 | Train Acc: 97.84%
2026-01-14 12:08:23,685 - INFO - [Valid] [68/90] | Loss: 0.5918 | Val Acc: 79.06%
2026-01-14 12:08:23,697 - INFO - [Metrics for 'abnormal'] | Precision: 0.7622 | Recall: 0.7962 | F1: 0.7788
2026-01-14 12:08:23,697 - INFO - [Metrics for 'normal'] | Precision: 0.8171 | Recall: 0.7857 | F1: 0.8011
2026-01-14 12:08:23,702 - INFO - --------------------------------------------------
2026-01-14 12:08:23,705 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 12:08:32,079 - INFO - [Train] [69/90] | Loss: 0.2337 | Train Acc: 98.81%
2026-01-14 12:08:35,052 - INFO - [Valid] [69/90] | Loss: 0.5336 | Val Acc: 81.71%
2026-01-14 12:08:35,061 - INFO - [Metrics for 'abnormal'] | Precision: 0.8146 | Recall: 0.7834 | F1: 0.7987
2026-01-14 12:08:35,061 - INFO - [Metrics for 'normal'] | Precision: 0.8191 | Recall: 0.8462 | F1: 0.8324
2026-01-14 12:08:35,065 - INFO - --------------------------------------------------
2026-01-14 12:08:35,067 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 12:08:44,049 - INFO - [Train] [70/90] | Loss: 0.2272 | Train Acc: 98.96%
2026-01-14 12:08:46,763 - INFO - [Valid] [70/90] | Loss: 0.5614 | Val Acc: 82.30%
2026-01-14 12:08:46,774 - INFO - [Metrics for 'abnormal'] | Precision: 0.8299 | Recall: 0.7771 | F1: 0.8026
2026-01-14 12:08:46,774 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8626 | F1: 0.8396
2026-01-14 12:08:46,779 - INFO - --------------------------------------------------
2026-01-14 12:08:46,782 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 12:08:57,248 - INFO - [Train] [71/90] | Loss: 0.2388 | Train Acc: 98.44%
2026-01-14 12:09:00,053 - INFO - [Valid] [71/90] | Loss: 0.5737 | Val Acc: 81.12%
2026-01-14 12:09:00,064 - INFO - [Metrics for 'abnormal'] | Precision: 0.8163 | Recall: 0.7643 | F1: 0.7895
2026-01-14 12:09:00,064 - INFO - [Metrics for 'normal'] | Precision: 0.8073 | Recall: 0.8516 | F1: 0.8289
2026-01-14 12:09:00,067 - INFO - --------------------------------------------------
2026-01-14 12:09:00,069 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 12:09:09,813 - INFO - [Train] [72/90] | Loss: 0.2359 | Train Acc: 98.36%
2026-01-14 12:09:12,717 - INFO - [Valid] [72/90] | Loss: 0.5910 | Val Acc: 79.65%
2026-01-14 12:09:12,746 - INFO - [Metrics for 'abnormal'] | Precision: 0.7933 | Recall: 0.7580 | F1: 0.7752
2026-01-14 12:09:12,746 - INFO - [Metrics for 'normal'] | Precision: 0.7989 | Recall: 0.8297 | F1: 0.8140
2026-01-14 12:09:12,754 - INFO - --------------------------------------------------
2026-01-14 12:09:12,760 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 12:09:23,542 - INFO - [Train] [73/90] | Loss: 0.2284 | Train Acc: 99.03%
2026-01-14 12:09:25,420 - INFO - [Valid] [73/90] | Loss: 0.5846 | Val Acc: 78.47%
2026-01-14 12:09:25,431 - INFO - [Metrics for 'abnormal'] | Precision: 0.7386 | Recall: 0.8280 | F1: 0.7808
2026-01-14 12:09:25,432 - INFO - [Metrics for 'normal'] | Precision: 0.8344 | Recall: 0.7473 | F1: 0.7884
2026-01-14 12:09:25,436 - INFO - --------------------------------------------------
2026-01-14 12:09:25,438 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 12:09:34,387 - INFO - [Train] [74/90] | Loss: 0.2241 | Train Acc: 99.26%
2026-01-14 12:09:36,966 - INFO - [Valid] [74/90] | Loss: 0.5881 | Val Acc: 79.35%
2026-01-14 12:09:36,978 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8280 | F1: 0.7879
2026-01-14 12:09:36,979 - INFO - [Metrics for 'normal'] | Precision: 0.8373 | Recall: 0.7637 | F1: 0.7989
2026-01-14 12:09:36,983 - INFO - --------------------------------------------------
2026-01-14 12:09:36,986 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 12:09:47,484 - INFO - [Train] [75/90] | Loss: 0.2461 | Train Acc: 97.92%
2026-01-14 12:09:49,782 - INFO - [Valid] [75/90] | Loss: 0.6230 | Val Acc: 78.17%
2026-01-14 12:09:49,793 - INFO - [Metrics for 'abnormal'] | Precision: 0.7485 | Recall: 0.7962 | F1: 0.7716
2026-01-14 12:09:49,793 - INFO - [Metrics for 'normal'] | Precision: 0.8140 | Recall: 0.7692 | F1: 0.7910
2026-01-14 12:09:49,798 - INFO - --------------------------------------------------
2026-01-14 12:09:49,801 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 12:09:59,069 - INFO - [Train] [76/90] | Loss: 0.2916 | Train Acc: 95.01%
2026-01-14 12:10:02,083 - INFO - [Valid] [76/90] | Loss: 0.6060 | Val Acc: 80.83%
2026-01-14 12:10:02,097 - INFO - [Metrics for 'abnormal'] | Precision: 0.8239 | Recall: 0.7452 | F1: 0.7826
2026-01-14 12:10:02,098 - INFO - [Metrics for 'normal'] | Precision: 0.7970 | Recall: 0.8626 | F1: 0.8285
2026-01-14 12:10:02,102 - INFO - --------------------------------------------------
2026-01-14 12:10:02,105 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 12:10:11,369 - INFO - [Train] [77/90] | Loss: 0.2532 | Train Acc: 97.54%
2026-01-14 12:10:14,553 - INFO - [Valid] [77/90] | Loss: 0.5276 | Val Acc: 82.30%
2026-01-14 12:10:14,565 - INFO - [Metrics for 'abnormal'] | Precision: 0.8050 | Recall: 0.8153 | F1: 0.8101
2026-01-14 12:10:14,566 - INFO - [Metrics for 'normal'] | Precision: 0.8389 | Recall: 0.8297 | F1: 0.8343
2026-01-14 12:10:14,571 - INFO - --------------------------------------------------
2026-01-14 12:10:14,574 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 12:10:24,931 - INFO - [Train] [78/90] | Loss: 0.2481 | Train Acc: 97.84%
2026-01-14 12:10:27,352 - INFO - [Valid] [78/90] | Loss: 0.5675 | Val Acc: 81.71%
2026-01-14 12:10:27,365 - INFO - [Metrics for 'abnormal'] | Precision: 0.8467 | Recall: 0.7389 | F1: 0.7891
2026-01-14 12:10:27,366 - INFO - [Metrics for 'normal'] | Precision: 0.7970 | Recall: 0.8846 | F1: 0.8385
2026-01-14 12:10:27,371 - INFO - --------------------------------------------------
2026-01-14 12:10:27,374 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 12:10:37,333 - INFO - [Train] [79/90] | Loss: 0.2299 | Train Acc: 98.88%
2026-01-14 12:10:39,895 - INFO - [Valid] [79/90] | Loss: 0.5316 | Val Acc: 81.12%
2026-01-14 12:10:39,906 - INFO - [Metrics for 'abnormal'] | Precision: 0.7853 | Recall: 0.8153 | F1: 0.8000
2026-01-14 12:10:39,907 - INFO - [Metrics for 'normal'] | Precision: 0.8352 | Recall: 0.8077 | F1: 0.8212
2026-01-14 12:10:39,911 - INFO - --------------------------------------------------
2026-01-14 12:10:39,914 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 12:10:48,572 - INFO - [Train] [80/90] | Loss: 0.2290 | Train Acc: 98.74%
2026-01-14 12:10:51,379 - INFO - [Valid] [80/90] | Loss: 0.5948 | Val Acc: 81.12%
2026-01-14 12:10:51,391 - INFO - [Metrics for 'abnormal'] | Precision: 0.7925 | Recall: 0.8025 | F1: 0.7975
2026-01-14 12:10:51,392 - INFO - [Metrics for 'normal'] | Precision: 0.8278 | Recall: 0.8187 | F1: 0.8232
2026-01-14 12:10:51,396 - INFO - --------------------------------------------------
2026-01-14 12:10:51,399 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 12:11:00,743 - INFO - [Train] [81/90] | Loss: 0.2230 | Train Acc: 99.11%
2026-01-14 12:11:03,826 - INFO - [Valid] [81/90] | Loss: 0.5933 | Val Acc: 80.83%
2026-01-14 12:11:03,851 - INFO - [Metrics for 'abnormal'] | Precision: 0.7840 | Recall: 0.8089 | F1: 0.7962
2026-01-14 12:11:03,852 - INFO - [Metrics for 'normal'] | Precision: 0.8305 | Recall: 0.8077 | F1: 0.8189
2026-01-14 12:11:03,859 - INFO - --------------------------------------------------
2026-01-14 12:11:03,866 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 12:11:13,323 - INFO - [Train] [82/90] | Loss: 0.2167 | Train Acc: 99.26%
2026-01-14 12:11:16,848 - INFO - [Valid] [82/90] | Loss: 0.5845 | Val Acc: 80.83%
2026-01-14 12:11:16,861 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 12:11:16,863 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 12:11:16,867 - INFO - --------------------------------------------------
2026-01-14 12:11:16,871 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 12:11:25,188 - INFO - [Train] [83/90] | Loss: 0.2124 | Train Acc: 99.78%
2026-01-14 12:11:28,927 - INFO - [Valid] [83/90] | Loss: 0.5651 | Val Acc: 80.83%
2026-01-14 12:11:28,956 - INFO - [Metrics for 'abnormal'] | Precision: 0.7911 | Recall: 0.7962 | F1: 0.7937
2026-01-14 12:11:28,956 - INFO - [Metrics for 'normal'] | Precision: 0.8232 | Recall: 0.8187 | F1: 0.8209
2026-01-14 12:11:28,963 - INFO - --------------------------------------------------
2026-01-14 12:11:28,968 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 12:11:38,623 - INFO - [Train] [84/90] | Loss: 0.2154 | Train Acc: 99.55%
2026-01-14 12:11:41,974 - INFO - [Valid] [84/90] | Loss: 0.5911 | Val Acc: 82.01%
2026-01-14 12:11:41,994 - INFO - [Metrics for 'abnormal'] | Precision: 0.8117 | Recall: 0.7962 | F1: 0.8039
2026-01-14 12:11:41,995 - INFO - [Metrics for 'normal'] | Precision: 0.8270 | Recall: 0.8407 | F1: 0.8338
2026-01-14 12:11:42,005 - INFO - --------------------------------------------------
2026-01-14 12:11:42,013 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 12:11:51,020 - INFO - [Train] [85/90] | Loss: 0.2232 | Train Acc: 99.18%
2026-01-14 12:11:54,532 - INFO - [Valid] [85/90] | Loss: 0.5814 | Val Acc: 81.12%
2026-01-14 12:11:54,543 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 12:11:54,544 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 12:11:54,548 - INFO - --------------------------------------------------
2026-01-14 12:11:54,551 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 12:12:03,283 - INFO - [Train] [86/90] | Loss: 0.2202 | Train Acc: 99.26%
2026-01-14 12:12:06,599 - INFO - [Valid] [86/90] | Loss: 0.5696 | Val Acc: 80.53%
2026-01-14 12:12:06,611 - INFO - [Metrics for 'abnormal'] | Precision: 0.7758 | Recall: 0.8153 | F1: 0.7950
2026-01-14 12:12:06,612 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7967 | F1: 0.8146
2026-01-14 12:12:06,616 - INFO - --------------------------------------------------
2026-01-14 12:12:06,619 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 12:12:15,287 - INFO - [Train] [87/90] | Loss: 0.2165 | Train Acc: 99.40%
2026-01-14 12:12:19,086 - INFO - [Valid] [87/90] | Loss: 0.5604 | Val Acc: 80.83%
2026-01-14 12:12:19,106 - INFO - [Metrics for 'abnormal'] | Precision: 0.8026 | Recall: 0.7771 | F1: 0.7896
2026-01-14 12:12:19,106 - INFO - [Metrics for 'normal'] | Precision: 0.8128 | Recall: 0.8352 | F1: 0.8238
2026-01-14 12:12:19,110 - INFO - --------------------------------------------------
2026-01-14 12:12:19,115 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 12:12:28,347 - INFO - [Train] [88/90] | Loss: 0.2132 | Train Acc: 99.55%
2026-01-14 12:12:31,190 - INFO - [Valid] [88/90] | Loss: 0.5643 | Val Acc: 79.94%
2026-01-14 12:12:31,202 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 12:12:31,203 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 12:12:31,207 - INFO - --------------------------------------------------
2026-01-14 12:12:31,210 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 12:12:40,501 - INFO - [Train] [89/90] | Loss: 0.2095 | Train Acc: 99.63%
2026-01-14 12:12:42,914 - INFO - [Valid] [89/90] | Loss: 0.6030 | Val Acc: 78.76%
2026-01-14 12:12:42,924 - INFO - [Metrics for 'abnormal'] | Precision: 0.7707 | Recall: 0.7707 | F1: 0.7707
2026-01-14 12:12:42,924 - INFO - [Metrics for 'normal'] | Precision: 0.8022 | Recall: 0.8022 | F1: 0.8022
2026-01-14 12:12:42,929 - INFO - --------------------------------------------------
2026-01-14 12:12:42,932 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 12:12:52,487 - INFO - [Train] [90/90] | Loss: 0.2173 | Train Acc: 99.26%
2026-01-14 12:12:55,682 - INFO - [Valid] [90/90] | Loss: 0.5600 | Val Acc: 79.94%
2026-01-14 12:12:55,693 - INFO - [Metrics for 'abnormal'] | Precision: 0.7834 | Recall: 0.7834 | F1: 0.7834
2026-01-14 12:12:55,693 - INFO - [Metrics for 'normal'] | Precision: 0.8132 | Recall: 0.8132 | F1: 0.8132
2026-01-14 12:12:55,698 - INFO - ==================================================
2026-01-14 12:12:55,699 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 12:12:55,699 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 12:12:55,699 - INFO - Baseline 모델 'mobilenet_v4_s'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:12:55,989 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 12:12:55,991 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 12:12:55,992 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:12:56,267 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.3233935546875)에 맞춰 변경되었습니다.
2026-01-14 12:12:56,267 - INFO - ==================================================
2026-01-14 12:12:56,383 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/best_model.pth'
2026-01-14 12:12:56,383 - INFO - ==================================================
2026-01-14 12:12:56,383 - INFO - Test 모드를 시작합니다.
2026-01-14 12:12:56,677 - INFO - 연산량 (MACs): 0.0913 GMACs per sample
2026-01-14 12:12:56,678 - INFO - 연산량 (FLOPs): 0.1826 GFLOPs per sample
2026-01-14 12:12:56,678 - INFO - ==================================================
2026-01-14 12:12:56,678 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 12:12:58,458 - INFO - 샘플 당 평균 Forward Pass 시간: 7.41ms (std: 6.68ms), FPS: 163.54 (std: 43.65) (1개 샘플 x 100회 반복)
2026-01-14 12:12:58,459 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 81.58 MB
2026-01-14 12:12:58,459 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 12:13:03,114 - INFO - [Test] Loss: 0.4109 | Test Acc: 81.42%
2026-01-14 12:13:03,131 - INFO - [Metrics for 'abnormal'] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-01-14 12:13:03,131 - INFO - [Metrics for 'normal'] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-01-14 12:13:03,889 - INFO - ==================================================
2026-01-14 12:13:03,890 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/confusion_matrix_20260114_115545.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/confusion_matrix_20260114_115545.pdf'
2026-01-14 12:13:03,890 - INFO - ==================================================
2026-01-14 12:13:03,891 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 12:13:14,631 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/model_fp32_20260114_115545.onnx'에 저장되었습니다. (크기: 4.40 MB)
2026-01-14 12:13:15,328 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2498.34 MB (증가량: 6.25 MB)
2026-01-14 12:13:15,328 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 12:13:18,009 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 19.56ms (std: 35.92ms)
2026-01-14 12:13:18,014 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 103.50 FPS (std: 64.55) (1개 샘플 x 100회 반복)
2026-01-14 12:13:18,014 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2503.34 MB (순수 증가량: 5.00 MB)
2026-01-14 12:13:18,014 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2503.34 MB (전체 증가량: 11.25 MB)
2026-01-14 12:13:24,199 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.42%
2026-01-14 12:13:24,233 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8052 | Recall: 0.7898 | F1: 0.7974
2026-01-14 12:13:24,233 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8216 | Recall: 0.8352 | F1: 0.8283
2026-01-14 12:13:24,796 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/val_acc.pdf'
2026-01-14 12:13:25,286 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/train_val_acc.pdf'
2026-01-14 12:13:25,803 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/F1_normal.pdf'
2026-01-14 12:13:26,306 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/val_loss.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/val_loss.pdf'
2026-01-14 12:13:26,844 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/learning_rate.pdf'
2026-01-14 12:13:32,645 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/compile.png' and 'log/Sewer-TAPNEW/baseline_mobilenet_v4_s_l1_20260114_115545/graph_20260114_115545/compile.pdf'
