2026-01-14 11:56:13,244 - INFO - 로그 파일이 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/log_20260114_115613.log'에 저장됩니다.
2026-01-14 11:56:13,253 - INFO - ==================================================
2026-01-14 11:56:13,254 - INFO - config.yaml:
2026-01-14 11:56:13,254 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: train
  pth_inference_dir: ./pretrained
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  show_log: true
  dataset:
    name: Sewer-TAPNEW
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/cau/workspace/data/Sewer/Sewer-ML/valid
      train_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/cau/workspace/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/cau/workspace/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  patch_size: 56
  stride: 56
  cnn_feature_extractor:
    name: efficientnet_b0_feat2
  featured_patch_dim: 24
  emb_dim: 24
  num_heads: 2
  num_decoder_layers: 2
  num_decoder_patches: 1
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: true
  save_attention: true
  num_plot_attention: 5
baseline:
  model_name: xie2019
  use_l1_pruning: true
  pruning_flops_target: 0.1829

2026-01-14 11:56:13,254 - INFO - ==================================================
2026-01-14 11:56:13,323 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA RTX PRO 6000 Blackwell Server Edition)
2026-01-14 11:56:13,324 - INFO - 'Sewer-TAPNEW' 데이터 로드를 시작합니다 (Type: image_folder).
2026-01-14 11:56:13,324 - INFO - '/home/cau/workspace/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-01-14 11:56:13,338 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-01-14 11:56:13,340 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-01-14 11:56:13,341 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-01-14 11:56:13,341 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 11:56:13,696 - INFO - ==================================================
2026-01-14 11:56:13,697 - INFO - 모델 파라미터 수:
2026-01-14 11:56:13,697 - INFO -   - 총 파라미터: 9,160,194 개
2026-01-14 11:56:13,697 - INFO -   - 학습 가능한 파라미터: 9,160,194 개
2026-01-14 11:56:13,698 - INFO - ================================================================================
2026-01-14 11:56:13,698 - INFO - 단계 1/2: 사전 훈련(Pre-training)을 시작합니다.
2026-01-14 11:56:13,698 - INFO - ================================================================================
2026-01-14 11:56:13,698 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 11:56:13,699 - INFO - 스케줄러: CosineAnnealingLR (T_max=10, eta_min=0.0001)
2026-01-14 11:56:13,699 - INFO - ==================================================
2026-01-14 11:56:13,699 - INFO - train 모드를 시작합니다.
2026-01-14 11:56:13,700 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 11:56:13,700 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 11:56:13,700 - INFO - --------------------------------------------------
2026-01-14 11:56:13,701 - INFO - [LR]    [1/10] | Learning Rate: 0.001000
2026-01-14 11:56:21,480 - INFO - [Train] [1/10] | Loss: 0.5910 | Train Acc: 74.33%
2026-01-14 11:56:24,436 - INFO - [Valid] [1/10] | Loss: 0.5861 | Val Acc: 75.22%
2026-01-14 11:56:24,453 - INFO - [Metrics for 'abnormal'] | Precision: 0.8349 | Recall: 0.5796 | F1: 0.6842
2026-01-14 11:56:24,454 - INFO - [Metrics for 'normal'] | Precision: 0.7130 | Recall: 0.9011 | F1: 0.7961
2026-01-14 11:56:24,537 - INFO - [Best Model Saved] (val loss: 0.5861) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:56:24,537 - INFO - --------------------------------------------------
2026-01-14 11:56:24,538 - INFO - [LR]    [2/10] | Learning Rate: 0.000978
2026-01-14 11:56:30,224 - INFO - [Train] [2/10] | Loss: 0.5426 | Train Acc: 79.69%
2026-01-14 11:56:32,338 - INFO - [Valid] [2/10] | Loss: 0.6111 | Val Acc: 73.16%
2026-01-14 11:56:32,351 - INFO - [Metrics for 'abnormal'] | Precision: 0.6634 | Recall: 0.8535 | F1: 0.7465
2026-01-14 11:56:32,352 - INFO - [Metrics for 'normal'] | Precision: 0.8321 | Recall: 0.6264 | F1: 0.7147
2026-01-14 11:56:32,357 - INFO - --------------------------------------------------
2026-01-14 11:56:32,358 - INFO - [LR]    [3/10] | Learning Rate: 0.000914
2026-01-14 11:56:38,072 - INFO - [Train] [3/10] | Loss: 0.5372 | Train Acc: 78.87%
2026-01-14 11:56:39,620 - INFO - [Valid] [3/10] | Loss: 0.5478 | Val Acc: 73.45%
2026-01-14 11:56:39,632 - INFO - [Metrics for 'abnormal'] | Precision: 0.6959 | Recall: 0.7580 | F1: 0.7256
2026-01-14 11:56:39,633 - INFO - [Metrics for 'normal'] | Precision: 0.7738 | Recall: 0.7143 | F1: 0.7429
2026-01-14 11:56:39,719 - INFO - [Best Model Saved] (val loss: 0.5478) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:56:39,720 - INFO - --------------------------------------------------
2026-01-14 11:56:39,720 - INFO - [LR]    [4/10] | Learning Rate: 0.000815
2026-01-14 11:56:45,329 - INFO - [Train] [4/10] | Loss: 0.5110 | Train Acc: 80.21%
2026-01-14 11:56:46,769 - INFO - [Valid] [4/10] | Loss: 0.5510 | Val Acc: 77.58%
2026-01-14 11:56:46,782 - INFO - [Metrics for 'abnormal'] | Precision: 0.8092 | Recall: 0.6752 | F1: 0.7361
2026-01-14 11:56:46,782 - INFO - [Metrics for 'normal'] | Precision: 0.7548 | Recall: 0.8626 | F1: 0.8051
2026-01-14 11:56:46,787 - INFO - --------------------------------------------------
2026-01-14 11:56:46,787 - INFO - [LR]    [5/10] | Learning Rate: 0.000689
2026-01-14 11:56:53,257 - INFO - [Train] [5/10] | Loss: 0.4834 | Train Acc: 81.70%
2026-01-14 11:56:55,028 - INFO - [Valid] [5/10] | Loss: 0.5196 | Val Acc: 80.24%
2026-01-14 11:56:55,040 - INFO - [Metrics for 'abnormal'] | Precision: 0.8000 | Recall: 0.7643 | F1: 0.7818
2026-01-14 11:56:55,042 - INFO - [Metrics for 'normal'] | Precision: 0.8042 | Recall: 0.8352 | F1: 0.8194
2026-01-14 11:56:55,143 - INFO - [Best Model Saved] (val loss: 0.5196) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:56:55,143 - INFO - --------------------------------------------------
2026-01-14 11:56:55,144 - INFO - [LR]    [6/10] | Learning Rate: 0.000550
2026-01-14 11:57:01,542 - INFO - [Train] [6/10] | Loss: 0.4784 | Train Acc: 84.15%
2026-01-14 11:57:03,299 - INFO - [Valid] [6/10] | Loss: 0.5030 | Val Acc: 80.83%
2026-01-14 11:57:03,316 - INFO - [Metrics for 'abnormal'] | Precision: 0.8067 | Recall: 0.7707 | F1: 0.7883
2026-01-14 11:57:03,316 - INFO - [Metrics for 'normal'] | Precision: 0.8095 | Recall: 0.8407 | F1: 0.8248
2026-01-14 11:57:03,406 - INFO - [Best Model Saved] (val loss: 0.5030) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:57:03,407 - INFO - --------------------------------------------------
2026-01-14 11:57:03,408 - INFO - [LR]    [7/10] | Learning Rate: 0.000411
2026-01-14 11:57:08,717 - INFO - [Train] [7/10] | Loss: 0.4602 | Train Acc: 84.97%
2026-01-14 11:57:10,247 - INFO - [Valid] [7/10] | Loss: 0.5045 | Val Acc: 81.42%
2026-01-14 11:57:10,259 - INFO - [Metrics for 'abnormal'] | Precision: 0.8013 | Recall: 0.7962 | F1: 0.7987
2026-01-14 11:57:10,259 - INFO - [Metrics for 'normal'] | Precision: 0.8251 | Recall: 0.8297 | F1: 0.8274
2026-01-14 11:57:10,263 - INFO - --------------------------------------------------
2026-01-14 11:57:10,264 - INFO - [LR]    [8/10] | Learning Rate: 0.000285
2026-01-14 11:57:15,724 - INFO - [Train] [8/10] | Loss: 0.4470 | Train Acc: 84.52%
2026-01-14 11:57:17,408 - INFO - [Valid] [8/10] | Loss: 0.4917 | Val Acc: 82.01%
2026-01-14 11:57:17,418 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 11:57:17,419 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 11:57:17,502 - INFO - [Best Model Saved] (val loss: 0.4917) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:57:17,502 - INFO - --------------------------------------------------
2026-01-14 11:57:17,503 - INFO - [LR]    [9/10] | Learning Rate: 0.000186
2026-01-14 11:57:23,736 - INFO - [Train] [9/10] | Loss: 0.4323 | Train Acc: 85.57%
2026-01-14 11:57:25,349 - INFO - [Valid] [9/10] | Loss: 0.5045 | Val Acc: 79.94%
2026-01-14 11:57:25,361 - INFO - [Metrics for 'abnormal'] | Precision: 0.7697 | Recall: 0.8089 | F1: 0.7888
2026-01-14 11:57:25,362 - INFO - [Metrics for 'normal'] | Precision: 0.8276 | Recall: 0.7912 | F1: 0.8090
2026-01-14 11:57:25,366 - INFO - --------------------------------------------------
2026-01-14 11:57:25,367 - INFO - [LR]    [10/10] | Learning Rate: 0.000122
2026-01-14 11:57:31,173 - INFO - [Train] [10/10] | Loss: 0.4288 | Train Acc: 86.09%
2026-01-14 11:57:32,953 - INFO - [Valid] [10/10] | Loss: 0.5059 | Val Acc: 80.83%
2026-01-14 11:57:32,963 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 11:57:32,963 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 11:57:32,967 - INFO - ================================================================================
2026-01-14 11:57:32,967 - INFO - 단계 2/2: Pruning 및 미세 조정(Fine-tuning)을 시작합니다.
2026-01-14 11:57:32,967 - INFO - ================================================================================
2026-01-14 11:57:33,015 - INFO - 사전 훈련된 모델 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'을(를) 불러왔습니다.
2026-01-14 11:57:33,016 - INFO - ================================================================================
2026-01-14 11:57:33,016 - INFO - 목표 FLOPs (0.1829 GFLOPs)에 맞는 최적의 Pruning 희소도를 탐색합니다.
2026-01-14 11:57:33,067 - INFO - 원본 모델 FLOPs: 2.8696 GFLOPs
2026-01-14 11:57:33,077 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:33,077 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:33,782 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.495)에 맞춰 변경되었습니다.
2026-01-14 11:57:33,783 - INFO - ==================================================
2026-01-14 11:57:33,791 - INFO -   [탐색  1] 희소도: 0.4950 -> FLOPs: 1.3003 GFLOPs (감소율: 54.69%)
2026-01-14 11:57:33,796 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:33,796 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:34,329 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.7424999999999999)에 맞춰 변경되었습니다.
2026-01-14 11:57:34,329 - INFO - ==================================================
2026-01-14 11:57:34,336 - INFO -   [탐색  2] 희소도: 0.7425 -> FLOPs: 0.6166 GFLOPs (감소율: 78.51%)
2026-01-14 11:57:34,341 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:34,341 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:34,896 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.86625)에 맞춰 변경되었습니다.
2026-01-14 11:57:34,897 - INFO - ==================================================
2026-01-14 11:57:34,905 - INFO -   [탐색  3] 희소도: 0.8662 -> FLOPs: 0.3005 GFLOPs (감소율: 89.53%)
2026-01-14 11:57:34,910 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:34,911 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:35,495 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.928125)에 맞춰 변경되었습니다.
2026-01-14 11:57:35,495 - INFO - ==================================================
2026-01-14 11:57:35,505 - INFO -   [탐색  4] 희소도: 0.9281 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:35,509 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:35,510 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:36,024 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.8971875)에 맞춰 변경되었습니다.
2026-01-14 11:57:36,025 - INFO - ==================================================
2026-01-14 11:57:36,034 - INFO -   [탐색  5] 희소도: 0.8972 -> FLOPs: 0.2238 GFLOPs (감소율: 92.20%)
2026-01-14 11:57:36,039 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:36,040 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:36,624 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.91265625)에 맞춰 변경되었습니다.
2026-01-14 11:57:36,625 - INFO - ==================================================
2026-01-14 11:57:36,635 - INFO -   [탐색  6] 희소도: 0.9127 -> FLOPs: 0.1858 GFLOPs (감소율: 93.52%)
2026-01-14 11:57:36,641 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:36,642 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:37,156 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.920390625)에 맞춰 변경되었습니다.
2026-01-14 11:57:37,157 - INFO - ==================================================
2026-01-14 11:57:37,163 - INFO -   [탐색  7] 희소도: 0.9204 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:37,167 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:37,168 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:37,960 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9242578125)에 맞춰 변경되었습니다.
2026-01-14 11:57:37,960 - INFO - ==================================================
2026-01-14 11:57:37,967 - INFO -   [탐색  8] 희소도: 0.9243 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:37,971 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:37,972 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:38,576 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.92232421875)에 맞춰 변경되었습니다.
2026-01-14 11:57:38,576 - INFO - ==================================================
2026-01-14 11:57:38,584 - INFO -   [탐색  9] 희소도: 0.9223 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:38,589 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:38,589 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:39,155 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921357421875)에 맞춰 변경되었습니다.
2026-01-14 11:57:39,155 - INFO - ==================================================
2026-01-14 11:57:39,159 - INFO -   [탐색 10] 희소도: 0.9214 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:39,163 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:39,164 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:39,642 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218408203125)에 맞춰 변경되었습니다.
2026-01-14 11:57:39,642 - INFO - ==================================================
2026-01-14 11:57:39,647 - INFO -   [탐색 11] 희소도: 0.9218 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:39,651 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:39,651 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:40,595 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9220825195312501)에 맞춰 변경되었습니다.
2026-01-14 11:57:40,596 - INFO - ==================================================
2026-01-14 11:57:40,605 - INFO -   [탐색 12] 희소도: 0.9221 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:40,616 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:40,617 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:41,169 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9219616699218751)에 맞춰 변경되었습니다.
2026-01-14 11:57:41,170 - INFO - ==================================================
2026-01-14 11:57:41,175 - INFO -   [탐색 13] 희소도: 0.9220 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:41,180 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:41,181 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:41,730 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9219012451171875)에 맞춰 변경되었습니다.
2026-01-14 11:57:41,730 - INFO - ==================================================
2026-01-14 11:57:41,734 - INFO -   [탐색 14] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:41,737 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:41,737 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:42,211 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218710327148438)에 맞춰 변경되었습니다.
2026-01-14 11:57:42,211 - INFO - ==================================================
2026-01-14 11:57:42,216 - INFO -   [탐색 15] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:42,219 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:42,220 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:42,784 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218861389160157)에 맞춰 변경되었습니다.
2026-01-14 11:57:42,785 - INFO - ==================================================
2026-01-14 11:57:42,790 - INFO -   [탐색 16] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:42,795 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:42,796 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:43,356 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218785858154297)에 맞춰 변경되었습니다.
2026-01-14 11:57:43,356 - INFO - ==================================================
2026-01-14 11:57:43,361 - INFO -   [탐색 17] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:43,365 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:43,365 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:44,159 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218748092651368)에 맞춰 변경되었습니다.
2026-01-14 11:57:44,160 - INFO - ==================================================
2026-01-14 11:57:44,165 - INFO -   [탐색 18] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:44,170 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:44,171 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:44,788 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218766975402832)에 맞춰 변경되었습니다.
2026-01-14 11:57:44,789 - INFO - ==================================================
2026-01-14 11:57:44,794 - INFO -   [탐색 19] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:44,799 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:44,800 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:45,383 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.92187575340271)에 맞춰 변경되었습니다.
2026-01-14 11:57:45,384 - INFO - ==================================================
2026-01-14 11:57:45,390 - INFO -   [탐색 20] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:45,395 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:45,395 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:45,945 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218752813339234)에 맞춰 변경되었습니다.
2026-01-14 11:57:45,946 - INFO - ==================================================
2026-01-14 11:57:45,950 - INFO -   [탐색 21] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:45,955 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:45,955 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:46,529 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750452995301)에 맞춰 변경되었습니다.
2026-01-14 11:57:46,530 - INFO - ==================================================
2026-01-14 11:57:46,535 - INFO -   [탐색 22] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:46,540 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:46,540 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:47,986 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749272823334)에 맞춰 변경되었습니다.
2026-01-14 11:57:47,987 - INFO - ==================================================
2026-01-14 11:57:47,998 - INFO -   [탐색 23] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:48,011 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:48,011 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:49,025 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749862909318)에 맞춰 변경되었습니다.
2026-01-14 11:57:49,026 - INFO - ==================================================
2026-01-14 11:57:49,031 - INFO -   [탐색 24] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:49,036 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:49,036 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:50,014 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750157952309)에 맞춰 변경되었습니다.
2026-01-14 11:57:50,015 - INFO - ==================================================
2026-01-14 11:57:50,019 - INFO -   [탐색 25] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:50,024 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:50,025 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:50,609 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750010430814)에 맞춰 변경되었습니다.
2026-01-14 11:57:50,610 - INFO - ==================================================
2026-01-14 11:57:50,615 - INFO -   [탐색 26] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:50,620 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:50,621 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:51,260 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749936670065)에 맞춰 변경되었습니다.
2026-01-14 11:57:51,260 - INFO - ==================================================
2026-01-14 11:57:51,265 - INFO -   [탐색 27] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:51,269 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:51,270 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:52,304 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921874997355044)에 맞춰 변경되었습니다.
2026-01-14 11:57:52,304 - INFO - ==================================================
2026-01-14 11:57:52,309 - INFO -   [탐색 28] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:52,314 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:52,314 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:53,600 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749991990627)에 맞춰 변경되었습니다.
2026-01-14 11:57:53,601 - INFO - ==================================================
2026-01-14 11:57:53,606 - INFO -   [탐색 29] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:53,612 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:53,612 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:54,228 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875000121072)에 맞춰 변경되었습니다.
2026-01-14 11:57:54,228 - INFO - ==================================================
2026-01-14 11:57:54,233 - INFO -   [탐색 30] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:54,238 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:54,239 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:54,822 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749996600674)에 맞춰 변경되었습니다.
2026-01-14 11:57:54,823 - INFO - ==================================================
2026-01-14 11:57:54,829 - INFO -   [탐색 31] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:54,834 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:54,835 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:55,492 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749998905698)에 맞춰 변경되었습니다.
2026-01-14 11:57:55,493 - INFO - ==================================================
2026-01-14 11:57:55,497 - INFO -   [탐색 32] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:55,501 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:55,501 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:56,109 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000058209)에 맞춰 변경되었습니다.
2026-01-14 11:57:56,109 - INFO - ==================================================
2026-01-14 11:57:56,113 - INFO -   [탐색 33] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:56,118 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:56,118 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:56,906 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999481953)에 맞춰 변경되었습니다.
2026-01-14 11:57:56,906 - INFO - ==================================================
2026-01-14 11:57:56,911 - INFO -   [탐색 34] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:56,916 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:56,916 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:57,435 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999770082)에 맞춰 변경되었습니다.
2026-01-14 11:57:57,436 - INFO - ==================================================
2026-01-14 11:57:57,440 - INFO -   [탐색 35] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:57,444 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:57,445 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:58,038 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999914145)에 맞춰 변경되었습니다.
2026-01-14 11:57:58,039 - INFO - ==================================================
2026-01-14 11:57:58,044 - INFO -   [탐색 36] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:58,049 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:58,050 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:58,602 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999986178)에 맞춰 변경되었습니다.
2026-01-14 11:57:58,603 - INFO - ==================================================
2026-01-14 11:57:58,607 - INFO -   [탐색 37] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:57:58,611 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:58,612 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:59,277 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000022193)에 맞춰 변경되었습니다.
2026-01-14 11:57:59,278 - INFO - ==================================================
2026-01-14 11:57:59,285 - INFO -   [탐색 38] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:59,293 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:59,294 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:57:59,899 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000004186)에 맞춰 변경되었습니다.
2026-01-14 11:57:59,900 - INFO - ==================================================
2026-01-14 11:57:59,905 - INFO -   [탐색 39] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:57:59,911 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:57:59,912 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:01,307 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999995182)에 맞춰 변경되었습니다.
2026-01-14 11:58:01,308 - INFO - ==================================================
2026-01-14 11:58:01,312 - INFO -   [탐색 40] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:01,317 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:01,318 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:02,749 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999999684)에 맞춰 변경되었습니다.
2026-01-14 11:58:02,749 - INFO - ==================================================
2026-01-14 11:58:02,754 - INFO -   [탐색 41] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:02,758 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:02,758 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:03,497 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000001934)에 맞춰 변경되었습니다.
2026-01-14 11:58:03,498 - INFO - ==================================================
2026-01-14 11:58:03,503 - INFO -   [탐색 42] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:03,509 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:03,509 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:04,199 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000808)에 맞춰 변경되었습니다.
2026-01-14 11:58:04,199 - INFO - ==================================================
2026-01-14 11:58:04,204 - INFO -   [탐색 43] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:04,209 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:04,210 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:05,019 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000246)에 맞춰 변경되었습니다.
2026-01-14 11:58:05,019 - INFO - ==================================================
2026-01-14 11:58:05,023 - INFO -   [탐색 44] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:05,028 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:05,029 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:05,763 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218749999999964)에 맞춰 변경되었습니다.
2026-01-14 11:58:05,763 - INFO - ==================================================
2026-01-14 11:58:05,771 - INFO -   [탐색 45] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:05,782 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:05,782 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:06,499 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000105)에 맞춰 변경되었습니다.
2026-01-14 11:58:06,499 - INFO - ==================================================
2026-01-14 11:58:06,503 - INFO -   [탐색 46] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:06,507 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:06,508 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:06,978 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000036)에 맞춰 변경되었습니다.
2026-01-14 11:58:06,978 - INFO - ==================================================
2026-01-14 11:58:06,982 - INFO -   [탐색 47] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:06,986 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:06,986 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:07,535 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:07,536 - INFO - ==================================================
2026-01-14 11:58:07,540 - INFO -   [탐색 48] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:07,544 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:07,544 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:08,289 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000018)에 맞춰 변경되었습니다.
2026-01-14 11:58:08,290 - INFO - ==================================================
2026-01-14 11:58:08,294 - INFO -   [탐색 49] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:08,300 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:08,301 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:08,823 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000009)에 맞춰 변경되었습니다.
2026-01-14 11:58:08,823 - INFO - ==================================================
2026-01-14 11:58:08,828 - INFO -   [탐색 50] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:08,831 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:08,832 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:09,612 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000004)에 맞춰 변경되었습니다.
2026-01-14 11:58:09,615 - INFO - ==================================================
2026-01-14 11:58:09,668 - INFO -   [탐색 51] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:09,673 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:09,674 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:10,591 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000002)에 맞춰 변경되었습니다.
2026-01-14 11:58:10,595 - INFO - ==================================================
2026-01-14 11:58:10,599 - INFO -   [탐색 52] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:10,611 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:10,612 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:11,556 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.9218750000000001)에 맞춰 변경되었습니다.
2026-01-14 11:58:11,558 - INFO - ==================================================
2026-01-14 11:58:11,566 - INFO -   [탐색 53] 희소도: 0.9219 -> FLOPs: 0.1481 GFLOPs (감소율: 94.84%)
2026-01-14 11:58:11,576 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:11,577 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:12,573 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:12,573 - INFO - ==================================================
2026-01-14 11:58:12,582 - INFO -   [탐색 54] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:12,589 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:12,593 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:13,339 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:13,339 - INFO - ==================================================
2026-01-14 11:58:13,345 - INFO -   [탐색 55] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:13,351 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:13,352 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:14,377 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:14,377 - INFO - ==================================================
2026-01-14 11:58:14,382 - INFO -   [탐색 56] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:14,390 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:14,390 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:15,190 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:15,191 - INFO - ==================================================
2026-01-14 11:58:15,198 - INFO -   [탐색 57] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:15,205 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:15,205 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:15,877 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:15,878 - INFO - ==================================================
2026-01-14 11:58:15,883 - INFO -   [탐색 58] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:15,889 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:15,890 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:16,469 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:16,470 - INFO - ==================================================
2026-01-14 11:58:16,474 - INFO -   [탐색 59] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:16,478 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:16,479 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:17,734 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:17,734 - INFO - ==================================================
2026-01-14 11:58:17,740 - INFO -   [탐색 60] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:17,745 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:17,746 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:18,342 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:18,343 - INFO - ==================================================
2026-01-14 11:58:18,348 - INFO -   [탐색 61] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:18,354 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:18,354 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:18,960 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:18,960 - INFO - ==================================================
2026-01-14 11:58:18,965 - INFO -   [탐색 62] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:18,970 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:18,971 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:19,556 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:19,556 - INFO - ==================================================
2026-01-14 11:58:19,561 - INFO -   [탐색 63] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:19,571 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:19,575 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:20,529 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:20,529 - INFO - ==================================================
2026-01-14 11:58:20,534 - INFO -   [탐색 64] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:20,540 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:20,540 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:21,205 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:21,206 - INFO - ==================================================
2026-01-14 11:58:21,210 - INFO -   [탐색 65] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:21,215 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:21,215 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:21,808 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:21,809 - INFO - ==================================================
2026-01-14 11:58:21,814 - INFO -   [탐색 66] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:21,819 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:21,819 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:22,394 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:22,395 - INFO - ==================================================
2026-01-14 11:58:22,400 - INFO -   [탐색 67] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:22,405 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:22,405 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:23,056 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:23,057 - INFO - ==================================================
2026-01-14 11:58:23,061 - INFO -   [탐색 68] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:23,066 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:23,067 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:23,910 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:23,910 - INFO - ==================================================
2026-01-14 11:58:23,915 - INFO -   [탐색 69] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:23,920 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:23,920 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:24,395 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:24,395 - INFO - ==================================================
2026-01-14 11:58:24,399 - INFO -   [탐색 70] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:24,403 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:24,403 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:25,050 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:25,050 - INFO - ==================================================
2026-01-14 11:58:25,055 - INFO -   [탐색 71] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:25,060 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:25,060 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:25,671 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:25,672 - INFO - ==================================================
2026-01-14 11:58:25,677 - INFO -   [탐색 72] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:25,682 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:25,683 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:26,312 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:26,312 - INFO - ==================================================
2026-01-14 11:58:26,317 - INFO -   [탐색 73] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:26,323 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:26,324 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:27,416 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:27,416 - INFO - ==================================================
2026-01-14 11:58:27,432 - INFO -   [탐색 74] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:27,437 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:27,438 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:28,273 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:28,274 - INFO - ==================================================
2026-01-14 11:58:28,280 - INFO -   [탐색 75] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:28,286 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:28,286 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:29,198 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:29,198 - INFO - ==================================================
2026-01-14 11:58:29,202 - INFO -   [탐색 76] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:29,205 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:29,205 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:29,796 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:29,797 - INFO - ==================================================
2026-01-14 11:58:29,801 - INFO -   [탐색 77] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:29,807 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:29,808 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:30,389 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:30,389 - INFO - ==================================================
2026-01-14 11:58:30,395 - INFO -   [탐색 78] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:30,400 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:30,401 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:30,903 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:30,903 - INFO - ==================================================
2026-01-14 11:58:30,908 - INFO -   [탐색 79] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:30,918 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:30,920 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:32,043 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:32,045 - INFO - ==================================================
2026-01-14 11:58:32,050 - INFO -   [탐색 80] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:32,056 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:32,057 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:32,544 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:32,545 - INFO - ==================================================
2026-01-14 11:58:32,550 - INFO -   [탐색 81] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:32,556 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:32,556 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:33,108 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:33,109 - INFO - ==================================================
2026-01-14 11:58:33,115 - INFO -   [탐색 82] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:33,120 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:33,121 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:33,757 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:33,757 - INFO - ==================================================
2026-01-14 11:58:33,764 - INFO -   [탐색 83] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:33,775 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:33,776 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:34,763 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:34,767 - INFO - ==================================================
2026-01-14 11:58:34,774 - INFO -   [탐색 84] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:34,786 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:34,786 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:35,690 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:35,690 - INFO - ==================================================
2026-01-14 11:58:35,695 - INFO -   [탐색 85] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:35,700 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:35,700 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:36,486 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:36,487 - INFO - ==================================================
2026-01-14 11:58:36,491 - INFO -   [탐색 86] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:36,496 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:36,497 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:37,139 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:37,140 - INFO - ==================================================
2026-01-14 11:58:37,145 - INFO -   [탐색 87] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:37,151 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:37,152 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:37,884 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:37,884 - INFO - ==================================================
2026-01-14 11:58:37,889 - INFO -   [탐색 88] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:37,894 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:37,894 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:38,681 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:38,682 - INFO - ==================================================
2026-01-14 11:58:38,686 - INFO -   [탐색 89] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:38,692 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:38,692 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:39,237 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:39,237 - INFO - ==================================================
2026-01-14 11:58:39,241 - INFO -   [탐색 90] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:39,247 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:39,247 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:39,734 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:39,734 - INFO - ==================================================
2026-01-14 11:58:39,739 - INFO -   [탐색 91] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:39,744 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:39,745 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:40,311 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:40,311 - INFO - ==================================================
2026-01-14 11:58:40,317 - INFO -   [탐색 92] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:40,329 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:40,329 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:40,794 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:40,794 - INFO - ==================================================
2026-01-14 11:58:40,798 - INFO -   [탐색 93] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:40,801 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:40,801 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:41,515 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:41,515 - INFO - ==================================================
2026-01-14 11:58:41,521 - INFO -   [탐색 94] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:41,526 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:41,527 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:42,151 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:42,152 - INFO - ==================================================
2026-01-14 11:58:42,156 - INFO -   [탐색 95] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:42,161 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:42,162 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:42,738 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:42,738 - INFO - ==================================================
2026-01-14 11:58:42,743 - INFO -   [탐색 96] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:42,748 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:42,748 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:43,351 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:43,352 - INFO - ==================================================
2026-01-14 11:58:43,357 - INFO -   [탐색 97] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:43,363 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:43,364 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:43,979 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:43,980 - INFO - ==================================================
2026-01-14 11:58:43,985 - INFO -   [탐색 98] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:43,991 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:43,991 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:44,582 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:44,583 - INFO - ==================================================
2026-01-14 11:58:44,588 - INFO -   [탐색 99] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:44,593 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:44,594 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:45,397 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921875)에 맞춰 변경되었습니다.
2026-01-14 11:58:45,398 - INFO - ==================================================
2026-01-14 11:58:45,402 - INFO -   [탐색 100] 희소도: 0.9219 -> FLOPs: 0.1854 GFLOPs (감소율: 93.54%)
2026-01-14 11:58:45,403 - INFO - 탐색 완료. 목표 FLOPs(0.1829)에 가장 근접한 최적 희소도는 0.9214 입니다.
2026-01-14 11:58:45,403 - INFO - ================================================================================
2026-01-14 11:58:45,407 - INFO - 계산된 Pruning 정보(희소도: 0.9214)를 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/pruning_info.yaml'에 저장했습니다.
2026-01-14 11:58:45,413 - INFO - Pruning 전 원본 모델의 FLOPs를 측정합니다.
2026-01-14 11:58:45,424 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 11:58:45,424 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 11:58:46,015 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921357421875)에 맞춰 변경되었습니다.
2026-01-14 11:58:46,016 - INFO - ==================================================
2026-01-14 11:58:46,016 - INFO - ==================================================
2026-01-14 11:58:46,016 - INFO - 모델 파라미터 수:
2026-01-14 11:58:46,016 - INFO -   - 총 파라미터: 57,792 개
2026-01-14 11:58:46,016 - INFO -   - 학습 가능한 파라미터: 57,792 개
2026-01-14 11:58:46,022 - INFO - Pruning 후 모델의 FLOPs를 측정합니다.
2026-01-14 11:58:46,031 - INFO - FLOPs가 2.8696 GFLOPs에서 0.1854 GFLOPs로 감소했습니다 (감소율: 93.54%).
2026-01-14 11:58:46,032 - INFO - 미세 조정을 위한 새로운 옵티마이저와 스케줄러를 생성합니다.
2026-01-14 11:58:46,032 - INFO - 옵티마이저: AdamW (lr=0.001, weight_decay=0.0001)
2026-01-14 11:58:46,033 - INFO - 스케줄러: CosineAnnealingLR (T_max=80, eta_min=0.0001)
2026-01-14 11:58:46,033 - INFO - ==================================================
2026-01-14 11:58:46,034 - INFO - train 모드를 시작합니다.
2026-01-14 11:58:46,034 - INFO - 손실 함수: CrossEntropyLoss (label_smoothing: 0.1)
2026-01-14 11:58:46,034 - INFO - Best metric을 초기값(inf)으로 설정합니다.
2026-01-14 11:58:46,034 - INFO - --------------------------------------------------
2026-01-14 11:58:46,035 - INFO - [LR]    [11/90] | Learning Rate: 0.001000
2026-01-14 11:58:52,688 - INFO - [Train] [11/90] | Loss: 0.5584 | Train Acc: 78.79%
2026-01-14 11:58:54,276 - INFO - [Valid] [11/90] | Loss: 0.5405 | Val Acc: 76.70%
2026-01-14 11:58:54,288 - INFO - [Metrics for 'abnormal'] | Precision: 0.7671 | Recall: 0.7134 | F1: 0.7393
2026-01-14 11:58:54,289 - INFO - [Metrics for 'normal'] | Precision: 0.7668 | Recall: 0.8132 | F1: 0.7893
2026-01-14 11:58:54,300 - INFO - [Best Model Saved] (val loss: 0.5405) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:58:54,301 - INFO - --------------------------------------------------
2026-01-14 11:58:54,301 - INFO - [LR]    [12/90] | Learning Rate: 0.001000
2026-01-14 11:59:01,075 - INFO - [Train] [12/90] | Loss: 0.4942 | Train Acc: 81.92%
2026-01-14 11:59:02,651 - INFO - [Valid] [12/90] | Loss: 0.5472 | Val Acc: 73.75%
2026-01-14 11:59:02,664 - INFO - [Metrics for 'abnormal'] | Precision: 0.6683 | Recall: 0.8599 | F1: 0.7521
2026-01-14 11:59:02,665 - INFO - [Metrics for 'normal'] | Precision: 0.8394 | Recall: 0.6319 | F1: 0.7210
2026-01-14 11:59:02,670 - INFO - --------------------------------------------------
2026-01-14 11:59:02,671 - INFO - [LR]    [13/90] | Learning Rate: 0.000999
2026-01-14 11:59:09,670 - INFO - [Train] [13/90] | Loss: 0.5136 | Train Acc: 80.65%
2026-01-14 11:59:11,523 - INFO - [Valid] [13/90] | Loss: 0.5050 | Val Acc: 80.24%
2026-01-14 11:59:11,531 - INFO - [Metrics for 'abnormal'] | Precision: 0.7961 | Recall: 0.7707 | F1: 0.7832
2026-01-14 11:59:11,531 - INFO - [Metrics for 'normal'] | Precision: 0.8075 | Recall: 0.8297 | F1: 0.8184
2026-01-14 11:59:11,536 - INFO - [Best Model Saved] (val loss: 0.5050) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:59:11,536 - INFO - --------------------------------------------------
2026-01-14 11:59:11,536 - INFO - [LR]    [14/90] | Learning Rate: 0.000997
2026-01-14 11:59:17,759 - INFO - [Train] [14/90] | Loss: 0.4810 | Train Acc: 82.29%
2026-01-14 11:59:19,464 - INFO - [Valid] [14/90] | Loss: 0.5100 | Val Acc: 76.70%
2026-01-14 11:59:19,475 - INFO - [Metrics for 'abnormal'] | Precision: 0.7321 | Recall: 0.7834 | F1: 0.7569
2026-01-14 11:59:19,476 - INFO - [Metrics for 'normal'] | Precision: 0.8012 | Recall: 0.7527 | F1: 0.7762
2026-01-14 11:59:19,480 - INFO - --------------------------------------------------
2026-01-14 11:59:19,480 - INFO - [LR]    [15/90] | Learning Rate: 0.000994
2026-01-14 11:59:25,807 - INFO - [Train] [15/90] | Loss: 0.4640 | Train Acc: 83.78%
2026-01-14 11:59:27,492 - INFO - [Valid] [15/90] | Loss: 0.5244 | Val Acc: 76.99%
2026-01-14 11:59:27,509 - INFO - [Metrics for 'abnormal'] | Precision: 0.7232 | Recall: 0.8153 | F1: 0.7665
2026-01-14 11:59:27,509 - INFO - [Metrics for 'normal'] | Precision: 0.8210 | Recall: 0.7308 | F1: 0.7733
2026-01-14 11:59:27,515 - INFO - --------------------------------------------------
2026-01-14 11:59:27,518 - INFO - [LR]    [16/90] | Learning Rate: 0.000991
2026-01-14 11:59:33,782 - INFO - [Train] [16/90] | Loss: 0.4734 | Train Acc: 84.15%
2026-01-14 11:59:35,414 - INFO - [Valid] [16/90] | Loss: 0.4989 | Val Acc: 79.06%
2026-01-14 11:59:35,429 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-01-14 11:59:35,430 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-01-14 11:59:35,441 - INFO - [Best Model Saved] (val loss: 0.4989) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 11:59:35,441 - INFO - --------------------------------------------------
2026-01-14 11:59:35,442 - INFO - [LR]    [17/90] | Learning Rate: 0.000988
2026-01-14 11:59:43,488 - INFO - [Train] [17/90] | Loss: 0.4622 | Train Acc: 84.00%
2026-01-14 11:59:45,604 - INFO - [Valid] [17/90] | Loss: 0.5119 | Val Acc: 78.17%
2026-01-14 11:59:45,617 - INFO - [Metrics for 'abnormal'] | Precision: 0.7345 | Recall: 0.8280 | F1: 0.7784
2026-01-14 11:59:45,618 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7418 | F1: 0.7849
2026-01-14 11:59:45,623 - INFO - --------------------------------------------------
2026-01-14 11:59:45,624 - INFO - [LR]    [18/90] | Learning Rate: 0.000983
2026-01-14 11:59:53,980 - INFO - [Train] [18/90] | Loss: 0.4617 | Train Acc: 85.34%
2026-01-14 11:59:56,052 - INFO - [Valid] [18/90] | Loss: 0.5047 | Val Acc: 77.88%
2026-01-14 11:59:56,062 - INFO - [Metrics for 'abnormal'] | Precision: 0.7470 | Recall: 0.7898 | F1: 0.7678
2026-01-14 11:59:56,062 - INFO - [Metrics for 'normal'] | Precision: 0.8092 | Recall: 0.7692 | F1: 0.7887
2026-01-14 11:59:56,066 - INFO - --------------------------------------------------
2026-01-14 11:59:56,066 - INFO - [LR]    [19/90] | Learning Rate: 0.000978
2026-01-14 12:00:03,530 - INFO - [Train] [19/90] | Loss: 0.4544 | Train Acc: 85.12%
2026-01-14 12:00:05,283 - INFO - [Valid] [19/90] | Loss: 0.4996 | Val Acc: 79.65%
2026-01-14 12:00:05,293 - INFO - [Metrics for 'abnormal'] | Precision: 0.7750 | Recall: 0.7898 | F1: 0.7823
2026-01-14 12:00:05,293 - INFO - [Metrics for 'normal'] | Precision: 0.8156 | Recall: 0.8022 | F1: 0.8089
2026-01-14 12:00:05,297 - INFO - --------------------------------------------------
2026-01-14 12:00:05,298 - INFO - [LR]    [20/90] | Learning Rate: 0.000972
2026-01-14 12:00:12,563 - INFO - [Train] [20/90] | Loss: 0.4458 | Train Acc: 84.90%
2026-01-14 12:00:14,606 - INFO - [Valid] [20/90] | Loss: 0.5078 | Val Acc: 78.76%
2026-01-14 12:00:14,631 - INFO - [Metrics for 'abnormal'] | Precision: 0.7673 | Recall: 0.7771 | F1: 0.7722
2026-01-14 12:00:14,634 - INFO - [Metrics for 'normal'] | Precision: 0.8056 | Recall: 0.7967 | F1: 0.8011
2026-01-14 12:00:14,641 - INFO - --------------------------------------------------
2026-01-14 12:00:14,642 - INFO - [LR]    [21/90] | Learning Rate: 0.000966
2026-01-14 12:00:22,139 - INFO - [Train] [21/90] | Loss: 0.4433 | Train Acc: 85.71%
2026-01-14 12:00:24,408 - INFO - [Valid] [21/90] | Loss: 0.5108 | Val Acc: 76.70%
2026-01-14 12:00:24,422 - INFO - [Metrics for 'abnormal'] | Precision: 0.7267 | Recall: 0.7962 | F1: 0.7599
2026-01-14 12:00:24,422 - INFO - [Metrics for 'normal'] | Precision: 0.8084 | Recall: 0.7418 | F1: 0.7736
2026-01-14 12:00:24,427 - INFO - --------------------------------------------------
2026-01-14 12:00:24,428 - INFO - [LR]    [22/90] | Learning Rate: 0.000959
2026-01-14 12:00:32,420 - INFO - [Train] [22/90] | Loss: 0.4453 | Train Acc: 85.04%
2026-01-14 12:00:34,861 - INFO - [Valid] [22/90] | Loss: 0.5410 | Val Acc: 79.35%
2026-01-14 12:00:34,874 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-01-14 12:00:34,875 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-01-14 12:00:34,880 - INFO - --------------------------------------------------
2026-01-14 12:00:34,881 - INFO - [LR]    [23/90] | Learning Rate: 0.000951
2026-01-14 12:00:44,075 - INFO - [Train] [23/90] | Loss: 0.4453 | Train Acc: 84.90%
2026-01-14 12:00:46,291 - INFO - [Valid] [23/90] | Loss: 0.5089 | Val Acc: 80.24%
2026-01-14 12:00:46,304 - INFO - [Metrics for 'abnormal'] | Precision: 0.8125 | Recall: 0.7452 | F1: 0.7774
2026-01-14 12:00:46,305 - INFO - [Metrics for 'normal'] | Precision: 0.7949 | Recall: 0.8516 | F1: 0.8223
2026-01-14 12:00:46,310 - INFO - --------------------------------------------------
2026-01-14 12:00:46,311 - INFO - [LR]    [24/90] | Learning Rate: 0.000943
2026-01-14 12:00:55,387 - INFO - [Train] [24/90] | Loss: 0.4319 | Train Acc: 87.13%
2026-01-14 12:00:57,763 - INFO - [Valid] [24/90] | Loss: 0.5322 | Val Acc: 77.29%
2026-01-14 12:00:57,795 - INFO - [Metrics for 'abnormal'] | Precision: 0.7000 | Recall: 0.8917 | F1: 0.7843
2026-01-14 12:00:57,795 - INFO - [Metrics for 'normal'] | Precision: 0.8777 | Recall: 0.6703 | F1: 0.7601
2026-01-14 12:00:57,806 - INFO - --------------------------------------------------
2026-01-14 12:00:57,806 - INFO - [LR]    [25/90] | Learning Rate: 0.000934
2026-01-14 12:01:06,862 - INFO - [Train] [25/90] | Loss: 0.4380 | Train Acc: 86.53%
2026-01-14 12:01:09,509 - INFO - [Valid] [25/90] | Loss: 0.5144 | Val Acc: 79.94%
2026-01-14 12:01:09,534 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-01-14 12:01:09,538 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-01-14 12:01:09,546 - INFO - --------------------------------------------------
2026-01-14 12:01:09,546 - INFO - [LR]    [26/90] | Learning Rate: 0.000924
2026-01-14 12:01:19,347 - INFO - [Train] [26/90] | Loss: 0.4252 | Train Acc: 87.13%
2026-01-14 12:01:22,050 - INFO - [Valid] [26/90] | Loss: 0.5437 | Val Acc: 77.58%
2026-01-14 12:01:22,062 - INFO - [Metrics for 'abnormal'] | Precision: 0.7213 | Recall: 0.8408 | F1: 0.7765
2026-01-14 12:01:22,063 - INFO - [Metrics for 'normal'] | Precision: 0.8397 | Recall: 0.7198 | F1: 0.7751
2026-01-14 12:01:22,068 - INFO - --------------------------------------------------
2026-01-14 12:01:22,069 - INFO - [LR]    [27/90] | Learning Rate: 0.000914
2026-01-14 12:01:31,227 - INFO - [Train] [27/90] | Loss: 0.4171 | Train Acc: 86.98%
2026-01-14 12:01:34,182 - INFO - [Valid] [27/90] | Loss: 0.5125 | Val Acc: 78.47%
2026-01-14 12:01:34,194 - INFO - [Metrics for 'abnormal'] | Precision: 0.7727 | Recall: 0.7580 | F1: 0.7653
2026-01-14 12:01:34,195 - INFO - [Metrics for 'normal'] | Precision: 0.7946 | Recall: 0.8077 | F1: 0.8011
2026-01-14 12:01:34,199 - INFO - --------------------------------------------------
2026-01-14 12:01:34,200 - INFO - [LR]    [28/90] | Learning Rate: 0.000903
2026-01-14 12:01:43,161 - INFO - [Train] [28/90] | Loss: 0.4104 | Train Acc: 87.65%
2026-01-14 12:01:45,624 - INFO - [Valid] [28/90] | Loss: 0.5217 | Val Acc: 78.47%
2026-01-14 12:01:45,637 - INFO - [Metrics for 'abnormal'] | Precision: 0.7471 | Recall: 0.8089 | F1: 0.7768
2026-01-14 12:01:45,637 - INFO - [Metrics for 'normal'] | Precision: 0.8225 | Recall: 0.7637 | F1: 0.7920
2026-01-14 12:01:45,641 - INFO - --------------------------------------------------
2026-01-14 12:01:45,642 - INFO - [LR]    [29/90] | Learning Rate: 0.000892
2026-01-14 12:01:54,387 - INFO - [Train] [29/90] | Loss: 0.4071 | Train Acc: 87.50%
2026-01-14 12:01:57,171 - INFO - [Valid] [29/90] | Loss: 0.5316 | Val Acc: 77.88%
2026-01-14 12:01:57,194 - INFO - [Metrics for 'abnormal'] | Precision: 0.7384 | Recall: 0.8089 | F1: 0.7720
2026-01-14 12:01:57,198 - INFO - [Metrics for 'normal'] | Precision: 0.8204 | Recall: 0.7527 | F1: 0.7851
2026-01-14 12:01:57,204 - INFO - --------------------------------------------------
2026-01-14 12:01:57,206 - INFO - [LR]    [30/90] | Learning Rate: 0.000880
2026-01-14 12:02:06,744 - INFO - [Train] [30/90] | Loss: 0.4067 | Train Acc: 87.35%
2026-01-14 12:02:09,081 - INFO - [Valid] [30/90] | Loss: 0.5026 | Val Acc: 80.53%
2026-01-14 12:02:09,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.7898 | Recall: 0.7898 | F1: 0.7898
2026-01-14 12:02:09,096 - INFO - [Metrics for 'normal'] | Precision: 0.8187 | Recall: 0.8187 | F1: 0.8187
2026-01-14 12:02:09,101 - INFO - --------------------------------------------------
2026-01-14 12:02:09,102 - INFO - [LR]    [31/90] | Learning Rate: 0.000868
2026-01-14 12:02:18,654 - INFO - [Train] [31/90] | Loss: 0.4052 | Train Acc: 87.87%
2026-01-14 12:02:21,382 - INFO - [Valid] [31/90] | Loss: 0.5100 | Val Acc: 79.06%
2026-01-14 12:02:21,403 - INFO - [Metrics for 'abnormal'] | Precision: 0.7654 | Recall: 0.7898 | F1: 0.7774
2026-01-14 12:02:21,406 - INFO - [Metrics for 'normal'] | Precision: 0.8136 | Recall: 0.7912 | F1: 0.8022
2026-01-14 12:02:21,414 - INFO - --------------------------------------------------
2026-01-14 12:02:21,415 - INFO - [LR]    [32/90] | Learning Rate: 0.000855
2026-01-14 12:02:31,047 - INFO - [Train] [32/90] | Loss: 0.3920 | Train Acc: 89.36%
2026-01-14 12:02:33,787 - INFO - [Valid] [32/90] | Loss: 0.5126 | Val Acc: 81.12%
2026-01-14 12:02:33,796 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 12:02:33,796 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 12:02:33,800 - INFO - --------------------------------------------------
2026-01-14 12:02:33,800 - INFO - [LR]    [33/90] | Learning Rate: 0.000842
2026-01-14 12:02:43,455 - INFO - [Train] [33/90] | Loss: 0.3938 | Train Acc: 88.54%
2026-01-14 12:02:46,527 - INFO - [Valid] [33/90] | Loss: 0.5152 | Val Acc: 79.35%
2026-01-14 12:02:46,550 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.7771 | F1: 0.7771
2026-01-14 12:02:46,550 - INFO - [Metrics for 'normal'] | Precision: 0.8077 | Recall: 0.8077 | F1: 0.8077
2026-01-14 12:02:46,559 - INFO - --------------------------------------------------
2026-01-14 12:02:46,561 - INFO - [LR]    [34/90] | Learning Rate: 0.000829
2026-01-14 12:02:55,579 - INFO - [Train] [34/90] | Loss: 0.3949 | Train Acc: 90.70%
2026-01-14 12:02:58,239 - INFO - [Valid] [34/90] | Loss: 0.5286 | Val Acc: 78.47%
2026-01-14 12:02:58,250 - INFO - [Metrics for 'abnormal'] | Precision: 0.7958 | Recall: 0.7197 | F1: 0.7559
2026-01-14 12:02:58,251 - INFO - [Metrics for 'normal'] | Precision: 0.7766 | Recall: 0.8407 | F1: 0.8074
2026-01-14 12:02:58,255 - INFO - --------------------------------------------------
2026-01-14 12:02:58,256 - INFO - [LR]    [35/90] | Learning Rate: 0.000815
2026-01-14 12:03:07,299 - INFO - [Train] [35/90] | Loss: 0.3886 | Train Acc: 89.21%
2026-01-14 12:03:09,340 - INFO - [Valid] [35/90] | Loss: 0.5122 | Val Acc: 80.24%
2026-01-14 12:03:09,368 - INFO - [Metrics for 'abnormal'] | Precision: 0.7848 | Recall: 0.7898 | F1: 0.7873
2026-01-14 12:03:09,369 - INFO - [Metrics for 'normal'] | Precision: 0.8177 | Recall: 0.8132 | F1: 0.8154
2026-01-14 12:03:09,373 - INFO - --------------------------------------------------
2026-01-14 12:03:09,374 - INFO - [LR]    [36/90] | Learning Rate: 0.000800
2026-01-14 12:03:18,745 - INFO - [Train] [36/90] | Loss: 0.3775 | Train Acc: 90.18%
2026-01-14 12:03:21,021 - INFO - [Valid] [36/90] | Loss: 0.5195 | Val Acc: 81.12%
2026-01-14 12:03:21,032 - INFO - [Metrics for 'abnormal'] | Precision: 0.8039 | Recall: 0.7834 | F1: 0.7935
2026-01-14 12:03:21,033 - INFO - [Metrics for 'normal'] | Precision: 0.8172 | Recall: 0.8352 | F1: 0.8261
2026-01-14 12:03:21,037 - INFO - --------------------------------------------------
2026-01-14 12:03:21,038 - INFO - [LR]    [37/90] | Learning Rate: 0.000785
2026-01-14 12:03:30,322 - INFO - [Train] [37/90] | Loss: 0.3817 | Train Acc: 89.96%
2026-01-14 12:03:32,169 - INFO - [Valid] [37/90] | Loss: 0.5267 | Val Acc: 79.35%
2026-01-14 12:03:32,180 - INFO - [Metrics for 'abnormal'] | Precision: 0.7326 | Recall: 0.8726 | F1: 0.7965
2026-01-14 12:03:32,181 - INFO - [Metrics for 'normal'] | Precision: 0.8684 | Recall: 0.7253 | F1: 0.7904
2026-01-14 12:03:32,186 - INFO - --------------------------------------------------
2026-01-14 12:03:32,187 - INFO - [LR]    [38/90] | Learning Rate: 0.000770
2026-01-14 12:03:41,607 - INFO - [Train] [38/90] | Loss: 0.3629 | Train Acc: 90.62%
2026-01-14 12:03:44,075 - INFO - [Valid] [38/90] | Loss: 0.5309 | Val Acc: 78.47%
2026-01-14 12:03:44,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.7471 | Recall: 0.8089 | F1: 0.7768
2026-01-14 12:03:44,099 - INFO - [Metrics for 'normal'] | Precision: 0.8225 | Recall: 0.7637 | F1: 0.7920
2026-01-14 12:03:44,108 - INFO - --------------------------------------------------
2026-01-14 12:03:44,108 - INFO - [LR]    [39/90] | Learning Rate: 0.000754
2026-01-14 12:03:52,836 - INFO - [Train] [39/90] | Loss: 0.3701 | Train Acc: 90.55%
2026-01-14 12:03:55,084 - INFO - [Valid] [39/90] | Loss: 0.5237 | Val Acc: 80.83%
2026-01-14 12:03:55,096 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 12:03:55,097 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 12:03:55,101 - INFO - --------------------------------------------------
2026-01-14 12:03:55,102 - INFO - [LR]    [40/90] | Learning Rate: 0.000738
2026-01-14 12:04:04,911 - INFO - [Train] [40/90] | Loss: 0.3704 | Train Acc: 90.62%
2026-01-14 12:04:07,142 - INFO - [Valid] [40/90] | Loss: 0.5060 | Val Acc: 80.83%
2026-01-14 12:04:07,157 - INFO - [Metrics for 'abnormal'] | Precision: 0.7805 | Recall: 0.8153 | F1: 0.7975
2026-01-14 12:04:07,158 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.8022 | F1: 0.8179
2026-01-14 12:04:07,161 - INFO - --------------------------------------------------
2026-01-14 12:04:07,162 - INFO - [LR]    [41/90] | Learning Rate: 0.000722
2026-01-14 12:04:16,737 - INFO - [Train] [41/90] | Loss: 0.3637 | Train Acc: 90.77%
2026-01-14 12:04:19,990 - INFO - [Valid] [41/90] | Loss: 0.4954 | Val Acc: 81.71%
2026-01-14 12:04:19,999 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-01-14 12:04:19,999 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-01-14 12:04:20,007 - INFO - [Best Model Saved] (val loss: 0.4954) -> 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 12:04:20,007 - INFO - --------------------------------------------------
2026-01-14 12:04:20,008 - INFO - [LR]    [42/90] | Learning Rate: 0.000706
2026-01-14 12:04:28,394 - INFO - [Train] [42/90] | Loss: 0.3557 | Train Acc: 91.59%
2026-01-14 12:04:31,558 - INFO - [Valid] [42/90] | Loss: 0.5113 | Val Acc: 81.71%
2026-01-14 12:04:31,569 - INFO - [Metrics for 'abnormal'] | Precision: 0.7811 | Recall: 0.8408 | F1: 0.8098
2026-01-14 12:04:31,569 - INFO - [Metrics for 'normal'] | Precision: 0.8529 | Recall: 0.7967 | F1: 0.8239
2026-01-14 12:04:31,574 - INFO - --------------------------------------------------
2026-01-14 12:04:31,574 - INFO - [LR]    [43/90] | Learning Rate: 0.000689
2026-01-14 12:04:39,754 - INFO - [Train] [43/90] | Loss: 0.3588 | Train Acc: 91.52%
2026-01-14 12:04:43,088 - INFO - [Valid] [43/90] | Loss: 0.5340 | Val Acc: 80.24%
2026-01-14 12:04:43,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.7557 | Recall: 0.8471 | F1: 0.7988
2026-01-14 12:04:43,113 - INFO - [Metrics for 'normal'] | Precision: 0.8528 | Recall: 0.7637 | F1: 0.8058
2026-01-14 12:04:43,117 - INFO - --------------------------------------------------
2026-01-14 12:04:43,122 - INFO - [LR]    [44/90] | Learning Rate: 0.000672
2026-01-14 12:04:51,424 - INFO - [Train] [44/90] | Loss: 0.3594 | Train Acc: 91.22%
2026-01-14 12:04:54,999 - INFO - [Valid] [44/90] | Loss: 0.5115 | Val Acc: 80.53%
2026-01-14 12:04:55,030 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-01-14 12:04:55,030 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-01-14 12:04:55,042 - INFO - --------------------------------------------------
2026-01-14 12:04:55,045 - INFO - [LR]    [45/90] | Learning Rate: 0.000655
2026-01-14 12:05:03,537 - INFO - [Train] [45/90] | Loss: 0.3516 | Train Acc: 91.74%
2026-01-14 12:05:06,882 - INFO - [Valid] [45/90] | Loss: 0.5289 | Val Acc: 79.65%
2026-01-14 12:05:06,910 - INFO - [Metrics for 'abnormal'] | Precision: 0.7857 | Recall: 0.7707 | F1: 0.7781
2026-01-14 12:05:06,911 - INFO - [Metrics for 'normal'] | Precision: 0.8054 | Recall: 0.8187 | F1: 0.8120
2026-01-14 12:05:06,918 - INFO - --------------------------------------------------
2026-01-14 12:05:06,925 - INFO - [LR]    [46/90] | Learning Rate: 0.000638
2026-01-14 12:05:16,697 - INFO - [Train] [46/90] | Loss: 0.3499 | Train Acc: 92.26%
2026-01-14 12:05:19,907 - INFO - [Valid] [46/90] | Loss: 0.5142 | Val Acc: 80.24%
2026-01-14 12:05:19,948 - INFO - [Metrics for 'abnormal'] | Precision: 0.7528 | Recall: 0.8535 | F1: 0.8000
2026-01-14 12:05:19,949 - INFO - [Metrics for 'normal'] | Precision: 0.8571 | Recall: 0.7582 | F1: 0.8047
2026-01-14 12:05:19,954 - INFO - --------------------------------------------------
2026-01-14 12:05:19,955 - INFO - [LR]    [47/90] | Learning Rate: 0.000620
2026-01-14 12:05:27,545 - INFO - [Train] [47/90] | Loss: 0.3521 | Train Acc: 92.04%
2026-01-14 12:05:30,102 - INFO - [Valid] [47/90] | Loss: 0.5158 | Val Acc: 80.83%
2026-01-14 12:05:30,115 - INFO - [Metrics for 'abnormal'] | Precision: 0.7644 | Recall: 0.8471 | F1: 0.8036
2026-01-14 12:05:30,115 - INFO - [Metrics for 'normal'] | Precision: 0.8545 | Recall: 0.7747 | F1: 0.8127
2026-01-14 12:05:30,119 - INFO - --------------------------------------------------
2026-01-14 12:05:30,120 - INFO - [LR]    [48/90] | Learning Rate: 0.000603
2026-01-14 12:05:37,840 - INFO - [Train] [48/90] | Loss: 0.3522 | Train Acc: 91.29%
2026-01-14 12:05:40,249 - INFO - [Valid] [48/90] | Loss: 0.5305 | Val Acc: 79.06%
2026-01-14 12:05:40,262 - INFO - [Metrics for 'abnormal'] | Precision: 0.7560 | Recall: 0.8089 | F1: 0.7815
2026-01-14 12:05:40,263 - INFO - [Metrics for 'normal'] | Precision: 0.8246 | Recall: 0.7747 | F1: 0.7989
2026-01-14 12:05:40,267 - INFO - --------------------------------------------------
2026-01-14 12:05:40,268 - INFO - [LR]    [49/90] | Learning Rate: 0.000585
2026-01-14 12:05:49,927 - INFO - [Train] [49/90] | Loss: 0.3422 | Train Acc: 92.71%
2026-01-14 12:05:52,768 - INFO - [Valid] [49/90] | Loss: 0.5304 | Val Acc: 80.24%
2026-01-14 12:05:52,790 - INFO - [Metrics for 'abnormal'] | Precision: 0.7711 | Recall: 0.8153 | F1: 0.7926
2026-01-14 12:05:52,791 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.7912 | F1: 0.8113
2026-01-14 12:05:52,795 - INFO - --------------------------------------------------
2026-01-14 12:05:52,797 - INFO - [LR]    [50/90] | Learning Rate: 0.000568
2026-01-14 12:06:01,857 - INFO - [Train] [50/90] | Loss: 0.3363 | Train Acc: 93.45%
2026-01-14 12:06:06,855 - INFO - [Valid] [50/90] | Loss: 0.5098 | Val Acc: 79.94%
2026-01-14 12:06:06,866 - INFO - [Metrics for 'abnormal'] | Precision: 0.7633 | Recall: 0.8217 | F1: 0.7914
2026-01-14 12:06:06,867 - INFO - [Metrics for 'normal'] | Precision: 0.8353 | Recall: 0.7802 | F1: 0.8068
2026-01-14 12:06:06,881 - INFO - --------------------------------------------------
2026-01-14 12:06:06,894 - INFO - [LR]    [51/90] | Learning Rate: 0.000550
2026-01-14 12:06:16,195 - INFO - [Train] [51/90] | Loss: 0.3334 | Train Acc: 93.60%
2026-01-14 12:06:19,140 - INFO - [Valid] [51/90] | Loss: 0.5270 | Val Acc: 79.35%
2026-01-14 12:06:19,161 - INFO - [Metrics for 'abnormal'] | Precision: 0.7403 | Recall: 0.8535 | F1: 0.7929
2026-01-14 12:06:19,162 - INFO - [Metrics for 'normal'] | Precision: 0.8544 | Recall: 0.7418 | F1: 0.7941
2026-01-14 12:06:19,172 - INFO - --------------------------------------------------
2026-01-14 12:06:19,173 - INFO - [LR]    [52/90] | Learning Rate: 0.000532
2026-01-14 12:06:27,856 - INFO - [Train] [52/90] | Loss: 0.3359 | Train Acc: 93.30%
2026-01-14 12:06:31,070 - INFO - [Valid] [52/90] | Loss: 0.5052 | Val Acc: 79.94%
2026-01-14 12:06:31,093 - INFO - [Metrics for 'abnormal'] | Precision: 0.7602 | Recall: 0.8280 | F1: 0.7927
2026-01-14 12:06:31,093 - INFO - [Metrics for 'normal'] | Precision: 0.8393 | Recall: 0.7747 | F1: 0.8057
2026-01-14 12:06:31,097 - INFO - --------------------------------------------------
2026-01-14 12:06:31,099 - INFO - [LR]    [53/90] | Learning Rate: 0.000515
2026-01-14 12:06:39,552 - INFO - [Train] [53/90] | Loss: 0.3315 | Train Acc: 93.53%
2026-01-14 12:06:43,630 - INFO - [Valid] [53/90] | Loss: 0.5312 | Val Acc: 79.94%
2026-01-14 12:06:43,656 - INFO - [Metrics for 'abnormal'] | Precision: 0.7799 | Recall: 0.7898 | F1: 0.7848
2026-01-14 12:06:43,660 - INFO - [Metrics for 'normal'] | Precision: 0.8167 | Recall: 0.8077 | F1: 0.8122
2026-01-14 12:06:43,668 - INFO - --------------------------------------------------
2026-01-14 12:06:43,670 - INFO - [LR]    [54/90] | Learning Rate: 0.000497
2026-01-14 12:06:51,841 - INFO - [Train] [54/90] | Loss: 0.3277 | Train Acc: 94.12%
2026-01-14 12:06:54,422 - INFO - [Valid] [54/90] | Loss: 0.5308 | Val Acc: 79.35%
2026-01-14 12:06:54,441 - INFO - [Metrics for 'abnormal'] | Precision: 0.7544 | Recall: 0.8217 | F1: 0.7866
2026-01-14 12:06:54,446 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7692 | F1: 0.8000
2026-01-14 12:06:54,452 - INFO - --------------------------------------------------
2026-01-14 12:06:54,453 - INFO - [LR]    [55/90] | Learning Rate: 0.000480
2026-01-14 12:07:03,881 - INFO - [Train] [55/90] | Loss: 0.3249 | Train Acc: 93.15%
2026-01-14 12:07:07,652 - INFO - [Valid] [55/90] | Loss: 0.5220 | Val Acc: 79.35%
2026-01-14 12:07:07,664 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-01-14 12:07:07,665 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-01-14 12:07:07,670 - INFO - --------------------------------------------------
2026-01-14 12:07:07,673 - INFO - [LR]    [56/90] | Learning Rate: 0.000462
2026-01-14 12:07:15,973 - INFO - [Train] [56/90] | Loss: 0.3224 | Train Acc: 94.20%
2026-01-14 12:07:18,960 - INFO - [Valid] [56/90] | Loss: 0.5114 | Val Acc: 80.24%
2026-01-14 12:07:18,996 - INFO - [Metrics for 'abnormal'] | Precision: 0.7778 | Recall: 0.8025 | F1: 0.7900
2026-01-14 12:07:18,996 - INFO - [Metrics for 'normal'] | Precision: 0.8249 | Recall: 0.8022 | F1: 0.8134
2026-01-14 12:07:19,004 - INFO - --------------------------------------------------
2026-01-14 12:07:19,006 - INFO - [LR]    [57/90] | Learning Rate: 0.000445
2026-01-14 12:07:27,046 - INFO - [Train] [57/90] | Loss: 0.3236 | Train Acc: 94.42%
2026-01-14 12:07:29,939 - INFO - [Valid] [57/90] | Loss: 0.5284 | Val Acc: 79.94%
2026-01-14 12:07:29,973 - INFO - [Metrics for 'abnormal'] | Precision: 0.7665 | Recall: 0.8153 | F1: 0.7901
2026-01-14 12:07:29,973 - INFO - [Metrics for 'normal'] | Precision: 0.8314 | Recall: 0.7857 | F1: 0.8079
2026-01-14 12:07:29,984 - INFO - --------------------------------------------------
2026-01-14 12:07:29,984 - INFO - [LR]    [58/90] | Learning Rate: 0.000428
2026-01-14 12:07:38,585 - INFO - [Train] [58/90] | Loss: 0.3169 | Train Acc: 94.49%
2026-01-14 12:07:41,432 - INFO - [Valid] [58/90] | Loss: 0.5110 | Val Acc: 81.71%
2026-01-14 12:07:41,456 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-01-14 12:07:41,459 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-01-14 12:07:41,467 - INFO - --------------------------------------------------
2026-01-14 12:07:41,468 - INFO - [LR]    [59/90] | Learning Rate: 0.000411
2026-01-14 12:07:49,863 - INFO - [Train] [59/90] | Loss: 0.3115 | Train Acc: 95.09%
2026-01-14 12:07:52,730 - INFO - [Valid] [59/90] | Loss: 0.5314 | Val Acc: 79.35%
2026-01-14 12:07:52,751 - INFO - [Metrics for 'abnormal'] | Precision: 0.7514 | Recall: 0.8280 | F1: 0.7879
2026-01-14 12:07:52,753 - INFO - [Metrics for 'normal'] | Precision: 0.8373 | Recall: 0.7637 | F1: 0.7989
2026-01-14 12:07:52,764 - INFO - --------------------------------------------------
2026-01-14 12:07:52,764 - INFO - [LR]    [60/90] | Learning Rate: 0.000394
2026-01-14 12:08:01,526 - INFO - [Train] [60/90] | Loss: 0.3167 | Train Acc: 94.72%
2026-01-14 12:08:04,232 - INFO - [Valid] [60/90] | Loss: 0.5046 | Val Acc: 79.35%
2026-01-14 12:08:04,257 - INFO - [Metrics for 'abnormal'] | Precision: 0.7574 | Recall: 0.8153 | F1: 0.7853
2026-01-14 12:08:04,257 - INFO - [Metrics for 'normal'] | Precision: 0.8294 | Recall: 0.7747 | F1: 0.8011
2026-01-14 12:08:04,265 - INFO - --------------------------------------------------
2026-01-14 12:08:04,269 - INFO - [LR]    [61/90] | Learning Rate: 0.000378
2026-01-14 12:08:13,158 - INFO - [Train] [61/90] | Loss: 0.3172 | Train Acc: 94.87%
2026-01-14 12:08:15,993 - INFO - [Valid] [61/90] | Loss: 0.5256 | Val Acc: 79.35%
2026-01-14 12:08:16,005 - INFO - [Metrics for 'abnormal'] | Precision: 0.7544 | Recall: 0.8217 | F1: 0.7866
2026-01-14 12:08:16,005 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.7692 | F1: 0.8000
2026-01-14 12:08:16,010 - INFO - --------------------------------------------------
2026-01-14 12:08:16,010 - INFO - [LR]    [62/90] | Learning Rate: 0.000362
2026-01-14 12:08:24,774 - INFO - [Train] [62/90] | Loss: 0.3166 | Train Acc: 94.79%
2026-01-14 12:08:27,190 - INFO - [Valid] [62/90] | Loss: 0.5181 | Val Acc: 80.24%
2026-01-14 12:08:27,213 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 12:08:27,217 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 12:08:27,221 - INFO - --------------------------------------------------
2026-01-14 12:08:27,225 - INFO - [LR]    [63/90] | Learning Rate: 0.000346
2026-01-14 12:08:36,251 - INFO - [Train] [63/90] | Loss: 0.3034 | Train Acc: 95.31%
2026-01-14 12:08:38,540 - INFO - [Valid] [63/90] | Loss: 0.5330 | Val Acc: 79.65%
2026-01-14 12:08:38,569 - INFO - [Metrics for 'abnormal'] | Precision: 0.7683 | Recall: 0.8025 | F1: 0.7850
2026-01-14 12:08:38,569 - INFO - [Metrics for 'normal'] | Precision: 0.8229 | Recall: 0.7912 | F1: 0.8067
2026-01-14 12:08:38,579 - INFO - --------------------------------------------------
2026-01-14 12:08:38,582 - INFO - [LR]    [64/90] | Learning Rate: 0.000330
2026-01-14 12:08:48,362 - INFO - [Train] [64/90] | Loss: 0.3020 | Train Acc: 95.61%
2026-01-14 12:08:51,093 - INFO - [Valid] [64/90] | Loss: 0.5446 | Val Acc: 80.24%
2026-01-14 12:08:51,105 - INFO - [Metrics for 'abnormal'] | Precision: 0.7557 | Recall: 0.8471 | F1: 0.7988
2026-01-14 12:08:51,106 - INFO - [Metrics for 'normal'] | Precision: 0.8528 | Recall: 0.7637 | F1: 0.8058
2026-01-14 12:08:51,111 - INFO - --------------------------------------------------
2026-01-14 12:08:51,112 - INFO - [LR]    [65/90] | Learning Rate: 0.000315
2026-01-14 12:09:00,279 - INFO - [Train] [65/90] | Loss: 0.3001 | Train Acc: 95.09%
2026-01-14 12:09:02,715 - INFO - [Valid] [65/90] | Loss: 0.5264 | Val Acc: 80.83%
2026-01-14 12:09:02,745 - INFO - [Metrics for 'abnormal'] | Precision: 0.7875 | Recall: 0.8025 | F1: 0.7950
2026-01-14 12:09:02,746 - INFO - [Metrics for 'normal'] | Precision: 0.8268 | Recall: 0.8132 | F1: 0.8199
2026-01-14 12:09:02,761 - INFO - --------------------------------------------------
2026-01-14 12:09:02,761 - INFO - [LR]    [66/90] | Learning Rate: 0.000300
2026-01-14 12:09:13,099 - INFO - [Train] [66/90] | Loss: 0.3074 | Train Acc: 95.31%
2026-01-14 12:09:15,620 - INFO - [Valid] [66/90] | Loss: 0.5274 | Val Acc: 80.24%
2026-01-14 12:09:15,644 - INFO - [Metrics for 'abnormal'] | Precision: 0.7744 | Recall: 0.8089 | F1: 0.7913
2026-01-14 12:09:15,648 - INFO - [Metrics for 'normal'] | Precision: 0.8286 | Recall: 0.7967 | F1: 0.8123
2026-01-14 12:09:15,656 - INFO - --------------------------------------------------
2026-01-14 12:09:15,656 - INFO - [LR]    [67/90] | Learning Rate: 0.000285
2026-01-14 12:09:26,173 - INFO - [Train] [67/90] | Loss: 0.3049 | Train Acc: 95.68%
2026-01-14 12:09:28,178 - INFO - [Valid] [67/90] | Loss: 0.5303 | Val Acc: 80.83%
2026-01-14 12:09:28,188 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 12:09:28,188 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 12:09:28,193 - INFO - --------------------------------------------------
2026-01-14 12:09:28,193 - INFO - [LR]    [68/90] | Learning Rate: 0.000271
2026-01-14 12:09:38,002 - INFO - [Train] [68/90] | Loss: 0.3021 | Train Acc: 95.54%
2026-01-14 12:09:40,303 - INFO - [Valid] [68/90] | Loss: 0.5257 | Val Acc: 81.12%
2026-01-14 12:09:40,316 - INFO - [Metrics for 'abnormal'] | Precision: 0.7751 | Recall: 0.8344 | F1: 0.8037
2026-01-14 12:09:40,317 - INFO - [Metrics for 'normal'] | Precision: 0.8471 | Recall: 0.7912 | F1: 0.8182
2026-01-14 12:09:40,321 - INFO - --------------------------------------------------
2026-01-14 12:09:40,322 - INFO - [LR]    [69/90] | Learning Rate: 0.000258
2026-01-14 12:09:50,246 - INFO - [Train] [69/90] | Loss: 0.2955 | Train Acc: 96.50%
2026-01-14 12:09:53,099 - INFO - [Valid] [69/90] | Loss: 0.5289 | Val Acc: 79.65%
2026-01-14 12:09:53,111 - INFO - [Metrics for 'abnormal'] | Precision: 0.7588 | Recall: 0.8217 | F1: 0.7890
2026-01-14 12:09:53,111 - INFO - [Metrics for 'normal'] | Precision: 0.8343 | Recall: 0.7747 | F1: 0.8034
2026-01-14 12:09:53,115 - INFO - --------------------------------------------------
2026-01-14 12:09:53,115 - INFO - [LR]    [70/90] | Learning Rate: 0.000245
2026-01-14 12:10:01,946 - INFO - [Train] [70/90] | Loss: 0.2981 | Train Acc: 95.61%
2026-01-14 12:10:03,982 - INFO - [Valid] [70/90] | Loss: 0.5279 | Val Acc: 80.53%
2026-01-14 12:10:04,010 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 12:10:04,010 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 12:10:04,019 - INFO - --------------------------------------------------
2026-01-14 12:10:04,023 - INFO - [LR]    [71/90] | Learning Rate: 0.000232
2026-01-14 12:10:13,070 - INFO - [Train] [71/90] | Loss: 0.2976 | Train Acc: 95.54%
2026-01-14 12:10:15,124 - INFO - [Valid] [71/90] | Loss: 0.5286 | Val Acc: 80.53%
2026-01-14 12:10:15,135 - INFO - [Metrics for 'abnormal'] | Precision: 0.7826 | Recall: 0.8025 | F1: 0.7925
2026-01-14 12:10:15,136 - INFO - [Metrics for 'normal'] | Precision: 0.8258 | Recall: 0.8077 | F1: 0.8167
2026-01-14 12:10:15,141 - INFO - --------------------------------------------------
2026-01-14 12:10:15,142 - INFO - [LR]    [72/90] | Learning Rate: 0.000220
2026-01-14 12:10:25,412 - INFO - [Train] [72/90] | Loss: 0.2918 | Train Acc: 96.06%
2026-01-14 12:10:27,752 - INFO - [Valid] [72/90] | Loss: 0.5391 | Val Acc: 79.94%
2026-01-14 12:10:27,764 - INFO - [Metrics for 'abnormal'] | Precision: 0.7572 | Recall: 0.8344 | F1: 0.7939
2026-01-14 12:10:27,764 - INFO - [Metrics for 'normal'] | Precision: 0.8434 | Recall: 0.7692 | F1: 0.8046
2026-01-14 12:10:27,769 - INFO - --------------------------------------------------
2026-01-14 12:10:27,769 - INFO - [LR]    [73/90] | Learning Rate: 0.000208
2026-01-14 12:10:37,885 - INFO - [Train] [73/90] | Loss: 0.2982 | Train Acc: 96.13%
2026-01-14 12:10:40,678 - INFO - [Valid] [73/90] | Loss: 0.5335 | Val Acc: 80.24%
2026-01-14 12:10:40,690 - INFO - [Metrics for 'abnormal'] | Precision: 0.7647 | Recall: 0.8280 | F1: 0.7951
2026-01-14 12:10:40,691 - INFO - [Metrics for 'normal'] | Precision: 0.8402 | Recall: 0.7802 | F1: 0.8091
2026-01-14 12:10:40,696 - INFO - --------------------------------------------------
2026-01-14 12:10:40,697 - INFO - [LR]    [74/90] | Learning Rate: 0.000197
2026-01-14 12:10:48,845 - INFO - [Train] [74/90] | Loss: 0.2959 | Train Acc: 96.35%
2026-01-14 12:10:51,228 - INFO - [Valid] [74/90] | Loss: 0.5334 | Val Acc: 80.24%
2026-01-14 12:10:51,237 - INFO - [Metrics for 'abnormal'] | Precision: 0.7679 | Recall: 0.8217 | F1: 0.7938
2026-01-14 12:10:51,238 - INFO - [Metrics for 'normal'] | Precision: 0.8363 | Recall: 0.7857 | F1: 0.8102
2026-01-14 12:10:51,241 - INFO - --------------------------------------------------
2026-01-14 12:10:51,242 - INFO - [LR]    [75/90] | Learning Rate: 0.000186
2026-01-14 12:11:00,234 - INFO - [Train] [75/90] | Loss: 0.2906 | Train Acc: 96.21%
2026-01-14 12:11:03,281 - INFO - [Valid] [75/90] | Loss: 0.5240 | Val Acc: 81.71%
2026-01-14 12:11:03,294 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-01-14 12:11:03,295 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-01-14 12:11:03,299 - INFO - --------------------------------------------------
2026-01-14 12:11:03,300 - INFO - [LR]    [76/90] | Learning Rate: 0.000176
2026-01-14 12:11:10,622 - INFO - [Train] [76/90] | Loss: 0.2969 | Train Acc: 95.98%
2026-01-14 12:11:12,851 - INFO - [Valid] [76/90] | Loss: 0.5262 | Val Acc: 80.83%
2026-01-14 12:11:12,862 - INFO - [Metrics for 'abnormal'] | Precision: 0.7771 | Recall: 0.8217 | F1: 0.7988
2026-01-14 12:11:12,863 - INFO - [Metrics for 'normal'] | Precision: 0.8382 | Recall: 0.7967 | F1: 0.8169
2026-01-14 12:11:12,867 - INFO - --------------------------------------------------
2026-01-14 12:11:12,867 - INFO - [LR]    [77/90] | Learning Rate: 0.000166
2026-01-14 12:11:21,586 - INFO - [Train] [77/90] | Loss: 0.2905 | Train Acc: 96.88%
2026-01-14 12:11:24,873 - INFO - [Valid] [77/90] | Loss: 0.5273 | Val Acc: 81.12%
2026-01-14 12:11:24,886 - INFO - [Metrics for 'abnormal'] | Precision: 0.7784 | Recall: 0.8280 | F1: 0.8025
2026-01-14 12:11:24,886 - INFO - [Metrics for 'normal'] | Precision: 0.8430 | Recall: 0.7967 | F1: 0.8192
2026-01-14 12:11:24,891 - INFO - --------------------------------------------------
2026-01-14 12:11:24,892 - INFO - [LR]    [78/90] | Learning Rate: 0.000157
2026-01-14 12:11:35,088 - INFO - [Train] [78/90] | Loss: 0.2878 | Train Acc: 96.88%
2026-01-14 12:11:39,115 - INFO - [Valid] [78/90] | Loss: 0.5203 | Val Acc: 81.12%
2026-01-14 12:11:39,124 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 12:11:39,125 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 12:11:39,131 - INFO - --------------------------------------------------
2026-01-14 12:11:39,132 - INFO - [LR]    [79/90] | Learning Rate: 0.000149
2026-01-14 12:11:47,332 - INFO - [Train] [79/90] | Loss: 0.2810 | Train Acc: 97.10%
2026-01-14 12:11:50,536 - INFO - [Valid] [79/90] | Loss: 0.5225 | Val Acc: 81.71%
2026-01-14 12:11:50,562 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 12:11:50,566 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 12:11:50,576 - INFO - --------------------------------------------------
2026-01-14 12:11:50,580 - INFO - [LR]    [80/90] | Learning Rate: 0.000141
2026-01-14 12:11:59,818 - INFO - [Train] [80/90] | Loss: 0.2910 | Train Acc: 96.43%
2026-01-14 12:12:03,910 - INFO - [Valid] [80/90] | Loss: 0.5340 | Val Acc: 80.83%
2026-01-14 12:12:03,923 - INFO - [Metrics for 'abnormal'] | Precision: 0.7738 | Recall: 0.8280 | F1: 0.8000
2026-01-14 12:12:03,924 - INFO - [Metrics for 'normal'] | Precision: 0.8421 | Recall: 0.7912 | F1: 0.8159
2026-01-14 12:12:03,929 - INFO - --------------------------------------------------
2026-01-14 12:12:03,930 - INFO - [LR]    [81/90] | Learning Rate: 0.000134
2026-01-14 12:12:12,354 - INFO - [Train] [81/90] | Loss: 0.2900 | Train Acc: 96.58%
2026-01-14 12:12:15,777 - INFO - [Valid] [81/90] | Loss: 0.5244 | Val Acc: 81.71%
2026-01-14 12:12:15,800 - INFO - [Metrics for 'abnormal'] | Precision: 0.7879 | Recall: 0.8280 | F1: 0.8075
2026-01-14 12:12:15,800 - INFO - [Metrics for 'normal'] | Precision: 0.8448 | Recall: 0.8077 | F1: 0.8258
2026-01-14 12:12:15,808 - INFO - --------------------------------------------------
2026-01-14 12:12:15,813 - INFO - [LR]    [82/90] | Learning Rate: 0.000128
2026-01-14 12:12:24,528 - INFO - [Train] [82/90] | Loss: 0.2886 | Train Acc: 96.50%
2026-01-14 12:12:27,744 - INFO - [Valid] [82/90] | Loss: 0.5234 | Val Acc: 82.01%
2026-01-14 12:12:27,757 - INFO - [Metrics for 'abnormal'] | Precision: 0.7892 | Recall: 0.8344 | F1: 0.8111
2026-01-14 12:12:27,757 - INFO - [Metrics for 'normal'] | Precision: 0.8497 | Recall: 0.8077 | F1: 0.8282
2026-01-14 12:12:27,761 - INFO - --------------------------------------------------
2026-01-14 12:12:27,762 - INFO - [LR]    [83/90] | Learning Rate: 0.000122
2026-01-14 12:12:38,023 - INFO - [Train] [83/90] | Loss: 0.2780 | Train Acc: 97.47%
2026-01-14 12:12:41,259 - INFO - [Valid] [83/90] | Loss: 0.5369 | Val Acc: 81.12%
2026-01-14 12:12:41,275 - INFO - [Metrics for 'abnormal'] | Precision: 0.7818 | Recall: 0.8217 | F1: 0.8012
2026-01-14 12:12:41,276 - INFO - [Metrics for 'normal'] | Precision: 0.8391 | Recall: 0.8022 | F1: 0.8202
2026-01-14 12:12:41,281 - INFO - --------------------------------------------------
2026-01-14 12:12:41,282 - INFO - [LR]    [84/90] | Learning Rate: 0.000117
2026-01-14 12:12:49,271 - INFO - [Train] [84/90] | Loss: 0.2831 | Train Acc: 96.80%
2026-01-14 12:12:51,808 - INFO - [Valid] [84/90] | Loss: 0.5426 | Val Acc: 80.53%
2026-01-14 12:12:51,820 - INFO - [Metrics for 'abnormal'] | Precision: 0.7661 | Recall: 0.8344 | F1: 0.7988
2026-01-14 12:12:51,821 - INFO - [Metrics for 'normal'] | Precision: 0.8452 | Recall: 0.7802 | F1: 0.8114
2026-01-14 12:12:51,826 - INFO - --------------------------------------------------
2026-01-14 12:12:51,827 - INFO - [LR]    [85/90] | Learning Rate: 0.000112
2026-01-14 12:12:59,986 - INFO - [Train] [85/90] | Loss: 0.2827 | Train Acc: 96.95%
2026-01-14 12:13:03,495 - INFO - [Valid] [85/90] | Loss: 0.5333 | Val Acc: 81.12%
2026-01-14 12:13:03,506 - INFO - [Metrics for 'abnormal'] | Precision: 0.7719 | Recall: 0.8408 | F1: 0.8049
2026-01-14 12:13:03,507 - INFO - [Metrics for 'normal'] | Precision: 0.8512 | Recall: 0.7857 | F1: 0.8171
2026-01-14 12:13:03,511 - INFO - --------------------------------------------------
2026-01-14 12:13:03,511 - INFO - [LR]    [86/90] | Learning Rate: 0.000109
2026-01-14 12:13:11,938 - INFO - [Train] [86/90] | Loss: 0.2832 | Train Acc: 96.21%
2026-01-14 12:13:14,508 - INFO - [Valid] [86/90] | Loss: 0.5318 | Val Acc: 82.01%
2026-01-14 12:13:14,521 - INFO - [Metrics for 'abnormal'] | Precision: 0.7927 | Recall: 0.8280 | F1: 0.8100
2026-01-14 12:13:14,522 - INFO - [Metrics for 'normal'] | Precision: 0.8457 | Recall: 0.8132 | F1: 0.8291
2026-01-14 12:13:14,527 - INFO - --------------------------------------------------
2026-01-14 12:13:14,528 - INFO - [LR]    [87/90] | Learning Rate: 0.000106
2026-01-14 12:13:25,602 - INFO - [Train] [87/90] | Loss: 0.2883 | Train Acc: 96.58%
2026-01-14 12:13:27,316 - INFO - [Valid] [87/90] | Loss: 0.5242 | Val Acc: 81.71%
2026-01-14 12:13:27,325 - INFO - [Metrics for 'abnormal'] | Precision: 0.7914 | Recall: 0.8217 | F1: 0.8063
2026-01-14 12:13:27,326 - INFO - [Metrics for 'normal'] | Precision: 0.8409 | Recall: 0.8132 | F1: 0.8268
2026-01-14 12:13:27,329 - INFO - --------------------------------------------------
2026-01-14 12:13:27,330 - INFO - [LR]    [88/90] | Learning Rate: 0.000103
2026-01-14 12:13:33,686 - INFO - [Train] [88/90] | Loss: 0.2790 | Train Acc: 96.88%
2026-01-14 12:13:36,034 - INFO - [Valid] [88/90] | Loss: 0.5333 | Val Acc: 81.42%
2026-01-14 12:13:36,045 - INFO - [Metrics for 'abnormal'] | Precision: 0.7866 | Recall: 0.8217 | F1: 0.8037
2026-01-14 12:13:36,046 - INFO - [Metrics for 'normal'] | Precision: 0.8400 | Recall: 0.8077 | F1: 0.8235
2026-01-14 12:13:36,049 - INFO - --------------------------------------------------
2026-01-14 12:13:36,050 - INFO - [LR]    [89/90] | Learning Rate: 0.000101
2026-01-14 12:13:42,987 - INFO - [Train] [89/90] | Loss: 0.2776 | Train Acc: 97.47%
2026-01-14 12:13:45,563 - INFO - [Valid] [89/90] | Loss: 0.5305 | Val Acc: 81.42%
2026-01-14 12:13:45,573 - INFO - [Metrics for 'abnormal'] | Precision: 0.7937 | Recall: 0.8089 | F1: 0.8013
2026-01-14 12:13:45,574 - INFO - [Metrics for 'normal'] | Precision: 0.8324 | Recall: 0.8187 | F1: 0.8255
2026-01-14 12:13:45,578 - INFO - --------------------------------------------------
2026-01-14 12:13:45,579 - INFO - [LR]    [90/90] | Learning Rate: 0.000100
2026-01-14 12:13:56,581 - INFO - [Train] [90/90] | Loss: 0.2814 | Train Acc: 97.54%
2026-01-14 12:13:59,831 - INFO - [Valid] [90/90] | Loss: 0.5148 | Val Acc: 82.60%
2026-01-14 12:13:59,843 - INFO - [Metrics for 'abnormal'] | Precision: 0.8063 | Recall: 0.8217 | F1: 0.8139
2026-01-14 12:13:59,844 - INFO - [Metrics for 'normal'] | Precision: 0.8436 | Recall: 0.8297 | F1: 0.8366
2026-01-14 12:13:59,848 - INFO - ==================================================
2026-01-14 12:13:59,849 - INFO - 훈련 완료. 최고 성능 모델을 불러와 테스트 세트로 최종 평가합니다.
2026-01-14 12:13:59,850 - INFO - 최종 평가를 위해 새로운 모델 객체를 생성합니다.
2026-01-14 12:13:59,850 - INFO - Baseline 모델 'xie2019'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-01-14 12:13:59,960 - INFO - 최종 평가 모델에 Pruning 구조를 재적용합니다.
2026-01-14 12:13:59,962 - INFO - torch-pruning을 사용한 L1 Norm Pruning을 시작합니다.
2026-01-14 12:13:59,962 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-01-14 12:14:00,473 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.921357421875)에 맞춰 변경되었습니다.
2026-01-14 12:14:00,473 - INFO - ==================================================
2026-01-14 12:14:00,478 - INFO - 최고 성능 모델 가중치를 새로 생성된 모델 객체에 로드 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/best_model.pth'
2026-01-14 12:14:00,478 - INFO - ==================================================
2026-01-14 12:14:00,479 - INFO - Test 모드를 시작합니다.
2026-01-14 12:14:00,692 - INFO - 연산량 (MACs): 0.0927 GMACs per sample
2026-01-14 12:14:00,694 - INFO - 연산량 (FLOPs): 0.1854 GFLOPs per sample
2026-01-14 12:14:00,695 - INFO - ==================================================
2026-01-14 12:14:00,695 - INFO - GPU 캐시를 비우고 측정을 시작합니다.
2026-01-14 12:14:01,192 - INFO - 샘플 당 평균 Forward Pass 시간: 0.52ms (std: 0.31ms), FPS: 2191.38 (std: 541.95) (1개 샘플 x 100회 반복)
2026-01-14 12:14:01,193 - INFO - 샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 160.08 MB
2026-01-14 12:14:01,193 - INFO - 테스트 데이터셋에 대한 추론을 시작합니다.
2026-01-14 12:14:03,922 - INFO - [Test] Loss: 0.4131 | Test Acc: 81.71%
2026-01-14 12:14:03,934 - INFO - [Metrics for 'abnormal'] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-01-14 12:14:03,935 - INFO - [Metrics for 'normal'] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-01-14 12:14:04,658 - INFO - ==================================================
2026-01-14 12:14:04,659 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/confusion_matrix_20260114_115613.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/confusion_matrix_20260114_115613.pdf'
2026-01-14 12:14:04,659 - INFO - ==================================================
2026-01-14 12:14:04,659 - INFO - ONNX 변환 및 평가를 시작합니다.
2026-01-14 12:14:04,963 - INFO - 모델이 ONNX 형식으로 변환되어 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/model_fp32_20260114_115613.onnx'에 저장되었습니다. (크기: 0.22 MB)
2026-01-14 12:14:05,257 - INFO - [Model Load] ONNX 모델(FP32) 로드 메모리: 2304.51 MB (증가량: 7.51 MB)
2026-01-14 12:14:05,257 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-01-14 12:14:06,178 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 6.95ms (std: 20.08ms)
2026-01-14 12:14:06,178 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 509.53 FPS (std: 303.95) (1개 샘플 x 100회 반복)
2026-01-14 12:14:06,178 - INFO - [Inference Only] ONNX 런타임 추론 중 최대 CPU 메모리: 2309.01 MB (순수 증가량: 4.50 MB)
2026-01-14 12:14:06,178 - INFO - [Total Process] ONNX 모델(FP32) 전체 메모리 사용량: 2309.01 MB (전체 증가량: 12.01 MB)
2026-01-14 12:14:09,192 - INFO - [Test (ONNX)] | Test Acc (ONNX): 81.71%
2026-01-14 12:14:09,209 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.7987 | Recall: 0.8089 | F1: 0.8038
2026-01-14 12:14:09,212 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8333 | Recall: 0.8242 | F1: 0.8287
2026-01-14 12:14:09,944 - INFO - Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/val_acc.pdf'
2026-01-14 12:14:10,664 - INFO - Train/Val Acc 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/train_val_acc.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/train_val_acc.pdf'
2026-01-14 12:14:11,126 - INFO - F1 (normal) 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/F1_normal.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/F1_normal.pdf'
2026-01-14 12:14:11,631 - INFO - Validation Loss 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/val_loss.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/val_loss.pdf'
2026-01-14 12:14:12,001 - INFO - Learning Rate 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/learning_rate.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/learning_rate.pdf'
2026-01-14 12:14:16,750 - INFO - 종합 그래프 저장 완료: 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/compile.png' and 'log/Sewer-TAPNEW/baseline_xie2019_l1_20260114_115613/graph_20260114_115613/compile.pdf'
