2026-02-10 13:16:04,848 - INFO - 로그 파일이 'log/Sewer-TAPNEW_flops/baseline_deit_tiny_wanda_20260210_131604/log_20260210_131604.log'에 저장됩니다.
2026-02-10 13:16:04,850 - INFO - ==================================================
2026-02-10 13:16:04,850 - INFO - config.yaml:
2026-02-10 13:16:04,850 - INFO - 
run:
  global_seed: 42
  cuda: true
  mode: inference
  pth_inference_dir: /home/user/workspace/CHOI/sewer_binary_cls_v9/log/Sewer-TAPNEW/iso_flops/fp32/wanda/baseline_deit_tiny_wanda_20260210_013631
  pth_best_name: best_model.pth
  evaluate_onnx: true
  only_inference: false
  use_int8_inference: true
  int8_calib_samples: 512
  int8_calibration_method: Percentile
  int8_activation_type: QUInt8
  int8_percentile: 99.99
  show_log: true
  dataset:
    name: Sewer-TAPNEW_flops
    type: image_folder
    train_split_ratio: 0.8
    paths:
      train_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train
      valid_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      test_img_dir: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid
      train_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv
      valid_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      test_csv: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv
      img_folder: /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16
training_main:
  epochs: 90
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 90
    eta_min: 0.0001
  best_model_criterion: val_loss
training_baseline:
  epochs: 10
  batch_size: 16
  pre_trained: false
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 10
    eta_min: 0.0001
  best_model_criterion: val_loss
finetuning_pruned:
  epochs: 80
  batch_size: 16
  optimizer: adamw
  lr: 0.001
  weight_decay: 0.0001
  loss_function: CrossEntropyLoss
  label_smoothing: 0.1
  scheduler: cosineannealinglr
  scheduler_params:
    T_max: 80
    eta_min: 0.0001
  best_model_criterion: val_loss
model:
  img_size: 224
  num_patches_per_side: 7
  num_decoder_patches: 1
  num_decoder_layers: 6
  num_heads: 2
  cnn_feature_extractor:
    name: custom24
  encoder_dim: 24
  emb_dim: 24
  adaptive_initial_query: true
  decoder_ff_ratio: 2
  dropout: 0.1
  positional_encoding: true
  res_attention: false
  drop_path_ratio: 0.2
  save_attention: false
  num_plot_attention: 600
baseline:
  model_name: deit_tiny
  use_wanda_pruning: true
  num_wanda_calib_samples: 1353
  pruning_sparsity: 0.8169

2026-02-10 13:16:04,850 - INFO - ==================================================
2026-02-10 13:16:04,911 - INFO - CUDA 사용 가능. GPU 사용을 시작합니다. (Device: NVIDIA GeForce RTX 5090)
2026-02-10 13:16:04,911 - INFO - 'Sewer-TAPNEW_flops' 데이터 로드를 시작합니다 (Type: image_folder).
2026-02-10 13:16:04,911 - INFO - '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW' 경로의 데이터를 훈련/테스트셋으로 분할합니다.
2026-02-10 13:16:04,914 - INFO - 총 1692개 데이터를 훈련용 1353개, 테스트용 339개로 분할합니다 (split_seed=42).
2026-02-10 13:16:04,914 - INFO - 데이터셋 클래스: ['abnormal', 'normal'] (총 2개)
2026-02-10 13:16:04,914 - INFO - 훈련 데이터: 1353개, 검증 데이터: 339개, 테스트 데이터: 339개
2026-02-10 13:16:04,914 - INFO - Baseline 모델 'deit_tiny'을(를) 생성합니다 (사전 훈련 가중치: 미사용).
2026-02-10 13:16:05,018 - INFO - timm 모델(deit_tiny)의 Attention.forward를 Pruning 호환성을 위해 Monkey-patching 합니다.
2026-02-10 13:16:05,019 - INFO - ==================================================
2026-02-10 13:16:05,019 - INFO - 모델 파라미터 수:
2026-02-10 13:16:05,019 - INFO -   - 총 파라미터: 5,524,802 개
2026-02-10 13:16:05,019 - INFO -   - 학습 가능한 파라미터: 5,524,802 개
2026-02-10 13:16:05,019 - INFO - '/home/user/workspace/CHOI/sewer_binary_cls_v9/log/Sewer-TAPNEW/iso_flops/fp32/wanda/baseline_deit_tiny_wanda_20260210_013631/pruning_info.yaml'에서 Pruning 희소도(0.8169)를 불러왔습니다.
2026-02-10 13:16:05,019 - INFO - 추론 모드: 훈련된 모델의 Pruning 구조를 재현합니다.
2026-02-10 13:16:05,020 - INFO - Wanda Pruning을 시작합니다.
2026-02-10 13:16:05,020 - INFO - Wanda 중요도 계산을 위해 Calibration을 수행합니다.
2026-02-10 13:16:05,020 - INFO -   - Calibration Samples: 1353 (approx 85 batches)
2026-02-10 13:16:06,621 - INFO - 분류 레이어 'Linear'을(를) Pruning 대상에서 제외합니다.
2026-02-10 13:16:06,621 - INFO - ViT 계열 모델의 모든 qkv 레이어를 Pruning 대상에서 제외합니다.
2026-02-10 13:16:06,762 - INFO - torch-pruning 완료. 모델 구조가 희소도(0.816943359375)에 맞춰 변경되었습니다.
2026-02-10 13:16:06,762 - INFO - ==================================================
2026-02-10 13:16:06,763 - INFO - ==================================================
2026-02-10 13:16:06,763 - INFO - 모델 파라미터 수:
2026-02-10 13:16:06,763 - INFO -   - 총 파라미터: 485,259 개
2026-02-10 13:16:06,763 - INFO -   - 학습 가능한 파라미터: 485,259 개
2026-02-10 13:16:06,763 - INFO - ==================================================
2026-02-10 13:16:06,763 - INFO - Inference 모드를 시작합니다.
2026-02-10 13:16:06,899 - INFO - [Model Load] PyTorch 모델 가중치 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 0.56 MB
2026-02-10 13:16:06,899 - INFO - '/home/user/workspace/CHOI/sewer_binary_cls_v9/log/Sewer-TAPNEW/iso_flops/fp32/wanda/baseline_deit_tiny_wanda_20260210_013631/best_model.pth' 가중치 로드 완료.
2026-02-10 13:16:06,923 - INFO - 연산량 (MACs): 0.0920 GMACs per sample
2026-02-10 13:16:06,923 - INFO - 연산량 (FLOPs): 0.1840 GFLOPs per sample
2026-02-10 13:16:06,923 - INFO - ==================================================
2026-02-10 13:16:06,923 - INFO - INT8 Static Quantization (ONNX)을 적용합니다.
2026-02-10 13:16:07,045 - INFO - Quantization 전처리를 수행합니다 (Fusion, Shape Inference)...
2026-02-10 13:16:07,045 - INFO - Performing symbolic shape inference...
2026-02-10 13:16:07,116 - INFO - Calibration 진행 (512 samples)...
2026-02-10 13:16:07,116 - INFO - Calibration Method: percentile (CalibrationMethod.Percentile)
2026-02-10 13:16:07,117 - INFO - Activation Type: QUInt8 (Extra Options: {'Percentile': 99.99})
2026-02-10 13:16:46,735 - WARNING - Axis 1 is out-of-range for weight 'blocks.0.norm1.weight' with rank 1
2026-02-10 13:16:46,736 - WARNING - Axis 1 is out-of-range for weight 'blocks.0.norm2.weight' with rank 1
2026-02-10 13:16:46,737 - WARNING - Axis 1 is out-of-range for weight 'blocks.1.norm1.weight' with rank 1
2026-02-10 13:16:46,738 - WARNING - Axis 1 is out-of-range for weight 'blocks.1.norm2.weight' with rank 1
2026-02-10 13:16:46,739 - WARNING - Axis 1 is out-of-range for weight 'blocks.2.norm1.weight' with rank 1
2026-02-10 13:16:46,740 - WARNING - Axis 1 is out-of-range for weight 'blocks.2.norm2.weight' with rank 1
2026-02-10 13:16:46,740 - WARNING - Axis 1 is out-of-range for weight 'blocks.3.norm1.weight' with rank 1
2026-02-10 13:16:46,741 - WARNING - Axis 1 is out-of-range for weight 'blocks.3.norm2.weight' with rank 1
2026-02-10 13:16:46,742 - WARNING - Axis 1 is out-of-range for weight 'blocks.4.norm1.weight' with rank 1
2026-02-10 13:16:46,743 - WARNING - Axis 1 is out-of-range for weight 'blocks.4.norm2.weight' with rank 1
2026-02-10 13:16:46,744 - WARNING - Axis 1 is out-of-range for weight 'blocks.5.norm1.weight' with rank 1
2026-02-10 13:16:46,745 - WARNING - Axis 1 is out-of-range for weight 'blocks.5.norm2.weight' with rank 1
2026-02-10 13:16:46,745 - WARNING - Axis 1 is out-of-range for weight 'blocks.6.norm1.weight' with rank 1
2026-02-10 13:16:46,746 - WARNING - Axis 1 is out-of-range for weight 'blocks.6.norm2.weight' with rank 1
2026-02-10 13:16:46,747 - WARNING - Axis 1 is out-of-range for weight 'blocks.7.norm1.weight' with rank 1
2026-02-10 13:16:46,748 - WARNING - Axis 1 is out-of-range for weight 'blocks.7.norm2.weight' with rank 1
2026-02-10 13:16:46,749 - WARNING - Axis 1 is out-of-range for weight 'blocks.8.norm1.weight' with rank 1
2026-02-10 13:16:46,750 - WARNING - Axis 1 is out-of-range for weight 'blocks.8.norm2.weight' with rank 1
2026-02-10 13:16:46,750 - WARNING - Axis 1 is out-of-range for weight 'blocks.9.norm1.weight' with rank 1
2026-02-10 13:16:46,751 - WARNING - Axis 1 is out-of-range for weight 'blocks.9.norm2.weight' with rank 1
2026-02-10 13:16:46,752 - WARNING - Axis 1 is out-of-range for weight 'blocks.10.norm1.weight' with rank 1
2026-02-10 13:16:46,753 - WARNING - Axis 1 is out-of-range for weight 'blocks.10.norm2.weight' with rank 1
2026-02-10 13:16:46,753 - WARNING - Axis 1 is out-of-range for weight 'blocks.11.norm1.weight' with rank 1
2026-02-10 13:16:46,755 - WARNING - Axis 1 is out-of-range for weight 'blocks.11.norm2.weight' with rank 1
2026-02-10 13:16:46,755 - WARNING - Axis 1 is out-of-range for weight 'norm.weight' with rank 1
2026-02-10 13:16:47,382 - INFO - ONNX INT8 모델 저장 완료: log/Sewer-TAPNEW_flops/baseline_deit_tiny_wanda_20260210_131604/best_model_int8.onnx
2026-02-10 13:16:47,544 - INFO - [Model Load] ONNX 모델(INT8) 로드 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 8.25 MB
2026-02-10 13:16:47,544 - INFO - ONNX 런타임의 샘플 당 Forward Pass 시간 측정을 시작합니다...
2026-02-10 13:16:48,013 - INFO - 샘플 당 평균 Forward Pass 시간 (ONNX, CPU): 3.20ms (std: 0.69ms)
2026-02-10 13:16:48,013 - INFO - 샘플 당 평균 FPS (ONNX, CPU): 316.97 FPS (std: 22.27) (1개 샘플 x 100회 반복)
2026-02-10 13:16:48,013 - INFO - [Inference] 추론 중 피크 메모리 - 모델 로드 후 메모리 정리 직후 메모리: 0.56 MB
2026-02-10 13:16:48,013 - INFO - [Total] (INT8) 추론 중 피크 메모리 - 모델 로드 전 청소 직후 메모리: 8.48 MB
2026-02-10 13:16:49,304 - INFO - [Inference (ONNX INT8)] | Test Acc (ONNX): 81.12%
2026-02-10 13:16:49,311 - INFO - [Metrics for 'abnormal' (ONNX)] | Precision: 0.8207 | Recall: 0.7580 | F1: 0.7881
2026-02-10 13:16:49,311 - INFO - [Metrics for 'normal' (ONNX)] | Precision: 0.8041 | Recall: 0.8571 | F1: 0.8298
2026-02-10 13:16:49,440 - INFO - ==================================================
2026-02-10 13:16:49,440 - INFO - 혼동 행렬 저장 완료. 'log/Sewer-TAPNEW_flops/baseline_deit_tiny_wanda_20260210_131604/confusion_matrix_20260210_131604.png' and 'log/Sewer-TAPNEW_flops/baseline_deit_tiny_wanda_20260210_131604/confusion_matrix_20260210_131604.pdf'
